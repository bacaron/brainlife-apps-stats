[{"_id":"62ab109aab3e669780634426","user_id":"2076","projects":[],"admins":["2076"],"github":"zahransa/app-decoding-full-epochs","github_branch":"main","tags":[],"config":{"epo":{"type":"input","file_id":"epo","input_id":"epo"}},"inputs":[{"id":"epo","datatype":"61797fc39538685e5db952b0","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"62ab109aab3e669780634427"}],"outputs":[],"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a452d62f3d3800f130f7d"}],"examples":0},"removed":false,"contributors":[{"name":"SaeedZahran","email":"saeedzahran@hotmail.com","_id":"634a452d62f3d3800f130f7e"}],"create_date":"2022-06-16T11:14:34.432Z","desc":null,"__v":252,"doi":"10.25663/brainlife.app.650","_canedit":true},{"_id":"605b9143edebf0f4fdd2a7cc","stats":{"resources":[],"success_rate":61.62988115449915,"users":4,"runtime_mean":87298.85,"runtime_std":268959.28725431196,"requested":665,"examples":1,"groups":3},"projects":[],"admins":["56","1"],"tags":[],"removed":false,"config":{"microperimetry":{"type":"input","file_id":"microperimetry","input_id":"microperimetry"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"605b9143edebf058a4d2a7cd","id":"microperimetry","datatype":"604976b3ebfe45c4633ae3d2"}],"outputs":[{"datatype_tags":["microperimetryRings"],"output_on_root":false,"archive":true,"_id":"605b9143edebf04a77d2a7ce","id":"output","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null}],"github":"brainlife/app-maiaRings","name":" MAIA microperimetry analysis","user_id":"56","contributors":[{"name":"Daniel Bullock","email":"iisdanbul@gmail.com","_id":"634a3fa562f3d3800f12d112"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a3fa562f3d3800f12d113"}],"create_date":"2021-03-24T19:21:39.729Z","desc":"A brainlife.io app for computing the degree-based ring averages for microperimetry measurements ","__v":3046,"avatar":"https://github.com/brainlife/app-maiaRings/blob/master/exampleImgs/radarPlot.png?raw=true","doi":"10.25663/brainlife.app.493","_canedit":true},{"_id":"63340316db978c79919b4c98","user_id":"2076","projects":[],"admins":["2076"],"name":" app-SSP-projectors-ECG ","github":"zahransa/app-SSP-projectors-ECG","github_branch":"main","tags":[],"config":{"fif":{"type":"input","file_id":"fif","input_id":"fif"},"tmin":{"id":"tmin","type":"number","placeholder":"","advanced":false,"desc":"","default":-0.2,"_order":2,"pid":0.6305192554072859},"tmax":{"id":"tmax","type":"number","placeholder":"","advanced":false,"desc":"","default":0.4,"_order":3,"pid":0.4151301388573636},"n_grad":{"id":"n_grad","type":"number","placeholder":"","advanced":false,"desc":"","default":1,"_order":4,"pid":0.6727479427775854},"n_mag":{"id":"n_mag","type":"number","placeholder":"","advanced":false,"desc":"","default":2,"_order":5,"pid":0.251079867840191},"n_eeg":{"id":"n_eeg","type":"number","placeholder":"","advanced":false,"desc":"","default":2,"_order":6,"pid":0.3045950800707131},"l_freq":{"id":"l_freq","type":"number","placeholder":"","advanced":false,"desc":"","default":1,"_order":7,"pid":0.613699834777784},"h_freq":{"id":"h_freq","type":"number","placeholder":"","advanced":false,"desc":"","default":35,"_order":8,"pid":0.08027306665690437},"average":{"id":"average","type":"boolean","placeholder":"","advanced":false,"desc":"","default":true,"_order":10,"pid":0.06462640289470445},"filter_length":{"id":"filter_length","type":"string","placeholder":"","advanced":false,"desc":"","default":"10s","_order":11,"pid":0.8249541175135344},"avg_ref":{"id":"avg_ref","type":"boolean","placeholder":"","advanced":false,"desc":"","default":false,"_order":12,"pid":0.32696134797270915},"no_proj":{"id":"no_proj","type":"boolean","placeholder":"","advanced":false,"desc":"","default":false,"_order":13,"pid":0.9245779015397572},"event_id":{"id":"event_id","type":"number","placeholder":"","advanced":false,"desc":"","default":999,"_order":14,"pid":0.1837204526648778},"ecg_l_freq":{"id":"ecg_l_freq","type":"number","placeholder":"","advanced":false,"desc":"","default":5,"_order":15,"pid":0.808567373971976},"ecg_h_freq":{"id":"ecg_h_freq","type":"number","placeholder":"","advanced":false,"desc":"","default":35,"_order":16,"pid":0.2622013063091243},"tstart":{"id":"tstart","type":"number","placeholder":"","advanced":false,"desc":"","default":0,"_order":17,"pid":0.20823749165199434},"qrs_threshold":{"id":"qrs_threshold","type":"string","placeholder":"","advanced":false,"desc":"","default":"auto","_order":18,"pid":0.10950083076442119},"filter_method":{"id":"filter_method","type":"string","placeholder":"","advanced":false,"desc":"","default":"fir","_order":19,"pid":0.9587098049196728},"copy":{"id":"copy","type":"boolean","placeholder":"","advanced":false,"desc":"","default":true,"_order":20,"pid":0.2607978144930194},"return_drop_log":{"id":"return_drop_log","type":"boolean","placeholder":"","advanced":false,"desc":"","default":false,"_order":21,"pid":0.5291588540847737},"meg":{"id":"meg","type":"string","placeholder":"","advanced":false,"desc":"","default":"separate","_order":22,"pid":0.8770238357096249}},"inputs":[{"id":"fif","datatype":"6000737faacf9ee51fa691cb","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"63340316db978c79919b4c99"}],"outputs":[{"id":"out_dir","datatype":"6283e7e9d0697cf1eade9bda","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"63340316db978c79919b4c9a"},{"id":"out_figs","datatype":"59666a40b09297d8d8271dfc","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"63370f1bd712a9c4c73b82fa"}],"stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a45ee62f3d3800f13128b"},{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a45ee62f3d3800f13128c"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a45ee62f3d3800f13128d"}],"success_rate":36,"users":1,"groups":1,"runtime_mean":92056.44444444444,"runtime_std":82363.60810470053,"requested":27,"examples":1},"removed":false,"contributors":[{"name":"SaeedZahran","email":"saeedzahran@hotmail.com","_id":"634a45ee62f3d3800f13128e"}],"create_date":"2022-09-28T08:17:26.547Z","desc":null,"__v":20,"doi":"10.25663/brainlife.app.672","_canedit":true},{"_id":"63341bd2db978c79919bff74","user_id":"2076","projects":[],"admins":["2076"],"name":" app-apply-projectors ","github":"zahransa/app-apply-projectors","github_branch":"main","tags":[],"config":{"fif":{"type":"input","file_id":"fif","input_id":"fif"},"projection":{"type":"input","file_id":"projection","input_id":"projection"}},"inputs":[{"id":"fif","datatype":"6000737faacf9ee51fa691cb","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"63341bd2db978c79919bff75"},{"id":"projection","datatype":"6283e7e9d0697cf1eade9bda","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"63341bd2db978c79919bff76"}],"outputs":[{"id":"out_figs","datatype":"59666a40b09297d8d8271dfc","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"63341bd2db978c79919bff77"},{"id":"out_dir","datatype":"6000737faacf9ee51fa691cb","datatype_tags":[],"datatype_tags_pass":"fif","output_on_root":false,"files":null,"archive":true,"_id":"633fe493fa262bbde29f9c77"}],"stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a45ff62f3d3800f1312a6"},{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a45ff62f3d3800f1312a7"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a45ff62f3d3800f1312a8"}],"success_rate":61.111111111111114,"users":2,"groups":1,"runtime_mean":40157,"runtime_std":28853.20615554787,"requested":20,"examples":1},"removed":false,"contributors":[{"name":"SaeedZahran","email":"saeedzahran@hotmail.com","_id":"634a460062f3d3800f1312a9"}],"create_date":"2022-09-28T10:02:58.317Z","desc":null,"__v":18,"doi":"10.25663/brainlife.app.674","_canedit":true},{"_id":"62b9789af3194eded6f719a6","user_id":"2076","projects":[],"admins":["2076"],"name":" app-decoding-time-by-time ","github":"zahransa/app-decoding-time-by-time","github_branch":"main","tags":[],"config":{"epo":{"type":"input","file_id":"epo","input_id":"epo"}},"inputs":[{"id":"epo","datatype":"61797fc39538685e5db952b0","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"62b9789af3194eded6f719a7"}],"outputs":[],"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a455b62f3d3800f131016"}],"examples":0},"removed":false,"contributors":[{"name":"SaeedZahran","email":"saeedzahran@hotmail.com","_id":"634a455b62f3d3800f131017"}],"create_date":"2022-06-27T09:30:02.889Z","desc":null,"__v":193,"doi":"10.25663/brainlife.app.655","_canedit":true},{"_id":"63357d2adb978c7991a2e781","user_id":"2076","projects":[],"admins":["2076"],"name":" app-find-bads-ecg","github":"zahransa/app-find-bads-ecg","github_branch":"master","tags":[],"config":{"fif":{"type":"input","file_id":"fif","input_id":"fif"},"ica":{"type":"input","file_id":"ica","input_id":"ica"},"threshold":{"id":"threshold","type":"string","placeholder":"","advanced":false,"desc":"","default":"","_order":2,"pid":0.956954180965869},"l_freq":{"id":"l_freq","type":"number","placeholder":"","advanced":false,"desc":"","default":null,"_order":3,"pid":0.7269956936262654},"h_freq":{"id":"h_freq","type":"number","placeholder":"","advanced":false,"desc":"","default":null,"_order":4,"pid":0.23087495099054323},"method":{"id":"method","type":"string","placeholder":"","advanced":false,"desc":"","default":"","_order":5,"pid":0.1634517502120969},"reject_by_annotation":{"id":"reject_by_annotation","type":"boolean","placeholder":"","advanced":false,"desc":"","default":false,"_order":6,"pid":0.0034756745129054245},"measure":{"id":"measure","type":"string","placeholder":"","advanced":false,"desc":"","default":"","_order":7,"pid":0.6273539707442592}},"inputs":[{"id":"fif","datatype":"6000737faacf9ee51fa691cb","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"63357d2adb978c7991a2e782"},{"id":"ica","datatype":"6283e821d0697cf1eade9d5c","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"63357d2adb978c7991a2e783"}],"outputs":[{"id":"out_dir","datatype":"6283e821d0697cf1eade9d5c","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"63357d2adb978c7991a2e784"},{"id":"out_figs","datatype":"59666a40b09297d8d8271dfc","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"633a898c6c7d095e9d72708e"}],"stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a461b62f3d3800f1312cb"},{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a461b62f3d3800f1312cc"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a461b62f3d3800f1312cd"}],"success_rate":75,"users":1,"groups":1,"runtime_mean":39573.666666666664,"runtime_std":17993.198795347336,"requested":4,"examples":1},"removed":false,"contributors":[{"name":"SaeedZahran","email":"saeedzahran@hotmail.com","_id":"634a461b62f3d3800f1312ce"},{"name":"Brad Caron","email":null,"_id":"634a461b62f3d3800f1312cf"}],"create_date":"2022-09-29T11:10:34.911Z","desc":null,"__v":17,"doi":"10.25663/brainlife.app.677","_canedit":true},{"_id":"593049d7ff090a00210eff05","name":"3D Tract Surfaces","desc":"app to generate surfaces of each fiber tract","avatar":"https://raw.githubusercontent.com/kitchell/app-generatetractsurfaces/master/tractsurfaces-01.png","github":"kitchell/app-generatetractsurfaces","github_branch":"v3.0","config":{"maskdir":{"type":"input","file_id":"masks","input_id":"masks"},"filetype":{"options":[{"value":"stl","label":".stl","desc":"use .stl file format"},{"value":"ply","label":".ply","desc":"use .ply file format"},{"value":"vtk","label":".vtk","desc":"use .vtk file format"}],"default":"vtk","desc":"output filetype","placeholder":"","type":"enum","id":"filetype","pid":0.8365316447190295,"_order":2,"readonly":false},"smooth_iter":{"id":"smooth_iter","type":"number","placeholder":"number of smoothing iterations","desc":"Choose the number of times you would like each tract to be smoothed. Smoothing makes the surfaces less blocky. ","default":5,"_order":3,"pid":0.23236771646372312,"min":0,"max":10}},"user_id":"43","removed":false,"create_date":"2017-06-01T17:07:35.770Z","outputs":[{"datatype_tags":[],"output_on_root":true,"archive":true,"_id":"593049d7ff090a00210eff03","id":"surfaces","datatype":"59307a08436ee50ffd973278","files":null,"desc":"3D surface for each binary volume input"}],"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"593049d7ff090a00210eff04","id":"masks","datatype":"592dded1436ee50ffd88f5d0","desc":"binary masks are converted to 3D triangular surfaces"}],"admins":["43"],"__v":14318,"_rate":5,"tags":["postprocessing"],"contributors":[{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a30ab62f3d3800f11650f"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a30ab62f3d3800f116510"},{"name":"Franco Pestilli","email":null,"_id":"634a30ab62f3d3800f116511"}],"projects":[],"references":[],"stats":{"stars":0,"requested":9423,"users":13,"success_rate":98.24561403508771,"serviceinfo":{"_id":"5d729e1f78356a109788b30b","counts":{"_id":"5e5c687a87cac73d90ab1b9c","failed":162,"finished":9184,"removed":9251,"requested":9420,"running":9303,"running_sync":0,"stop_requested":13},"success_rate":98.26663813396105,"users":10,"readme_status":"ok","runtime_mean":325577.4,"runtime_std":313812.4076364094,"service":"kitchell/app-generatetractsurfaces","__v":0},"gitinfo":{"desc":"app to generate surfaces of each fiber tract","tags":["postprocessing"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":325577.4,"runtime_std":313812.4076364094,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a30ab62f3d3800f11650e"}],"examples":0,"groups":4},"doi":"10.25663/brainlife.app.108","_canedit":true},{"_id":"5fc668231828bc57c651fdb1","stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3e3162f3d3800f12ba61"}],"success_rate":45.04504504504504,"users":6,"runtime_mean":53381357.24,"runtime_std":16689720.004323015,"requested":138,"examples":1,"groups":4},"projects":["5ca37dee65ade200e89d64b5","5fdd2da657aacd5e682f5145"],"admins":["41","146","1"],"tags":[],"removed":false,"config":{"t1":{"type":"input","file_id":"t1","input_id":"t1"},"t2":{"type":"input","file_id":"t2","input_id":"t2"},"bold":{"type":"input","file_id":"bold","input_id":"fmri"},"events":{"type":"input","file_id":"events","input_id":"fmri"},"events_json":{"type":"input","file_id":"events_json","input_id":"fmri"},"sbref":{"type":"input","file_id":"sbref","input_id":"fmri"},"sbref_json":{"type":"input","file_id":"sbref_json","input_id":"fmri"},"physio":{"type":"input","file_id":"physio","input_id":"fmri"},"physio_json":{"type":"input","file_id":"physio_json","input_id":"fmri"},"phasediff":{"type":"input","file_id":"phasediff","input_id":"fmap"},"phasediff_json":{"type":"input","file_id":"phasediff_json","input_id":"fmap"},"magnitude":{"type":"input","file_id":"magnitude","input_id":"fmap"},"magnitude_json":{"type":"input","file_id":"magnitude_json","input_id":"fmap"},"magnitude1":{"type":"input","file_id":"magnitude1","input_id":"fmap"},"magnitude1_json":{"type":"input","file_id":"magnitude1_json","input_id":"fmap"},"magnitude2":{"type":"input","file_id":"magnitude2","input_id":"fmap"},"magnitude2_json":{"type":"input","file_id":"magnitude2_json","input_id":"fmap"},"fieldmap":{"type":"input","file_id":"fieldmap","input_id":"fmap"},"fieldmap_json":{"type":"input","file_id":"fieldmap_json","input_id":"fmap"},"phase1":{"type":"input","file_id":"phase1","input_id":"fmap"},"phase1_json":{"type":"input","file_id":"phase1_json","input_id":"fmap"},"phase2":{"type":"input","file_id":"phase2","input_id":"fmap"},"phase2_json":{"type":"input","file_id":"phase2_json","input_id":"fmap"},"epi1":{"type":"input","file_id":"epi1","input_id":"fmap"},"epi1_json":{"type":"input","file_id":"epi1_json","input_id":"fmap"},"epi2":{"type":"input","file_id":"epi2","input_id":"fmap"},"epi2_json":{"type":"input","file_id":"epi2_json","input_id":"fmap"},"stage":{"id":"stage","type":"enum","placeholder":"","advanced":false,"desc":"Begin from a given stage, continuing through. [only PreFreeSurfer at the moment]","default":"PreFreeSurfer","_order":2,"pid":0.9260104196556287,"options":[{"desc":"","label":"PreFreeSurfer","value":"PreFreeSurfer"},{"desc":"","label":"FreeSurfer","value":"FreeSurfer"},{"desc":"","label":"PostFreeSurfer","value":"PostFreeSurfer"},{"desc":"","label":"FMRIVolume","value":"FMRIVolume"},{"desc":"","label":"FMRISurface","value":"FMRISurface"},{"desc":"","label":"DCANBOLDProcessing","value":"DCANBOLDProcessing"},{"desc":"","label":"ExecutiveSummary","value":"ExecutiveSummary"},{"desc":"","label":"CustomClean","value":"CustomClean"}],"readonly":true}},"inputs":[{"id":"t1","desc":"T1 image","datatype":"58c33bcee13a50849b25879a","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5fc668231828bc8d0d51fdb2"},{"id":"t2","desc":"T2 image","datatype":"594c0325fa1d2e5a1f0beda5","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"624754055d8ab5d5f066ec89"},{"id":"fmri","desc":"fmri data to preprocess","datatype":"59b685a08e5d38b0b331ddc5","datatype_tags":["!preprocessed"],"optional":true,"multi":true,"advanced":false,"_id":"6076b56ee8c7641fb4e4f1e5"},{"id":"fmap","desc":"fieldmap","datatype":"5c390505f9109beac42b00df","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"607dab7a98cade76dd9e1611"}],"outputs":[{"id":"output","datatype":"61e8834d33cb3deb49960f3c","datatype_tags":[],"datatype_tags_pass":"fmri","output_on_root":false,"files":null,"archive":true,"_id":"5fc668231828bc23f151fdb3"}],"github_branch":"v0.0.3","github":"brainlife/app-abcd-hcp-pipeline","name":"ABCD HCP Pipeline","user_id":"146","contributors":[{"name":"Giulia Bertò","email":null,"_id":"634a3e3262f3d3800f12ba62"}],"create_date":"2020-12-01T15:58:27.417Z","desc":"ABCD-BIDS pipeline used to process the BIDS input data (DCAN Labs' modified HCP pipeline)","__v":3865,"doi":"10.25663/brainlife.app.452","_canedit":true},{"_id":"5a0def2eb2f8e6004a894f3b","name":"ACPC alignment via ART","desc":"This app uses the Automatic Registration Toolbox (ART) to perform ACPC alignment of the T1 image. See https://www.nitrc.org/projects/art/ for more information.","avatar":"https://brainlife.io/images/app-logos/app-acpcalign.png","github":"brainlife/app-acpcART","github_branch":"1.4","config":{"t1":{"type":"input","file_id":"t1","input_id":"0"},"crop":{"type":"boolean","placeholder":"","desc":"Remove neck and lower head using robustfov (fsl)","default":true,"id":"crop","pid":0.14380902677154817,"_order":2},"reorient":{"type":"boolean","placeholder":"","desc":"Assist with future registration steps and makes the views in FSLView more \"standard\" (fslreorient2std)","default":true,"id":"reorient","pid":0.7398934033638089,"_order":3}},"user_id":"43","create_date":"2017-11-16T20:03:58.889Z","removed":false,"_rate":4,"outputs":[{"datatype_tags":["acpc_aligned"],"output_on_root":true,"archive":true,"_id":"5a0def2eb2f8e6004a894f3c","id":"0","datatype":"58c33bcee13a50849b25879a","files":null,"datatype_tags_pass":"0"}],"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5a0def2eb2f8e6004a894f3d","id":"0","datatype":"58c33bcee13a50849b25879a"}],"contributors":[{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a318462f3d3800f1167b0"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a318462f3d3800f1167b1"},{"name":"Franco Pestilli","email":null,"_id":"634a318462f3d3800f1167b2"}],"tags":["anatomy-preprocessing"],"admins":["16","41","146","43","1"],"projects":[],"__v":14283,"references":[],"stats":{"stars":0,"requested":18714,"users":56,"success_rate":82.7434162841266,"serviceinfo":{"_id":"5d729e1e78356a109788b231","counts":{"_id":"5e5c688e87cac7fdc3ab1bb6","failed":577,"finished":3221,"removed":5480,"requested":5782,"running":3839,"running_sync":0,"stop_requested":69},"success_rate":84.8077935755661,"users":21,"readme_status":"too short","runtime_mean":319906.39,"runtime_std":778869.994165148,"service":"brainlife/app-acpcART","__v":0},"gitinfo":{"desc":"This app uses the Automatic Registration Toolbox (ART) to perform ACPC alignment of the T1 image. See https://www.nitrc.org/projects/art/ for more information.","tags":["anatomy-preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":83309.39,"runtime_std":296033.6285060836,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a318362f3d3800f1167af"}],"examples":2,"groups":53},"doi":"10.25663/bl.app.16","deprecated_by":"5b96d5ed059cf9002719250b","_canedit":true},{"_id":"619daaba09959fabbdc0517f","user_id":"386","projects":[],"admins":["386"],"name":"AFNI pRF","github":"anibalsolon/bl-app-prfmodel","github_branch":"main","tags":[],"config":{"bold":{"type":"input","file_id":"bold","input_id":"fmri"},"events":{"type":"input","file_id":"events","input_id":"fmri"},"events_json":{"type":"input","file_id":"events_json","input_id":"fmri"},"sbref":{"type":"input","file_id":"sbref","input_id":"fmri"},"sbref_json":{"type":"input","file_id":"sbref_json","input_id":"fmri"},"physio":{"type":"input","file_id":"physio","input_id":"fmri"},"physio_json":{"type":"input","file_id":"physio_json","input_id":"fmri"},"stim":{"type":"input","file_id":"stim","input_id":"stim"},"mask":{"type":"input","file_id":"mask","input_id":"mask"}},"inputs":[{"id":"fmri","datatype":"59b685a08e5d38b0b331ddc5","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"619daaba09959fabbdc05180"},{"id":"stim","desc":"","datatype":"5afc7c555858d874a40c6dda","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"619daaba09959fabbdc05181"},{"id":"mask","datatype":"5a281aee2c214c9ba83ce620","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"619e640109959fabbdc2113a"}],"outputs":[{"id":"output","datatype":"5d9d18d8e30ae43bb0612715","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"619daaba09959fabbdc05182"}],"stats":{"resources":[],"examples":0,"success_rate":0,"users":1,"requested":9,"groups":2},"removed":false,"contributors":[{"name":"Anibal Sólon","email":"anibalsolon@gmail.com","_id":"634a435b62f3d3800f12ff69"}],"create_date":"2021-11-24T03:00:10.790Z","desc":null,"__v":1296,"doi":"10.25663/brainlife.app.598","_canedit":true},{"_id":"59dff93521ff360021b24ebf","project":null,"name":"AFQ Tract Classification","desc":"This service uses Automated fiber quantification AFQ and fe structure output from LiFE to identify major tract segments and quantify tissue properties along their trajectories. You can choose to have the zero weighted fibers (as determined by LiFE) removed before or after AFQ is applied. useinterhemisphericsplit is a variable from AFQ, which if set to true will cut fibers crossing between hemispheres with a midsaggital plane below z=-10. This is to get rid of CST fibers that appear to cross at the level of the brainstem. For more information about AFQ see https://github.com/yeatmanlab/AFQ/wiki","avatar":"http://www.brainlife.io/images/app-logos/wmc.png","github":"brainlife/app-tractclassification","github_branch":"1.2","config":{"track":{"type":"input","file_id":"track","input_id":"track"},"dtiinit":{"type":"input","file_id":"output","input_id":"dtiinit"},"useinterhemisphericsplit":{"default":false,"desc":"","placeholder":"","type":"boolean","id":"useinterhemisphericsplit","pid":0.6274548719102251,"_order":2}},"user_id":"43","create_date":"2017-10-12T23:22:29.220Z","removed":false,"_rate":0,"outputs":[{"datatype_tags":["afq"],"output_on_root":true,"archive":true,"_id":"59dff93521ff360021b24ec0","id":"wmc","datatype":"58f10a90436ee50ffd9063c5","files":null,"datatype_tags_pass":"track"}],"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"59dff93521ff360021b24ec2","id":"track","datatype":"5907d922436ee50ffde9c549"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"59dff93521ff360021b24ec1","id":"dtiinit","datatype":"58cb234be13a50849b25882f"}],"tags":["analysis"],"admins":["16","41","146","43","1"],"__v":14285,"contributors":[{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a314e62f3d3800f1166a3"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a314e62f3d3800f1166a4"},{"name":"Franco Pestilli","email":null,"_id":"634a314e62f3d3800f1166a5"},{"name":"Steven O'Riley","email":null,"_id":"634a314e62f3d3800f1166a6"}],"projects":[],"references":[],"stats":{"stars":0,"requested":3422,"users":32,"success_rate":49.98354721948009,"serviceinfo":{"_id":"5d729e1e78356a109788b21b","counts":{"_id":"5e5c688987cac740d4ab1bb0","failed":352,"finished":255,"removed":787,"requested":809,"running":280,"running_sync":0,"stop_requested":22},"success_rate":42.00988467874794,"users":21,"readme_status":"too short","runtime_mean":4841074.02,"runtime_std":6487919.963962646,"service":"brainlife/app-tractclassification","__v":0},"gitinfo":{"desc":"This service uses Automated fiber quantification AFQ and fe structure output from LiFE to identify major tract segments and quantify tissue properties along their trajectories. You can choose to have the zero weighted fibers (as determined by LiFE) removed before or after AFQ is applied. useinterhemisphericsplit is a variable from AFQ, which if set to true will cut fibers crossing between hemispheres with a midsaggital plane below z=-10. This is to get rid of CST fibers that appear to cross at the level of the brainstem. For more information about AFQ see https://github.com/yeatmanlab/AFQ/wiki","tags":["analysis"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null},{"name":"Steven O'Riley","email":null}]},"runtime_mean":506468.95,"runtime_std":549388.260618688,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a314d62f3d3800f1166a2"}],"examples":0,"groups":26},"doi":"10.25663/bl.app.13","deprecated_by":"5cf8256e94cb4c02b711c745","_canedit":true},{"_id":"5cf8256e94cb4c02b711c745","projects":[],"admins":["16","41","146","43","1"],"tags":["analysis"],"removed":false,"name":"AFQ Tract Classification","desc":"This service uses Automated fiber quantification AFQ and fe structure output from LiFE to identify major tract segments and quantify tissue properties along their trajectories. You can choose to have the zero weighted fibers (as determined by LiFE) removed before or after AFQ is applied. useinterhemisphericsplit is a variable from AFQ, which if set to true will cut fibers crossing between hemispheres with a midsaggital plane below z=-10. This is to get rid of CST fibers that appear to cross at the level of the brainstem. For more information about AFQ see https://github.com/yeatmanlab/AFQ/wiki","avatar":"http://www.brainlife.io/images/app-logos/wmc.png","github":"brainlife/app-tractclassification","github_branch":"1.4","config":{"track":{"type":"input","file_id":"track","input_id":"track"},"dtiinit":{"type":"input","file_id":"output","input_id":"dtiinit"},"useinterhemisphericsplit":{"default":false,"desc":"","placeholder":"","type":"boolean","id":"useinterhemisphericsplit","pid":0.037839631340613966,"_order":2}},"user_id":"1","outputs":[{"datatype_tags":["afq"],"output_on_root":false,"archive":true,"_id":"59dff93521ff360021b24ec0","id":"wmc","datatype":"5cc1d64c44947d8aea6b2d8b","files":null,"datatype_tags_pass":"track"}],"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"59dff93521ff360021b24ec2","id":"track","datatype":"5907d922436ee50ffde9c549"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"59dff93521ff360021b24ec1","id":"dtiinit","datatype":"58cb234be13a50849b25882f"}],"__v":7848,"contributors":[{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a368962f3d3800f11cf1f"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a368962f3d3800f11cf20"},{"name":"Franco Pestilli","email":null,"_id":"634a368962f3d3800f11cf21"},{"name":"Steven O'Riley","email":null,"_id":"634a368962f3d3800f11cf22"}],"stats":{"stars":0,"requested":3422,"users":32,"success_rate":49.98354721948009,"serviceinfo":{"_id":"5d729e1e78356a109788b21b","counts":{"_id":"5e5c3e0587cac70210ab141c","failed":352,"finished":255,"removed":787,"requested":809,"running":280,"running_sync":0,"stop_requested":22},"success_rate":42.00988467874794,"users":21,"readme_status":"too short","runtime_mean":4841074.02,"runtime_std":6487919.963962646,"service":"brainlife/app-tractclassification","__v":0},"gitinfo":{"desc":"This service uses Automated fiber quantification AFQ and fe structure output from LiFE to identify major tract segments and quantify tissue properties along their trajectories. You can choose to have the zero weighted fibers (as determined by LiFE) removed before or after AFQ is applied. useinterhemisphericsplit is a variable from AFQ, which if set to true will cut fibers crossing between hemispheres with a midsaggital plane below z=-10. This is to get rid of CST fibers that appear to cross at the level of the brainstem. For more information about AFQ see https://github.com/yeatmanlab/AFQ/wiki","tags":["analysis"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null},{"name":"Steven O'Riley","email":null}]},"runtime_mean":506468.95,"runtime_std":549388.260618688,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a368862f3d3800f11cf1e"}],"examples":0,"groups":26},"create_date":"2019-06-05T20:26:22.330Z","doi":"10.25663/brainlife.app.207","_canedit":true},{"_id":"58f10d01436ee50ffd906e68","user_id":"1","create_date":"2017-02-18T01:05:51.509Z","name":"AFQ Tract Classification with LiFE","desc":"This service uses Automated fiber quantification AFQ and fe structure output from LiFE to identify major tract segments and quantify tissue properties along their trajectories. You can choose to have the zero weighted fibers (as determined by LiFE) removed before or after AFQ is applied. useinterhemisphericsplit is a variable from AFQ, which if set to true will cut fibers crossing between hemispheres with a midsaggital plane below z=-10. This is to get rid of CST fibers that appear to cross at the level of the brainstem. For more information about AFQ see https://github.com/yeatmanlab/AFQ/wiki","github":"brainlife/app-tractclassification","admins":["16","41","146","43","1"],"config":{"fe":{"type":"input","file_id":"fe","input_id":"fe"},"dtiinit":{"type":"input","file_id":"output","input_id":"dtiinit"},"useinterhemisphericsplit":{"default":false,"type":"boolean","desc":"Cut fibers crossing between hemispheres with a midsaggital plane below z=-10. This is to get rid of CST (corticospinal tract) fibers that appear to cross at the level of the brainstem","id":"useinterhemisphericsplit","pid":0.41871807223125823,"_order":2},"remove_zero_weighted_fibers":{"desc":"Select when you would like the zero weighted fibers removed","type":"enum","default":"before","options":[{"value":"before","label":"Before","desc":"Remove the zero weighted fibers before performing AFQ"},{"value":"after","label":"After","desc":"Remove the zero weighted fibers after performing AFQ"}],"id":"remove_zero_weighted_fibers","pid":0.08777860579343866,"_order":3}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"58f10f21af44920021b9e09e","id":"fe","datatype":"58d15eaee13a50849b258844"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"58f10f21af44920021b9e09d","id":"dtiinit","datatype":"58cb234be13a50849b25882f"}],"outputs":[{"datatype_tags":["afq","life"],"output_on_root":true,"archive":true,"_id":"58f10f21af44920021b9e09f","id":"output","datatype":"58f10a90436ee50ffd9063c5","files":null,"datatype_tags_pass":"fe"}],"__v":14333,"tags":["analysis"],"_rate":5,"removed":false,"github_branch":"1.2","avatar":"https://brainlife.io/images/app-logos/wmc.png","contributors":[{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a307c62f3d3800f1161e1"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a307c62f3d3800f1161e2"},{"name":"Franco Pestilli","email":null,"_id":"634a307c62f3d3800f1161e3"},{"name":"Steven O'Riley","email":null,"_id":"634a307c62f3d3800f1161e4"}],"projects":[],"references":[],"stats":{"stars":0,"requested":3422,"users":32,"success_rate":49.98354721948009,"serviceinfo":{"_id":"5d729e1e78356a109788b21b","counts":{"_id":"5e5c687587cac76bafab1b97","failed":352,"finished":255,"removed":787,"requested":809,"running":280,"running_sync":0,"stop_requested":22},"success_rate":42.00988467874794,"users":21,"readme_status":"too short","runtime_mean":4841074.02,"runtime_std":6487919.963962646,"service":"brainlife/app-tractclassification","__v":0},"gitinfo":{"desc":"This service uses Automated fiber quantification AFQ and fe structure output from LiFE to identify major tract segments and quantify tissue properties along their trajectories. You can choose to have the zero weighted fibers (as determined by LiFE) removed before or after AFQ is applied. useinterhemisphericsplit is a variable from AFQ, which if set to true will cut fibers crossing between hemispheres with a midsaggital plane below z=-10. This is to get rid of CST fibers that appear to cross at the level of the brainstem. For more information about AFQ see https://github.com/yeatmanlab/AFQ/wiki","tags":["analysis"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null},{"name":"Steven O'Riley","email":null}]},"runtime_mean":506468.95,"runtime_std":549388.260618688,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a307b62f3d3800f1161e0"}],"examples":0,"groups":26},"doi":"10.25663/bl.app.56","deprecated_by":"5cf8252694cb4c02b711c739","_canedit":true},{"_id":"5cf8252694cb4c02b711c739","projects":[],"admins":["16","41","146","43","1"],"tags":["analysis"],"removed":false,"user_id":"1","name":"AFQ Tract Classification with LiFE","desc":"This service uses Automated fiber quantification AFQ and fe structure output from LiFE to identify major tract segments and quantify tissue properties along their trajectories. You can choose to have the zero weighted fibers (as determined by LiFE) removed before or after AFQ is applied. useinterhemisphericsplit is a variable from AFQ, which if set to true will cut fibers crossing between hemispheres with a midsaggital plane below z=-10. This is to get rid of CST fibers that appear to cross at the level of the brainstem. For more information about AFQ see https://github.com/yeatmanlab/AFQ/wiki","github":"brainlife/app-tractclassification","config":{"fe":{"type":"input","file_id":"fe","input_id":"fe"},"dtiinit":{"type":"input","file_id":"output","input_id":"dtiinit"},"useinterhemisphericsplit":{"default":false,"type":"boolean","desc":"Cut fibers crossing between hemispheres with a midsaggital plane below z=-10. This is to get rid of CST (corticospinal tract) fibers that appear to cross at the level of the brainstem","id":"useinterhemisphericsplit","pid":0.3569725707246043,"_order":2},"remove_zero_weighted_fibers":{"desc":"Select when you would like the zero weighted fibers removed","type":"enum","default":"before","options":[{"value":"before","label":"Before","desc":"Remove the zero weighted fibers before performing AFQ"},{"value":"after","label":"After","desc":"Remove the zero weighted fibers after performing AFQ"}],"id":"remove_zero_weighted_fibers","pid":0.7669382496487827,"_order":3}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"58f10f21af44920021b9e09e","id":"fe","datatype":"58d15eaee13a50849b258844"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"58f10f21af44920021b9e09d","id":"dtiinit","datatype":"58cb234be13a50849b25882f"}],"outputs":[{"datatype_tags":["afq","life"],"output_on_root":false,"archive":true,"_id":"58f10f21af44920021b9e09f","id":"wmc","datatype":"5cc1d64c44947d8aea6b2d8b","files":null,"datatype_tags_pass":"fe"}],"__v":7850,"github_branch":"1.4","avatar":"https://brainlife.io/images/app-logos/wmc.png","contributors":[{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a368062f3d3800f11ced3"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a368062f3d3800f11ced4"},{"name":"Franco Pestilli","email":null,"_id":"634a368062f3d3800f11ced5"},{"name":"Steven O'Riley","email":null,"_id":"634a368062f3d3800f11ced6"}],"stats":{"stars":0,"requested":3422,"users":32,"success_rate":49.98354721948009,"serviceinfo":{"_id":"5d729e1e78356a109788b21b","counts":{"_id":"5e5c3e0487cac7a1ccab141b","failed":352,"finished":255,"removed":787,"requested":809,"running":280,"running_sync":0,"stop_requested":22},"success_rate":42.00988467874794,"users":21,"readme_status":"too short","runtime_mean":4841074.02,"runtime_std":6487919.963962646,"service":"brainlife/app-tractclassification","__v":0},"gitinfo":{"desc":"This service uses Automated fiber quantification AFQ and fe structure output from LiFE to identify major tract segments and quantify tissue properties along their trajectories. You can choose to have the zero weighted fibers (as determined by LiFE) removed before or after AFQ is applied. useinterhemisphericsplit is a variable from AFQ, which if set to true will cut fibers crossing between hemispheres with a midsaggital plane below z=-10. This is to get rid of CST fibers that appear to cross at the level of the brainstem. For more information about AFQ see https://github.com/yeatmanlab/AFQ/wiki","tags":["analysis"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null},{"name":"Steven O'Riley","email":null}]},"runtime_mean":506468.95,"runtime_std":549388.260618688,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a367f62f3d3800f11ced2"}],"examples":2,"groups":26},"create_date":"2019-06-05T20:25:10.787Z","doi":"10.25663/brainlife.app.206","_canedit":true},{"_id":"5adbe476da9f040027366d14","stats":{"stars":0,"requested":262,"users":3,"success_rate":86.56126482213439,"serviceinfo":{"_id":"5d729e1f78356a109788b28b","counts":{"_id":"5e5c3d9987cac72a8bab13a8","failed":1,"finished":4,"removed":4,"requested":6,"running":5,"running_sync":0,"stop_requested":0},"success_rate":80,"users":1,"readme_status":"too short","runtime_mean":1842386.25,"runtime_std":68179.52391068377,"service":"giulia-berto/app-ants-transformation","__v":0},"gitinfo":{"desc":"Compute ANTs transformation between two subjects based on T1 and FA volumes.","tags":[],"stats":{"stars":0},"contributors":[{"name":"Giulia Bertò","email":null}]},"runtime_mean":3510126.06,"runtime_std":4853633.012268294,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a328762f3d3800f1176e7"}],"examples":0,"groups":3},"name":"ANTs tensor registration based on FA","desc":"FA-based non linear ANTs registration of the tensor to the FMRIB58_FA_1mm.nii.gz template or the IITmean_FA template.","citation":null,"github":"giulia-berto/app-ants-FA-registration","github_branch":"1.2","config":{"fa_moving":{"type":"input","file_id":"fa","input_id":"0"},"md_moving":{"type":"input","file_id":"md","input_id":"0"},"rd_moving":{"type":"input","file_id":"rd","input_id":"0"},"ad_moving":{"type":"input","file_id":"ad","input_id":"0"},"fa_template":{"id":"fa_template","type":"enum","placeholder":"","advanced":false,"desc":"FA template","default":"FMRIB58_FA_1mm","_order":2,"pid":0.6652543277688558,"options":[{"desc":"","label":"FMRIB58_FA_1mm","value":"FMRIB58_FA_1mm"},{"desc":"","label":"IITmean_FA","value":"IITmean_FA"}]}},"user_id":"146","create_date":"2018-04-22T01:25:10.450Z","removed":false,"outputs":[{"id":"warp","desc":"non linear warp (warp and inverse-warp)","datatype":"5bbfb28071454db2a890fbce","datatype_tags":["fa_warping"],"output_on_root":false,"files":{"warp":"output.var-t1w_warp.nii.gz","inverse-warp":"output.var-t1w_inverse-warp.nii.gz"},"archive":true,"_id":"5adbe476da9f040027366d15"},{"id":"tensor_aligned","desc":"aligned tensor","datatype":"5a79df48d071a1753f1d661b","datatype_tags":[],"datatype_tags_pass":"0","output_on_root":false,"files":null,"archive":true,"_id":"5ef46027c67a0d6c6a29adb4"}],"inputs":[{"id":"0","desc":"tensor to be aligned to the template","datatype":"5a79df48d071a1753f1d661b","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5adbe476da9f040027366d18"}],"contributors":[{"name":"Giulia Bertò","email":null,"_id":"634a328762f3d3800f1176e8"}],"tags":["alignment"],"references":[],"admins":["146"],"projects":[],"__v":13989,"doi":"10.25663/brainlife.app.118","desc_override":"","_canedit":true},{"_id":"5ce719f440363b003536782e","stats":{"stars":0,"requested":388,"users":7,"success_rate":78.41269841269842,"serviceinfo":{"_id":"5d729e1e78356a109788b205","counts":{"_id":"5e5c3e0187cac7d0f4ab1417","failed":64,"finished":191,"removed":174,"requested":261,"running":241,"running_sync":0,"stop_requested":0},"success_rate":74.90196078431373,"users":1,"readme_status":"no README.md","runtime_mean":1325627.87,"runtime_std":2061983.1164898155,"service":"giulia-berto/app-ants-mni","__v":0},"gitinfo":{"desc":"ANTs transformation based on T1 and tractogram registration in MNI space","tags":[],"stats":{"stars":0},"contributors":[{"name":"Giulia Bertò","email":null}]},"runtime_mean":1821983.73,"runtime_std":2410794.8762443513,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a366262f3d3800f11cdad"}],"examples":2,"groups":11},"projects":[],"admins":["146"],"tags":["alignment"],"removed":false,"config":{"track":{"type":"input","file_id":"track","input_id":"0"},"t1":{"type":"input","file_id":"t1","input_id":"1"},"mask":{"type":"input","file_id":"mask","input_id":"2"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ce719f440363b0035367831","id":"0","datatype":"5907d922436ee50ffde9c549","desc":"Tractogram to register"},{"datatype_tags":["acpc_aligned"],"optional":false,"multi":false,"advanced":false,"_id":"5ce719f440363b0035367830","id":"1","datatype":"58c33bcee13a50849b25879a","desc":"T1 to use for the transformation"},{"datatype_tags":["acpc_aligned"],"optional":true,"multi":false,"advanced":false,"_id":"5ce719f440363b003536782f","id":"2","datatype":"5a281aee2c214c9ba83ce620","desc":"Brain mask (if not provided, the BET algorithm will be used)"}],"outputs":[{"datatype_tags":["mni_space"],"output_on_root":false,"archive":true,"_id":"5ce719f440363b0035367832","id":"track_aligned","datatype":"5907d922436ee50ffde9c549","datatype_tags_pass":"0","files":null,"desc":"Tractogram registered in MNI space"},{"datatype_tags":["t1_warping_mni152"],"output_on_root":false,"archive":true,"_id":"5e56b14f0f7fa645243cadde","id":"warps","datatype":"5bbfb28071454db2a890fbce","datatype_tags_pass":null,"files":null,"desc":"warp and inverse-warp used for the registration"},{"datatype_tags":["mni_space"],"output_on_root":false,"archive":true,"_id":"5f7f25e0268f7615b52a627a","id":"t1_aligned","datatype":"58c33bcee13a50849b25879a","datatype_tags_pass":"1","files":null,"desc":"T1 registered in MNI space"}],"github_branch":"2.0","github":"giulia-berto/app-ants-mni","name":"ANTs tractogram registration in MNI space","user_id":"146","contributors":[{"name":"Giulia Bertò","email":null,"_id":"634a366362f3d3800f11cdae"}],"create_date":"2019-05-23T22:08:52.761Z","desc":"ANTs transformation and tractogram registration in MNI space, using as the reference template the MNI152 T1 at 1.25 mm. WARNING: all the given inputs should be in the same anatomical space.","doi":"10.25663/brainlife.app.202","__v":7958,"desc_override":"ANTs transformation and tractogram registration in MNI space, using as the reference template the MNI152 T1 at 1.25 mm. WARNING: all the given inputs should be in the same anatomical space.","_canedit":true},{"_id":"5af0680d8b3100002bcc2b24","doi":"10.25663/bl.app.27","stats":{"stars":0,"requested":27,"users":1,"success_rate":61.53846153846154,"serviceinfo":{"_id":"5d729e1f78356a109788b359","counts":{"_id":"5e5c3d9e87cac722efab13ae","failed":5,"finished":8,"removed":12,"requested":27,"running":14,"running_sync":0,"stop_requested":1},"success_rate":61.53846153846154,"users":1,"readme_status":"too short","runtime_mean":3008707.75,"runtime_std":2967110.560963298,"service":"giulia-berto/app-ants-transformation-registration","__v":0},"gitinfo":{"desc":"Compute ANTs transformation between two subjects based on T1 or FA volumes and apply the transformation to the AFQ segmentation provided. ","tags":[],"stats":{"stars":0},"contributors":[{"name":"Giulia Bertò","email":null}]},"runtime_mean":3008707.75,"runtime_std":2967110.560963298,"resources":[],"examples":0,"groups":1},"name":"ANTs transformation and wmc registration with FA","desc":"Compute ANTs transformation between two subjects based on T1 or FA volumes and apply the transformation to the AFQ segmentation provided. ","citation":null,"avatar":null,"github":"giulia-berto/app-ants-transformation-registration","github_branch":null,"config":{"fa_moving":{"type":"input","file_id":"fa","input_id":"0"},"t1_moving":{"type":"input","file_id":"t1","input_id":"1"},"segmentation":{"type":"input","file_id":"output","input_id":"2"},"fa_static":{"type":"input","file_id":"fa","input_id":"3"},"tract1":{"type":"number","placeholder":"","desc":"Tract 1","default":null,"min":0,"max":20,"optional":true,"id":"tract1","pid":0.9182441623622897,"_order":2},"tract2":{"type":"number","placeholder":"","desc":"Tract 2","default":null,"optional":true,"min":0,"max":20,"id":"tract2","pid":0.9673331908688441,"_order":3},"tract3":{"type":"number","placeholder":"","desc":"Tract 3","default":null,"optional":true,"min":0,"max":20,"id":"tract3","pid":0.6436872903918631,"_order":4},"tract4":{"type":"number","placeholder":"","desc":"Tract 4","default":null,"optional":true,"min":0,"max":20,"id":"tract4","pid":0.6789349339835014,"_order":5}},"user_id":"146","create_date":"2018-05-07T14:51:57.044Z","removed":false,"outputs":[{"datatype_tags":["ants_fa_aligned"],"_id":"5af0680d8b3100002bcc2b25","id":"4","datatype":"58f10a90436ee50ffd9063c5","datatype_tags_pass":null,"files":null,"output_on_root":true,"archive":true}],"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"_id":"5af0680d8b3100002bcc2b29","id":"0","datatype":"5a79df48d071a1753f1d661b","desc":"FA of moving subject"},{"datatype_tags":[],"optional":false,"multi":false,"_id":"5af0680d8b3100002bcc2b28","id":"1","datatype":"58c33bcee13a50849b25879a","desc":"T1 of moving subject"},{"datatype_tags":[],"optional":false,"multi":false,"_id":"5af0680d8b3100002bcc2b27","id":"2","datatype":"58f10a90436ee50ffd9063c5","desc":"Segmentation of moving subject"},{"datatype_tags":[],"optional":false,"multi":false,"_id":"5af0680d8b3100002bcc2b26","id":"3","datatype":"5a79df48d071a1753f1d661b","desc":"FA of static subject"}],"contributors":[{"name":"Giulia Bertò","email":null,"_id":"634a32bd62f3d3800f117a83"}],"tags":[],"references":[],"admins":["146"],"projects":["5a78c177340591004da75e6f"],"__v":13633,"_canedit":true},{"_id":"5add38f4da9f040027366d26","stats":{"stars":0,"requested":27,"users":1,"success_rate":61.53846153846154,"serviceinfo":{"_id":"5d729e1f78356a109788b359","counts":{"_id":"5e5c3d9a87cac729c5ab13a9","failed":5,"finished":8,"removed":12,"requested":27,"running":14,"running_sync":0,"stop_requested":1},"success_rate":61.53846153846154,"users":1,"readme_status":"too short","runtime_mean":3008707.75,"runtime_std":2967110.560963298,"service":"giulia-berto/app-ants-transformation-registration","__v":0},"gitinfo":{"desc":"Compute ANTs transformation between two subjects based on T1 or FA volumes and apply the transformation to the AFQ segmentation provided. ","tags":[],"stats":{"stars":0},"contributors":[{"name":"Giulia Bertò","email":null}]},"runtime_mean":3008707.75,"runtime_std":2967110.560963298,"resources":[],"examples":0,"groups":1},"name":"ANTs transformation and wmc registration with T1","desc":"Compute ANTs transformation between two subjects based on T1 or FA volumes and apply the transformation to the AFQ segmentation provided. ","citation":null,"avatar":null,"github":"giulia-berto/app-ants-transformation-registration","github_branch":null,"config":{"t1_moving":{"type":"input","file_id":"t1","input_id":"0"},"segmentation":{"type":"input","file_id":"output","input_id":"1"},"t1_static":{"type":"input","file_id":"t1","input_id":"2"},"tract1":{"max":20,"min":0,"optional":true,"default":null,"desc":"Tract 1","placeholder":"","type":"number","id":"tract1","pid":0.5106730421958126,"_order":2},"tract2":{"max":20,"min":0,"optional":true,"default":null,"desc":"Tract 2","placeholder":"","type":"number","id":"tract2","pid":0.9239453331086753,"_order":3},"tract3":{"max":20,"min":0,"optional":true,"default":null,"desc":"Tract 3","placeholder":"","type":"number","id":"tract3","pid":0.6437464894014424,"_order":4},"tract4":{"optional":true,"max":20,"min":0,"default":"","desc":"Tract 4","placeholder":"","type":"number","id":"tract4","pid":0.39094461650375356,"_order":5}},"desc_override":"","user_id":"146","create_date":"2018-04-23T01:37:56.234Z","removed":false,"outputs":[{"datatype_tags":["ants_t1_aligned"],"_id":"5add38f4da9f040027366d27","id":"3","datatype":"58f10a90436ee50ffd9063c5","files":null,"output_on_root":true,"archive":true}],"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"_id":"5add38f4da9f040027366d2c","id":"0","datatype":"58c33bcee13a50849b25879a","desc":"T1 of moving subject"},{"datatype_tags":[],"optional":false,"multi":false,"_id":"5add38f4da9f040027366d2a","id":"1","datatype":"58f10a90436ee50ffd9063c5","desc":"Segmentation of moving subject"},{"datatype_tags":[],"optional":false,"multi":false,"_id":"5add38f4da9f040027366d29","id":"2","datatype":"58c33bcee13a50849b25879a","desc":"T1 of static subject"}],"contributors":[{"name":"Giulia Bertò","email":null,"_id":"634a329062f3d3800f1176ea"}],"tags":[],"references":[],"admins":["146"],"projects":["5a78c177340591004da75e6f"],"__v":13980,"doi":"10.25663/bl.app.26","_canedit":true},{"_id":"6166e55afc8eb93fb7fce780","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a42c862f3d3800f12fa57"}],"success_rate":93.02711676812396,"users":5,"runtime_mean":2901481.85,"runtime_std":453434.43858205946,"requested":2895,"examples":1,"groups":9},"projects":[],"admins":["1619"],"tags":[],"removed":false,"config":{"t1":{"type":"input","file_id":"t1","input_id":"skullstripped_nifti"},"template":{"id":"template","type":"string","placeholder":"","advanced":false,"desc":"currently the only option is mni 1 mm with a dilated mask","default":"template/mni_t1_template_masked.nii.gz","_order":2,"pid":0.38692954046179184,"readonly":true},"optional_params":{"id":"optional_params","type":"string","placeholder":"","advanced":false,"desc":"currently no optional parameters at this time","default":"null","_order":4,"pid":0.66481095211746,"readonly":true},"intense":{"id":"intense","type":"string","placeholder":"","advanced":false,"desc":"you must enter one of the following values: true, false, test.\ntrue = more intense; iterates 100x100x100x25\nfalse = less intense; iterates 100x100x50\ntest = for testing only; iterates 1x1x1\n","default":"false","_order":5,"pid":0.05522103140324297}},"inputs":[{"id":"skullstripped_nifti","desc":"t1w to be registered to template space","datatype":"58c33bcee13a50849b25879a","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"6166e55afc8eb9f912fce781"}],"outputs":[{"id":"registered","desc":"t1w registered to template space","datatype":"58c33bcee13a50849b25879a","datatype_tags":["registered","MNI152","ANTs"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"6166e55afc8eb98dd8fce782"},{"id":"output","desc":"warp files","datatype":"5bbfb28071454db2a890fbce","datatype_tags":["warp","MNI152","ANTs"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"6182abddafcc1f4f0420a2f5"}],"github_branch":"1.2","github":"vnbcs/app-ANTsRegistration","name":"ANTsRegistration","avatar":"https://camo.githubusercontent.com/ac30e91e9a09652adaf1fa4c00454a659868b056dc43bc26e3668227fcc80789/687474703a2f2f692e696d6775722e636f6d2f6d4c5a373141692e706e67","user_id":"1619","contributors":[{"name":"eva bacas","email":"enbacas@gmail.com","_id":"634a42c962f3d3800f12fa58"}],"create_date":"2021-10-13T13:55:38.121Z","desc":"registering t1w images with ANTs","__v":1600,"doi":"10.25663/brainlife.app.581","_canedit":true},{"_id":"5c5087d514061b00377b22d4","stats":{"stars":0,"requested":271,"users":2,"success_rate":96.66666666666667,"serviceinfo":{"_id":"5d729e1f78356a109788b259","counts":{"_id":"5e5c3ddc87cac76e42ab13ed","failed":1,"finished":43,"removed":44,"requested":44,"running":44,"running_sync":0,"stop_requested":0},"success_rate":97.72727272727273,"users":1,"readme_status":"ok","runtime_mean":461485.74418604653,"runtime_std":165362.0856416965,"service":"brainlife/app-dwiToDtiinit","__v":0},"gitinfo":{"desc":"This app will align DWI data to a DTIINIT DWI dataset in order to fit models that require multi-shell data to tracking","tags":["preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null}]},"runtime_mean":76730.02,"runtime_std":20387.570866084076,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a34e462f3d3800f118ed6"}],"examples":1,"groups":3},"projects":[],"admins":["1","16"],"tags":["preprocessing"],"removed":false,"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"input_dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"input_dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"input_dwi"},"dtiinit":{"type":"input","file_id":"output","input_id":"dtiinit"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c5087d514061b00377b22d6","id":"input_dwi","datatype":"58c33c5fe13a50849b25879b","desc":"The path to the dwi datatype to be aligned"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c5087d514061b00377b22d5","id":"dtiinit","datatype":"58cb234be13a50849b25882f","desc":"The path to the top directory containing the output from DTIINIT"}],"outputs":[{"datatype_tags":["aligned_dtiinit"],"output_on_root":false,"archive":true,"_id":"5c5087d514061b00377b22d7","id":"dwi","datatype":"58c33c5fe13a50849b25879b","datatype_tags_pass":null,"files":null,"desc":"A DWI dataype, including the DWI nifti and corrected bvecs and bvals, aligned to the DTIINIT output"}],"github_branch":"v1.0.0","github":"brainlife/app-dwiToDtiinit","name":"Align DWI to Dtiinit","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a34e562f3d3800f118ed7"}],"create_date":"2019-01-29T17:05:25.561Z","desc":"This app will align DWI data to a DTIINIT DWI dataset in order to fit models that require multi-shell data to tracking","doi":"10.25663/brainlife.app.153","__v":8867,"desc_override":"This app will align a DWI datatype to the output from DTIInit. This may be necessary if a user is using DTIInit purely for the anatomical alignment and the input dataset contains multi-shell data.","_canedit":true},{"_id":"5b96d5ed059cf9002719250b","projects":[],"admins":["1","19","16"],"tags":["anatomy-preprocessing"],"removed":false,"config":{"input":{"type":"input","file_id":"t1","input_id":"t1"},"type":{"id":"type","type":"string","placeholder":"","desc":"This controls whether the datatype of the app is T1 or T2. Not to be changed, used in order to keep the code same between T1 and T2","default":"T1","_order":2,"pid":0.7562989828391864,"optional":false,"readonly":true,"advanced":true},"template":{"id":"template","type":"enum","placeholder":"","advanced":false,"desc":"This template is used to align the input image to standard MNI orientation (acpc aligned). For adult brain, MNI152 should work fine, however, if you have pediatric images please select a template with correct age group in order to ensure that your input image will better align with the template. Otherwise, flirt will fail to correctly align your image.","default":"MNI152_1mm","_order":3,"pid":0.8926801745032462,"options":[{"desc":"The 1mm MNI_152 template","label":"MNI152_1mm","value":"MNI152_1mm"},{"desc":"4.5–8.5 y.o Asymmetric (natural) templates","label":"4.5–8.5 y.o Asymmetric (natural) templates","value":"nihpd_asym_04.5-08.5"},{"desc":"4.5-18.5 y.o Asymmetric (natural) templates","label":"4.5-18.5 y.o Asymmetric (natural) templates","value":"nihpd_asym_04.5-18.5"},{"desc":"7.0-11.0 y.o Asymmetric (natural) templates","label":"7.0-11.0 y.o Asymmetric (natural) templates","value":"nihpd_asym_07.0-11.0"},{"desc":"7.5-13.5 y.o Asymmetric (natural) templates","label":"7.5-13.5 y.o Asymmetric (natural) templates","value":"nihpd_asym_07.5-13.5"},{"desc":"10.0-14.0 y.o Asymmetric (natural) templates","label":"10.0-14.0 y.o Asymmetric (natural) templates","value":"nihpd_asym_10.0-14.0"},{"desc":"13.0-18.5 y.o Asymmetric (natural) templates","label":"13.0-18.5 y.o Asymmetric (natural) templates","value":"nihpd_asym_13.0-18.5"}]},"reorient":{"id":"reorient","type":"boolean","placeholder":"","advanced":false,"desc":"If true, will reorient image to FSL standard using fslreorient2std","default":true,"_order":4,"pid":0.8188145107264839}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5b96d5ed059cf9002719250c","id":"t1","datatype":"58c33bcee13a50849b25879a","desc":"The path to the anat/t1w datatype to be aligned"}],"outputs":[{"datatype_tags":["acpc_aligned","preprocessed"],"output_on_root":false,"archive":true,"_id":"5b96d5ed059cf9002719250d","id":"output","datatype":"58c33bcee13a50849b25879a","datatype_tags_pass":"t1","files":{"t1":"out.nii.gz"},"desc":"The ACPC aligned anat/t1w datatype"},{"datatype_tags":["affine","t1_to_acpc"],"output_on_root":false,"archive":true,"_id":"60e4c7ab4cb7045ccd069096","id":"transform","datatype":"5bbfb28071454db2a890fbce","datatype_tags_pass":null,"files":null}],"name":"Align T1 to ACPC Plane (HCP-based)","desc_override":"","github":"brainlife/app-hcp-acpc-alignment","user_id":"16","references":[],"contributors":[{"name":"Brad Caron","email":null,"_id":"634a33c462f3d3800f118210"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a33c462f3d3800f118211"},{"name":"Franco Pestilli","email":null,"_id":"634a33c462f3d3800f118212"},{"name":"Josh Faskowitz","email":null,"_id":"634a33c462f3d3800f118213"}],"create_date":"2018-09-10T20:37:01.031Z","desc":"This app will align a T1w image to the ACPC plane (specifically, the MNI152_T1_1mm template from FSL using a 6 DOF alignment via FSL commands. This protocol was adapted from the HCP Preprocessing Pipeline (https://github.com/Washington-University/HCPpipelines.git). Requires a T1w image input and outputs an acpc_aligned T1w image.","stats":{"stars":1,"requested":96841,"users":136,"success_rate":87.17818904577075,"serviceinfo":{"_id":"5d729e1f78356a109788b29f","counts":{"_id":"5e5c3db987cac715c3ab13ce","failed":259,"finished":6239,"removed":6417,"requested":7347,"running":6560,"running_sync":0,"stop_requested":264},"success_rate":96.01415820252386,"users":56,"readme_status":"ok","runtime_mean":1274538.2,"runtime_std":2614641.7180160973,"service":"brain-life/app-hcp-acpc-alignment","__v":0},"gitinfo":{"desc":"This app will align a T1w image to the ACPC plane (specifically, the MNI152_T1_1mm template from FSL using a 6 DOF alignment via FSL commands. This protocol was adapted from the HCP Preprocessing Pipeline (https://github.com/Washington-University/HCPpipelines.git). Requires a T1w image input and outputs an acpc_aligned T1w image.","tags":["anatomy-preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null},{"name":"Josh Faskowitz","email":null}]},"runtime_mean":268221,"runtime_std":677864.6485550489,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a33c362f3d3800f11820f"}],"examples":3,"groups":265},"doi":"10.25663/bl.app.99","__v":10728,"github_branch":"1.4","_canedit":true},{"_id":"6081c92b89df431f726940d8","projects":[],"admins":["16","126"],"tags":[],"removed":false,"stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a403c62f3d3800f12d61c"}],"success_rate":40,"users":3,"runtime_mean":619667,"runtime_std":481310,"requested":23,"examples":0,"groups":3},"config":{"t1":{"type":"input","file_id":"t1","input_id":"t1"},"t2":{"type":"input","file_id":"t2","input_id":"t2"},"crop":{"id":"crop","type":"boolean","placeholder":"","advanced":true,"desc":"If true, will crop using fsl robustfov. if false, will not. default == false","default":false,"_order":2,"pid":0.3968859144765968},"cost":{"id":"cost","type":"enum","placeholder":"","advanced":true,"desc":"","default":"mutualinfo","_order":3,"pid":0.4931400419635519,"options":[{"desc":"mutual info","label":"mutualinfo","value":"mutualinfo"},{"desc":"corratio","label":"corratio","value":"corratio"},{"desc":"norm corr","label":"normcorr","value":"normcorr"},{"desc":"norm mutual info","label":"normmi","value":"normmi"},{"desc":"least-squares","label":"leastsq","value":"leastsq"},{"desc":"labeldiff","label":"labeldiff","value":"labeldiff"},{"desc":"bbr","label":"bbr","value":"bbr"}]},"dof":{"id":"dof","type":"number","placeholder":"","advanced":true,"desc":"","default":12,"_order":4,"pid":0.7676515426155657}},"inputs":[{"datatype_tags":["acpc_aligned"],"optional":false,"multi":false,"advanced":false,"_id":"6081c1d389df43c3c56922af","id":"t1","datatype":"58c33bcee13a50849b25879a","desc":"reference t1 to align t2 data to"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"6081c92b89df435ffa6940da","id":"t2","datatype":"594c0325fa1d2e5a1f0beda5","desc":"t2 data to align"}],"outputs":[{"datatype_tags":["acpc_aligned"],"output_on_root":false,"archive":true,"_id":"6081c1d389df43337f6922b1","id":"output","datatype":"594c0325fa1d2e5a1f0beda5","datatype_tags_pass":"t2","files":null}],"github_branch":"v1.0","github":"brainlife/app-align-t2-to-t1","name":"Align T2  to T1 using FSL Flirt","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a403c62f3d3800f12d61d"}],"desc":null,"__v":2764,"create_date":"2021-04-22T19:06:19.669Z","doi":"10.25663/brainlife.app.510","_canedit":true},{"_id":"5bc0f0d0afd0bc0027efcd66","projects":[],"admins":["1","19","16"],"tags":["anatomy-preprocessing"],"removed":false,"config":{"input":{"type":"input","file_id":"t2","input_id":"t2"},"type":{"id":"type","type":"string","placeholder":"","desc":"This field controls whether the input image is a T1 or T2. Not meant to be changed. Makes pointing to the same github repository easier.","default":"T2","_order":2,"pid":0.8650054811548962,"readonly":true,"advanced":true},"template":{"id":"template","type":"enum","placeholder":"","advanced":false,"desc":"The template to which the T2w image is to be aligned","default":"MNI152_1mm","_order":3,"pid":0.8182597717857241,"options":[{"desc":"The MNI 152 1mm template","label":"MNI152_1mm","value":"MNI152_1mm"},{"desc":"4.5–8.5 y.o Asymmetric (natural) templates","label":"4.5–8.5 y.o Asymmetric (natural) templates","value":"nihpd_asym_04.5-08.5"},{"desc":"4.5-18.5 y.o Asymmetric (natural) templates","label":"4.5-18.5 y.o Asymmetric (natural) templates","value":"nihpd_asym_04.5-18.5"},{"desc":"7.0-11.0 y.o Asymmetric (natural) templates","label":"7.0-11.0 y.o Asymmetric (natural) templates","value":"nihpd_asym_07.0-11.0"},{"desc":"7.5-13.5 y.o Asymmetric (natural) templates","label":"7.5-13.5 y.o Asymmetric (natural) templates","value":"nihpd_asym_07.5-13.5"},{"desc":"10.0-14.0 y.o Asymmetric (natural) templates","label":"10.0-14.0 y.o Asymmetric (natural) templates","value":"nihpd_asym_10.0-14.0"},{"desc":"13.0-18.5 y.o Asymmetric (natural) templates","label":"13.0-18.5 y.o Asymmetric (natural) templates","value":"nihpd_asym_13.0-18.5"}]},"reorient":{"id":"reorient","type":"boolean","placeholder":"","advanced":false,"desc":"If true, will reorient image to fsl standard using fslreorient2std","default":true,"_order":4,"pid":0.18365575515339083,"readonly":false}},"inputs":[{"datatype_tags":["!acpc_aligned"],"optional":false,"multi":false,"advanced":false,"_id":"5bc0f0d0afd0bc0027efcd67","id":"t2","datatype":"594c0325fa1d2e5a1f0beda5","desc":"The path to the anat/t2w datatype to be aligned"}],"outputs":[{"datatype_tags":["acpc_aligned","preprocessed"],"output_on_root":false,"archive":true,"_id":"5bc0f0d0afd0bc0027efcd68","id":"output","datatype":"594c0325fa1d2e5a1f0beda5","datatype_tags_pass":"t2","files":{"t2":"out.nii.gz"},"desc":"The template aligned T2w image"},{"datatype_tags":["affine","t2_to_acpc"],"output_on_root":false,"archive":true,"_id":"60e4c7c24cb7044f980690ef","id":"transform","datatype":"5bbfb28071454db2a890fbce","datatype_tags_pass":null,"files":null}],"name":"Align T2 to ACPC Plane (HCP-based)","github":"brainlife/app-hcp-acpc-alignment","user_id":"1","references":[],"contributors":[{"name":"Brad Caron","email":null,"_id":"634a342062f3d3800f11861d"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a342062f3d3800f11861e"},{"name":"Franco Pestilli","email":null,"_id":"634a342062f3d3800f11861f"},{"name":"Josh Faskowitz","email":null,"_id":"634a342062f3d3800f118620"}],"create_date":"2018-10-12T19:06:56.774Z","desc":"This app will align a T1w image to the ACPC plane (specifically, the MNI152_T1_1mm template from FSL using a 6 DOF alignment via FSL commands. This protocol was adapted from the HCP Preprocessing Pipeline (https://github.com/Washington-University/HCPpipelines.git). Requires a T1w image input and outputs an acpc_aligned T1w image.","stats":{"stars":1,"serviceinfo":{"_id":"5d729e1f78356a109788b29f","counts":{"_id":"5e5c3dc387cac75d4eab13d8","failed":259,"finished":6239,"removed":6417,"requested":7347,"running":6560,"running_sync":0,"stop_requested":264},"success_rate":96.01415820252386,"users":56,"readme_status":"ok","runtime_mean":1274538.2,"runtime_std":2614641.7180160973,"service":"brain-life/app-hcp-acpc-alignment","__v":0},"success_rate":87.17818904577075,"users":136,"runtime_mean":268221,"runtime_std":677864.6485550489,"requested":96841,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a341f62f3d3800f11861c"}],"examples":2,"groups":265},"doi":"10.25663/brainlife.app.116","__v":10027,"github_branch":"1.4","_canedit":true},{"_id":"60832a3789df43532e6dbb7b","projects":[],"admins":["16","19","1","126"],"tags":["anatomy-preprocessing"],"removed":false,"config":{"mag_inv1":{"type":"input","file_id":"mag_inv1","input_id":"mp2rage"},"phase_inv1":{"type":"input","file_id":"phase_inv1","input_id":"mp2rage"},"mag_inv2":{"type":"input","file_id":"mag_inv2","input_id":"mp2rage"},"phase_inv2":{"type":"input","file_id":"phase_inv2","input_id":"mp2rage"},"unit1":{"type":"input","file_id":"unit1","input_id":"mp2rage"},"mag_inv1_json":{"type":"input","file_id":"mag_inv1_json","input_id":"mp2rage"},"phase_inv1_json":{"type":"input","file_id":"phase_inv1_json","input_id":"mp2rage"},"mag_inv2_json":{"type":"input","file_id":"mag_inv2_json","input_id":"mp2rage"},"phase_inv2_json":{"type":"input","file_id":"phase_inv2_json","input_id":"mp2rage"},"unit1_json":{"type":"input","file_id":"unit1_json","input_id":"mp2rage"},"anat":{"type":"input","file_id":"t1","input_id":"anat"},"template":{"id":"template","type":"enum","placeholder":"","advanced":false,"desc":"This template is used to align the input image to standard MNI orientation (acpc aligned). For adult brain, MNI152 should work fine, however, if you have pediatric images please select a template with correct age group in order to ensure that your input image will better align with the template. Otherwise, flirt will fail to correctly align your image.","default":"MNI152_1mm","_order":3,"pid":0.18836224242025623,"options":[{"desc":"The 1mm MNI_152 template","label":"MNI152_1mm","value":"MNI152_1mm"},{"desc":"4.5–8.5 y.o Asymmetric (natural) templates","label":"4.5–8.5 y.o Asymmetric (natural) templates","value":"nihpd_asym_04.5-08.5"},{"desc":"4.5-18.5 y.o Asymmetric (natural) templates","label":"4.5-18.5 y.o Asymmetric (natural) templates","value":"nihpd_asym_04.5-18.5"},{"desc":"7.0-11.0 y.o Asymmetric (natural) templates","label":"7.0-11.0 y.o Asymmetric (natural) templates","value":"nihpd_asym_07.0-11.0"},{"desc":"7.5-13.5 y.o Asymmetric (natural) templates","label":"7.5-13.5 y.o Asymmetric (natural) templates","value":"nihpd_asym_07.5-13.5"},{"desc":"10.0-14.0 y.o Asymmetric (natural) templates","label":"10.0-14.0 y.o Asymmetric (natural) templates","value":"nihpd_asym_10.0-14.0"},{"desc":"13.0-18.5 y.o Asymmetric (natural) templates","label":"13.0-18.5 y.o Asymmetric (natural) templates","value":"nihpd_asym_13.0-18.5"}]},"resample":{"id":"resample","type":"boolean","placeholder":"","advanced":false,"desc":"set whether to resample the voxels during alignment. default = true","default":true,"_order":4,"pid":0.2879134938938137},"interp":{"id":"interp","type":"enum","placeholder":"","advanced":true,"desc":"interpolation type to use","default":"nearestneighbour","_order":5,"pid":0.12049333187910982,"options":[{"desc":"trilinear","label":"trilinear","value":"trilinear"},{"desc":"nearestneighbour","label":"nearestneighbour","value":"nearestneighbour"},{"desc":"spline","label":"spline","value":"spline"},{"desc":"sinc","label":"sinc","value":"sinc"}]}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5b96d5ed059cf9002719250c","id":"mp2rage","datatype":"60634f0de4a8347569337f97","desc":"The path to the anat/mp2rage datatype to be aligned"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"6116af1ea5a04c353cfa2f72","id":"anat","datatype":"58c33bcee13a50849b25879a","desc":"If you want to align the mp2rage data to a T1 instead of the MNI template, input the T1 here"}],"outputs":[{"datatype_tags":["acpc_aligned"],"output_on_root":false,"archive":true,"_id":"5b96d5ed059cf9002719250d","id":"output","datatype":"60634f0de4a8347569337f97","datatype_tags_pass":"mp2rage","files":{"t1":"out.nii.gz"},"desc":"The ACPC aligned anat/mp2rage datatype"}],"name":"Align mp2rage to ACPC Plane (HCP-based)","desc_override":"This app will align mp2rage images to the ACPC plane (specifically, the MNI152_T1_1mm template) from FSL using a 6 DOF alignment via FSL commands. This protocol was adapted from the HCP Preprocessing Pipeline (https://github.com/Washington-University/HCPpipelines.git). Requires mp2rage images input and outputs an MNI_aligned ('ACPC aligned') mp2rage images. ","github":"brainlife/app-hcp-acpc-alignment","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a404562f3d3800f12d679"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a404562f3d3800f12d67a"},{"name":"Franco Pestilli","email":null,"_id":"634a404562f3d3800f12d67b"},{"name":"Josh Faskowitz","email":null,"_id":"634a404562f3d3800f12d67c"}],"desc":"This app will align a T1w image to the ACPC plane (specifically, the MNI152_T1_1mm template from FSL using a 6 DOF alignment via FSL commands. This protocol was adapted from the HCP Preprocessing Pipeline (https://github.com/Washington-University/HCPpipelines.git). Requires a T1w image input and outputs an acpc_aligned T1w image.","stats":{"requested":96841,"users":136,"success_rate":87.17818904577075,"gitinfo":{"desc":"This app will align a T1w image to the ACPC plane (specifically, the MNI152_T1_1mm template from FSL using a 6 DOF alignment via FSL commands. This protocol was adapted from the HCP Preprocessing Pipeline (https://github.com/Washington-University/HCPpipelines.git). Requires a T1w image input and outputs an acpc_aligned T1w image.","tags":["anatomy-preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null},{"name":"Josh Faskowitz","email":null}]},"runtime_mean":268221,"runtime_std":677864.6485550489,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a404562f3d3800f12d678"}],"examples":1,"groups":265},"__v":2770,"github_branch":"mp2rage-v1.5","create_date":"2021-04-23T20:12:39.566Z","doi":"10.25663/brainlife.app.511","_canedit":true},{"_id":"6081c1d389df434ba96922ae","stats":{"resources":[{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a403362f3d3800f12d608"}],"success_rate":50,"users":1,"runtime_mean":431592.5,"runtime_std":347707.5,"requested":6,"examples":1,"groups":1},"projects":[],"admins":["16","126"],"tags":[],"removed":false,"config":{"t1":{"type":"input","file_id":"t1","input_id":"t1"},"mag_inv1":{"type":"input","file_id":"mag_inv1","input_id":"mp2rage"},"phase_inv1":{"type":"input","file_id":"phase_inv1","input_id":"mp2rage"},"mag_inv2":{"type":"input","file_id":"mag_inv2","input_id":"mp2rage"},"phase_inv2":{"type":"input","file_id":"phase_inv2","input_id":"mp2rage"},"unit1":{"type":"input","file_id":"unit1","input_id":"mp2rage"},"mag_inv1_json":{"type":"input","file_id":"mag_inv1_json","input_id":"mp2rage"},"phase_inv1_json":{"type":"input","file_id":"phase_inv1_json","input_id":"mp2rage"},"mag_inv2_json":{"type":"input","file_id":"mag_inv2_json","input_id":"mp2rage"},"phase_inv2_json":{"type":"input","file_id":"phase_inv2_json","input_id":"mp2rage"},"unit1_json":{"type":"input","file_id":"unit1_json","input_id":"mp2rage"},"crop":{"id":"crop","type":"boolean","placeholder":"","advanced":true,"desc":"If true, will crop using fsl robustfov. if false, will not. default == true","default":true,"_order":2,"pid":0.8047838677460213}},"inputs":[{"datatype_tags":["acpc_aligned"],"optional":false,"multi":false,"advanced":false,"_id":"6081c1d389df43c3c56922af","id":"t1","datatype":"58c33bcee13a50849b25879a","desc":"reference t1 to align mp2rage data to"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"6081c1d389df433e396922b0","id":"mp2rage","datatype":"60634f0de4a8347569337f97","desc":"mp2rage data to align"}],"outputs":[{"datatype_tags":["acpc_aligned"],"output_on_root":false,"archive":true,"_id":"6081c1d389df43337f6922b1","id":"output","datatype":"60634f0de4a8347569337f97","datatype_tags_pass":"mp2rage","files":null}],"github_branch":"uni-included-v1.0","github":"brainlife/app-align-mp2rage-to-t1","name":"Align mp2rage volumes to T1 using FSL Flirt","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a403362f3d3800f12d609"}],"create_date":"2021-04-22T18:34:59.755Z","desc":null,"__v":2761,"doi":"10.25663/brainlife.app.509","_canedit":true},{"_id":"5cae3ef776cdaa0030b9232b","stats":{"stars":0,"requested":174,"users":4,"success_rate":62.40601503759399,"serviceinfo":{"_id":"5d729e1e78356a109788b225","counts":{"_id":"5e5c3dee87cac755dcab1402","failed":33,"finished":31,"removed":64,"requested":71,"running":63,"running_sync":0,"stop_requested":4},"success_rate":48.4375,"users":2,"readme_status":"ok","runtime_mean":43105379.87096774,"runtime_std":90548576.05385062,"service":"davhunt/app-analyzePRF","__v":0},"gitinfo":{"desc":null,"tags":[],"stats":{"stars":0},"contributors":[{"name":"David Hunt","email":"davhunt@indiana.edu"},{"name":"Kendrick Kay","email":"kendrick@post.harvard.edu"}]},"runtime_mean":27333635.578313254,"runtime_std":64753970.438755125,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a358f62f3d3800f11a208"}],"examples":0,"groups":4},"projects":[],"admins":["16","283"],"tags":[],"removed":false,"config":{"fmri":{"type":"input","file_id":"bold","input_id":"fmri"},"stim":{"type":"input","file_id":"stim","input_id":"stim"},"output":{"type":"input","file_id":"output","input_id":"freesurfer"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"frontal":{"id":"frontal","type":"boolean","placeholder":"","advanced":false,"desc":"Include frontal cortex in analysis","default":false,"_order":2,"pid":0.6440712812326232},"parietal":{"id":"parietal","type":"boolean","placeholder":"","advanced":false,"desc":"Include parietal cortex in analysis","default":false,"_order":3,"pid":0.46681475063525557},"temporal":{"id":"temporal","type":"boolean","placeholder":"","advanced":false,"desc":"Include temporal cortex in analysis","default":false,"_order":4,"pid":0.13387178683105572},"occipital":{"id":"occipital","type":"boolean","placeholder":"","advanced":false,"desc":"Include occipital cortex in analysis","default":true,"_order":5,"pid":0.4290641807370761},"preprocess":{"id":"preprocess","type":"boolean","placeholder":"","advanced":false,"desc":"Perform slice-timing and head motion correction on fMRI if not already preprocessed","default":true,"_order":6,"pid":0.08674053552166283},"TR":{"id":"TR","type":"number","placeholder":"","advanced":true,"desc":"Repetition time of fMRI (read from the nii header if unspecified)","default":null,"_order":7,"pid":0.2277167149152297,"optional":true},"pxtodeg":{"id":"pxtodeg","type":"number","placeholder":"","advanced":false,"desc":"Conversion factor from pixels to degrees subtended for visual stimulus (16 deg / 200 px for HCP data)","default":0.08,"_order":8,"pid":0.9043686147699757},"gsr":{"id":"gsr","type":"enum","placeholder":"","advanced":true,"desc":"Specifies whether global signal regression (GSR) on input fMRI should be done, conversion to % change from baseline","default":"none","_order":9,"pid":0.3118688548454067,"options":[{"desc":"no GSR","label":"none","value":"none"},{"desc":"regresses out mean signal per voxel","label":"per-voxel normalization","value":"pvn"},{"desc":"regresses out global mean","label":"grand-mean scaling","value":"gms"}]},"wantquick":{"id":"wantquick","type":"boolean","placeholder":"","advanced":true,"desc":"Use seedmode -2 and perform very quick PRF analysis\n\n% - When <seedmode> is -2, optimization is not performed and instead the best seed based on the super-grid is returned as the final estimate.","default":false,"_order":10,"pid":0.25353299486924175},"seedmode0":{"id":"seedmode0","type":"boolean","placeholder":"","advanced":true,"desc":"seedmode 0:\n% - The first seed is a generic large pRF that is centered with respect to the stimulus, has a pRF size equal to 1/4th of the stimulus extent (thus, +/- 2 pRF sizes matches the stimulus extent), and has an exponent of 0.5.","default":true,"_order":11,"pid":0.28678253589119107},"seedmode1":{"id":"seedmode1","type":"boolean","placeholder":"","advanced":true,"desc":"seedmode 1:\n% - The second seed is a generic small pRF that is just like the first seed except has a pRF size that is 10 times smaller.","default":true,"_order":12,"pid":0.937719222862629},"seedmode2":{"id":"seedmode2","type":"boolean","placeholder":"","advanced":true,"desc":"seedmode 2:\n% - The third seed is a \"supergrid\" seed that is identified by performing a quick grid search prior to optimization (similar in spirit to methods described in Dumoulin and Wandell, 2008).  In this procedure, a list of potential seeds is constructed by \n%   exploring a range of eccentricities, angles, and exponents.  For each potential \n%   seed, the model prediction is computed, and the seed that produces the closest \n%   match to the data is identified.","default":true,"_order":13,"pid":0.39105413736349903}},"inputs":[{"datatype_tags":[],"optional":false,"multi":true,"advanced":false,"_id":"5cae3ef776cdaa0030b9232d","id":"fmri","datatype":"59b685a08e5d38b0b331ddc5"},{"datatype_tags":[],"optional":false,"multi":true,"advanced":false,"_id":"5cae3ef776cdaa0030b9232c","id":"stim","datatype":"5afc7c555858d874a40c6dda"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5db347f98aeeee5449f2a108","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e","desc":"Used to generate .vtk surfaces"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5e798b52dd840e0139e851f2","id":"mask","datatype":"5a281aee2c214c9ba83ce620"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5cae3ef776cdaa0030b9232e","id":"prf","datatype":"5d9d18d8e30ae43bb0612715","datatype_tags_pass":null,"files":null}],"github_branch":"master","github":"davhunt/app-analyzePRF","name":"AnalyzepRF on volume","desc_override":"An app to do a population receptive field analysis on HCP 7T retinotopy fMRI data","user_id":"283","contributors":[{"name":"David Hunt","email":"davhunt@iu.edu","_id":"634a359062f3d3800f11a209"},{"name":"Kendrick Kay","email":"kendrick.kay@gmail.com","_id":"634a359062f3d3800f11a20a"}],"create_date":"2019-04-10T19:07:35.451Z","desc":null,"doi":"10.25663/brainlife.app.177","__v":8310,"_canedit":true},{"_id":"5e88b8bf952fef39d57abcf2","stats":{"success_rate":81.29148230088495,"users":30,"runtime_mean":13268972.2,"runtime_std":21354224.0111234,"requested":17873,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a38f362f3d3800f120528"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a38f362f3d3800f120529"}],"examples":5,"groups":63},"projects":[],"admins":["16","1"],"tags":[],"removed":false,"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"anat":{"type":"input","file_id":"t1","input_id":"anat"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"brainmask":{"type":"input","file_id":"mask","input_id":"brainmask"},"response":{"type":"input","file_id":"response","input_id":"csd"},"lmax2":{"type":"input","file_id":"lmax2","input_id":"csd"},"lmax4":{"type":"input","file_id":"lmax4","input_id":"csd"},"lmax6":{"type":"input","file_id":"lmax6","input_id":"csd"},"lmax8":{"type":"input","file_id":"lmax8","input_id":"csd"},"lmax10":{"type":"input","file_id":"lmax10","input_id":"csd"},"lmax12":{"type":"input","file_id":"lmax12","input_id":"csd"},"lmax14":{"type":"input","file_id":"lmax14","input_id":"csd"},"tensor_fit":{"id":"tensor_fit","type":"string","placeholder":"","advanced":false,"desc":"If multi-shell data is passed, this selects the shell that will be extracted and have a tensor fit performed\n\nIf single-shell data is passed, this is ignored","default":"","_order":2,"pid":0.41279437300414,"optional":true},"min_length":{"id":"min_length","type":"number","placeholder":"","advanced":false,"desc":"the minimum length a streamline may be","default":10,"_order":3,"pid":0.4937983607256262},"max_length":{"id":"max_length","type":"number","placeholder":"","advanced":false,"desc":"the maximum length a streamline may be","default":200,"_order":4,"pid":0.9466585680848167},"imaxs":{"id":"imaxs","type":"number","placeholder":"","advanced":false,"desc":"The lmax(s) or maximum value to create tractography data","default":8,"_order":5,"pid":0.5815211224850806},"ens_lmax":{"id":"ens_lmax","type":"boolean","placeholder":"","advanced":false,"desc":"perform ensemble tracking on every lmax up to the maximum value passed","default":true,"_order":6,"pid":0.3473074893819793},"curvs":{"id":"curvs","type":"string","placeholder":"","advanced":false,"desc":"the maximum curvature angle streamline can take during tracking","default":"5 10 20 40 80","_order":7,"pid":0.03710534199640003},"num_fibers":{"id":"num_fibers","type":"number","placeholder":"","advanced":false,"desc":"the number of streamlines to produce per parameter combination","default":15000,"_order":8,"pid":0.3159429727683706},"do_dtdt":{"id":"do_dtdt","type":"boolean","placeholder":"","advanced":false,"desc":"perform tensor-based deterministic tractography","default":true,"_order":9,"pid":0.4871323379659177},"do_dtpb":{"id":"do_dtpb","type":"boolean","placeholder":"","advanced":false,"desc":"perform tensor-based probabilistic tractography","default":false,"_order":10,"pid":0.4179445287430643},"do_detr":{"id":"do_detr","type":"boolean","placeholder":"","advanced":false,"desc":"perform deterministic tractography","default":true,"_order":11,"pid":0.8353210181393588},"do_prb1":{"id":"do_prb1","type":"boolean","placeholder":"","advanced":false,"desc":"perform mrtrix2 probabilistic tractography","default":false,"_order":12,"pid":0.6012354971256243},"do_prb2":{"id":"do_prb2","type":"boolean","placeholder":"","advanced":false,"desc":"perform mrtrix3 probabilistic tractography","default":true,"_order":13,"pid":0.33931047491451927},"do_fact":{"id":"do_fact","type":"boolean","placeholder":"","advanced":false,"desc":"Perform FACT tracking","default":false,"_order":14,"pid":0.7632873415962009},"fact_dirs":{"id":"fact_dirs","type":"number","placeholder":"","advanced":false,"desc":"The number of directions to perform FACT tracking on.\nmin: 1 max: 5","default":3,"_order":15,"pid":0.7305354224265617,"min":1,"max":5},"fact_fibs":{"id":"fact_fibs","type":"number","placeholder":"","advanced":false,"desc":"The number of FACT fibers to track per lmax.\nmin: 0 max: 1000000","default":0,"_order":16,"pid":0.14801313930640614,"min":0,"max":1000000},"premask":{"id":"premask","type":"boolean","placeholder":"","advanced":true,"desc":"If the input anatomical T1s have already been skull stripped, check this to prevent 5ttgen from cutting off a portion of the brain. (This sets -premasked option for 5ttgens)","default":false,"_order":17,"pid":0.8140249982003299},"stepsize":{"id":"stepsize","type":"number","placeholder":"","advanced":true,"desc":"If you want to predefine step size, do it here","default":null,"_order":18,"pid":0.6354782653579347}},"inputs":[{"id":"dwi","desc":"The path to the DWI datatype","datatype":"58c33c5fe13a50849b25879b","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e88b8bf952fef78ae7abcf3"},{"id":"anat","desc":"The path to the anat/t1w datatype","datatype":"58c33bcee13a50849b25879a","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e88b8bf952fef8a017abcf4"},{"id":"mask","desc":"The path to the  5tt probability mask generated using the Tissue-type Segmentation app. ","datatype":"5a281aee2c214c9ba83ce620","datatype_tags":["5tt_masks"],"optional":true,"multi":false,"advanced":false,"_id":"5e88b8bf952fef3a067abcf5"},{"id":"brainmask","desc":"The path to the brainmask of the dwi","datatype":"5a281aee2c214c9ba83ce620","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5e88b8bf952fef05ad7abcf6"},{"id":"csd","desc":"The path to the CSD datatype files","datatype":"5c536bf0f9109beac46adb45","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e88b8bf952fefbbad7abcf7"}],"outputs":[{"id":"tracking","desc":"The whole-brain tractogram, formatted as a .tck file","datatype":"5907d922436ee50ffde9c549","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":true,"files":null,"archive":true,"_id":"5e88b8bf952fefcbd87abcf8"},{"id":"tensor","desc":"The DTI output generated using MRTrix3","datatype":"5a79df48d071a1753f1d661b","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":true,"files":null,"archive":true,"_id":"5e88b8bf952fefc79a7abcf9"}],"github_branch":"1.3","github":"bacaron/app-mrtrix3-act","name":"Anatomically Constrained Tractography using precomputed 5tt & CSD","desc_override":"Runs mrtrix3 ACT (Anatomically Constrained Tractography) using either single- or multi-shell diffusion-weighted MRI data. Clone of https://doi.org/10.25663/bl.app.101 (written by Brent McPherson) that requires csd input and allows for 5tt probability mask and brainmask inputs.","user_id":"16","contributors":[{"name":"Brent McPherson","email":"bcmcpher@gmail.com","_id":"634a38f362f3d3800f12052a"},{"name":"Brad Caron","email":null,"_id":"634a38f362f3d3800f12052b"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a38f362f3d3800f12052c"}],"create_date":"2020-04-04T16:41:35.886Z","desc":"Runs mrtrix3 ACT (Anatomically Constrained Tractography) using either single- or multi-shell diffusion-weighted MRI data. ","doi":"10.25663/brainlife.app.297","__v":5199,"_canedit":true},{"_id":"5d6f9160398672065e49642f","projects":[],"admins":["146"],"tags":["segmentation","white-matter-segmentation"],"removed":false,"stats":{"stars":1,"serviceinfo":{"_id":"5d729e1f78356a109788b283","counts":{"_id":"5e5c3e1387cac75940ab142b","failed":150,"finished":806,"removed":741,"requested":1024,"running":982,"running_sync":0,"stop_requested":39},"success_rate":84.30962343096235,"users":1,"readme_status":"ok","runtime_mean":19688102.98,"runtime_std":11191394.632128878,"service":"giulia-berto/app-multi-lap-anat","__v":0},"gitinfo":{"desc":"White matter bundle segmentation as Anatomically-Informed multiple Linear Assignment Problems (multi-LAP-anat).","tags":[],"stats":{"stars":0},"contributors":[{"name":"Giulia Bertò","email":null}]},"success_rate":83.97502601456816,"users":1,"runtime_mean":19616098.84,"runtime_std":11230532.48671157,"requested":1036,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a36f762f3d3800f11d319"}],"examples":0,"groups":4},"config":{"tractogram_static":{"type":"input","file_id":"track","input_id":"0"},"t1_static":{"type":"input","file_id":"t1","input_id":"1"},"segmentations":{"type":"input","file_id":"classification","input_id":"2"},"tracts":{"type":"input","file_id":"tracts","input_id":"2"},"tractograms_moving":{"type":"input","file_id":"track","input_id":"3"},"t1s_moving":{"type":"input","file_id":"t1","input_id":"4"},"fsDir":{"type":"input","file_id":"output","input_id":"5"},"k":{"id":"k","type":"number","placeholder":"","desc":"value for k-NN to compute the superset","default":2000,"_order":3,"pid":0.2967945807900778},"step_size":{"id":"step_size","type":"number","placeholder":"","desc":"step size for resampling","default":0.625,"_order":4,"pid":0.25330458609878903},"slr":{"id":"slr","type":"boolean","placeholder":"","desc":"If false, assuming subjects already co-registered in the same space","default":true,"_order":6,"pid":0.835340484501907},"lambdaD":{"id":"lambdaD","type":"number","placeholder":"","advanced":false,"desc":"weight for the distance matrix","default":1,"_order":7,"pid":0.4033213789809136},"lambdaE":{"id":"lambdaE","type":"number","placeholder":"","advanced":false,"desc":"weight for the endpoint-based distance matrix","default":1,"_order":8,"pid":0.7267409602994028},"lambdaR":{"id":"lambdaR","type":"number","placeholder":"","advanced":false,"desc":"weight for the ROI-based distance matrix","default":1,"_order":9,"pid":0.5118153534378518},"norm_mat":{"id":"norm_mat","type":"boolean","placeholder":"","advanced":false,"desc":"matrices normalization","default":true,"_order":10,"pid":0.40992824080777734},"tractID_list":{"id":"tractID_list","type":"string","placeholder":"allowed values: 1-20 (if AFQ examples provided), 38-45 (if WMA examples provided)","desc":"ID list of the bundles of interest, separated by commas (refer to the README.md for the mapping)","default":"","_order":11,"pid":0.5725153057855084}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d14bc062daec10035f3f873","id":"0","datatype":"5907d922436ee50ffde9c549","desc":"Tractogram of static (target) subject"},{"datatype_tags":["acpc_aligned"],"optional":false,"multi":false,"advanced":false,"_id":"5d14bc062daec10035f3f872","id":"1","datatype":"58c33bcee13a50849b25879a","desc":"T1 of static (target) subject"},{"datatype_tags":[],"optional":false,"multi":true,"advanced":false,"_id":"5d14bc062daec10035f3f871","id":"2","datatype":"5cc1d64c44947d8aea6b2d8b","desc":"Segmentations of moving (examples) subjects (they should be extracted from the tractogram provided)"},{"datatype_tags":[],"optional":false,"multi":true,"advanced":false,"_id":"5d14bc062daec10035f3f870","id":"3","datatype":"5907d922436ee50ffde9c549","desc":"Tractograms of moving (example) subjects"},{"datatype_tags":["acpc_aligned"],"optional":false,"multi":true,"advanced":false,"_id":"5d14bc062daec10035f3f86f","id":"4","datatype":"58c33bcee13a50849b25879a","desc":"Ts1 of moving (example) subjects"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5d6f91603986724176496430","id":"5","datatype":"58cb22c8e13a50849b25882e","desc":"FreeSurfer parcellation of static (target) subject (not used in version 1.0, needed for tractID from 38 to 45)"}],"outputs":[{"datatype_tags":["multi-LAPanat"],"output_on_root":false,"archive":true,"_id":"5d14bc062daec10035f3f874","id":"output_wmc","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags_pass":"2","files":null,"desc":"segmented bundles"}],"github_branch":"2.1","github":"giulia-berto/app-multi-lap-anat","name":"Anatomically-informed multi-LAP","user_id":"146","contributors":[{"name":"Giulia Bertò","email":null,"_id":"634a36f862f3d3800f11d31a"}],"desc":"White matter bundle segmentation as Anatomically-Informed multiple Linear Assignment Problems (multi-LAP-anat).","__v":7289,"avatar":"https://github.com/giulia-berto/app-multi-lap-anat/blob/master/app-multi-lap-anat-avatar.png?raw=true","create_date":"2019-09-04T10:26:40.524Z","doi":"10.25663/brainlife.app.227","_canedit":true},{"_id":"5bd46dddf384a600273bf480","projects":[],"admins":["146"],"tags":["segmentation","white-matter-segmentation"],"removed":false,"config":{"tractogram_static":{"type":"input","file_id":"track","input_id":"0"},"t1_static":{"type":"input","file_id":"t1","input_id":"1"},"segmentations":{"type":"input","file_id":"output","input_id":"2"},"tractograms_moving":{"type":"input","file_id":"track","input_id":"3"},"t1s_moving":{"type":"input","file_id":"t1","input_id":"4"},"fsDir":{"type":"input","file_id":"output","input_id":"5"},"k":{"id":"k","type":"number","placeholder":"","desc":"value for k-NN to compute the superset","default":2000,"_order":2,"pid":0.12150190482169432},"step_size":{"id":"step_size","type":"number","placeholder":"","desc":"step size for resampling","default":0.625,"_order":3,"pid":0.24631594890206632},"lambdaD":{"id":"lambdaD","type":"number","placeholder":"","desc":"weight for the distance matrix","default":1,"_order":4,"pid":0.7382100359235821},"lambdaE":{"id":"lambdaE","type":"number","placeholder":"","desc":"weight for the endpoint matrix","default":1,"_order":5,"pid":0.34260986198362264},"lambdaR":{"id":"lambdaR","type":"number","placeholder":"","desc":"weight for the ROI-based matrix","default":1,"_order":6,"pid":0.584631859739672},"norm_mat":{"id":"norm_mat","type":"boolean","placeholder":"","desc":"matrices normalization","default":true,"_order":7,"pid":0.3713540570138836},"tract1":{"id":"tract1","type":"number","placeholder":"allowed values: 1-20, 38-45","desc":"ID of the bundle of interest (refer to the README.md for the mapping)","default":null,"_order":9,"pid":0.5016103139251704,"min":"","max":""}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5bd46dddf384a600273bf486","id":"0","datatype":"5907d922436ee50ffde9c549","desc":"Tractogram of static (target) subject"},{"datatype_tags":["acpc_aligned"],"optional":false,"multi":false,"advanced":false,"_id":"5bd46dddf384a600273bf485","id":"1","datatype":"58c33bcee13a50849b25879a","desc":"T1 of static (target) subject"},{"datatype_tags":[],"optional":false,"multi":true,"advanced":false,"_id":"5bd46dddf384a600273bf484","id":"2","datatype":"58f10a90436ee50ffd9063c5","desc":"Segmentations of moving (examples) subjects (they should be extracted from the tractogram provided - only AFQ segmentations allowed for version 1.0)"},{"datatype_tags":[],"optional":false,"multi":true,"advanced":false,"_id":"5bd46dddf384a600273bf483","id":"3","datatype":"5907d922436ee50ffde9c549","desc":"Tractograms of moving (example) subjects"},{"datatype_tags":["acpc_aligned"],"optional":false,"multi":true,"advanced":false,"_id":"5bd46dddf384a600273bf482","id":"4","datatype":"58c33bcee13a50849b25879a","desc":"Ts1 of moving (example) subjects"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5bfc1c8cbba1a80027ec0ad9","id":"5","datatype":"58cb22c8e13a50849b25882e","desc":"FreeSurfer parcellation of static (target) subject (not used in version 1.0, needed for tractID from 38 to 45)"}],"outputs":[{"datatype_tags":["multi-LAPanat"],"output_on_root":true,"archive":true,"_id":"5bd5c8bff384a600273bf4a2","id":"7","datatype":"58f10a90436ee50ffd9063c5","datatype_tags_pass":null,"files":null,"desc":"segmented bundles"}],"name":"Anatomically-informed multi-LAP (deprecated)","github":"giulia-berto/app-multi-lap-anat","user_id":"146","references":[],"contributors":[{"name":"Giulia Bertò","email":null,"_id":"634a344762f3d3800f118aa9"}],"create_date":"2018-10-27T13:53:33.162Z","desc":"White matter bundle segmentation as Anatomically-Informed multiple Linear Assignment Problems (multi-LAP-anat).","stats":{"stars":1,"serviceinfo":{"_id":"5d729e1f78356a109788b283","counts":{"_id":"5e5c3dc787cac77ccfab13dc","failed":150,"finished":806,"removed":741,"requested":1024,"running":982,"running_sync":0,"stop_requested":39},"success_rate":84.30962343096235,"users":1,"readme_status":"ok","runtime_mean":19688102.98,"runtime_std":11191394.632128878,"service":"giulia-berto/app-multi-lap-anat","__v":0},"gitinfo":{"desc":"White matter bundle segmentation as Anatomically-Informed multiple Linear Assignment Problems (multi-LAP-anat).","tags":[],"stats":{"stars":0},"contributors":[{"name":"Giulia Bertò","email":null}]},"success_rate":83.97502601456816,"users":1,"runtime_mean":19616098.84,"runtime_std":11230532.48671157,"requested":1036,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a344762f3d3800f118aa8"}],"examples":0,"groups":4},"doi":"10.25663/brainlife.app.122","__v":9053,"github_branch":"1.1","avatar":"https://github.com/giulia-berto/app-multi-lap-anat/blob/master/LAP-anat.png?raw=true","deprecated_by":"5d6f9160398672065e49642f","_canedit":true},{"_id":"602bc6a33a001123014c442a","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3f0562f3d3800f12c79c"}],"success_rate":46.625544267053705,"users":2,"runtime_mean":69107.43,"runtime_std":72154.07483299264,"requested":2767,"examples":3,"groups":9},"projects":[],"admins":["1342","1348","670","2076"],"tags":["meg"],"removed":false,"config":{"fif":{"type":"input","file_id":"fif","input_id":"fif01"},"crosstalk":{"type":"input","file_id":"crosstalk","input_id":"fif01"},"calibration":{"type":"input","file_id":"calibration","input_id":"fif01"},"events":{"type":"input","file_id":"events","input_id":"fif01"},"headshape":{"type":"input","file_id":"headshape","input_id":"fif01"},"channels":{"type":"input","file_id":"channels","input_id":"fif01"},"channels_override":{"type":"input","file_id":"channels","input_id":"opt01"},"headshape_override":{"type":"input","file_id":"headshape","input_id":"opt01"},"destination_override":{"type":"input","file_id":"destination","input_id":"opt01"},"param_int_order":{"id":"param_int_order","type":"number","placeholder":"","advanced":true,"desc":"Order of internal component of spherical expansion. The number provided must be an integer.","default":8,"_order":5,"pid":0.4439781816375663,"optional":false},"param_ext_order":{"id":"param_ext_order","type":"number","placeholder":"","advanced":true,"desc":"Order of external component of spherical expansion. The number provided must be an integer. ","default":3,"_order":6,"pid":0.45479668808721807,"optional":false,"min":"","max":"","readonly":null},"param_st_duration":{"id":"param_st_duration","type":"number","placeholder":"","advanced":false,"desc":"If not None, apply tSSS with specified buffer duration (in seconds). The number provided can be a float. ","default":"","_order":7,"pid":0.2936048875211694,"optional":true,"readonly":false},"param_st_correlation":{"id":"param_st_correlation","type":"number","placeholder":"","advanced":false,"desc":"Correlation limit between inner and outer subspaces used to reject overlapping intersecting inner/outer signals during tSSS. The number provided can be a float. ","default":0.98,"_order":8,"pid":0.15610171514419835},"param_coord_frame":{"id":"param_coord_frame","type":"enum","placeholder":"","advanced":true,"desc":"The coordinate frame that the origin is specified in, either meg or head.","default":"head","_order":9,"pid":0.5478924366714397,"options":[{"desc":"","label":"","value":"head"},{"desc":"","label":"","value":"meg"}],"optional":false},"param_regularize":{"id":"param_regularize","type":"enum","placeholder":"","advanced":true,"desc":"The destination location for the head, either in or None.","default":"in","_order":13,"pid":0.47196469614230563,"options":[{"desc":"","label":"","value":"in"}],"optional":true},"param_ignore_ref":{"id":"param_ignore_ref","type":"boolean","placeholder":"","advanced":true,"desc":"If True, do not include reference channels in compensation.","default":false,"_order":14,"pid":0.35854133188177717},"param_bad_condition":{"id":"param_bad_condition","type":"enum","placeholder":"","advanced":true,"desc":"How to deal with ill-conditioned SSS matrices, either 'error', 'warning', 'info', or 'ignore'.","default":"error","_order":15,"pid":0.28355651141607785,"options":[{"desc":"","label":"","value":"error"},{"desc":"","label":"","value":"warning"},{"desc":"","label":"","value":"info"},{"desc":"","label":"","value":"ignore"}],"optional":false,"readonly":null},"param_st_fixed":{"id":"param_st_fixed","type":"boolean","placeholder":"","advanced":true,"desc":"If True, do tSSS using the median head position during the st_duration window.","default":true,"_order":16,"pid":0.4995495587282257},"param_st_only":{"id":"param_st_only","type":"boolean","placeholder":"","advanced":true,"desc":"If True, only tSSS projection of MEG data will be performed on the output data.","default":false,"_order":17,"pid":0.5158712507207694},"param_origin":{"id":"param_origin","type":"string","placeholder":"","advanced":true,"desc":"Origin of internal and external multipolar moment space in meters. Can be \"auto\" or three numbers separated by a comma (example: 0, 0, 0).","default":"auto","_order":20,"pid":0.10472236631393361,"readonly":false},"param_skip_by_annotation":{"id":"param_skip_by_annotation","type":"string","placeholder":"","advanced":true,"desc":"Any annotation segment that begins with the given string will not be included in filtering, and segments on either side of the given excluded annotated segment will be filtered separately. Can be an empty list [].","default":"[edge, bad_acq_skip]","_order":22,"pid":0.1552955774205509},"param_mag_scale":{"id":"param_mag_scale","type":"string","placeholder":"","advanced":true,"desc":"The magnetometer scale-factor used to bring the magnetometers to approximately the same order of magnitude as the gradiometers, as they have different units (T vs T/m). The number provided can be a float. Can be \"auto\".","default":"100","_order":23,"pid":0.28516595999618355},"param_destination":{"id":"param_destination","type":"string","placeholder":"","advanced":false,"desc":"The 3 elements giving the coordinates to translate to (with no rotations). Can be None or three numbers separated by a comma (example: 0, 0, 0). This parameter must be set to None when a desrination file is provided. ","default":"","_order":24,"pid":0.07368236599221278,"optional":true},"param_extended_proj":{"id":"param_extended_proj","type":"string","placeholder":"","advanced":true,"desc":"The empty-room projection vectors used to extend the external SSS basis (i.e., use eSSS).","default":"[]","_order":25,"pid":0.11519757222005067,"readonly":true}},"inputs":[{"id":"fif01","desc":"Maxwell filtering will be applied to MEG signals. ","datatype":"6000737faacf9ee51fa691cb","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"602bc6a33a0011033c4c442b"},{"id":"opt01","desc":"Channels.tsv file in a BIDS compliant format (computed with app-bad-channels), head positions in a .pos file (computed by app-head-pos), and destination file (computed by app-mean-tranformation-matrix). These files will override the events.tsv and channels.tsv linked to the neuro/meg/fif datatype.","datatype":"608195ce89df435fd26893c1","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"609570d3d7a32acd7ae47f9b"}],"outputs":[{"id":"out_dir_maxwell_filter","desc":"MEG signals after Maxwell filtering","datatype":"6000737faacf9ee51fa691cb","datatype_tags":["maxwell"],"datatype_tags_pass":"fif01","output_on_root":false,"files":null,"archive":true,"_id":"602bc6a33a00119c404c442c"},{"id":"out_dir_report","desc":"HTML report with plots of MEG signals before and after Maxwell filtering","datatype":"5e56dc330f7fa604cc3cc291","datatype_tags":["maxwell"],"datatype_tags_pass":"fif01","output_on_root":false,"files":null,"archive":true,"_id":"602bc6a33a0011610e4c442d"}],"github_branch":"master","github":"brainlife/app-maxwell-filter","name":"Apply Maxwell filter on MEG signals ","user_id":"1342","contributors":[{"name":null,"email":null,"_id":"634a3f0562f3d3800f12c79d"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a3f0562f3d3800f12c79e"}],"create_date":"2021-02-16T13:20:35.558Z","desc":"Apply Maxwell filtering on MEG signals recorded with Elketa (or MEGIN or Neuromag) machine using MNE Python. ","__v":3325,"doi":"10.25663/brainlife.app.476","_canedit":true},{"_id":"60770020e8c764b2bae512ae","stats":{"resources":[],"success_rate":0,"users":1,"requested":4,"examples":2,"groups":1},"projects":[],"admins":["1342","664","670"],"tags":["meg"],"removed":false,"config":{"fif":{"type":"input","file_id":"fif","input_id":"fif0"},"headshape":{"type":"input","file_id":"headshape","input_id":"fif0"},"calibration":{"type":"input","file_id":"calibration","input_id":"fif0"},"crosstalk":{"type":"input","file_id":"crosstalk","input_id":"fif0"},"destination":{"type":"input","file_id":"destination","input_id":"fif0"},"events":{"type":"input","file_id":"events","input_id":"fif0"},"channels":{"type":"input","file_id":"channels","input_id":"fif0"},"param_freqs_specific_or_start":{"id":"param_freqs_specific_or_start","type":"number","placeholder":"","advanced":false,"desc":"Specific frequency to filter out in Hz or the start of the frequencies to filter out in Hz. This value can be a float or None if the method 'spectrum_fit' is applied.","default":50,"_order":3,"pid":0.7466706394552254,"optional":true},"param_freqs_end":{"id":"param_freqs_end","type":"number","placeholder":"","advanced":false,"desc":"End of the interval of frequencies to filter out in Hz. This value is excluded. This value can be a float or None if the method 'spectrum_fit' is applied.","default":251,"_order":4,"pid":0.48361503914636983,"optional":true},"param_freqs_step":{"id":"param_freqs_step","type":"number","placeholder":"","advanced":false,"desc":"The step in Hz to filter out specific frequencies (for instance the power lines harmonics) between param_freqs_start and param_freqs_end. This value can be a float or None.","default":50,"_order":5,"pid":0.36835486937909123,"optional":true},"param_picks_by_channel_types_or_names":{"id":"param_picks_by_channel_types_or_names","type":"string","placeholder":"","advanced":false,"desc":"Channels to include. In lists, channel type strings (e.g., [meg, eeg]) will pick channels of those types, channel name strings (e.g., [MEG0111, MEG2623]) will pick the given channels. When you use a list, don't forget to use the square brackets. Can also be the string values “all” to pick all channels, or “data” to pick data channels. None will pick all data channels. \nNote that channels in info['bads'] will be included if their names are explicitly provided.","default":"meg","_order":6,"pid":0.5795790785303543,"optional":true},"param_picks_by_channel_indices":{"id":"param_picks_by_channel_indices","type":"string","placeholder":"","advanced":true,"desc":"Channels to include. Slices (e.g., 0, 10, 2 or 0, 10 if you don't want a step) and lists of integers (e.g., [10, 12]) are interpreted as channel indices. For slices, enter the start index, the end index, and optionally the step and separate them by a coma. For list, don't forget the square brackets.\nNone (default) will pick all data channels. This parameter must be set to None if param_picks_by_channel_types_or_names is not None. \nNote that channels in info['bads'] will be included if their indices are explicitly provided.","default":"","_order":7,"pid":0.14080702424737002,"optional":true},"param_filter_length":{"id":"param_filter_length","type":"string","placeholder":"","advanced":true,"desc":"Length of the FIR filter to use (if applicable). Can be ‘auto’ (default) : the filter length is chosen based on the size of the transition regions, or an other string (human-readable time in units of “s” or “ms”: e.g., “10s” or “5500ms”). \nIf an integer value is given, it corresponds to the specified length in samples. For fir_design=”firwin”, this should not be used.","default":"auto","_order":8,"pid":0.32165239845051974},"param_iir_parameters":{"id":"param_iir_parameters","type":"number","placeholder":"","advanced":true,"desc":"If param_method is \"iir\", 4th order Butterworth will be used. ","default":null,"_order":10,"pid":0.6943642830551842,"readonly":true,"optional":true},"param_trans_bandwidth":{"id":"param_trans_bandwidth","type":"number","placeholder":"","advanced":true,"desc":" Width of the transition band in Hz. This value can be a float.","default":1,"_order":12,"pid":0.9687618145665311},"param_n_jobs":{"id":"param_n_jobs","type":"string","placeholder":"","advanced":true,"desc":"Number of jobs to run in parallel. This value must be an integer. Can be ‘cuda’ if cupy is installed properly and method is ’fir’.","default":"1","_order":13,"pid":0.8276038887504478},"param_method":{"id":"param_method","type":"enum","placeholder":"","advanced":true,"desc":"‘fir’ (default) will use overlap-add FIR filtering, ‘iir’ will use IIR forward-backward filtering (via filtfilt).","default":"fir","_order":15,"pid":0.10959651685617677,"options":[{"desc":"overlap-add FIR filtering","label":"","value":"fir"},{"desc":"IIR forward-backward filtering","label":"","value":"iir"},{"desc":"","label":"","value":"spectrum_fit"}]},"param_notch_widths":{"id":"param_notch_widths","type":"string","placeholder":"","advanced":true,"desc":"Width of the stop band in Hz. If None, freqs / 200 is used. This value can be a float or several floats separated by a comma.","default":"","_order":16,"pid":0.006174660417991307,"optional":true},"param_mt_bandwidth":{"id":"param_mt_bandwidth","type":"number","placeholder":"","advanced":true,"desc":"The bandwidth of the multitaper windowing function in Hz. This value can be a float.","default":null,"_order":17,"pid":0.12222504746756058,"optional":true},"param_p_value":{"id":"param_p_value","type":"number","placeholder":"","advanced":true,"desc":"P-value to use in F-test thresholding to determine significant sinusoidal components \nto remove when method=’spectrum_fit’ and freqs=None.","default":0.05,"_order":18,"pid":0.097536924365478},"param_phase":{"id":"param_phase","type":"enum","placeholder":"","advanced":true,"desc":"Phase of the filter, only used if method='fir'.","default":"zero","_order":19,"pid":0.21065249404520392,"options":[{"desc":"","label":"","value":"zero"},{"desc":"","label":"","value":"zero-double"}]},"param_fir_window":{"id":"param_fir_window","type":"enum","placeholder":"","advanced":true,"desc":"The window to use in FIR design.","default":"hamming","_order":20,"pid":0.23714519367950104,"options":[{"desc":"","label":"","value":"hamming"},{"desc":"","label":"","value":"hann"},{"desc":"","label":"","value":"blackman"}]},"param_fir_design":{"id":"param_fir_design","type":"enum","placeholder":"","advanced":true,"desc":"Can be “firwin” (default) or “firwin2”.","default":"firwin","_order":21,"pid":0.5696515555254522,"options":[{"desc":"","label":"","value":"firwin"},{"desc":"","label":"","value":"firwin2"}]},"param_pad":{"id":"param_pad","type":"enum","placeholder":"","advanced":true,"desc":"The type of padding to use.","default":"reflect_limited","_order":22,"pid":0.7619563855385489,"options":[{"desc":"Pads with a constant value.","label":"","value":"constant"},{"desc":"Pads with the edge values of array.","label":"","value":"edge"},{"desc":"Pads with the linear ramp between end_value and the array edge value.","label":"","value":"linear_ramp"},{"desc":"Pads with the maximum value of all or part of the vector along each axis.","label":"","value":"maximum"},{"desc":"Pads with the mean value of all or part of the vector along each axis.","label":"","value":"mean"},{"desc":"Pads with the median value of all or part of the vector along each axis.","label":"","value":"median"},{"desc":"Pads with the minimum value of all or part of the vector along each axis.","label":"","value":"minimum"},{"desc":"Pads with the reflection of the vector mirrored on the first and last values of the vector along each axis.","label":"","value":"reflect"},{"desc":"Pads with the reflection of the vector mirrored along the edge of the array.","label":"","value":"symmetric"},{"desc":"Pads with the wrap of the vector along the axis. The first values are used to pad the end and the end values are used to pad the beginning.","label":"","value":"wrap"},{"desc":"Pads with undefined values.","label":"","value":"empty"},{"desc":"","label":"","value":"reflect_limited"}]}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"60770020e8c7641272e512af","id":"fif0","datatype":"6000737faacf9ee51fa691cb","desc":"The MEG file to notch filter."}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"60770020e8c7649e79e512b0","id":"out_dir_notch_filter","datatype":"6000737faacf9ee51fa691cb","datatype_tags_pass":null,"files":null,"desc":"MEG data after notch filter applied."},{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"60770020e8c764dac7e512b1","id":"out_dir_report","datatype":"5e56dc330f7fa604cc3cc291","datatype_tags_pass":null,"files":null,"desc":"HTML report."}],"github_branch":"master","github":"brainlife/app-notch-filter","name":"Apply a notch filter on continuous MEG data","user_id":"1342","contributors":[{"name":null,"email":null,"_id":"634a400762f3d3800f12d4db"}],"create_date":"2021-04-14T14:45:52.429Z","desc":"Notch filter MEG data stored in a .fif file using MNE Python.","__v":2906,"doi":"10.25663/brainlife.app.504","_canedit":true},{"_id":"6066eab2c7f80a647b93d1a7","stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3fc762f3d3800f12d25e"},{"resource_id":"5e309300e017b06c99948e0a","name":"stampede2(knl) @ TACC/UT","_id":"634a3fc762f3d3800f12d25f"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3fc762f3d3800f12d260"}],"success_rate":50,"users":5,"runtime_mean":46210.28571428572,"runtime_std":17185.538053959255,"requested":19,"examples":1,"groups":6},"projects":[],"admins":["1342","664","670"],"tags":["meg"],"removed":false,"config":{"fif":{"type":"input","file_id":"fif","input_id":"fif"},"headshape":{"type":"input","file_id":"headshape","input_id":"fif"},"crosstalk":{"type":"input","file_id":"crosstalk","input_id":"fif"},"calibration":{"type":"input","file_id":"calibration","input_id":"fif"},"destination":{"type":"input","file_id":"destination","input_id":"fif"},"events":{"type":"input","file_id":"events","input_id":"fif"},"channels":{"type":"input","file_id":"channels","input_id":"fif"},"param_epoched_data":{"id":"param_epoched_data","type":"boolean","placeholder":"","advanced":false,"desc":"If True, the data to be filtered is epoched, else it is continuous.","default":false,"_order":2,"pid":0.29840905158754105},"param_l_freq":{"id":"param_l_freq","type":"number","placeholder":"","advanced":false,"desc":"For FIR filters, the lower pass-band edge; for IIR filters, the lower cutoff frequency. If None the data are only low-passed. The value can be a float. ","default":0.5,"_order":3,"pid":0.4466323258752629,"optional":true},"param_h_freq":{"id":"param_h_freq","type":"number","placeholder":"","advanced":false,"desc":"For FIR filters, the higher pass-band edge; for IIR filters, the higher cutoff frequency. If None the data are only high-passed. The value can be a float. ","default":150,"_order":4,"pid":0.22163105316253295,"optional":true},"param_picks_by_channel_types_or_names":{"id":"param_picks_by_channel_types_or_names","type":"string","placeholder":"","advanced":false,"desc":"Channels to include. In lists, channel type strings (e.g., [meg, eeg]) will pick channels of those types, channel name strings (e.g., [MEG0111, MEG2623]) will pick the given channels. When you use a list, don't forget to use the square brackets. Can also be the string values “all” to pick all channels, or “data” to pick data channels. \nNone will pick all data channels. \nNote that channels in info['bads'] will be included if their names are explicitly provided.","default":"meg","_order":5,"pid":0.34818328348046856,"optional":true},"param_picks_by_channel_indices":{"id":"param_picks_by_channel_indices","type":"string","placeholder":"","advanced":true,"desc":"Channels to include. Slices (e.g., 0, 10, 2 or 0, 10 if you don't want a step) and lists of integers (e.g., [10, 12]) are interpreted as channel indices. For slices, enter the start index, the end index and optionaly the step and separate them by a coma. For list, don't forget the square brackets.\nNone (default) will pick all data channels. This parameter must be set to None if param_picks_by_channel_types_or_names is not None. \nNote that channels in info['bads'] will be included if their indices are explicitly provided.","default":"","_order":6,"pid":0.39874637478047936,"optional":true},"param_filter_length":{"id":"param_filter_length","type":"string","placeholder":"","advanced":true,"desc":"Length of the FIR filter to use (if applicable). Can be \"auto\" (default) : the filter length is chosen based on the size of the transition regions, or an other string (human-readable time in units of “s” or “ms”: e.g., “10s” or “5500ms”). \nIf an integer value is given, it corresponds to the specified length in samples. For fir_design=”firwin”, this should not be used.","default":"auto","_order":7,"pid":0.08834948095450534},"param_l_trans_bandwidth":{"id":"param_l_trans_bandwidth","type":"string","placeholder":"","advanced":true,"desc":"Width of the transition band at the low cut-off frequency in Hz. This value can be a float.","default":"auto","_order":8,"pid":0.2663762814975743,"readonly":false},"param_h_trans_bandwidth":{"id":"param_h_trans_bandwidth","type":"string","placeholder":"","advanced":true,"desc":"Width of the transition band at the high cut-off frequency in Hz. This value can be a float.","default":"auto","_order":9,"pid":0.4735707247544465,"readonly":false},"param_method":{"id":"param_method","type":"enum","placeholder":"","advanced":true,"desc":"‘fir’ will use overlap-add FIR filtering, ‘iir’ will use IIR forward-backward filtering","default":"fir","_order":11,"pid":0.543595875678575,"options":[{"desc":"","label":"","value":"fir"},{"desc":"","label":"","value":"iir"}]},"param_iir_params":{"id":"param_iir_params","type":"number","placeholder":"","advanced":true,"desc":"Dictionary of parameters to use for IIR filtering. If iir_params is None and method=”iir”, 4th order Butterworth will be used.","default":null,"_order":13,"pid":0.006245964926818726,"readonly":true,"optional":true},"param_phase":{"id":"param_phase","type":"enum","placeholder":"","advanced":true,"desc":"Phase of the filter, only used if method='fir'.","default":"zero-double","_order":14,"pid":0.2673049936385061,"options":[{"desc":"","label":"","value":"zero"},{"desc":"","label":"","value":"zero-double"}]},"param_fir_window":{"id":"param_fir_window","type":"enum","placeholder":"","advanced":true,"desc":"The window to use in FIR design.","default":"hamming","_order":15,"pid":0.28309643899851644,"options":[{"desc":"","label":"","value":"hamming"},{"desc":"","label":"","value":"hann"},{"desc":"","label":"","value":"blackman"}]},"param_fir_design":{"id":"param_fir_design","type":"enum","placeholder":"","advanced":true,"desc":"Can be “firwin” or “firwin2”.","default":"firwin","_order":17,"pid":0.40226214142918537,"options":[{"desc":"","label":"","value":"firwin"},{"desc":"","label":"","value":"firwin2"}]},"param_skip_by_annotation":{"id":"param_skip_by_annotation","type":"string","placeholder":"","advanced":true,"desc":"If a string (or list of str), any annotation segment that begins with the given string will not be included in filtering, and segments on either side of the given excluded annotated segment will be filtered separately. Can be an empty list [].","default":"[edge, bad_acq_skip]","_order":18,"pid":0.7360776154894686},"param_raw_pad":{"id":"param_raw_pad","type":"enum","placeholder":"","advanced":true,"desc":"The type of padding to use for raw data.","default":"reflect_limited","_order":19,"pid":0.5318653968807481,"options":[{"desc":"","label":"","value":"reflect_limited"},{"desc":"Pads with a constant value.","label":"","value":"constant"},{"desc":"Pads with the edge values of array.","label":"","value":"edge"},{"desc":"Pads with the linear ramp between end_value and the array edge value.","label":"","value":"linear_ramp"},{"desc":"Pads with the maximum value of all or part of the vector along each axis.","label":"","value":"maximum"},{"desc":"Pads with the mean value of all or part of the vector along each axis.","label":"","value":"mean"},{"desc":"Pads with the median value of all or part of the vector along each axis.","label":"","value":"median"},{"desc":"Pads with the minimum value of all or part of the vector along each axis.","label":"","value":"minimum"},{"desc":"Pads with the reflection of the vector mirrored on the first and last values of the vector along each axis.","label":"","value":"reflect"},{"desc":"Pads with the reflection of the vector mirrored along the edge of the array.","label":"","value":"symmetric"},{"desc":"Pads with the wrap of the vector along the axis. The first values are used to pad the end and the end values are used to pad the beginning.","label":"","value":"wrap"},{"desc":"Pads with undefined values.","label":"","value":"empty"}]},"param_epoch_pad":{"id":"param_epoch_pad","type":"enum","placeholder":"","advanced":true,"desc":"The type of padding to use for epoched data.","default":"edge","_order":20,"pid":0.8431643115441592,"options":[{"desc":"","label":"","value":"reflect_limited"},{"desc":"Pads with a constant value.","label":"","value":"constant"},{"desc":"Pads with the edge values of array.","label":"","value":"edge"},{"desc":"Pads with the linear ramp between end_value and the array edge value.","label":"","value":"linear_ramp"},{"desc":"Pads with the maximum value of all or part of the vector along each axis.","label":"","value":"maximum"},{"desc":"Pads with the mean value of all or part of the vector along each axis.","label":"","value":"mean"},{"desc":"Pads with the median value of all or part of the vector along each axis.","label":"","value":"median"},{"desc":"Pads with the minimum value of all or part of the vector along each axis.","label":"","value":"minimum"},{"desc":"Pads with the reflection of the vector mirrored on the first and last values of the vector along each axis.","label":"","value":"reflect"},{"desc":"Pads with the reflection of the vector mirrored along the edge of the array.","label":"","value":"symmetric"},{"desc":"Pads with the wrap of the vector along the axis. The first values are used to pad the end and the end values are used to pad the beginning.","label":"","value":"wrap"},{"desc":"Pads with undefined values.","label":"","value":"empty"}]},"param_n_jobs":{"id":"param_n_jobs","type":"string","placeholder":"","advanced":true,"desc":"Number of jobs to run in parallel. This value is an int. Can be ‘cuda’ if cupy is installed properly and method is 'fir’.","default":"1","_order":21,"pid":0.027537506534515144}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"6066eab2c7f80a884d93d1a8","id":"fif","datatype":"6000737faacf9ee51fa691cb","desc":"MEG data to be filtered."}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"6066eab2c7f80a8b4093d1a9","id":"out_dir_temporal_filtering","datatype":"6000737faacf9ee51fa691cb","datatype_tags_pass":null,"files":null,"desc":"MEG data after filtering"},{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"6066eab2c7f80a275a93d1aa","id":"out_dir_report","datatype":"5e56dc330f7fa604cc3cc291","datatype_tags_pass":null,"files":null,"desc":"HTML report comparing MEG data before and after filtering"}],"github_branch":"master","github":"brainlife/app-temporal-filtering","name":"Apply a temporal filter (lowpass, highpass, or bandpass) on MEG signals (epoched or continuous)","user_id":"1342","contributors":[{"name":null,"email":null,"_id":"634a3fc862f3d3800f12d261"}],"create_date":"2021-04-02T09:58:10.669Z","desc":"Filter MEG signals using MNE Python","__v":2998,"doi":"10.25663/brainlife.app.497","_canedit":true},{"_id":"6331b1fe2aea314314dbd0f2","user_id":"16","projects":[],"admins":["16"],"name":"Apply warp from subject-to-standard space to ROIs (T1w)","github":"brainlife/app-register-rois-mni","github_branch":"1.0","desc":null,"desc_override":"","tags":[],"contributors":[{"name":"Brad Caron","email":null,"_id":"634a45dc62f3d3800f13122c"}],"config":{"input":{"type":"input","file_id":"t1","input_id":"t1"},"rois":{"type":"input","file_id":"rois","input_id":"rois"},"label":{"type":"input","file_id":"label","input_id":"rois"},"warp":{"type":"input","file_id":"warp","input_id":"warp"},"inverse_warp":{"type":"input","file_id":"inverse-warp","input_id":"warp"},"affine":{"type":"input","file_id":"affine","input_id":"warp"},"input_type":{"id":"input_type","type":"enum","placeholder":"","advanced":true,"desc":"This controls the datatype (T1 or T2) to use. This should not be changed. Only used to keep the github repository between the two apps the same","default":"T1","_order":9,"pid":0.2303361089348004,"options":[{"desc":"T1","label":"T1","value":"T1"}]},"template":{"id":"template","type":"enum","placeholder":"","advanced":false,"desc":"The template to which to align the T2","default":"MNI152_1mm","_order":10,"pid":0.6111730841592238,"options":[{"desc":"1.0 mm MNI 152 template","label":"MNI152_1mm","value":"MNI152_1mm"},{"desc":"4.5–8.5 y.o Asymmetric (natural) templates","label":"4.5–8.5 y.o Asymmetric (natural) templates","value":"nihpd_asym_04.5-08.5"},{"desc":"4.5-18.5 y.o Asymmetric (natural) templates","label":"4.5-18.5 y.o Asymmetric (natural) templates","value":"nihpd_asym_04.5-18.5"},{"desc":"7.0-11.0 y.o Asymmetric (natural) templates","label":"7.0-11.0 y.o Asymmetric (natural) templates","value":"nihpd_asym_07.0-11.0"},{"desc":"7.5-13.5 y.o Asymmetric (natural) templates","label":"7.5-13.5 y.o Asymmetric (natural) templates","value":"nihpd_asym_07.5-13.5"},{"desc":"10.0-14.0 y.o Asymmetric (natural) templates","label":"10.0-14.0 y.o Asymmetric (natural) templates","value":"nihpd_asym_10.0-14.0"},{"desc":"13.0-18.5 y.o Asymmetric (natural) templates","label":"13.0-18.5 y.o Asymmetric (natural) templates","value":"nihpd_asym_13.0-18.5"},{"desc":"0.7 mm MNI 152 template","label":"MNI152_0.7mm","value":"MNI152_0.7mm"},{"desc":"0.8 mm MNI 152 template","label":"MNI152_0.8mm","value":"MNI152_0.8mm"},{"desc":"2.0 mm MNI 152 template","label":"MNI152_2mm","value":"MNI152_2mm"}]},"interp":{"id":"interp","type":"enum","placeholder":"","advanced":true,"desc":"","default":"nn","_order":11,"pid":0.29431183877663547,"options":[{"desc":"nn","label":"nn","value":"nn"},{"desc":"spline","label":"spline","value":"spline"}]},"warp_to_use":{"id":"warp_to_use","type":"enum","placeholder":"","advanced":true,"desc":"","default":"warp","_order":12,"pid":0.9665734918615123,"options":[{"desc":"warp","label":"warp","value":"warp"},{"desc":"inv_warp","label":"inv_warp","value":"inv_warp"}]}},"inputs":[{"id":"t1","desc":"The path to the anat/t2w datatype","datatype":"58c33bcee13a50849b25879a","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e3c87ae9362b7d9a5f9c7f5"},{"id":"rois","datatype":"5be9ea0315a8683a39a1ebd9","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"632a582271291bb27f9c6fcd"},{"id":"warp","datatype":"5bbfb28071454db2a890fbce","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"632a582271291bb27f9c6fce"}],"outputs":[{"id":"standard_nonlin_warp","desc":"Nonlinear warp generated from T2 to standard via fnirt","datatype":"5bbfb28071454db2a890fbce","datatype_tags":["standard"],"datatype_tags_pass":"t1","output_on_root":false,"files":null,"archive":true,"_id":"5e3c87ae9362b72555f9c7f9"},{"id":"raw","desc":"Output directory for all the data derivatives generated","datatype":"59c3eae633fc1cf9ead71679","datatype_tags":["standard"],"datatype_tags_pass":"t1","output_on_root":false,"files":null,"archive":false,"_id":"5e3c87ae9362b713def9c7fa"},{"id":"rois","datatype":"5be9ea0315a8683a39a1ebd9","datatype_tags":["warped"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"632b2cfc71291bb27f9e3d33"}],"stats":{"success_rate":93.33333333333333,"groups":2,"users":3,"runtime_mean":1009702.1666666666,"runtime_std":2284880.723245015,"requested":113,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a45db62f3d3800f131228"},{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a45db62f3d3800f131229"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a45db62f3d3800f13122a"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"634a45db62f3d3800f13122b"}],"examples":1},"removed":false,"__v":23,"create_date":"2022-09-26T14:06:54.513Z","doi":"10.25663/brainlife.app.670","_canedit":true},{"_id":"632a582271291bb27f9c6fca","user_id":"16","projects":[],"admins":["16"],"name":"Apply warp from subject-to-standard space to ROIs (T2w)","github":"brainlife/app-register-rois-mni","github_branch":"1.0","desc":null,"desc_override":"","tags":[],"contributors":[{"name":"Brad Caron","email":null,"_id":"634a45c962f3d3800f1311ec"}],"config":{"input":{"type":"input","file_id":"t2","input_id":"t2"},"rois":{"type":"input","file_id":"rois","input_id":"rois"},"label":{"type":"input","file_id":"label","input_id":"rois"},"warp":{"type":"input","file_id":"warp","input_id":"warp"},"inverse_warp":{"type":"input","file_id":"inverse-warp","input_id":"warp"},"affine":{"type":"input","file_id":"affine","input_id":"warp"},"input_type":{"id":"input_type","type":"enum","placeholder":"","advanced":false,"desc":"This controls the datatype (T1 or T2) to use. This should not be changed. Only used to keep the github repository between the two apps the same","default":"T2","_order":9,"pid":0.7364755281861561,"options":[{"desc":"T2","label":"T2","value":"T2"}]},"template":{"id":"template","type":"enum","placeholder":"","advanced":false,"desc":"The template to which to align the T2","default":"MNI152_1mm","_order":10,"pid":0.682255982277794,"options":[{"desc":"1.0 mm MNI 152 template","label":"MNI152_1mm","value":"MNI152_1mm"},{"desc":"4.5–8.5 y.o Asymmetric (natural) templates","label":"4.5–8.5 y.o Asymmetric (natural) templates","value":"nihpd_asym_04.5-08.5"},{"desc":"4.5-18.5 y.o Asymmetric (natural) templates","label":"4.5-18.5 y.o Asymmetric (natural) templates","value":"nihpd_asym_04.5-18.5"},{"desc":"7.0-11.0 y.o Asymmetric (natural) templates","label":"7.0-11.0 y.o Asymmetric (natural) templates","value":"nihpd_asym_07.0-11.0"},{"desc":"7.5-13.5 y.o Asymmetric (natural) templates","label":"7.5-13.5 y.o Asymmetric (natural) templates","value":"nihpd_asym_07.5-13.5"},{"desc":"10.0-14.0 y.o Asymmetric (natural) templates","label":"10.0-14.0 y.o Asymmetric (natural) templates","value":"nihpd_asym_10.0-14.0"},{"desc":"13.0-18.5 y.o Asymmetric (natural) templates","label":"13.0-18.5 y.o Asymmetric (natural) templates","value":"nihpd_asym_13.0-18.5"},{"desc":"0.7 mm MNI 152 template","label":"MNI152_0.7mm","value":"MNI152_0.7mm"},{"desc":"0.8 mm MNI 152 template","label":"MNI152_0.8mm","value":"MNI152_0.8mm"},{"desc":"2.0 mm MNI 152 template","label":"MNI152_2mm","value":"MNI152_2mm"}]},"interp":{"id":"interp","type":"enum","placeholder":"","advanced":true,"desc":"","default":"nn","_order":11,"pid":0.8747224573967027,"options":[{"desc":"nn","label":"nn","value":"nn"},{"desc":"spline","label":"spline","value":"spline"}]},"warp_to_use":{"id":"warp_to_use","type":"enum","placeholder":"","advanced":true,"desc":"","default":"warp","_order":12,"pid":0.5640264605784551,"options":[{"desc":"warp","label":"warp","value":"warp"},{"desc":"inv_warp","label":"inv_warp","value":"inv_warp"}]}},"inputs":[{"id":"t2","desc":"The path to the anat/t2w datatype","datatype":"594c0325fa1d2e5a1f0beda5","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e3c87ae9362b7d9a5f9c7f5"},{"id":"rois","datatype":"5be9ea0315a8683a39a1ebd9","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"632a582271291bb27f9c6fcd"},{"id":"warp","datatype":"5bbfb28071454db2a890fbce","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"632a582271291bb27f9c6fce"}],"outputs":[{"id":"standard_nonlin_warp","desc":"Nonlinear warp generated from T2 to standard via fnirt","datatype":"5bbfb28071454db2a890fbce","datatype_tags":["standard"],"datatype_tags_pass":"t2","output_on_root":false,"files":null,"archive":true,"_id":"5e3c87ae9362b72555f9c7f9"},{"id":"raw","desc":"Output directory for all the data derivatives generated","datatype":"59c3eae633fc1cf9ead71679","datatype_tags":["standard"],"datatype_tags_pass":"t2","output_on_root":false,"files":null,"archive":false,"_id":"5e3c87ae9362b713def9c7fa"},{"id":"rois","datatype":"5be9ea0315a8683a39a1ebd9","datatype_tags":["warped"],"datatype_tags_pass":"rois","output_on_root":false,"files":null,"archive":true,"_id":"632b2cfc71291bb27f9e3d33"}],"stats":{"success_rate":93.33333333333333,"groups":2,"users":3,"runtime_mean":1009702.1666666666,"runtime_std":2284880.723245015,"requested":113,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a45c962f3d3800f1311e8"},{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a45c962f3d3800f1311e9"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a45c962f3d3800f1311ea"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"634a45c962f3d3800f1311eb"}],"examples":2},"removed":false,"__v":29,"create_date":"2022-09-21T00:17:38.930Z","doi":"10.25663/brainlife.app.667","_canedit":true},{"_id":"612fd650584a769e283c22d5","projects":[],"admins":["16","1"],"tags":[],"removed":false,"config":{"input":{"type":"input","file_id":"bold","input_id":"bold"},"warp":{"type":"input","file_id":"warp","input_id":"transform"},"template":{"id":"template","type":"enum","placeholder":"","advanced":false,"desc":"This template is used to align the input image to standard MNI orientation (acpc aligned). For adult brain, MNI152 should work fine, however, if you have pediatric images please select a template with correct age group in order to ensure that your input image will better align with the template. Otherwise, flirt will fail to correctly align your image.","default":"MNI152_1mm","_order":3,"pid":0.7828314402302315,"options":[{"desc":"The 1mm MNI_152 template","label":"MNI152_1mm","value":"MNI152_1mm"},{"desc":"4.5–8.5 y.o Asymmetric (natural) templates","label":"4.5–8.5 y.o Asymmetric (natural) templates","value":"nihpd_asym_04.5-08.5"},{"desc":"4.5-18.5 y.o Asymmetric (natural) templates","label":"4.5-18.5 y.o Asymmetric (natural) templates","value":"nihpd_asym_04.5-18.5"},{"desc":"7.0-11.0 y.o Asymmetric (natural) templates","label":"7.0-11.0 y.o Asymmetric (natural) templates","value":"nihpd_asym_07.0-11.0"},{"desc":"7.5-13.5 y.o Asymmetric (natural) templates","label":"7.5-13.5 y.o Asymmetric (natural) templates","value":"nihpd_asym_07.5-13.5"},{"desc":"10.0-14.0 y.o Asymmetric (natural) templates","label":"10.0-14.0 y.o Asymmetric (natural) templates","value":"nihpd_asym_10.0-14.0"},{"desc":"13.0-18.5 y.o Asymmetric (natural) templates","label":"13.0-18.5 y.o Asymmetric (natural) templates","value":"nihpd_asym_13.0-18.5"}]}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5b96d5ed059cf9002719250c","id":"bold","datatype":"59b685a08e5d38b0b331ddc5","desc":"The path to the anat/t1w datatype to be aligned"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"612fd650584a76cedb3c22d7","id":"transform","datatype":"5bbfb28071454db2a890fbce"}],"outputs":[{"datatype_tags":["warped"],"output_on_root":false,"archive":true,"_id":"5b96d5ed059cf9002719250d","id":"output","datatype":"59b685a08e5d38b0b331ddc5","datatype_tags_pass":"bold","files":{"t1":"out.nii.gz"},"desc":"The warped BOLD file"}],"name":"Apply warp to BOLD data","desc_override":"","github":"brainlife/app-warp-bold","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a424862f3d3800f12f45b"}],"desc":null,"stats":{"requested":3690,"users":1,"success_rate":66.75824175824175,"gitinfo":{"desc":"This app will align a T1w image to the ACPC plane (specifically, the MNI152_T1_1mm template from FSL using a 6 DOF alignment via FSL commands. This protocol was adapted from the HCP Preprocessing Pipeline (https://github.com/Washington-University/HCPpipelines.git). Requires a T1w image input and outputs an acpc_aligned T1w image.","tags":["anatomy-preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null},{"name":"Josh Faskowitz","email":null}]},"runtime_mean":15979.66,"runtime_std":13425.741584895784,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a424762f3d3800f12f45a"}],"examples":1,"groups":2},"__v":1922,"github_branch":"v1.0","create_date":"2021-09-01T19:36:48.840Z","doi":"10.25663/brainlife.app.566","_canedit":true},{"_id":"6138cab4584a762c35417ac8","projects":[],"admins":["16","1"],"tags":[],"removed":false,"config":{"input":{"type":"input","file_id":"parc","input_id":"parc"},"key":{"type":"input","file_id":"key","input_id":"parc"},"label":{"type":"input","file_id":"label","input_id":"parc"},"warp":{"type":"input","file_id":"warp","input_id":"transform"},"template":{"id":"template","type":"enum","placeholder":"","advanced":false,"desc":"This template is used to align the input image to standard MNI orientation (acpc aligned). For adult brain, MNI152 should work fine, however, if you have pediatric images please select a template with correct age group in order to ensure that your input image will better align with the template. Otherwise, flirt will fail to correctly align your image.","default":"MNI152_1mm","_order":3,"pid":0.3770632259995126,"options":[{"desc":"The 1mm MNI_152 template","label":"MNI152_1mm","value":"MNI152_1mm"},{"desc":"4.5–8.5 y.o Asymmetric (natural) templates","label":"4.5–8.5 y.o Asymmetric (natural) templates","value":"nihpd_asym_04.5-08.5"},{"desc":"4.5-18.5 y.o Asymmetric (natural) templates","label":"4.5-18.5 y.o Asymmetric (natural) templates","value":"nihpd_asym_04.5-18.5"},{"desc":"7.0-11.0 y.o Asymmetric (natural) templates","label":"7.0-11.0 y.o Asymmetric (natural) templates","value":"nihpd_asym_07.0-11.0"},{"desc":"7.5-13.5 y.o Asymmetric (natural) templates","label":"7.5-13.5 y.o Asymmetric (natural) templates","value":"nihpd_asym_07.5-13.5"},{"desc":"10.0-14.0 y.o Asymmetric (natural) templates","label":"10.0-14.0 y.o Asymmetric (natural) templates","value":"nihpd_asym_10.0-14.0"},{"desc":"13.0-18.5 y.o Asymmetric (natural) templates","label":"13.0-18.5 y.o Asymmetric (natural) templates","value":"nihpd_asym_13.0-18.5"}]}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"6138cab4584a76066b417ac9","id":"parc","datatype":"5c1a7489f9109beac4a88a1f"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"612fd650584a76cedb3c22d7","id":"transform","datatype":"5bbfb28071454db2a890fbce"}],"outputs":[{"datatype_tags":["warped"],"output_on_root":false,"archive":true,"_id":"5b96d5ed059cf9002719250d","id":"output","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags_pass":"parc","files":{"t1":"out.nii.gz"},"desc":"The warped parcellation datatype"}],"name":"Apply warp to Parcellation","desc_override":"","github":"brainlife/app-warp-bold","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a426362f3d3800f12f539"}],"desc":null,"stats":{"requested":3690,"users":1,"success_rate":66.75824175824175,"gitinfo":{"desc":"This app will align a T1w image to the ACPC plane (specifically, the MNI152_T1_1mm template from FSL using a 6 DOF alignment via FSL commands. This protocol was adapted from the HCP Preprocessing Pipeline (https://github.com/Washington-University/HCPpipelines.git). Requires a T1w image input and outputs an acpc_aligned T1w image.","tags":["anatomy-preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null},{"name":"Josh Faskowitz","email":null}]},"runtime_mean":15979.66,"runtime_std":13425.741584895784,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a426362f3d3800f12f538"}],"examples":0,"groups":2},"__v":1869,"github_branch":"parc-v1.0","create_date":"2021-09-08T14:37:40.841Z","doi":"10.25663/brainlife.app.569","_canedit":true},{"_id":"5c72e7e3badd19003102e8d3","stats":{"stars":0,"requested":591,"users":2,"success_rate":92.32081911262799,"serviceinfo":{"_id":"5d729e1f78356a109788b23f","counts":{"_id":"5e5c3de787cac709c6ab13fa","failed":45,"finished":541,"removed":540,"requested":591,"running":581,"running_sync":0,"stop_requested":0},"success_rate":92.32081911262799,"users":2,"readme_status":"no README.md","runtime_mean":33937525.85,"runtime_std":120381276.51463279,"service":"brainlife/VisWMROIWarp","__v":0},"gitinfo":{"desc":null,"tags":[],"stats":{"stars":0},"contributors":[{"name":"Daniel Bullock","email":null},{"name":"Ilaria Sani","email":"ila.gina@virgilio.it"}]},"runtime_mean":33937525.85,"runtime_std":120381276.51463279,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a354e62f3d3800f119f16"}],"examples":0,"groups":2},"projects":[],"admins":["56","135"],"tags":[],"removed":false,"config":{"t1":{"type":"input","file_id":"t1","input_id":"t1"},"mask":{"type":"input","file_id":"mask","input_id":"mask"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c72e7e3badd19003102e8d5","id":"t1","datatype":"58c33bcee13a50849b25879a"},{"datatype_tags":["brain"],"optional":false,"multi":false,"advanced":false,"_id":"5c72e7e3badd19003102e8d4","id":"mask","datatype":"5a281aee2c214c9ba83ce620"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5c72e7e3badd19003102e8d6","id":"output","datatype":"5be9ea0315a8683a39a1ebd9","datatype_tags_pass":null,"files":null}],"github_branch":"master","github":"brainlife/VisWMROIWarp","name":"Attention ROI warp","user_id":"56","contributors":[{"name":"Daniel Bullock","email":"iisdanbul@gmail.com","_id":"634a354e62f3d3800f119f17"},{"name":"Ilaria Sani","email":"ila.gina@virgilio.it","_id":"634a354e62f3d3800f119f18"}],"create_date":"2019-02-24T18:52:19.433Z","desc":null,"doi":"10.25663/brainlife.app.168","__v":8646,"desc_override":"This service aligns two sets of Regions of Interest (ROIs) from Sani et al., in preparation to the individual subject space. A first set of ROIs has been obtained by thresholding functional MRI data. A second set of ROIs has been obtained by creating sphere ROIs around the peak of functional MRI activation. The ROIs are stored here: https://github.com/brainlife/VisWMROIWarp/tree/master/rois","_canedit":true},{"_id":"5deece232d1c254a76929834","stats":{"stars":0,"serviceinfo":{"_id":"5e23a244b0d615607b79bdd9","counts":{"_id":"5e5c3e3087cac7276dab1445","failed":86,"finished":87,"removed":10,"requested":181,"running":175,"running_sync":0,"stop_requested":3},"users":2,"readme_status":"ok","service":"svincibo/app-ashs-segment","__v":0,"success_rate":50.28901734104046,"runtime_mean":6964495.356321839,"runtime_std":2307340.749197013},"success_rate":68.73156342182891,"users":5,"runtime_mean":6275028.89,"runtime_std":692367.1580469987,"requested":818,"resources":[{"resource_id":"5e309300e017b06c99948e0a","name":"stampede2(knl) @ TACC/UT","_id":"634a37e762f3d3800f11e5a0"}],"examples":1,"groups":12},"projects":[],"admins":["41","146","1","126"],"tags":[],"removed":false,"config":{"t1":{"type":"input","file_id":"t1","input_id":"t1"},"t2":{"type":"input","file_id":"t2","input_id":"t2"},"atlas":{"id":"atlas","type":"enum","placeholder":"","advanced":false,"desc":"","default":"","_order":2,"pid":0.32278687399494954,"options":[{"desc":"","label":"UPENN-PMC-3t","value":"UPENN-PMC-3t"}]}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5deece232d1c25384a929836","id":"t1","datatype":"58c33bcee13a50849b25879a","desc":"t1 anatomical image used for hippocampus segmentation. Must be in register with the t2."},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5deece232d1c254566929835","id":"t2","datatype":"594c0325fa1d2e5a1f0beda5","desc":"t2 anatomical image used for hippocampus segmentation. Must be in register with the t1."}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5e4c51a41eafff3b94fa388c","id":"output-volume","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags_pass":null,"files":null},{"datatype_tags":[],"output_on_root":false,"archive":false,"_id":"5deece232d1c254030929837","id":"output","datatype":"5e4c47041eafffca2efa3545","datatype_tags_pass":null,"files":null}],"github_branch":"master","github":"svincibo/app-ashs-segment","name":"Automated Segmentation of Hippocampal Subfields (ASHS)","avatar":"https://images.fineartamerica.com/images/artworkimages/mediumlarge/3/the-fantastic-seahorse-in-the-ocean-a-surrealist-hippocampus-horse-andreea-dumez.jpg","user_id":"126","contributors":[{"name":"Sophia Vinci-Booher","email":null,"_id":"634a37e862f3d3800f11e5a1"}],"create_date":"2019-12-09T22:43:47.156Z","desc":"brainlife.io app for using Automated Segmentation of Hippocampal Subfields (ASHS) software to segment hippocampal subfields based on previously acquired atlases","doi":"10.25663/brainlife.app.262","__v":6576,"_canedit":true},{"_id":"62a20ab1ab3e6697805fc07f","user_id":"1348","projects":[],"admins":["1348"],"name":"Average ERP (MNE)","github":"guiomar/app-average-erp","github_branch":"main","desc":null,"desc_override":"","tags":[],"contributors":[{"name":"Julia Guiomar Niso Galán","email":null,"_id":"634a44f762f3d3800f130ee2"}],"config":{"evoked":{"type":"input","file_id":"evoked","input_id":"raw01"},"duration":{"id":"duration","type":"number","placeholder":"","advanced":false,"desc":"Duration of each epoch in seconds.","default":4,"_order":2,"pid":0.201565014670672,"optional":false,"min":1,"max":100,"readonly":null}},"inputs":[{"id":"raw01","datatype":"5978fd38b09297d8d8aa8746","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"616e7fd8fc8eb9dccfff8eab"}],"outputs":[{"id":"out_dir","desc":"Epoched data (equal length)","datatype":"5978fd38b09297d8d8aa8746","datatype_tags":[],"datatype_tags_pass":"raw01","output_on_root":false,"files":null,"archive":true,"_id":"616e7fd8fc8eb9b2b3ff8eac"}],"stats":{"success_rate":99.49945593035908,"groups":8,"users":2,"runtime_mean":24796.16,"runtime_std":10354.143488207994,"requested":4709,"resources":[],"examples":0},"removed":false,"__v":288,"create_date":"2022-06-09T14:58:57.834Z","doi":"10.25663/brainlife.app.644","_canedit":true},{"_id":"61b35c3952911e175a209747","user_id":"1348","projects":[],"admins":["1348"],"name":"Average channels","github":"guiomar/app-average-channels","github_branch":"main","desc_override":"Average channels","tags":[],"config":{"psd":{"type":"input","file_id":"psd","input_id":"psd01"},"channel_list":{"id":"channel_list","type":"string","placeholder":"","advanced":false,"desc":"List of channels to average. \nExample: \n# Elekta Gradiometers\nMEG2042, MEG2043, MEG1913, MEG1912, MEG2113, MEG2112, MEG1922, MEG1923, MEG1942, MEG1943, MEG1642, MEG1643, MEG1933, MEG1932, MEG1733, MEG1732, MEG1723, MEG1722, MEG2143, MEG2142, MEG1742, MEG1743, MEG1712, MEG1713, MEG2032, MEG2033, MEG2313, MEG2312, MEG2342, MEG2343, MEG2322, MEG2323, MEG2433, MEG2432, MEG2122, MEG2123, MEG2333, MEG2332, MEG2513, MEG2512, MEG2523, MEG2522, MEG2133, MEG2132, MEG2542, MEG2543, MEG2532, MEG2533\n\n# Elekta Magnetometers\nMEG2041, MEG1911, MEG2111, MEG1921, MEG1941, MEG1641, MEG1931, MEG1731, MEG1721, MEG2141, MEG1741, MEG1711, MEG2031, MEG2311, MEG2341, MEG2321, MEG2431, MEG2121, MEG2331, MEG2511, MEG2521, MEG2131, MEG2541, MEG2531","default":"","_order":2,"pid":0.6909349974748313,"multiline":true,"optional":null},"new_name":{"id":"new_name","type":"string","placeholder":"","advanced":false,"desc":"","default":"avg_occipital","_order":3,"pid":0.7950579295523666}},"inputs":[{"id":"psd01","datatype":"60c7669e7657d98fe5e128b1","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"61b35c3952911e175a209748"}],"outputs":[{"id":"out_dir","datatype":"60c7669e7657d98fe5e128b1","datatype_tags":["avg"],"datatype_tags_pass":"psd01","output_on_root":false,"files":null,"archive":true,"_id":"61b35c3952911e175a209749"},{"id":"out_figs","datatype":"59666a40b09297d8d8271dfc","datatype_tags":["avg"],"datatype_tags_pass":"psd01","output_on_root":false,"files":null,"archive":false,"_id":"61b35c3952911e175a20974a"}],"stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a436462f3d3800f130026"},{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"634a436462f3d3800f130027"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a436462f3d3800f130028"}],"examples":2,"success_rate":90.81805912316601,"users":2,"runtime_mean":12303.39,"runtime_std":7175.335982231075,"requested":23546,"groups":3},"removed":false,"contributors":[{"name":"Julia Guiomar Niso Galán","email":null,"_id":"634a436462f3d3800f130029"}],"create_date":"2021-12-10T13:55:05.861Z","desc":null,"__v":1208,"doi":"10.25663/brainlife.app.599","_canedit":true},{"_id":"5ac39b3014f0d4002802e150","name":"BIDS Mrtrix3 Connectome","desc":"BIDS app for Mrtrix3 Connectome DTI processing for BrainLife. Generates subject connectomes from raw image data using tools provided in the *MRtrix3* software package. http://www.mrtrix.org/. Optional preprocessing includes FSL's topup analysis for spatial correction and requires at least 2 input DTI images.","citation":null,"avatar":null,"github":"kathrynalpert/app-bids-mrtrix3_connectome","github_branch":"master","config":{"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"t1":{"type":"input","file_id":"t1","input_id":"t1"},"streamlines":{"min":0,"optional":true,"default":"","desc":"The number of streamlines to generate","placeholder":"","type":"number","id":"streamlines","pid":0.3067608779332849,"_order":2},"parcellation":{"options":[{"value":"aal","label":"","desc":""},{"value":"aal2","label":"","desc":""},{"value":"fs_2005","label":"","desc":""},{"value":"fs_2009","label":"","desc":""}],"default":"aal","desc":"Connectome parcellation scheme","placeholder":"","type":"enum","id":"parcellation","pid":0.7023509861678705,"_order":3},"preprocessed":{"default":true,"desc":"Uncheck this to run mrtrix3 dwipreproc. To do so, you must have at least 2 DWI inputs and your metadata must contain both TotalReadoutTime and PhaseEncodingDirection.","placeholder":"","type":"boolean","id":"preprocessed","pid":0.09386514374150279,"_order":4}},"user_id":"121","create_date":"2018-04-03T15:18:08.438Z","removed":false,"_rate":0,"outputs":[{"datatype_tags":["mrtrix3_connectome"],"output_on_root":true,"_id":"5ac39b3014f0d4002802e151","id":"mrtrix3_connectome","datatype":"59c3eae633fc1cf9ead71679","files":{"output":"output"},"archive":true}],"inputs":[{"datatype_tags":[],"optional":false,"multi":true,"_id":"5ac39b3014f0d4002802e154","id":"dwi","datatype":"58c33c5fe13a50849b25879b"},{"datatype_tags":[],"optional":false,"multi":false,"_id":"5ac39b3014f0d4002802e152","id":"t1","datatype":"58c33bcee13a50849b25879a","desc":""}],"contributors":[{"name":null,"email":null,"_id":"634a326b62f3d3800f1174fd"}],"tags":["pipeline"],"references":[],"admins":["121"],"projects":[],"__v":14231,"stats":{"stars":1,"requested":1088,"users":14,"success_rate":44.776119402985074,"serviceinfo":{"_id":"5d729e1f78356a109788b2d5","counts":{"_id":"5e5c68a787cac7466dab1bd3","failed":141,"finished":34,"removed":555,"requested":588,"running":59,"running_sync":0,"stop_requested":2},"success_rate":19.428571428571427,"users":8,"readme_status":"no README.md","runtime_mean":20855814.44117647,"runtime_std":5221154.285834318,"service":"kathrynalpert/app-bids-mrtrix3_connectome","__v":0},"gitinfo":{"desc":"BIDS app for Mrtrix3 Connectome DTI processing for BrainLife. Generates subject connectomes from raw image data using tools provided in the *MRtrix3* software package. http://www.mrtrix.org/. Optional preprocessing includes FSL's topup analysis for spatial correction and requires at least 2 input DTI images.","tags":["pipeline"],"stats":{"stars":1},"contributors":[{"name":null,"email":null}]},"runtime_mean":22175443.37,"runtime_std":11101744.517676584,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a326a62f3d3800f1174fb"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a326a62f3d3800f1174fc"}],"examples":0,"groups":13},"doi":"10.25663/bl.app.77","_canedit":true},{"_id":"5aaffb4ec931e60132a6a4a0","name":"BIDS Tracula (under development)","desc":"BIDS app for FS Tracula for BrainLife. Implements Freesurfer's TRACULA (TRActs Constrained by UnderLying Anatomy) tool.","citation":null,"github":"soichih/app-bids-tracula","github_branch":"1.0","config":{"t1":{"type":"input","file_id":"t1","input_id":"t1"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"}},"user_id":"121","create_date":"2018-03-19T18:02:54.919Z","removed":false,"_rate":0,"outputs":[{"datatype_tags":["tracula"],"output_on_root":true,"archive":true,"_id":"5aaffb4ec931e60132a6a4a1","id":"tracula","datatype":"59c3eae633fc1cf9ead71679","files":null}],"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5aaffb4ec931e60132a6a4a6","id":"t1","datatype":"58c33bcee13a50849b25879a","desc":"T1 image"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5aaffb4ec931e60132a6a4a5","id":"dwi","datatype":"58c33c5fe13a50849b25879b","desc":"DWI image"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5aaffb4ec931e60132a6a4a2","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e"}],"contributors":[{"name":null,"email":null,"_id":"634a326262f3d3800f1174dd"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a326262f3d3800f1174de"}],"tags":[],"references":[],"admins":["16","41","146","1"],"projects":[],"__v":14236,"stats":{"stars":0,"requested":26,"users":5,"success_rate":0,"serviceinfo":{"_id":"5d729e1e78356a109788b1f7","counts":{"_id":"5e5c68a687cac70779ab1bd2","failed":11,"finished":0,"removed":9,"requested":23,"running":9,"running_sync":0,"stop_requested":1},"success_rate":0,"users":4,"readme_status":"no README.md","service":"soichih/app-bids-tracula","__v":0},"gitinfo":{"desc":"BIDS app for FS Tracula for BrainLife. Implements Freesurfer's TRACULA (TRActs Constrained by UnderLying Anatomy) tool.","tags":[],"stats":{"stars":0},"contributors":[{"name":null,"email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a326162f3d3800f1174dc"}],"examples":0,"groups":3},"doi":"10.25663/bl.app.76","_canedit":true},{"_id":"60912e1e8fe49fc00e1bbf26","stats":{"resources":[{"resource_id":"5ffc99da0df8ff7fc740c95a","name":"Bridges2 @ PSC (GPU-Shared)","_id":"634a407b62f3d3800f12d778"}],"success_rate":32.467532467532465,"users":2,"runtime_mean":387174.52,"runtime_std":95035.50390422308,"requested":79,"examples":1,"groups":3},"projects":["5a78c177340591004da75e6f","60757d37e8c7641c55e4a7e8"],"admins":["146"],"tags":[],"removed":false,"config":{"t1":{"type":"input","file_id":"t1","input_id":"t1"},"bold":{"type":"input","file_id":"bold","input_id":"fmri"},"events":{"type":"input","file_id":"events","input_id":"fmri"},"events_json":{"type":"input","file_id":"events_json","input_id":"fmri"},"sbref":{"type":"input","file_id":"sbref","input_id":"fmri"},"sbref_json":{"type":"input","file_id":"sbref_json","input_id":"fmri"},"physio":{"type":"input","file_id":"physio","input_id":"fmri"},"physio_json":{"type":"input","file_id":"physio_json","input_id":"fmri"},"thr":{"id":"thr","type":"number","placeholder":"","advanced":false,"desc":"tscores threshold to get the activation map","default":5,"_order":2,"pid":0.1267282545292432,"optional":true}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"60912e1e8fe49f38371bbf27","id":"t1","datatype":"58c33bcee13a50849b25879a","desc":"T1 anatomical"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"60912e1e8fe49f0f5d1bbf28","id":"fmri","datatype":"59b685a08e5d38b0b331ddc5","desc":"BOLD data"}],"outputs":[{"datatype_tags":["broccoli"],"output_on_root":false,"archive":true,"_id":"60912e1e8fe49f8fb91bbf29","id":"output","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null,"desc":"first-level analysis results"},{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"60a3bb7d03bcad3d657d220a","id":"figures","datatype":"5967b799b09297d8d831709e","datatype_tags_pass":null,"files":null}],"github_branch":"1.0","github":"brainlife/app-broccoli","name":"BROCCOLI (experimental)","user_id":"146","contributors":[{"name":"Giulia Bertò","email":null,"_id":"634a407b62f3d3800f12d779"}],"create_date":"2021-05-04T11:21:02.091Z","desc":"Fast fMRI analysis on many-core CPUs and GPUs.","__v":2737,"doi":"10.25663/brainlife.app.517","avatar":"https://cdn.pixabay.com/photo/2012/04/24/16/15/broccoli-40295_960_720.png","_canedit":true},{"_id":"60e605644cb704633c072687","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a414d62f3d3800f12e263"}],"success_rate":0,"users":1,"requested":1,"examples":0,"groups":1},"projects":[],"admins":["218","110","285","1"],"tags":[],"removed":false,"config":{"model_bundle":{"type":"input","file_id":"track","input_id":"model_bundle"},"rec_bundle":{"type":"input","file_id":"track","input_id":"rec_bundle"},"org_bundle":{"type":"input","file_id":"track","input_id":"org_bundle"},"measure":{"type":"input","file_id":"fa","input_id":"metric"},"    \"no_disks\": 100,":{"id":"    \"no_disks\": 100,","type":"number","placeholder":"","advanced":false,"desc":"The number of segments along the length of the tract.","default":100,"_order":2,"pid":0.4335570233287387}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"60e605644cb7043c84072688","id":"model_bundle","datatype":"5b956f6cd7b3f1e24e9121ce","desc":"Model bundle in standard space"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"60e605644cb704527f072689","id":"rec_bundle","datatype":"5b956f6cd7b3f1e24e9121ce","desc":"Subject's bundle in common space"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"60e605644cb704a0af07268a","id":"org_bundle","datatype":"5b956f6cd7b3f1e24e9121ce","desc":"Subject's bundle in native space"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"60e605644cb7044b4207268b","id":"metric","datatype":"5a79df48d071a1753f1d661b","desc":"Anatomical measures such as FA."}],"outputs":[{"datatype_tags":["csv"],"output_on_root":false,"archive":true,"_id":"60e605644cb7044e3707268c","id":"output","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null,"desc":"output directory"}],"github_branch":"single_subject","github":"BramshQamar/brainlife_buan_bundle_profile","name":"BUAN Bundle Profiles","user_id":"110","contributors":[{"name":"Bramsh Q Chandio","email":null,"_id":"634a414e62f3d3800f12e264"}],"create_date":"2021-07-07T19:49:56.970Z","desc":null,"__v":2358,"doi":"10.25663/brainlife.app.540","_canedit":true},{"_id":"5fce6ccd678a91c40249c0cd","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3e4d62f3d3800f12bac9"}],"examples":0},"projects":[],"admins":["16","218","41","285","1"],"tags":[],"removed":false,"config":{},"inputs":[],"outputs":[],"github_branch":"1.1.1","github":"brainlife/bl_apps_dipy_buan_profiles","name":"BUAN Compute Bundles Profiles ","user_id":"41","contributors":[{"name":"Bramsh Q Chandio","email":null,"_id":"634a3e4e62f3d3800f12baca"}],"create_date":"2020-12-07T17:56:29.028Z","desc":"BUAN bundle profiles ","__v":3808,"doi":"10.25663/brainlife.app.456","_canedit":true},{"_id":"5fce6bec678a91593049bfb6","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3e4462f3d3800f12bac6"}],"examples":0},"projects":[],"admins":["16","218","41","285","1"],"tags":[],"removed":false,"config":{},"inputs":[],"outputs":[],"github_branch":"1.1.1","github":"brainlife/bl_apps_dipy_buan_shapes","name":"BUAN Compute Bundles Shapes ","user_id":"41","contributors":[{"name":"Bramsh Q Chandio","email":null,"_id":"634a3e4562f3d3800f12bac7"}],"create_date":"2020-12-07T17:52:44.144Z","desc":"BUAN shape analysis App in BrainLife","__v":3809,"doi":"10.25663/brainlife.app.455","_canedit":true},{"_id":"5dbe0820fdefb1e42b771dda","stats":{"stars":0,"serviceinfo":{"_id":"5dbe1d3b62838771c9d1d0fb","counts":{"_id":"5e5c3e2187cac73b16ab143a","failed":16,"finished":18,"removed":29,"requested":47,"running":46,"running_sync":0,"stop_requested":12},"success_rate":52.94117647058824,"users":1,"readme_status":"ok","service":"davhunt/app-bayesian-retinotopy","__v":0,"runtime_mean":4759028.777777778,"runtime_std":3964010.8445363003},"success_rate":60.97560975609756,"users":1,"runtime_mean":5492316.96,"runtime_std":7835151.103487678,"requested":56,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a377462f3d3800f11e0c0"}],"examples":0,"groups":1},"projects":[],"admins":["16","283"],"tags":[],"removed":false,"config":{"output":{"type":"input","file_id":"output","input_id":"freesurfer"},"r2":{"type":"input","file_id":"r2","input_id":"prf"},"polarAngle":{"type":"input","file_id":"polarAngle","input_id":"prf"},"eccentricity":{"type":"input","file_id":"eccentricity","input_id":"prf"},"rfWidth":{"type":"input","file_id":"rfWidth","input_id":"prf"},"surfaces":{"type":"input","file_id":"surfaces","input_id":"prf"},"prf_surfs":{"type":"input","file_id":"prf_surfaces","input_id":"prf"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5dbe0820fdefb1badf771ddc","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5dbe0820fdefb12a68771ddb","id":"prf","datatype":"5d9d18d8e30ae43bb0612715"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5dbe0820fdefb12eee771ddd","id":"prf","datatype":"5d9d18d8e30ae43bb0612715","datatype_tags_pass":null,"files":null},{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5de5745e67e2941252444dcb","id":"varea","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags_pass":null,"files":null},{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5df128e82d1c25009c92b62a","id":"varea_surf","datatype":"5c478b7bf9109beac4520be6","datatype_tags_pass":null,"files":null}],"github_branch":"master","github":"davhunt/app-bayesian-retinotopy","name":"Bayesian Analysis of Retinotopic Maps","user_id":"283","contributors":[{"name":"David Hunt","email":"davhunt@iu.edu","_id":"634a377562f3d3800f11e0c1"}],"create_date":"2019-11-02T22:50:08.205Z","desc":null,"doi":"10.25663/brainlife.app.245","__v":6582,"_canedit":true},{"_id":"5a0f2dba19b13d1e190f1eeb","name":"Bias Field Correction (anat/t1w)","desc":"This application will correct for bias field issues in T1 images using ANTs N4BiasFieldCorrection algorithm","github":"kitchell/app-biasfieldcorrection","config":{"t1":{"type":"input","file_id":"t1","input_id":"0"}},"user_id":"43","create_date":"2017-11-17T18:43:06.250Z","removed":false,"_rate":0,"outputs":[{"datatype_tags":["bias_corrected"],"output_on_root":true,"archive":true,"_id":"5a0f2dba19b13d1e190f1eec","id":"0","datatype":"58c33bcee13a50849b25879a","files":null,"datatype_tags_pass":"0"},{"datatype_tags":["biasfield"],"output_on_root":true,"archive":true,"_id":"5aecd1f3f446980028b15f31","id":"bias","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":{"antscorrected":"t1ants.nii.gz","biasfield":"bias.nii.gz"}}],"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5a0f2dba19b13d1e190f1eed","id":"0","datatype":"58c33bcee13a50849b25879a"}],"contributors":[{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a318d62f3d3800f1167b4"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a318d62f3d3800f1167b5"}],"tags":["anatomy-preprocessing"],"admins":["16","41","43","1"],"projects":[],"__v":14269,"references":[],"stats":{"stars":0,"requested":312,"users":20,"success_rate":86.02150537634408,"serviceinfo":{"_id":"5d729e1f78356a109788b33b","counts":{"_id":"5e5c688f87cac7c436ab1bb7","failed":11,"finished":80,"removed":85,"requested":101,"running":91,"running_sync":0,"stop_requested":1},"success_rate":87.91208791208791,"users":10,"readme_status":"ok","runtime_mean":184480.8625,"runtime_std":331632.5116014617,"service":"kitchell/app-biasfieldcorrection","__v":0},"gitinfo":{"desc":"This application will correct for bias field issues in T1 images using ANTs N4BiasFieldCorrection algorithm","tags":["anatomy-preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":184480.8625,"runtime_std":331632.5116014617,"resources":[],"examples":0,"groups":15},"doi":"10.25663/bl.app.14","deprecated_by":"5e3c87ae9362b7166cf9c7f4","_canedit":true},{"_id":"5ae9c55df446980028b15eba","doi":"10.25663/bl.app.7","stats":{"stars":0,"requested":312,"users":20,"success_rate":86.02150537634408,"serviceinfo":{"_id":"5d729e1f78356a109788b33b","counts":{"_id":"5e5c3d9b87cac70dcaab13ab","failed":11,"finished":80,"removed":85,"requested":101,"running":91,"running_sync":0,"stop_requested":1},"success_rate":87.91208791208791,"users":10,"readme_status":"ok","runtime_mean":184480.8625,"runtime_std":331632.5116014617,"service":"kitchell/app-biasfieldcorrection","__v":0},"gitinfo":{"desc":"This application will correct for bias field issues in T1 images using ANTs N4BiasFieldCorrection algorithm","tags":["anatomy-preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":184480.8625,"runtime_std":331632.5116014617,"resources":[],"examples":0,"groups":15},"name":"Bias Field Correction (dwi)","desc":"This application will correct for bias field issues in T1 images using ANTs N4BiasFieldCorrection algorithm","citation":null,"github":"kitchell/app-biasfieldcorrection","github_branch":"dwi","config":{"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"}},"user_id":"43","create_date":"2018-05-02T14:04:13.681Z","removed":false,"outputs":[{"datatype_tags":["biasfieldcorrected"],"output_on_root":true,"archive":true,"_id":"5ae9c55df446980028b15ebb","id":"dwi","datatype":"58c33c5fe13a50849b25879b","datatype_tags_pass":"dwi","files":null},{"datatype_tags":["biasfield"],"output_on_root":true,"archive":true,"_id":"5aecd251f446980028b15f36","id":"biasfield","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":{"antscorrected":"dwiants.nii.gz","biasfield":"bias.nii.gz"}}],"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ae9c55df446980028b15ebc","id":"dwi","datatype":"58c33c5fe13a50849b25879b"}],"contributors":[{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a32a262f3d3800f117717"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a32a262f3d3800f117718"}],"tags":["anatomy-preprocessing"],"references":[],"admins":["16","41","43","1"],"projects":[],"__v":13756,"deprecated_by":"5d9e9b8a2b4f67c7b8e670b1","_canedit":true},{"_id":"5dbc9db38aeeee0c95f37020","stats":{"stars":0,"serviceinfo":null,"success_rate":88.05460750853243,"users":26,"runtime_mean":2118298.04,"runtime_std":3977244.637515472,"requested":308,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a376b62f3d3800f11e0bc"}],"examples":1,"groups":24},"projects":[],"admins":["16"],"tags":[],"removed":false,"config":{"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"prf":{"type":"input","file_id":"prf_surfaces","input_id":"prf"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5dbc9db38aeeee8b55f37022","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e","desc":"The path to the top directory containing the output from Freesurfer"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5dbc9db38aeeee984cf37021","id":"prf","datatype":"5d9d18d8e30ae43bb0612715","desc":"The path to the directory containing the surface-mapped prf files from the prf datatype"}],"outputs":[{"datatype_tags":["volThickEcc"],"output_on_root":true,"archive":true,"_id":"5dbc9db38aeeee4afcf37023","id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null,"desc":"This contains the data and figures outputted from the app"}],"github_branch":"v1.0.0","github":"brainlife/app-thickness-volume-eccentricity","name":"Bin cortical volume and thickness by eccentricity","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a376c62f3d3800f11e0bd"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a376c62f3d3800f11e0be"}],"create_date":"2019-11-01T21:03:47.863Z","desc":null,"doi":"10.25663/brainlife.app.243","__v":6251,"desc_override":"This app will bin values of cortical thickness and volume from the Freesurfer pial surface by pRF eccentricity. This app takes as input a Freesurfer segmentation and a pRF mapping and outputs both a .mat structure and graph pngs.","_canedit":true},{"_id":"592dc03eb3cd7c00211dc239","name":"Binary Tract Masks","desc":"app to generate binary masks of the segmented fiber tracts","avatar":"https://raw.githubusercontent.com/kitchell/app-generatetractmasks/master/app-generatetrackmasks.png","github":"kitchell/app-generatetractmasks","github_branch":"v3.00","config":{"T1":{"type":"input","file_id":"t1","input_id":"T1"},"classification":{"type":"input","file_id":"classification","input_id":"wmc"},"tracts":{"type":"input","file_id":"tracts","input_id":"wmc"},"track":{"type":"input","file_id":"track","input_id":"wbfg"},"threshold":{"type":"number","placeholder":"","desc":"","default":2,"id":"threshold","pid":0.8240867085482301,"_order":2},"smooth":{"default":true,"type":"boolean","id":"smooth","pid":0.2569839099382146,"_order":3},"voxelResize":{"default":0.7,"type":"number","id":"voxelResize","pid":0.5950993794790513,"_order":4}},"user_id":"43","create_date":"2017-05-30T18:55:58.823Z","outputs":[{"datatype_tags":[],"output_on_root":true,"archive":true,"_id":"592dc03eb3cd7c00211dc236","id":"output","datatype":"592dded1436ee50ffd88f5d0","files":null}],"inputs":[{"datatype_tags":["acpc_aligned"],"optional":false,"multi":false,"advanced":false,"_id":"592dc03eb3cd7c00211dc238","id":"T1","datatype":"58c33bcee13a50849b25879a"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"592dc03eb3cd7c00211dc237","id":"wmc","datatype":"5cc1d64c44947d8aea6b2d8b"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d2f869b6c03750a8a525334","id":"wbfg","datatype":"5907d922436ee50ffde9c549"}],"admins":["43","1"],"__v":14322,"_rate":5,"tags":["postprocessing"],"removed":false,"contributors":[{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a30a262f3d3800f11650b"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a30a262f3d3800f11650c"}],"projects":[],"references":[],"stats":{"stars":0,"requested":10227,"users":8,"success_rate":97.32898056091408,"serviceinfo":{"_id":"5d729e1f78356a109788b2f1","counts":{"_id":"5e5c687987cac7ba03ab1b9b","failed":158,"finished":6143,"removed":7259,"requested":9779,"running":6321,"running_sync":0,"stop_requested":65},"success_rate":97.49246151404539,"users":6,"readme_status":"ok","runtime_mean":7967674.38,"runtime_std":20064547.981120333,"service":"kitchell/app-generatetractmasks","__v":0},"gitinfo":{"desc":"app to generate binary masks of the segmented fiber tracts","tags":["postprocessing"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":1867230.15,"runtime_std":1669497.647901622,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a30a262f3d3800f11650a"}],"examples":0,"groups":7},"doi":"10.25663/brainlife.app.142","_canedit":true},{"_id":"604695d5ebfe450f303a744e","stats":{"resources":[{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"634a3f7662f3d3800f12cf38"}],"success_rate":90.69767441860465,"users":1,"runtime_mean":1427644.8717948718,"runtime_std":5580119.07053104,"requested":117,"examples":1,"groups":4},"projects":["5d64733db29ac960ca2e797f","6046775eebfe453e373a6b1a","5ff749bc41130def6518592f","60467ae9ebfe45364c3a6ed4"],"admins":["1348"],"tags":[],"removed":false,"config":{"fif":{"type":"input","file_id":"fif","input_id":"meg fif"},"channels":{"type":"input","file_id":"channels","input_id":"meg fif"},"headshape":{"type":"input","file_id":"headshape","input_id":"meg fif"},"coordsystem":{"type":"input","file_id":"coordsystem","input_id":"meg fif"},"calibration":{"type":"input","file_id":"calibration","input_id":"meg fif"},"crosstalk":{"type":"input","file_id":"crosstalk","input_id":"meg fif"},"destination":{"type":"input","file_id":"destination","input_id":"meg fif"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"604695d5ebfe454fa43a744f","id":"meg fif","datatype":"6000737faacf9ee51fa691cb"}],"outputs":[{"datatype_tags":["meg-preproc"],"output_on_root":false,"archive":true,"_id":"604695d5ebfe45c8e63a7450","id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null},{"datatype_tags":["bst_html"],"output_on_root":false,"archive":true,"_id":"604695d5ebfe4539443a7451","id":"out_dir","datatype":"5e56dc330f7fa604cc3cc291","datatype_tags_pass":null,"files":null}],"github_branch":"master","github":"guiomar/app-brainstorm-2_meg_preprocessing","name":"Brainstorm: MEG preprocessing","user_id":"1348","contributors":[{"name":"Julia Guiomar Niso Galán","email":null,"_id":"634a3f7662f3d3800f12cf39"}],"create_date":"2021-03-08T21:23:33.375Z","desc":null,"__v":3118,"doi":"10.25663/brainlife.app.488","avatar":"data:image/jpeg;base64,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","_canedit":true},{"_id":"62a7bf96ab3e66978061f0af","user_id":"16","projects":[],"admins":["16","41","1"],"name":"Bundle segmented tracks by eccentricity","github":"brainlife/app-eccentricity-classification","github_branch":"v1.0","desc":null,"tags":[],"contributors":[{"name":"Brad Caron","email":null,"_id":"634a451b62f3d3800f130f77"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a451b62f3d3800f130f78"}],"config":{"classification":{"type":"input","file_id":"classification","input_id":"wmc"},"wbFG":{"type":"input","file_id":"track","input_id":"wbFG"},"rois":{"type":"input","file_id":"rois","input_id":"rois"},"output":{"type":"input","file_id":"output","input_id":"freesurfer"},"tractNames":{"id":"tractNames","type":"string","placeholder":"","advanced":false,"desc":"name of tracts","default":"","_order":3,"pid":0.14677142331410864},"visualArea":{"id":"visualArea","type":"string","placeholder":"","advanced":false,"desc":"name of visual area ROIs with eccentricity. ex: varea","default":"","_order":4,"pid":0.6181451573171326},"MinDegree":{"id":"MinDegree","type":"string","placeholder":"","advanced":false,"desc":"","default":"0 15 30","_order":5,"pid":0.2769670251276547},"MaxDegree":{"id":"MaxDegree","type":"string","placeholder":"","advanced":false,"desc":"","default":"3 30 90","_order":6,"pid":0.6655616312232595},"operations":{"id":"operations","type":"string","placeholder":"","advanced":false,"desc":"","default":"","_order":7,"pid":0.19060724823347963}},"inputs":[{"id":"wmc","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5f74f385ed40af4c77d17ccf"},{"id":"wbFG","datatype":"5907d922436ee50ffde9c549","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d940c37f6484a0fe86a879c"},{"id":"rois","datatype":"5be9ea0315a8683a39a1ebd9","datatype_tags":["eccentricity"],"optional":false,"multi":false,"advanced":false,"_id":"5f74f35ced40afbd90d17c2f"},{"id":"freesurfer","datatype":"58cb22c8e13a50849b25882e","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"62a7bf96ab3e66978061f0b5"}],"outputs":[{"id":"classification","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags":["eccentricity"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5d940c37f6484a45006a879d"}],"stats":{"success_rate":57.03703703703704,"groups":2,"users":1,"runtime_mean":124260.07792207792,"runtime_std":143446.6022025216,"requested":191,"resources":[],"examples":0},"removed":false,"__v":264,"create_date":"2022-06-13T22:52:06.975Z","doi":"10.25663/brainlife.app.648","_canedit":true},{"_id":"5d940c37f6484af52e6a8799","stats":{"stars":0,"serviceinfo":{"_id":"5d953e85978f7c1dd0300e9a","counts":{"_id":"5e5c3e1887cac71536ab1430","failed":4,"finished":1,"removed":7,"requested":8,"running":7,"running_sync":0,"stop_requested":2},"success_rate":20,"users":1,"readme_status":"too short","runtime_mean":1288773,"runtime_std":0,"service":"brainlife/app-eccentricity-classification","__v":0},"success_rate":57.03703703703704,"users":1,"runtime_mean":124260.07792207792,"runtime_std":143446.6022025216,"requested":191,"resources":[],"examples":1,"groups":2},"projects":[],"admins":["16","41","1"],"tags":[],"removed":false,"config":{"classification":{"type":"input","file_id":"classification","input_id":"wmc"},"wbFG":{"type":"input","file_id":"track","input_id":"wbFG"},"rois":{"type":"input","file_id":"rois","input_id":"rois"},"tractNames":{"id":"tractNames","type":"string","placeholder":"","advanced":false,"desc":"name of tracts","default":"","_order":3,"pid":0.4789214323831462},"visualArea":{"id":"visualArea","type":"string","placeholder":"","advanced":false,"desc":"name of visual area ROIs with eccentricity. ex: varea","default":"","_order":4,"pid":0.8838733330925819},"MinDegree":{"id":"MinDegree","type":"string","placeholder":"","advanced":false,"desc":"","default":"0 15 30","_order":5,"pid":0.49691241533942976},"MaxDegree":{"id":"MaxDegree","type":"string","placeholder":"","advanced":false,"desc":"","default":"3 30 90","_order":6,"pid":0.6968760737801516},"operations":{"id":"operations","type":"string","placeholder":"","advanced":false,"desc":"","default":"","_order":7,"pid":0.7920415853489546}},"inputs":[{"id":"wmc","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5f74f385ed40af4c77d17ccf"},{"id":"wbFG","datatype":"5907d922436ee50ffde9c549","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d940c37f6484a0fe86a879c"},{"id":"rois","datatype":"5be9ea0315a8683a39a1ebd9","datatype_tags":["eccentricity"],"optional":false,"multi":false,"advanced":false,"_id":"5f74f35ced40afbd90d17c2f"}],"outputs":[{"id":"classification","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags":["eccentricity"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5d940c37f6484a45006a879d"}],"github_branch":"v1.0","github":"brainlife/app-eccentricity-classification","name":"Bundle segmented tracks by eccentricity - Deprecated","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a371d62f3d3800f11d460"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a371d62f3d3800f11d461"}],"create_date":"2019-10-02T02:32:23.325Z","desc":null,"doi":"10.25663/brainlife.app.232","__v":6843,"_canedit":true},{"_id":"62aa8b47ab3e6697806319ea","user_id":"16","projects":[],"admins":["16","41","1"],"name":"Bundle segmented tracks by eccentricity - Parcellation","github":"brainlife/app-eccentricity-classification","github_branch":"v1.0","desc":null,"tags":[],"contributors":[{"name":"Brad Caron","email":null,"_id":"634a452462f3d3800f130f7a"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a452462f3d3800f130f7b"}],"config":{"parc":{"type":"input","file_id":"parc","input_id":"parcellation"},"key":{"type":"input","file_id":"key","input_id":"parcellation"},"label":{"type":"input","file_id":"label","input_id":"parcellation"},"classification":{"type":"input","file_id":"classification","input_id":"wmc"},"wbFG":{"type":"input","file_id":"track","input_id":"wbFG"},"output":{"type":"input","file_id":"output","input_id":"freesurfer"},"tractNames":{"id":"tractNames","type":"string","placeholder":"","advanced":false,"desc":"name of tracts","default":"","_order":3,"pid":0.7553935908193703},"visualArea":{"id":"visualArea","type":"string","placeholder":"","advanced":false,"desc":"name of visual area ROIs with eccentricity. ex: varea","default":"","_order":4,"pid":0.6822887328776714},"MinDegree":{"id":"MinDegree","type":"string","placeholder":"","advanced":false,"desc":"","default":"0 15 30","_order":5,"pid":0.09342694686872166},"MaxDegree":{"id":"MaxDegree","type":"string","placeholder":"","advanced":false,"desc":"","default":"3 30 90","_order":6,"pid":0.758003296875531},"operations":{"id":"operations","type":"string","placeholder":"","advanced":false,"desc":"","default":"","_order":7,"pid":0.6271819111735042}},"inputs":[{"id":"parcellation","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"62aa8b47ab3e6697806319ed"},{"id":"wmc","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5f74f385ed40af4c77d17ccf"},{"id":"wbFG","datatype":"5907d922436ee50ffde9c549","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d940c37f6484a0fe86a879c"},{"id":"freesurfer","datatype":"58cb22c8e13a50849b25882e","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"62a7bf96ab3e66978061f0b5"}],"outputs":[{"id":"classification","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags":["eccentricity"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5d940c37f6484a45006a879d"}],"stats":{"success_rate":57.03703703703704,"groups":2,"users":1,"runtime_mean":124260.07792207792,"runtime_std":143446.6022025216,"requested":191,"resources":[],"examples":0},"removed":false,"__v":253,"create_date":"2022-06-16T01:45:43.405Z","doi":"10.25663/brainlife.app.649","_canedit":true},{"_id":"5f3593e84615e04651bf9364","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3c8e62f3d3800f1298ab"}],"success_rate":66.03375527426161,"users":21,"runtime_mean":10032356.97,"runtime_std":18388646.955457095,"requested":750,"examples":1,"groups":23},"projects":[],"admins":["386","16","640","41","146","1224","880","1","1223"],"tags":["analysis","closember","connectomics","fmri","hacktoberfest","mri","pipeline"],"removed":false,"config":{"t1":{"type":"input","file_id":"t1","input_id":"t1"},"bold":{"type":"input","file_id":"bold","input_id":"func"},"events":{"type":"input","file_id":"events","input_id":"func"},"events_json":{"type":"input","file_id":"events_json","input_id":"func"},"sbref":{"type":"input","file_id":"sbref","input_id":"func"},"sbref_json":{"type":"input","file_id":"sbref_json","input_id":"func"},"physio":{"type":"input","file_id":"physio","input_id":"func"},"physio_json":{"type":"input","file_id":"physio_json","input_id":"func"},"preconfig":{"id":"preconfig","type":"string","placeholder":"default","advanced":false,"desc":"For a list of and descriptions of available preconfigured pipelines, see https://fcp-indi.github.io/docs/latest/user/preconfig","default":"","_order":2,"pid":0.27745762818500963,"optional":true}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5f3593e84615e01dd7bf9365","id":"t1","datatype":"58c33bcee13a50849b25879a"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5f3593e84615e05179bf9366","id":"func","datatype":"59b685a08e5d38b0b331ddc5"}],"outputs":[{"datatype_tags":["c-pac"],"output_on_root":false,"archive":true,"_id":"5f3593e84615e0c4a4bf9367","id":"output","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null}],"github_branch":"main","github":"FCP-INDI/app-C-PAC-brainlife.io","name":"C-PAC","user_id":"880","contributors":[{"name":"Jon Clucas","email":"jon.clucas@childmind.org","_id":"634a3c9262f3d3800f1298ac"},{"name":"Olivier Lacan","email":"hi@olivierlacan.com","_id":"634a3c9262f3d3800f1298ad"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a3c9262f3d3800f1298ae"},{"name":"Xinhui Li","email":null,"_id":"634a3c9262f3d3800f1298af"},{"name":"Arthur Maltson","email":null,"_id":"634a3c9262f3d3800f1298b0"},{"name":"Nathaniel Bibler","email":null,"_id":"634a3c9262f3d3800f1298b1"},{"name":"Steve Giavasis","email":"steven.giavasis@childmind.org","_id":"634a3c9262f3d3800f1298b2"},{"name":"Emre Erkan","email":"kara@karalamalar.net","_id":"634a3c9262f3d3800f1298b3"},{"name":"Michele Castoldi","email":"azkidenz@protonmail.ch","_id":"634a3c9262f3d3800f1298b4"},{"name":"Crayon","email":null,"_id":"634a3c9262f3d3800f1298b5"},{"name":"Danny Guo","email":"danny@dannyguo.com","_id":"634a3c9262f3d3800f1298b6"},{"name":"Michael Burri","email":null,"_id":"634a3c9262f3d3800f1298b7"},{"name":null,"email":null,"_id":"634a3c9262f3d3800f1298b8"},{"name":"Magnus Österlund","email":null,"_id":"634a3c9262f3d3800f1298b9"},{"name":"Alexandr Borisov","email":"aishek@gmail.com","_id":"634a3c9262f3d3800f1298ba"},{"name":"Daniel Abrão","email":"danielpaladar@gmail.com","_id":"634a3c9262f3d3800f1298bb"},{"name":"Dhruv Bhanushali","email":"hi@dhruvkb.dev","_id":"634a3c9262f3d3800f1298bc"},{"name":"Frederik Spang","email":"fst@progras.dk","_id":"634a3c9262f3d3800f1298bd"},{"name":"Jan Havránek","email":null,"_id":"634a3c9262f3d3800f1298be"},{"name":"Juraj Kostolanský","email":"juraj@kostolansky.sk","_id":"634a3c9262f3d3800f1298bf"},{"name":"Katrin Leinweber","email":null,"_id":"634a3c9262f3d3800f1298c0"},{"name":"Lucid One","email":null,"_id":"634a3c9262f3d3800f1298c1"},{"name":"MOZGIII","email":null,"_id":"634a3c9262f3d3800f1298c2"},{"name":"Maciej Olko","email":"maciej.olko@affirm.com","_id":"634a3c9262f3d3800f1298c3"},{"name":"Serhii Osadchyi","email":"sergijlys@gmail.com","_id":"634a3c9262f3d3800f1298c4"},{"name":"Robin Schneider","email":null,"_id":"634a3c9262f3d3800f1298c5"},{"name":"Stevoisiak","email":"stevoisiak@gmail.com","_id":"634a3c9262f3d3800f1298c6"},{"name":"Webysther Sperandio","email":"webysther@gmail.com","_id":"634a3c9262f3d3800f1298c7"},{"name":null,"email":null,"_id":"634a3c9262f3d3800f1298c8"},{"name":"Roal Zanazzi","email":"roal.zanazzi@gmail.com","_id":"634a3c9262f3d3800f1298c9"}],"create_date":"2020-08-13T19:26:32.683Z","desc":"This is the official C-PAC (Configurable Pipeline for the Analysis of Connectomes) brainlife.io app. Currently this app runs either the default pipeline or one of our preconfigured pipelines.","doi":"10.25663/brainlife.app.399","__v":4179,"avatar":"https://s3.amazonaws.com/awsmp-logos/00-Childmind-5-26.jpg","_canedit":true},{"_id":"5fb2f28a7e8ecb7444aaf372","stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3e1f62f3d3800f12ba28"}],"success_rate":79.55536181342633,"users":14,"runtime_mean":4027176.53,"runtime_std":4813391.959229656,"requested":4872,"examples":2,"groups":24},"projects":[],"admins":["56","1"],"tags":[],"removed":false,"config":{"t1":{"type":"input","file_id":"t1","input_id":"t1w"}},"inputs":[{"datatype_tags":["!brain_extracted"],"optional":false,"multi":false,"advanced":false,"_id":"5fb2f28a7e8ecbf9ddaaf373","id":"t1w","datatype":"58c33bcee13a50849b25879a","desc":"This is the T1 image which will be have its subcortical regions parcellated and labeled."}],"outputs":[{"datatype_tags":["subcortical"],"output_on_root":false,"archive":true,"_id":"5fb2f28a7e8ecb2c19aaf374","id":"output","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags_pass":null,"files":null,"desc":"This is a 3D, volumetric parcellation of subcortical regions(in nifti format) of the associated input T1 image"}],"github_branch":"main","github":"brainlife/app-CIT168Parc","name":"CIT168 parcellation of human subcortical brain nuclei","user_id":"56","contributors":[{"name":"Daniel Bullock","email":"iisdanbul@gmail.com","_id":"634a3e2062f3d3800f12ba29"}],"create_date":"2020-11-16T21:43:38.723Z","desc":"A dockerized parcellation of human subcortical brain nuclei from the work of Pauli et al. 2018","doi":"10.25663/brainlife.app.449","__v":3908,"avatar":"https://raw.githubusercontent.com/brainlife/app-CIT168Parc/main/birdface.gif","_canedit":true},{"_id":"5a0261991ccc0d0041437678","name":"CONN preprocessing","desc":"fMRI preprocessing via CONN","avatar":"https://raw.githubusercontent.com/soichih/app-conn-preprocessing/master/conn.jpg","github":"soichih/app-conn-preprocessing","github_branch":"1.0","config":{"bold":{"type":"input","file_id":"bold","input_id":"0"},"t1":{"type":"input","file_id":"t1","input_id":"1"},"filter_bandpass_min":{"type":"number","placeholder":"","desc":"","default":0.01,"id":"filter_bandpass_min","pid":0.3111785030600147,"_order":2},"filter_bandpass_max":{"type":"number","placeholder":"","desc":"","default":0.1,"id":"filter_bandpass_max","pid":0.9112980068054892,"_order":3},"steps":{"type":"enum","placeholder":"","desc":"Data preprocessing steps to perform","default":"default_mni","options":[{"desc":"default MNI-space preprocessing pipeline                          'default_mniphase'                      : same as default_mni but with vdm/fieldmap information                          'default_ss'                            : default subject-space preprocessing pipe","label":"default_mni","value":"default_mni"},{"desc":"same as default_mni but with vdm/fieldmap information","label":"default_mniphase","value":"default_mniphase"},{"desc":"default subject-space preprocessing pipeline","label":"default_ss","value":"default_ss"},{"desc":"same as default_ss but with vdm/fieldmap information","label":"default_ssphase","value":"default_ssphase"},{"desc":"same as default_ss but with non-linear coregistration","label":"default_ssnl","value":"default_ssnl"}],"id":"steps","pid":0.2647300833609587,"_order":4},"sliceorder":{"type":"enum","placeholder":"","desc":"When DICOM images are converted to nifti, the slice order may not be preserved. This parameter tells CONN how slices within nifti is ordered.","default":"ascending","options":[{"desc":"Single package ascending order slices are as follows: 1, 2, 3, 4, 5... from anterior to posterior, from left to right, and from foot to head. For multiple packages, it would be slice 1, 3, 5, 7 in the first package and 2, 4, 6, 8 in the second.","label":"ascending","value":"ascending"},{"desc":"Single package descending order slices are as follows: ...5, 4, 3, 2, 1 from posterior to anterior, from right to left, and from head to foot. For multiple packages, it would be slice ...8, 6, 4, 2 in the first package and ...7, 5, 3, 1 in the second one.","label":"descending","value":"descending"},{"desc":"(todo.. explain)","label":"interleaved (middle-top)","value":"interleaved (middle-top)"},{"desc":"(todo.. explain)","label":"interleaved (bottom-up)","value":"interleaved (bottom-up)"},{"desc":"(todo.. explain)","label":"interleaved (top-down)","value":"interleaved (top-down)"},{"desc":"(todo.. explain)","label":"interleaved (Siemens)","value":"interleaved (Siemens)"},{"desc":"(not yet implemented)","label":"BIDS","value":"BIDS"}],"id":"sliceorder","pid":0.4771511334280143,"_order":5},"do_global_signal_regression":{"type":"boolean","placeholder":"","desc":"Do global signal regression","default":true,"id":"do_global_signal_regression","pid":0.4157803447801749,"_order":6},"tr":{"type":"integer","placeholder":"Repetition Time (sec)","desc":"","default":2,"id":"tr","pid":0.45158951161523886,"_order":7},"fwhm":{"type":"integer","placeholder":"Smoothing kernel","desc":"Edit me","default":8,"id":"fwhm","pid":0.4372461391696616,"_order":8}},"user_id":"1","create_date":"2017-11-08T01:44:57.046Z","removed":false,"_rate":0,"outputs":[{"datatype_tags":["conn_preprocessing"],"output_on_root":true,"archive":true,"_id":"5a0261991ccc0d0041437679","id":"0","datatype":"59c3eae633fc1cf9ead71679","files":null}],"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5a0261991ccc0d004143767b","id":"0","datatype":"59b685a08e5d38b0b331ddc5"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5a0261991ccc0d004143767a","id":"1","datatype":"58c33bcee13a50849b25879a"}],"tags":["fmri"],"admins":["16","41","146","1","119"],"projects":[],"__v":14278,"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a317b62f3d3800f116749"},{"name":"Lorenzo Pasquini","email":null,"_id":"634a317b62f3d3800f11674a"}],"references":[],"stats":{"stars":1,"requested":266,"users":22,"success_rate":92.99065420560748,"serviceinfo":{"_id":"5d729e1f78356a109788b37b","counts":{"_id":"5e5c688d87cac7b0e1ab1bb5","failed":7,"finished":155,"removed":205,"requested":213,"running":177,"running_sync":0,"stop_requested":22},"success_rate":95.67901234567901,"users":11,"readme_status":"ok","runtime_mean":5263175.37,"runtime_std":12958374.504101079,"service":"soichih/app-conn-preprocessing","__v":0},"gitinfo":{"desc":"fMRI preprocessing via CONN","tags":["fmri-preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Lorenzo Pasquini","email":null}]},"runtime_mean":5518665.9,"runtime_std":15554406.820722286,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a317b62f3d3800f116748"}],"examples":1,"groups":16},"doi":"10.25663/bl.app.54","deprecated_by":"5c61c69f14027a01b14adcb3","_canedit":true},{"_id":"5a4fb3d1fdf677004993ee18","name":"Check DWI Orientation","desc":"This application checks and reports the orientation (neurological or radiological) of a nifti file.","citation":null,"avatar":"http://nipy.org/nibabel/_images/rorden_radio_neuro.jpg","github":"brainlife/app-checkOrientation","config":{"input":{"type":"input","file_id":"dwi","input_id":"0"}},"user_id":"43","create_date":"2018-01-05T17:20:17.711Z","removed":false,"_rate":0,"outputs":[{"datatype_tags":["orientation","dwi"],"output_on_root":true,"archive":true,"_id":"5a4fb3d1fdf677004993ee19","id":"0","datatype":"59c3eae633fc1cf9ead71679","files":null}],"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5a4fb3d1fdf677004993ee1a","id":"0","datatype":"58c33c5fe13a50849b25879b"}],"contributors":[{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a31b962f3d3800f1168ad"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a31b962f3d3800f1168ae"}],"tags":["qa"],"references":[],"admins":["16","41","146","43","1"],"projects":[],"__v":14262,"stats":{"stars":0,"requested":1568,"users":9,"success_rate":97.33009708737865,"serviceinfo":{"_id":"5d729e1f78356a109788b2fb","counts":{"_id":"5e5c689487cac78ea9ab1bbd","failed":10,"finished":238,"removed":252,"requested":296,"running":249,"running_sync":0,"stop_requested":8},"success_rate":95.96774193548387,"users":24,"readme_status":"too short","runtime_mean":1629653.97,"runtime_std":6945459.606330997,"service":"brain-life/app-checkOrientation","__v":0},"gitinfo":{"desc":"This application checks and reports the orientation (neurological or radiological) of a nifti file.","tags":["quality-check"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null}]},"runtime_mean":585518.52,"runtime_std":831877.6599616494,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a31b962f3d3800f1168ac"}],"examples":0,"groups":12},"doi":"10.25663/bl.app.20","_canedit":true},{"_id":"5b58b3f3786e0f002791d384","projects":[],"admins":["16","41","146","1"],"tags":["qa"],"removed":false,"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5b58b3f3786e0f002791d385","id":"dwi","datatype":"58c33c5fe13a50849b25879b"}],"outputs":[],"name":"Check Gradient Flip","github":"brainlife/app-testflip","user_id":"1","references":[],"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a337e62f3d3800f117f96"}],"create_date":"2018-07-25T17:31:31.023Z","desc":"This app will quickly check the dwi image to see if any bvecs directions needs to be flipped. The algorithm finds bvecs that are pointing toward certain direction and find the volume slice within 4D DWI data and see how many image slices indeed seems to contain features that are orthogonal to the bvecs directions. Inconclusive output from this App usually means you have some data quality issue with your dwi.","stats":{"stars":0,"requested":168,"users":8,"success_rate":96.81528662420382,"serviceinfo":{"_id":"5d729e1f78356a109788b279","counts":{"_id":"5e5c3db487cac7d77fab13c6","failed":14,"finished":118,"removed":113,"requested":143,"running":133,"running_sync":0,"stop_requested":1},"success_rate":89.39393939393939,"users":16,"readme_status":"ok","runtime_mean":5599684,"runtime_std":23684325.233460553,"service":"brain-life/app-testflip","__v":0},"gitinfo":{"desc":"This app will quickly check the dwi image to see if any bvecs directions needs to be flipped. The algorithm finds bvecs that are pointing toward certain direction and find the volume slice within 4D DWI data and see how many image slices indeed seems to contain features that are orthogonal to the bvecs directions. Inconclusive output from this App usually means you have some data quality issue with your dwi.","tags":["quality-check"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":1571132.49,"runtime_std":9388518.642642489,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a337e62f3d3800f117f95"}],"examples":4,"groups":17},"doi":"10.25663/bl.app.85","__v":11792,"github_branch":"1.3","avatar":"https://raw.githubusercontent.com/brain-life/app-testflip/master/img/testflip.png","_canedit":true},{"_id":"5a4e8622e7a2ee0035d0b8e3","name":"Check T1 Orientation","desc":"This application checks and reports the orientation (neurological or radiological) of a nifti file.","citation":null,"avatar":"http://nipy.org/nibabel/_images/rorden_radio_neuro.jpg","github":"brainlife/app-checkOrientation","config":{"input":{"type":"input","file_id":"t1","input_id":"0"}},"user_id":"43","create_date":"2018-01-04T19:53:06.862Z","removed":false,"_rate":0,"outputs":[{"datatype_tags":["orientation","t1"],"output_on_root":true,"archive":true,"_id":"5a4e8622e7a2ee0035d0b8e4","id":"0","datatype":"59c3eae633fc1cf9ead71679","files":null}],"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5a4e8622e7a2ee0035d0b8e5","id":"0","datatype":"58c33bcee13a50849b25879a"}],"contributors":[{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a31b062f3d3800f116886"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a31b062f3d3800f116887"}],"tags":["qa"],"references":[],"admins":["16","41","146","43","1"],"projects":[],"__v":14262,"stats":{"stars":0,"requested":1568,"users":9,"success_rate":97.33009708737865,"serviceinfo":{"_id":"5d729e1f78356a109788b2fb","counts":{"_id":"5e5c689387cac72649ab1bbc","failed":10,"finished":238,"removed":252,"requested":296,"running":249,"running_sync":0,"stop_requested":8},"success_rate":95.96774193548387,"users":24,"readme_status":"too short","runtime_mean":1629653.97,"runtime_std":6945459.606330997,"service":"brain-life/app-checkOrientation","__v":0},"gitinfo":{"desc":"This application checks and reports the orientation (neurological or radiological) of a nifti file.","tags":["quality-check"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null}]},"runtime_mean":585518.52,"runtime_std":831877.6599616494,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a31b062f3d3800f116885"}],"examples":2,"groups":12},"doi":"10.25663/bl.app.19","_canedit":true},{"_id":"5a50fa17fdf677004993ee23","name":"Check dtiInit Orientation","desc":"This application checks and reports the orientation (neurological or radiological) of a nifti file.","citation":null,"avatar":"http://nipy.org/nibabel/_images/rorden_radio_neuro.jpg","github":"brainlife/app-checkOrientation","github_branch":"dtiinit","config":{"dtiinit":{"type":"input","file_id":"output","input_id":"0"}},"user_id":"43","create_date":"2018-01-06T16:32:23.037Z","removed":false,"_rate":0,"outputs":[{"datatype_tags":["orientation","dtiinit"],"output_on_root":true,"archive":true,"_id":"5a50fb4706b9e8003f1ee682","id":"0","datatype":"59c3eae633fc1cf9ead71679","files":null}],"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5a50fa17fdf677004993ee24","id":"0","datatype":"58cb234be13a50849b25882f"}],"contributors":[{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a31c262f3d3800f1168b1"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a31c262f3d3800f1168b2"}],"tags":["qa"],"references":[],"admins":["16","41","146","43","1"],"projects":[],"__v":14261,"stats":{"stars":0,"requested":1568,"users":9,"success_rate":97.33009708737865,"serviceinfo":{"_id":"5d729e1f78356a109788b2fb","counts":{"_id":"5e5c689487cac7088aab1bbe","failed":10,"finished":238,"removed":252,"requested":296,"running":249,"running_sync":0,"stop_requested":8},"success_rate":95.96774193548387,"users":24,"readme_status":"too short","runtime_mean":1629653.97,"runtime_std":6945459.606330997,"service":"brain-life/app-checkOrientation","__v":0},"gitinfo":{"desc":"This application checks and reports the orientation (neurological or radiological) of a nifti file.","tags":["quality-check"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null}]},"runtime_mean":585518.52,"runtime_std":831877.6599616494,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a31c262f3d3800f1168b0"}],"examples":0,"groups":12},"doi":"10.25663/bl.app.21","_canedit":true},{"_id":"5d6fcae439867216d8496442","projects":[],"admins":["146"],"tags":[],"removed":false,"stats":{"stars":2,"serviceinfo":{"_id":"5e3b5bba3b3f0a0c99d7d0a2","counts":{"_id":"5e5c3e1487cac7ec9aab142c","failed":30,"finished":30,"removed":3,"requested":84,"running":85,"running_sync":0,"stop_requested":24},"success_rate":50,"users":1,"readme_status":"ok","service":"FBK-NILab/app-classifyber","__v":0,"runtime_mean":22420538.133333333,"runtime_std":20062322.87835786},"gitinfo":{"desc":"Linear classification of single streamlines.","tags":[],"stats":{"stars":0},"contributors":[{"name":"Giulia Bertò","email":null}]},"success_rate":46.26865671641791,"users":4,"runtime_mean":23490576.48387097,"runtime_std":20587921.063224338,"requested":94,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a370062f3d3800f11d31c"},{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a370062f3d3800f11d31d"}],"examples":0,"groups":4},"config":{"tractogram_static":{"type":"input","file_id":"track","input_id":"0"},"t1_static":{"type":"input","file_id":"t1","input_id":"1"},"segmentations":{"type":"input","file_id":"classification","input_id":"2"},"tracts":{"type":"input","file_id":"tracts","input_id":"2"},"tractograms_moving":{"type":"input","file_id":"track","input_id":"3"},"t1s_moving":{"type":"input","file_id":"t1","input_id":"4"},"tractID_list":{"id":"tractID_list","type":"string","placeholder":"allowed values: 1-20 (if AFQ examples provided), 38-45 (if WMA examples provided)","desc":"ID list of the bundles of interest, separated by commas (refer to the README.md for the mapping)","default":"","_order":7,"pid":0.8607518797109572}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d14bc062daec10035f3f873","id":"0","datatype":"5907d922436ee50ffde9c549","desc":"Tractogram of static (target) subject"},{"datatype_tags":["acpc_aligned"],"optional":false,"multi":false,"advanced":false,"_id":"5d14bc062daec10035f3f872","id":"1","datatype":"58c33bcee13a50849b25879a","desc":"T1 of static (target) subject"},{"datatype_tags":[],"optional":false,"multi":true,"advanced":false,"_id":"5d14bc062daec10035f3f871","id":"2","datatype":"5cc1d64c44947d8aea6b2d8b","desc":"Segmentations of moving (examples) subjects (they should be extracted from the tractogram provided)"},{"datatype_tags":[],"optional":false,"multi":true,"advanced":false,"_id":"5d14bc062daec10035f3f870","id":"3","datatype":"5907d922436ee50ffde9c549","desc":"Tractograms of moving (example) subjects"},{"datatype_tags":["acpc_aligned"],"optional":false,"multi":true,"advanced":false,"_id":"5d14bc062daec10035f3f86f","id":"4","datatype":"58c33bcee13a50849b25879a","desc":"Ts1 of moving (example) subjects"}],"outputs":[{"datatype_tags":["classifyber"],"output_on_root":false,"archive":true,"_id":"5d14bc062daec10035f3f874","id":"output_wmc","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags_pass":"2","files":null}],"github_branch":"1.0","github":"FBK-NILab/app-classifyber","name":"Classifyber","user_id":"146","contributors":[{"name":"Giulia Bertò","email":null,"_id":"634a370162f3d3800f11d31e"}],"desc":"Linear classification of single streamlines.","__v":7012,"create_date":"2019-09-04T14:32:04.629Z","doi":"10.25663/brainlife.app.228","avatar":"https://github.com/FBK-NILab/app-classifyber/blob/master/app-classifyber-avatar.png?raw=true","desc_override":"Code of Classifyber, a robust streamline-based linear classifier for white matter bundle segmentation.","_canedit":true},{"_id":"5df937ff32bff0566ae23cff","projects":[],"admins":["146"],"tags":["segmentation","white-matter-segmentation"],"removed":false,"stats":{"stars":1,"serviceinfo":{"_id":"5e4496d545e14842a4f7a7d2","counts":{"_id":"5e5c3e3287cac7792bab1448","failed":4,"finished":7,"removed":1,"requested":12,"running":12,"running_sync":0,"stop_requested":1},"success_rate":63.63636363636363,"users":3,"readme_status":"ok","runtime_mean":1102862.7142857143,"runtime_std":525790.412974522,"service":"FBK-NILab/app-classifyber-segmentation","__v":0},"gitinfo":{"desc":"Linear classification of single streamlines.","tags":[],"stats":{"stars":0},"contributors":[{"name":"Giulia Bertò","email":null}]},"success_rate":71.48148148148148,"users":16,"runtime_mean":4984131.95,"runtime_std":5242932.53837804,"requested":310,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a380362f3d3800f11e697"},{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a380362f3d3800f11e698"}],"examples":2,"groups":22},"config":{"tractogram_static":{"type":"input","file_id":"track","input_id":"0"},"t1_static":{"type":"input","file_id":"t1","input_id":"1"},"tractID_list":{"id":"tractID_list","type":"string","placeholder":"allowed values: from 21 to 30, from 32 to 33, from 35 to 36, and from 38 to 45","desc":"ID list of the bundles of interest, separated by commas, e.g. 32, 40, 45  (refer to the README.md for the mapping)","default":"","_order":7,"pid":0.9937675063745659}},"inputs":[{"id":"0","desc":"Tractogram of static (target) subject","datatype":"5907d922436ee50ffde9c549","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d14bc062daec10035f3f873"},{"id":"1","desc":"T1 of static (target) subject","datatype":"58c33bcee13a50849b25879a","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d14bc062daec10035f3f872"}],"outputs":[{"id":"output_wmc","desc":"Segmented bundles in wmc format","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags":["classifyber"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5d14bc062daec10035f3f874"},{"id":"output","desc":"segmented bundles in tck format","datatype":"5dcf0047c4ae28d7f2298f48","datatype_tags":["classifyber"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5e624f4482b37fe550901f73"}],"github_branch":"1.3","github":"FBK-NILab/app-classifyber-segmentation","name":"Classifyber - segmentation","user_id":"146","contributors":[{"name":"Giulia Bertò","email":null,"_id":"634a380362f3d3800f11e699"}],"desc":"Code to run Classifyber as a pre-trained bundle segmentation method.","__v":6512,"create_date":"2019-12-17T20:18:07.079Z","doi":"10.25663/brainlife.app.265","avatar":"https://github.com/FBK-NILab/app-classifyber-segmentation/blob/master/app-classifyber-segmentation-avatar.png?raw=true","_canedit":true},{"_id":"597f8c463a37c7002e39bf77","name":"Clean WMC output","desc":"(deprecated by Remove Tract Outliers App) This service cleans the output from AFQ and WMA using AFQ's AFQ_removeFiberOutliers function. For more information on the inputs of this application, please read the documentation at the top of the function: https://github.com/yeatmanlab/AFQ/blob/master/functions/AFQ_removeFiberOutliers.m","avatar":"https://raw.githubusercontent.com/kitchell/app-AFQclean/master/app-cleanafq.png","github":"brainlife/app-AFQclean","github_branch":"1.4","config":{"afq_fg":{"type":"input","file_id":"output","input_id":"AFQ"},"maxiter":{"default":5,"type":"integer","id":"maxiter","pid":0.511597475249816,"_order":2},"numnodes":{"default":100,"type":"integer","id":"numnodes","pid":0.41158325142225083,"_order":3},"maxlen":{"default":4,"type":"integer","id":"maxlen","pid":0.41334742422053616,"_order":4},"maxdist":{"default":4,"type":"integer","id":"maxdist","pid":0.28340927139132654,"_order":5},"M":{"desc":"Select method for representing the center of the tract","type":"enum","default":"mean","options":[{"value":"mean","label":"Mean","desc":"Use the mean to represent the center of the tract"},{"value":"median","label":"Median","desc":"Use the median to represent the center of the tract"}],"id":"M","pid":0.6256094581826812,"_order":6}},"user_id":"43","create_date":"2017-07-31T20:00:06.462Z","removed":false,"_rate":5,"outputs":[{"datatype_tags":["cleaned"],"output_on_root":true,"archive":true,"_id":"597f8c463a37c7002e39bf78","id":"output","datatype":"58f10a90436ee50ffd9063c5","files":null,"datatype_tags_pass":"AFQ"}],"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"597f8c463a37c7002e39bf79","id":"AFQ","datatype":"58f10a90436ee50ffd9063c5"}],"tags":["postprocessing"],"admins":["16","56","41","146","43","1"],"__v":14304,"contributors":[{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a310562f3d3800f11655a"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a310562f3d3800f11655b"},{"name":"Steven O'Riley","email":null,"_id":"634a310562f3d3800f11655c"},{"name":"Franco Pestilli","email":null,"_id":"634a310562f3d3800f11655d"}],"projects":[],"references":[],"stats":{"stars":0,"serviceinfo":{"_id":"5d729e1e78356a109788b209","counts":{"_id":"5e5c688287cac7c174ab1ba8","failed":627,"finished":3584,"removed":3926,"requested":4382,"running":4023,"running_sync":0,"stop_requested":25},"success_rate":85.11042507717882,"users":7,"readme_status":"too short","runtime_mean":1411358.6,"runtime_std":1492658.6931826174,"service":"brainlife/app-AFQclean","__v":0},"gitinfo":{"desc":"(deprecated by Remove Tract Outliers App) This service cleans the output from AFQ and WMA using AFQ's AFQ_removeFiberOutliers function. For more information on the inputs of this application, please read the documentation at the top of the function: https://github.com/yeatmanlab/AFQ/blob/master/functions/AFQ_removeFiberOutliers.m","tags":["postprocessing"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Steven O'Riley","email":null},{"name":"Franco Pestilli","email":null}]},"success_rate":85.11042507717882,"users":7,"runtime_mean":1411358.6,"runtime_std":1492658.6931826174,"requested":4382,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a310562f3d3800f116559"}],"examples":0,"groups":2},"doi":"10.25663/bl.app.11","deprecated_by":"5c59dc65464fde003639ebb2","_canedit":true},{"_id":"6091fb348fe49f74c01c20ed","stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a408462f3d3800f12d789"}],"success_rate":16.666666666666664,"users":1,"runtime_mean":1576384,"runtime_std":1565256,"requested":18,"examples":1,"groups":1},"projects":[],"admins":["16"],"tags":[],"removed":false,"config":{"parcellation":{"type":"input","file_id":"parc","input_id":"parc"},"key":{"type":"input","file_id":"key","input_id":"parc"},"labels":{"type":"input","file_id":"label","input_id":"parc"},"discard_labels":{"id":"discard_labels","type":"string","placeholder":"","advanced":false,"desc":"Labels you wish to remove. Corresponds to the voxel value found in the label.json of the original parcellation\n\nEx. \"1 181\"","default":"","_order":2,"pid":0.713580879175093}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"6091fb348fe49fd9201c20ee","id":"parc","datatype":"5c1a7489f9109beac4a88a1f"}],"outputs":[{"datatype_tags":["cleaned"],"output_on_root":false,"archive":true,"_id":"6091fb348fe49f8a361c20ef","id":"output","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags_pass":"parc","files":null,"desc":"This parcellation will have missing and unwanted parcels removed from the parcellation. This will help with network generation and summary statistics"}],"github_branch":"v1.0","github":"brainlife/app-clean-parcellation","name":"Clean parcellations","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a408462f3d3800f12d78a"}],"create_date":"2021-05-05T01:56:04.722Z","desc":null,"__v":2724,"doi":"10.25663/brainlife.app.518","_canedit":true},{"_id":"629e58a57f60950a54d386d2","user_id":"1447","projects":[],"admins":["1447"],"name":"Clustering edge time series","github":"FarnazZE/bnbl-brainlife-clustering-edge-time-series","github_branch":"main","tags":[],"config":{"tsv":{"type":"input","file_id":"tsv","input_id":"ts"},"json":{"type":"input","file_id":"json","input_id":"ts"},"nclus":{"id":"nclus","type":"number","placeholder":"","advanced":false,"desc":"number of clusters","default":5,"_order":2,"pid":0.14963105204375537,"min":2}},"inputs":[{"id":"ts","datatype":"604a4553ebfe4559de3af944","datatype_tags":["time series"],"optional":false,"multi":false,"advanced":false,"_id":"629e58a57f60950a54d386d3"}],"outputs":[{"id":"output","datatype":"606345ade4a8347b6f337de4","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"629e58a57f60950a54d386d4"}],"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a44e462f3d3800f130edd"}],"users":1,"groups":1,"requested":4,"examples":1,"success_rate":33.33333333333333,"runtime_mean":32563,"runtime_std":0},"removed":false,"contributors":[{"name":"Farnaz Zamani Esfahlani","email":null,"_id":"634a44e562f3d3800f130ede"}],"create_date":"2022-06-06T19:42:29.836Z","desc":null,"__v":297,"doi":"10.25663/brainlife.app.642","_canedit":true},{"_id":"5f73a86a0a320c3226112026","stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3da262f3d3800f12af45"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3da262f3d3800f12af46"}],"success_rate":1.9024970273483945,"users":6,"runtime_mean":192642.9375,"runtime_std":261323.4194445335,"requested":844,"examples":1,"groups":8},"projects":[],"admins":["16"],"tags":[],"removed":false,"config":{"tractmeasures":{"type":"input","file_id":"tractmeasures","input_id":"tractmeasures"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":true,"advanced":false,"_id":"5f73a86a0a320c8c4d112027","id":"tractmeasures","datatype":"5f6aa135cfa3656ab4c9e245"}],"outputs":[{"datatype_tags":["compiled"],"output_on_root":false,"archive":true,"_id":"5f73a86a0a320ccbd3112028","id":"tractmeasures","datatype":"5f6aa135cfa3656ab4c9e245","datatype_tags_pass":null,"files":null}],"github_branch":"tracts-v1.0","github":"brainlife/app-compile-tractmeasures","name":"Compile measures from dsistudio tractmeasures datatype","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3da262f3d3800f12af47"}],"create_date":"2020-09-29T21:34:34.069Z","desc":null,"doi":"10.25663/brainlife.app.436","__v":4148,"_canedit":true},{"_id":"5f6ce9c96bbee3b9469a3127","stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3d7c62f3d3800f12a59b"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3d7c62f3d3800f12a59c"}],"success_rate":1.9024970273483945,"users":6,"runtime_mean":192642.9375,"runtime_std":261323.4194445335,"requested":844,"examples":1,"groups":8},"projects":[],"admins":["16"],"tags":[],"removed":false,"config":{"tractmeasures":{"type":"input","file_id":"tractmeasure","input_id":"tractmeasures"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":true,"advanced":false,"_id":"5f6ce9c96bbee3cc549a3128","id":"tractmeasures","datatype":"5f6bf981cfa36596f6ca7dd4"}],"outputs":[{"datatype_tags":["compiled"],"output_on_root":false,"archive":true,"_id":"5f6ce9c96bbee3810e9a3129","id":"tractmeasures","datatype":"5f6bf981cfa36596f6ca7dd4","datatype_tags_pass":"tractmeasures","files":null}],"github_branch":"qc-v1.0","github":"brainlife/app-compile-tractmeasures","name":"Compile qc data from tractmeasures (tsv) data","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3d7c62f3d3800f12a59d"}],"create_date":"2020-09-24T18:47:37.341Z","desc":null,"doi":"10.25663/brainlife.app.432","__v":4151,"_canedit":true},{"_id":"5f31b6d18a0b7ab423cc7683","stats":{"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"634a3c8562f3d3800f129806"},{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"634a3c8562f3d3800f129807"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3c8562f3d3800f129808"}],"success_rate":89.57334611697027,"users":11,"runtime_mean":27482.09,"runtime_std":15806.349915837622,"requested":9308,"examples":5,"groups":23},"projects":[],"admins":["16"],"tags":[],"removed":false,"config":{"profiles":{"type":"input","file_id":"csv","input_id":"profiles"},"macro":{"type":"input","file_id":"csv","input_id":"macro"}},"inputs":[{"datatype_tags":["profiles"],"optional":false,"multi":false,"advanced":false,"_id":"5f31b6d18a0b7aca97cc7684","id":"profiles","datatype":"599f305ad1f46fec1759f363"},{"datatype_tags":["!profiles","!macro_micro"],"optional":false,"multi":false,"advanced":false,"_id":"5f31b6d18a0b7a5375cc7685","id":"macro","datatype":"599f305ad1f46fec1759f363"}],"outputs":[{"datatype_tags":["macro_micro"],"output_on_root":false,"archive":true,"_id":"5f31b6d18a0b7a7397cc7686","id":"tractmeasures","datatype":"599f305ad1f46fec1759f363","datatype_tags_pass":null,"files":null}],"github_branch":"v1.1","github":"brainlife/app-compile-macro-micro-tract-stats","name":"Compile tract macro-structural and profile data","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3c8562f3d3800f129809"}],"create_date":"2020-08-10T21:06:25.229Z","desc":null,"doi":"10.25663/brainlife.app.397","__v":4188,"_canedit":true},{"_id":"5eed6986d39ceb4bd5a0efde","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3c1862f3d3800f127c28"}],"success_rate":84.47488584474885,"users":4,"runtime_mean":91287.58,"runtime_std":153553.7515613461,"requested":287,"examples":1,"groups":6},"projects":[],"admins":["16"],"tags":[],"removed":false,"config":{"profiles":{"type":"input","file_id":"profiles","input_id":"profiles"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5eed6986d39ceb17aba0efdf","id":"profiles","datatype":"5965467cb09297d8d81bdbcd","desc":"The path to the top directory containing the tract profile .csv files"}],"outputs":[{"datatype_tags":["profiles"],"output_on_root":false,"archive":true,"_id":"5eed6986d39ceb605da0efe0","id":"tractmeasures","datatype":"599f305ad1f46fec1759f363","datatype_tags_pass":"profiles","files":null,"desc":"The output is a combined version of the inputted .csvs file into a single .csv file analyses"}],"github_branch":"v1.1","github":"brainlife/app-compile-tract-profiles","name":"Compile tract profiles to summary structure","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3c1962f3d3800f127c29"},{"name":"Franco Pestilli","email":null,"_id":"634a3c1962f3d3800f127c2a"}],"create_date":"2020-06-20T01:42:30.566Z","desc":null,"doi":"10.25663/brainlife.app.384","__v":4590,"desc_override":"This app will the individual tract tract profiles csv’s from the tractprofile dataype into a single summary csv for group analysis and machine learning. This app takes in a tractprofile datatype. The app will output a csv entitled ‘tracts.csv’ that can be used for group statistics and machine learning.","_canedit":true},{"_id":"63471bcbfa262bbde2ac4a73","user_id":"16","projects":[],"admins":["16"],"name":"Compile tractmeasures csvs across project into one dataframe","github":"brainlife/app-compile-tractmeasures","github_branch":"tractmeasures-non-dsistudio-v1.0","tags":[],"config":{"csv":{"type":"input","file_id":"csv","input_id":"tractmeasures"}},"inputs":[{"id":"tractmeasures","datatype":"599f305ad1f46fec1759f363","datatype_tags":[],"optional":false,"multi":true,"advanced":false,"_id":"63471bcbfa262bbde2ac4a74"}],"outputs":[{"id":"output","datatype":"599f305ad1f46fec1759f363","datatype_tags":["group_analysis"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"63471bcbfa262bbde2ac4a75"}],"stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a465562f3d3800f131634"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a465562f3d3800f131635"}],"success_rate":1.9024970273483945,"users":6,"groups":8,"runtime_mean":192642.9375,"runtime_std":261323.4194445335,"requested":844,"examples":1},"removed":false,"contributors":[{"name":"Brad Caron","email":null,"_id":"634a465662f3d3800f131636"}],"create_date":"2022-10-12T19:55:55.820Z","desc":null,"__v":6,"doi":"10.25663/brainlife.app.683","_canedit":true},{"_id":"5eea7b12d39cebfb5ca08df0","stats":{"resources":[],"success_rate":87.87878787878788,"users":1,"runtime_mean":6516969.5344827585,"runtime_std":10713287.969975939,"requested":78,"examples":1,"groups":3},"projects":[],"admins":["16"],"tags":[],"removed":false,"config":{"brainmask":{"type":"input","file_id":"mask","input_id":"brainmask"},"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"}},"inputs":[{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5eea7b12d39ceb16b3a08df1","id":"brainmask","datatype":"5a281aee2c214c9ba83ce620"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5eea7b12d39cebb8faa08df2","id":"dwi","datatype":"58c33c5fe13a50849b25879b"}],"outputs":[{"datatype_tags":["tSNR"],"output_on_root":false,"archive":true,"_id":"5eea7b12d39cebdd2ba08df3","id":"outdir","datatype":"60ca4e7e8b8b725ea44295bc","datatype_tags_pass":"dwi","files":null},{"datatype_tags":["tSNR_derivatives"],"output_on_root":false,"archive":true,"_id":"5eea7b12d39cebb31fa08df4","id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":"dwi","files":null}],"github_branch":"v1.0","github":"brainlife/app-compute-temporal-snr","name":"Compute  tSNR of DMRI Images","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3bd462f3d3800f1268c9"}],"create_date":"2020-06-17T20:20:34.790Z","desc":null,"doi":"10.25663/brainlife.app.378","__v":4607,"_canedit":true},{"_id":"63028e6f19b13f0a0ee0a35c","user_id":"16","projects":[],"admins":["16"],"name":"Compute Network Backbone","github":"brainlife/app-network-backbone","github_branch":"v1.0","tags":[],"config":{"network":{"type":"input","file_id":"network","input_id":"network"},"alpha":{"id":"alpha","type":"number","placeholder":"","advanced":false,"desc":"This is the threshold value for identifying the \"backbone\" nodes\"","default":0.05,"_order":2,"pid":0.8528296124655641}},"inputs":[{"id":"network","datatype":"5ed0352de3f453b13b267dae","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"63028e6f19b13f0a0ee0a35d"}],"outputs":[{"id":"output","datatype":"5ed0352de3f453b13b267dae","datatype_tags":["backbone"],"datatype_tags_pass":"network","output_on_root":false,"files":null,"archive":true,"_id":"63028e6f19b13f0a0ee0a35e"}],"stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a45b662f3d3800f1311b7"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a45b662f3d3800f1311b8"}],"success_rate":99.73359973359973,"users":1,"groups":4,"runtime_mean":11797.99,"runtime_std":4696.903255326855,"requested":3160,"examples":1},"removed":false,"contributors":[{"name":"Brad Caron","email":null,"_id":"634a45b762f3d3800f1311b9"}],"create_date":"2022-08-21T19:58:39.061Z","desc":"Compute the backbone network from a structural or functional connectivity network","__v":23,"doi":"10.25663/brainlife.app.665","_canedit":true},{"_id":"626eacabcbc76827b7188b93","user_id":"16","projects":[],"admins":["16"],"name":"Compute Peaks from Spherical Harmonic (SH) data","github":"brainlife/app-sh2peaks","github_branch":"v1.0","tags":[],"config":{"response":{"type":"input","file_id":"response","input_id":"csd"},"lmax2":{"type":"input","file_id":"lmax2","input_id":"csd"},"lmax4":{"type":"input","file_id":"lmax4","input_id":"csd"},"lmax6":{"type":"input","file_id":"lmax6","input_id":"csd"},"lmax8":{"type":"input","file_id":"lmax8","input_id":"csd"},"lmax10":{"type":"input","file_id":"lmax10","input_id":"csd"},"lmax12":{"type":"input","file_id":"lmax12","input_id":"csd"},"lmax14":{"type":"input","file_id":"lmax14","input_id":"csd"},"lmax":{"id":"lmax","type":"number","placeholder":"","advanced":false,"desc":"","default":8,"_order":2,"pid":0.9942922331301086},"num_peaks":{"id":"num_peaks","type":"number","placeholder":"","advanced":true,"desc":"","default":3,"_order":3,"pid":0.497405598251748},"threshold":{"id":"threshold","type":"number","placeholder":"","advanced":true,"desc":"","default":0,"_order":4,"pid":0.7196090234973297},"fast":{"id":"fast","type":"boolean","placeholder":"","advanced":true,"desc":"","default":false,"_order":5,"pid":0.7664106655352811}},"inputs":[{"id":"csd","datatype":"5c536bf0f9109beac46adb45","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"626eacabcbc76827b7188b94"}],"outputs":[{"id":"peaks","datatype":"5c9276dc44947d8aea7d6454","datatype_tags":[],"datatype_tags_pass":"csd","output_on_root":false,"files":null,"archive":true,"_id":"626eacabcbc76827b7188b95"}],"stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a444262f3d3800f130de0"}],"examples":1,"success_rate":56.930693069306926,"users":2,"groups":2,"runtime_mean":11444.81,"runtime_std":2517.4815816406694,"requested":216},"removed":false,"contributors":[{"name":"Brad Caron","email":null,"_id":"634a444262f3d3800f130de1"}],"create_date":"2022-05-01T15:52:11.583Z","desc":null,"__v":293,"doi":"10.25663/brainlife.app.623","_canedit":true},{"_id":"5bca308550fdf50028c6342c","projects":[],"admins":["16","283"],"tags":[],"removed":false,"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5bca308550fdf50028c6342d","id":"dwi","datatype":"58c33c5fe13a50849b25879b"}],"outputs":[{"datatype_tags":["snr-cc"],"output_on_root":true,"archive":true,"_id":"5bca308550fdf50028c6342e","id":"output","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null},{"datatype_tags":["CC","dwi"],"output_on_root":false,"archive":true,"_id":"5e26406467c9e9566f549501","id":"cc_mask","datatype":"5a281aee2c214c9ba83ce620","datatype_tags_pass":null,"files":null},{"datatype_tags":["noise","dwi"],"output_on_root":false,"archive":true,"_id":"5e26406467c9e9625d549500","id":"noise_mask","datatype":"5a281aee2c214c9ba83ce620","datatype_tags_pass":null,"files":null},{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"60ef24feddc2df25a965fb53","id":"snr-stats","datatype":"60ca4f058b8b7238324295d3","datatype_tags_pass":"dwi","files":null}],"name":"Compute SNR on Corpus Callosum","github":"brainlife/app-snr_in_cc","user_id":"283","references":[],"contributors":[{"name":"David Hunt","email":"davhunt@iu.edu","_id":"634a343462f3d3800f1188f3"},{"name":"Brad Caron","email":null,"_id":"634a343462f3d3800f1188f4"},{"name":"Brent McPherson","email":"bcmcpher@gmail.com","_id":"634a343462f3d3800f1188f5"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a343462f3d3800f1188f6"}],"create_date":"2018-10-19T19:29:09.781Z","desc":"Brainlife.io app that computes the signal-to-noise ratio in the corpus callosum","stats":{"stars":1,"requested":6430,"users":11,"success_rate":53.95403194390339,"serviceinfo":{"_id":"5d729e1f78356a109788b277","counts":{"_id":"5e5c3dc587cac7e7f2ab13da","failed":789,"finished":3502,"removed":3901,"requested":4372,"running":4273,"running_sync":0,"stop_requested":11},"success_rate":81.61267769750641,"users":13,"readme_status":"ok","runtime_mean":274705.08,"runtime_std":341073.32374334644,"service":"davhunt/app-snr_in_cc","__v":0},"gitinfo":{"desc":"Brainlife.io app that computes the signal-to-noise ratio in the corpus callosum","tags":[],"stats":{"stars":1},"contributors":[{"name":"David Hunt","email":"davhunt@indiana.edu"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":179493.48,"runtime_std":454946.11365423235,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a343362f3d3800f1188f2"}],"examples":4,"groups":21},"doi":"10.25663/brainlife.app.120","__v":9852,"github_branch":"plot","_canedit":true},{"_id":"608b188b89df43179075b628","stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a406062f3d3800f12d722"}],"success_rate":71.80555555555556,"users":3,"runtime_mean":247269.01,"runtime_std":713593.3964819531,"requested":726,"examples":2,"groups":3},"projects":[],"admins":["126"],"tags":[],"removed":false,"config":{"mag_inv1":{"type":"input","file_id":"mag_inv1","input_id":"neuro/anat/mp2rage"},"mag_inv2":{"type":"input","file_id":"mag_inv2","input_id":"neuro/anat/mp2rage"},"unit1":{"type":"input","file_id":"unit1","input_id":"neuro/anat/mp2rage"},"json_inv1":{"type":"input","file_id":"mag_inv1_json","input_id":"neuro/anat/mp2rage"},"json_inv2":{"type":"input","file_id":"mag_inv2_json","input_id":"neuro/anat/mp2rage"},"json_unit1":{"type":"input","file_id":"unit1_json","input_id":"neuro/anat/mp2rage"},"mask":{"type":"input","file_id":"mask","input_id":"neuro/mask"},"slicesperslab":{"id":"slicesperslab","type":"number","placeholder":"Enter the Slices Per Slab parameter.","advanced":false,"desc":"Slices Per Slab should be available in the MRI sequence protocol. It is not always available in the image's header information. If you are sure that Slices Per Slab is available in the image's header information, you can leave this blank and we will get the value from there. Otherwise, please look up this value in the MRI sequence protocol and enter it here.","default":null,"_order":2,"pid":0.3282345970898235,"optional":true}},"inputs":[{"datatype_tags":["denoised"],"optional":false,"multi":false,"advanced":false,"_id":"608b188b89df4343c775b629","id":"neuro/anat/mp2rage","datatype":"60634f0de4a8347569337f97"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"608b1eec89df430f5675b9fd","id":"neuro/mask","datatype":"5a281aee2c214c9ba83ce620"}],"outputs":[{"datatype_tags":["mp2rage"],"output_on_root":false,"archive":true,"_id":"608b188b89df4332f075b62a","id":"output","datatype":"608ac8b089df43e33c758fa1","datatype_tags_pass":null,"files":null,"desc":"T1map and R1 map"}],"github_branch":"main","github":"svincibo/app-mp2rage-computeT1andR1","name":"Compute T1 and R1 maps from MP2RAGE","avatar":"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQ_Mf4MFoKarAseVD5gPFCgvURUiFP_WKCk9Q&usqp=CAU","user_id":"126","contributors":[{"name":"Sophia Vinci-Booher","email":null,"_id":"634a406062f3d3800f12d723"}],"create_date":"2021-04-29T20:35:23.263Z","desc":"Computes T1map and R1map images when provided a denoised mp2rage t1 image (see app-mp2rage-denoiseUNI).","__v":2766,"doi":"10.25663/brainlife.app.514","_canedit":true},{"_id":"5afe0f2a2e93b90028263655","doi":"10.25663/bl.app.32","stats":{"stars":0,"requested":383,"users":3,"success_rate":94.9868073878628,"serviceinfo":{"_id":"5d729e1f78356a109788b2af","counts":{"_id":"5e5c3da187cac71d7aab13b2","failed":14,"finished":259,"removed":261,"requested":277,"running":267,"running_sync":0,"stop_requested":1},"success_rate":94.87179487179486,"users":2,"readme_status":"ok","runtime_mean":1511337.12,"runtime_std":1535459.4813143804,"service":"kitchell/app-binvolvolume","__v":0},"gitinfo":{"desc":"computes the volume of binary nifti images","tags":["analysis"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":31540.56,"runtime_std":12406.246232700689,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a32d862f3d3800f117b09"}],"examples":0,"groups":2},"name":"Compute Volume of Binary Nifti images","desc":"computes the volume of binary nifti images","citation":null,"github":"kitchell/app-binvolvolume","github_branch":"v1.0","config":{"fsurfer":{"type":"input","file_id":"output","input_id":"fsurfer"},"maskdir":{"type":"input","file_id":"masks","input_id":"vols"}},"user_id":"43","create_date":"2018-05-17T23:24:26.925Z","removed":false,"outputs":[{"datatype_tags":["volume"],"output_on_root":true,"archive":true,"_id":"5afe19732e93b90028263658","id":"output","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null}],"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5afe0f2a2e93b90028263656","id":"fsurfer","datatype":"58cb22c8e13a50849b25882e"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5afe19732e93b90028263659","id":"vols","datatype":"592dded1436ee50ffd88f5d0"}],"contributors":[{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a32d962f3d3800f117b0a"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a32d962f3d3800f117b0b"}],"tags":["analysis"],"references":[],"admins":["16","41","146","43","1"],"projects":[],"__v":13394,"_canedit":true},{"_id":"6102f439b99111e76fbb74e4","stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a41c362f3d3800f12ed86"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a41c362f3d3800f12ed87"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"634a41c362f3d3800f12ed88"}],"success_rate":76.42612120442129,"users":15,"runtime_mean":966510.03,"runtime_std":1250650.5328230064,"requested":19020,"examples":1,"groups":42},"projects":[],"admins":["16"],"tags":["postprocessing"],"removed":false,"config":{"inputs":{"type":"input","file_id":"cortexmap","input_id":"inputs"},"threshold":{"id":"threshold","type":"number","placeholder":"","advanced":true,"desc":"","default":0.5,"_order":2,"pid":0.6176176383152137},"dilate":{"id":"dilate","type":"number","placeholder":"","advanced":true,"desc":"","default":10,"_order":3,"pid":0.11195455214550687}},"inputs":[{"datatype_tags":[],"optional":false,"multi":true,"advanced":false,"_id":"6102f439b9911166bebb74e5","id":"inputs","datatype":"5c58aa5ef9109beac4b52f61"}],"outputs":[{"datatype_tags":["averaged"],"output_on_root":false,"archive":true,"_id":"6102f439b991115cc7bb74e6","id":"cortexmap","datatype":"5c58aa5ef9109beac4b52f61","datatype_tags_pass":null,"files":null}],"github_branch":"average-template-generation-v1.1","github":"brainlife/app-cortex-tissue-mapping","name":"Compute average cortexmap data for group analysis","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a41c362f3d3800f12ed89"},{"name":"Franco Pestilli","email":null,"_id":"634a41c362f3d3800f12ed8a"}],"create_date":"2021-07-29T18:32:25.225Z","desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","__v":2175,"doi":"10.25663/brainlife.app.552","desc_override":"This app will compute average surfaces and cortexmap data for group anaylsis","_canedit":true},{"_id":"623bbbaa5d8ab5d5f04af6f4","user_id":"16","projects":[],"admins":["16"],"name":"Compute dice similarity coefficient between parcels in parcellations","github":"brainlife/app-compute-similarity-parcellations","github_branch":"v1.0","tags":[],"config":{"parc_compare":{"type":"input","file_id":"parc","input_id":"parc_compare"},"parc_reference":{"type":"input","file_id":"parc","input_id":"parc_reference"},"labels":{"type":"input","file_id":"label","input_id":"parc_reference"}},"inputs":[{"id":"parc_compare","desc":"This is the path to the parcellation you would like to compare to the reference parcellation","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"623bbbaa5d8ab5d5f04af6f5"},{"id":"parc_reference","desc":"This is the path to the reference parcellation","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"623bbbaa5d8ab5d5f04af6f6"}],"outputs":[{"id":"parc_stats","datatype":"5edd3b77c5972b8c47b3a2c3","datatype_tags":["dice_similarity","parcellations"],"datatype_tags_pass":"parc_compare","output_on_root":false,"files":null,"archive":true,"_id":"623bbbaa5d8ab5d5f04af6f7"}],"stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a43e262f3d3800f13081d"}],"examples":0,"success_rate":100,"users":2,"runtime_mean":683446.5333333333,"runtime_std":601002.971139452,"requested":30,"groups":2},"removed":false,"contributors":[{"name":"Brad Caron","email":null,"_id":"634a43e262f3d3800f13081e"}],"create_date":"2022-03-24T00:30:34.545Z","desc":null,"__v":643,"desc_override":"This app will compute the dice similarity between parcels within parcellations. This app takes input a parcellation (parc_compare), whose date will be compared to the reference parcellation. The main output of this app is a .csv file that documents the dice coefficient for each parcel.","doi":"10.25663/brainlife.app.612","_canedit":true},{"_id":"60700d80c7f80a2c9095701f","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3fd962f3d3800f12d303"}],"success_rate":100,"users":1,"runtime_mean":35908,"runtime_std":5050.392525999011,"requested":3,"examples":1,"groups":2},"projects":[],"admins":["1342","664","670"],"tags":[],"removed":false,"config":{"fif":{"type":"input","file_id":"fif","input_id":"fif file"},"headshape":{"type":"input","file_id":"headshape","input_id":"Opt files"},"destination":{"type":"input","file_id":"destination","input_id":"Opt files"},"param_compute_amplitudes_t_step_min":{"id":"param_compute_amplitudes_t_step_min","type":"number","placeholder":"","advanced":true,"desc":"Minimum time step to use to compute cHPI amplitudes. If correlations are sufficiently high, t_step_max. This value can be a float.","default":0.01,"_order":2,"pid":0.38212916384364526},"param_compute_amplitudes_t_window":{"id":"param_compute_amplitudes_t_window","type":"number","placeholder":"","advanced":true,"desc":"Time window to use to estimate the amplitudes. This value can be a float.","default":0.2,"_order":3,"pid":0.6171912980666543},"param_compute_amplitudes_ext_order":{"id":"param_compute_amplitudes_ext_order","type":"number","placeholder":"","advanced":true,"desc":"The external order for SSS-like interfence suppression to compute cHPI amplitudes. This value must be an integer.","default":1,"_order":4,"pid":0.49709707525237645},"param_compute_amplitudes_tmin":{"id":"param_compute_amplitudes_tmin","type":"number","placeholder":"","advanced":true,"desc":"Start time of the raw data to use in seconds to compute cHPI amplitudes. This value can be a float.","default":0,"_order":5,"pid":0.5943294136749766},"param_compute_amplitudes_tmax":{"id":"param_compute_amplitudes_tmax","type":"number","placeholder":"","advanced":true,"desc":"End time of the raw data to use in seconds to compute cHPI amplitudes. This value can be a float.","default":null,"_order":6,"pid":0.6275127268179894,"optional":true},"param_compute_locs_t_step_max":{"id":"param_compute_locs_t_step_max","type":"number","placeholder":"","advanced":true,"desc":"Maximum step to use to compute HPI coils locations. This value can be a float.","default":1,"_order":7,"pid":0.29710441294856316,"optional":false},"param_compute_locs_too_close":{"id":"param_compute_locs_too_close","type":"enum","placeholder":"","advanced":true,"desc":"How to handle HPI positions too close to sensors when computing HPI coils locations.","default":"raise","_order":8,"pid":0.4638422253002479,"options":[{"desc":"","label":"","value":"raise"},{"desc":"","label":"","value":"warning"},{"desc":"","label":"","value":"info"}]},"param_compute_locs_adjust_dig":{"id":"param_compute_locs_adjust_dig","type":"boolean","placeholder":"","advanced":true,"desc":"If True, adjust the digitization locations used for fitting when computing HPI coils locations.","default":false,"_order":9,"pid":0.3365389614302945},"param_compute_head_pos_dist_limit":{"id":"param_compute_head_pos_dist_limit","type":"number","placeholder":"","advanced":true,"desc":"Minimum distance (m) to accept for coil position fitting when computing head positions. This value can be a float.","default":0.005,"_order":10,"pid":0.49231402509290256,"optional":false,"readonly":null},"param_compute_head_pos_gof_limit":{"id":"param_compute_head_pos_gof_limit","type":"number","placeholder":"","advanced":true,"desc":"Minimum goodness of fit to accept for each coil to compute head positions. This value can be a float.","default":0.98,"_order":11,"pid":0.5750566400126693,"optional":false},"param_compute_head_pos_adjust_dig":{"id":"param_compute_head_pos_adjust_dig","type":"boolean","placeholder":"","advanced":true,"desc":"If True, adjust the digitization locations used for fitting when computing head positions.","default":false,"_order":12,"pid":0.8643782364546344}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"60700d80c7f80a8394957020","id":"fif file","datatype":"6000737faacf9ee51fa691cb","desc":"MEG data in .fif format containing cHPI data."},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"60a641af22b42a20f16fc70c","id":"Opt files","datatype":"608195ce89df435fd26893c1","desc":"Optional destination file computed by app-mean-transformation-matrix."}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"60700d80c7f80a2d40957021","id":"out_dir","datatype":"608195ce89df435fd26893c1","datatype_tags_pass":null,"files":null,"desc":".pos file containing the time-varying head positions. This file will be used during detection of bad channels in MEG data (app-bad-channels) and Maxwell filtering (app-maxwell-filter) steps. "}],"github_branch":"master","github":"brainlife/app-head-pos","name":"Compute headshape.pos file from cHPI recorded during MEG acquisition","user_id":"1342","contributors":[{"name":null,"email":null,"_id":"634a3fda62f3d3800f12d304"}],"create_date":"2021-04-09T08:17:04.657Z","desc":"Compute time varying head positions from MEG signals when cHPI were recorded.","__v":2932,"doi":"10.25663/brainlife.app.499","_canedit":true},{"_id":"5f794bde268f765c3929bda2","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3dc362f3d3800f12b73c"}],"success_rate":61.165048543689316,"users":5,"runtime_mean":372456.6349206349,"runtime_std":316625.53128383606,"requested":106,"examples":1,"groups":7},"projects":[],"admins":["16"],"tags":[],"removed":false,"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"classification":{"type":"input","file_id":"classification","input_id":"wmc"},"tractogram":{"type":"input","file_id":"track","input_id":"track"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5f794bde268f767d9029bda3","id":"dwi","datatype":"58c33c5fe13a50849b25879b"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5f794bde268f76799f29bda4","id":"wmc","datatype":"5cc1d64c44947d8aea6b2d8b"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5f794bde268f76a6f429bda5","id":"track","datatype":"5907d922436ee50ffde9c549"}],"outputs":[{"datatype_tags":["macro"],"output_on_root":false,"archive":true,"_id":"5f794bde268f761d4629bda6","id":"tractmeasures","datatype":"599f305ad1f46fec1759f363","datatype_tags_pass":"wmc","files":null}],"github_branch":"v1.0","github":"brainlife/app-compute-tract-stats","name":"Compute macro-structural statistics of tracts using Dipy","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3dc462f3d3800f12b73d"}],"create_date":"2020-10-04T04:13:18.743Z","desc":null,"doi":"10.25663/brainlife.app.439","__v":4148,"_canedit":true},{"_id":"6065cee9d040085be2b0a9b7","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3fbe62f3d3800f12d211"}],"success_rate":63.41463414634146,"users":1,"runtime_mean":31031.73076923077,"runtime_std":19647.396354337587,"requested":51,"examples":1},"projects":[],"admins":["1342","664","670"],"tags":[],"removed":false,"config":{"fif_runs":{"type":"input","file_id":"fif","input_id":"fif files"},"headshape":{"type":"input","file_id":"headshape","input_id":"Opt files"},"destination":{"type":"input","file_id":"destination","input_id":"Opt files"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":true,"advanced":false,"_id":"6065cee9d04008b4d1b0a9b8","id":"fif files","datatype":"6000737faacf9ee51fa691cb","desc":"All the runs of a MEG session that we want to realign by computing the mean head position across all these runs (this position is stored in a transformation matrix). At least two runs are required."},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"60a6420c22b42a47c36fc766","id":"Opt files","datatype":"608195ce89df435fd26893c1","desc":"Headshape.pos file. This file is computed with app-head-pos."}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"6065cee9d040085ea1b0a9ba","id":"out_dir","datatype":"608195ce89df435fd26893c1","datatype_tags_pass":null,"files":null,"desc":"Destination file containing the mean transformation matrix to realign all the runs on the same head position and .fif file to preprocess."}],"github_branch":"master","github":"brainlife/app-mean-transformation-matrix","name":"Compute mean transformation across MEG runs","user_id":"1342","contributors":[{"name":null,"email":null,"_id":"634a3fbf62f3d3800f12d212"}],"create_date":"2021-04-01T13:47:21.173Z","desc":"Compute mean transformation matrix across MEG runs.","__v":2998,"doi":"10.25663/brainlife.app.496","_canedit":true},{"_id":"60355b8a3a0011acbb52c3c5","stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3f1762f3d3800f12c8a9"},{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"634a3f1762f3d3800f12c8aa"}],"success_rate":91.68053244592346,"users":8,"runtime_mean":7588676.02,"runtime_std":8902474.732481435,"requested":664,"examples":3,"groups":13},"projects":[],"admins":["16"],"tags":[],"removed":false,"config":{"t1":{"type":"input","file_id":"t1","input_id":"t1"},"t2":{"type":"input","file_id":"t2","input_id":"t2"},"reslice":{"id":"reslice","type":"boolean","placeholder":"","advanced":true,"desc":"If true, will use mri_vol2vol from Freesurfer to align and reslice the t2 to the t1 space before computing ratio","default":false,"_order":2,"pid":0.3264246653805811}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"60355b8a3a0011cb3452c3c6","id":"t1","datatype":"58c33bcee13a50849b25879a"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"60355b8a3a00112e3552c3c7","id":"t2","datatype":"594c0325fa1d2e5a1f0beda5"}],"outputs":[{"datatype_tags":["t1-t2-ratio"],"output_on_root":false,"archive":true,"_id":"60355b8a3a00110a3652c3c8","id":"output","datatype":"5fad54c27e8ecba2c3aa0c24","datatype_tags_pass":null,"files":null}],"github_branch":"t1-t2-ratio-v1.0","github":"brainlife/app-myelin-mapping","name":"Compute myelin map using T1w / T2w ratio","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3f1862f3d3800f12c8ab"}],"create_date":"2021-02-23T19:46:18.762Z","desc":null,"__v":3211,"doi":"10.25663/brainlife.app.478","_canedit":true},{"_id":"626c8036f3858674a2a803fd","user_id":"16","projects":[],"admins":["16"],"name":"Compute streamline weights using COMMIT","github":"brainlife/app-commit","github_branch":"v1.0","tags":[],"config":{"track":{"type":"input","file_id":"track","input_id":"track"},"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"lmax2":{"type":"input","file_id":"lmax2","input_id":"csd"},"lmax4":{"type":"input","file_id":"lmax4","input_id":"csd"},"lmax6":{"type":"input","file_id":"lmax6","input_id":"csd"},"lmax8":{"type":"input","file_id":"lmax8","input_id":"csd"},"lmax10":{"type":"input","file_id":"lmax10","input_id":"csd"},"lmax12":{"type":"input","file_id":"lmax12","input_id":"csd"},"lmax14":{"type":"input","file_id":"lmax14","input_id":"csd"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"peaks":{"type":"input","file_id":"peaks","input_id":"peaks"},"dPar":{"id":"dPar","type":"number","placeholder":"","advanced":true,"desc":"parallel diffusivity value","default":0.0017,"_order":2,"pid":0.24632756618175022},"dPerp":{"id":"dPerp","type":"number","placeholder":"","advanced":true,"desc":"perpendicular diffusivity value","default":0.00051,"_order":3,"pid":0.18583172881644006},"dIso":{"id":"dIso","type":"string","placeholder":"","advanced":true,"desc":"isotropic diffusivity values","default":"0.0017, 0.003","_order":4,"pid":0.05622116425472412},"model":{"id":"model","type":"enum","placeholder":"","advanced":true,"desc":"The model to use","default":"StickZeppelinBall","_order":5,"pid":0.36070770976215416,"options":[{"desc":"StickZeppelinBall","label":"StickZeppelinBall","value":"StickZeppelinBall"},{"desc":"CylinderZeppelinBall","label":"CylinderZeppelinBall","value":"CylinderZeppelinBall"},{"desc":"VolumeFraction","label":"VolumeFraction","value":"VolumeFraction"}]},"lmax":{"id":"lmax","type":"number","placeholder":"","advanced":false,"desc":"the spherical harmonic order (lmax) to generate peaks from to use in model fitting","default":8,"_order":6,"pid":0.03110042166628546},"fiber_shift":{"id":"fiber_shift","type":"number","placeholder":"","advanced":true,"desc":"","default":0,"_order":7,"pid":0.09768479264152141},"peaks_use_affine":{"id":"peaks_use_affine","type":"boolean","placeholder":"","advanced":true,"desc":"","default":false,"_order":8,"pid":0.8256384710989918},"b0_threshold":{"id":"b0_threshold","type":"number","placeholder":"","advanced":true,"desc":"","default":0,"_order":9,"pid":0.16960772352366826},"b0_min_signal":{"id":"b0_min_signal","type":"number","placeholder":"","advanced":true,"desc":"","default":0,"_order":10,"pid":0.7990113463463122},"max_iters":{"id":"max_iters","type":"number","placeholder":"","advanced":true,"desc":"","default":1000,"_order":11,"pid":0.8366197828096933},"stat_coef":{"id":"stat_coef","type":"enum","placeholder":"","advanced":true,"desc":"","default":"sum","_order":12,"pid":0.01168262593784064,"options":[{"desc":"sum","label":"sum","value":"sum"},{"desc":"mean","label":"mean","value":"mean"},{"desc":"median","label":"median","value":"median"},{"desc":"min","label":"min","value":"min"},{"desc":"max","label":"max","value":"max"},{"desc":"all","label":"all","value":"all"}]},"min_seg_len":{"id":"min_seg_len","type":"number","placeholder":"","advanced":true,"desc":"","default":0.001,"_order":13,"pid":0.7650917854048047,"optional":false},"min_fiber_len":{"id":"min_fiber_len","type":"number","placeholder":"","advanced":true,"desc":"","default":0,"_order":14,"pid":0.7738164572887017},"max_fiber_len":{"id":"max_fiber_len","type":"number","placeholder":"","advanced":true,"desc":"","default":250,"_order":15,"pid":0.4480244761022095},"vf_THR":{"id":"vf_THR","type":"number","placeholder":"","advanced":true,"desc":"","default":0.1,"_order":16,"pid":0.5915308065541108},"blur_spacing":{"id":"blur_spacing","type":"number","placeholder":"","advanced":true,"desc":"","default":0.25,"_order":18,"pid":0.5614142502282967},"blur_core_extent":{"id":"blur_core_extent","type":"number","placeholder":"","advanced":true,"desc":"","default":0,"_order":19,"pid":0.0553083066614366},"blur_gauss_extent":{"id":"blur_gauss_extent","type":"number","placeholder":"","advanced":true,"desc":"","default":0,"_order":20,"pid":0.551114371353436},"blur_gauss_min":{"id":"blur_gauss_min","type":"number","placeholder":"","advanced":true,"desc":"","default":0.1,"_order":21,"pid":0.8895339943614209},"flip_peaks":{"id":"flip_peaks","type":"string","placeholder":"","advanced":true,"desc":"","default":"false false false","_order":22,"pid":0.7694183065735412}},"inputs":[{"id":"track","datatype":"5907d922436ee50ffde9c549","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"626c8036f3858674a2a803ff"},{"id":"dwi","datatype":"58c33c5fe13a50849b25879b","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"626c8036f3858674a2a80400"},{"id":"csd","datatype":"5c536bf0f9109beac46adb45","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"626c8036f3858674a2a80401"},{"id":"mask","datatype":"5a281aee2c214c9ba83ce620","datatype_tags":["5tt_masks"],"optional":false,"multi":false,"advanced":false,"_id":"626c8036f3858674a2a803fe"},{"id":"peaks","datatype":"5c9276dc44947d8aea7d6454","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"626eaf37cbc76827b718a45c"}],"outputs":[{"id":"streamline_weights","datatype":"5dcecaffc4ae284155298383","datatype_tags":["commit"],"datatype_tags_pass":"track","output_on_root":false,"files":null,"archive":true,"_id":"626c8036f3858674a2a80402"},{"id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags":["commit_dictionaries"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"626c8036f3858674a2a80403"},{"id":"errors","datatype":"59c3eae633fc1cf9ead71679","datatype_tags":["commit_errors","rmse","nrmse"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"626c8036f3858674a2a80404"},{"id":"noddi-commit","desc":"Note: this is not the same as a normal noddi dataset.\n\ncompartment_IC from COMMIT => ndi.nii.gz\ncompartment_EC from COMMIT => odi.nii.gz\ncompartment_ISO from COMMIT => isovf.nii.gz\n\nThis is temporary until we develop a datatype to capture these outputs","datatype":"5ed02a620a8ed8e39c482a61","datatype_tags":["commit"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"626c8036f3858674a2a80405"},{"id":"tdi","desc":"temporary until we figure out a datatype for tract density images","datatype":"59c3eae633fc1cf9ead71679","datatype_tags":["tract_density_image"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"626c8036f3858674a2a80406"},{"id":"peaks","datatype":"5c9276dc44947d8aea7d6454","datatype_tags":[],"datatype_tags_pass":"csd","output_on_root":false,"files":null,"archive":true,"_id":"626eaf37cbc76827b718a462"}],"stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a443862f3d3800f130d66"}],"examples":1,"success_rate":31.03448275862069,"users":1,"groups":1,"runtime_mean":1133728.5555555555,"runtime_std":1321638.393454134,"requested":37},"removed":false,"contributors":[{"name":"Brad Caron","email":null,"_id":"634a443962f3d3800f130d67"}],"create_date":"2022-04-30T00:17:58.555Z","desc":null,"__v":450,"doi":"10.25663/brainlife.app.622","_canedit":true},{"_id":"62681cd2f3858674a29f554e","user_id":"16","projects":[],"admins":["16"],"name":"Compute streamline weights using SIFT2","github":"brainlife/app-sift-sift2","github_branch":"sift2-v1.0","tags":[],"config":{"track":{"type":"input","file_id":"track","input_id":"track"},"response":{"type":"input","file_id":"response","input_id":"csd"},"lmax2":{"type":"input","file_id":"lmax2","input_id":"csd"},"lmax4":{"type":"input","file_id":"lmax4","input_id":"csd"},"lmax6":{"type":"input","file_id":"lmax6","input_id":"csd"},"lmax8":{"type":"input","file_id":"lmax8","input_id":"csd"},"lmax10":{"type":"input","file_id":"lmax10","input_id":"csd"},"lmax12":{"type":"input","file_id":"lmax12","input_id":"csd"},"lmax14":{"type":"input","file_id":"lmax14","input_id":"csd"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"anat":{"type":"input","file_id":"t1","input_id":"anat"},"lmax":{"id":"lmax","type":"number","placeholder":"","advanced":false,"desc":"the spherical harmonic order (lmax) to use","default":8,"_order":2,"pid":0.27256114830412514},"fd_scale_gm":{"id":"fd_scale_gm","type":"boolean","placeholder":"","advanced":true,"desc":"provide this option (in conjunction with -act) to heuristically downsize the fibre density estimates based on the presence of GM in the voxel. This can assist in reducing tissue interface effects when using a single-tissue deconvolution algorithm","default":true,"_order":3,"pid":0.032948765574269956},"no_dilate_lut":{"id":"no_dilate_lut","type":"boolean","placeholder":"","advanced":true,"desc":" do NOT dilate FOD lobe lookup tables; only map streamlines to FOD lobes if the precise tangent lies within the angular spread of that lobe","default":false,"_order":4,"pid":0.13932094452597332},"linear":{"id":"linear","type":"boolean","placeholder":"","advanced":true,"desc":"perform a linear estimation of streamline weights, rather than the standard non-linear optimisation (typically does not provide as accurate a model fit; but only requires a single pass)","default":false,"_order":5,"pid":0.8151313834669149},"fd_thresh":{"id":"fd_thresh","type":"number","placeholder":"","advanced":true,"desc":" fibre density threshold; exclude an FOD lobe from filtering processing if its integral is less than this amount (streamlines will still be mapped to it, but it will not contribute to the cost function or the filtering)","default":0,"_order":6,"pid":0.5186869874598592},"reg_tikhonov":{"id":"reg_tikhonov","type":"number","placeholder":"","advanced":true,"desc":"provide coefficient for regularising streamline weighting coefficients (Tikhonov regularisation) (default: 0)","default":0,"_order":7,"pid":0.100603280069959},"reg_tv":{"id":"reg_tv","type":"number","placeholder":"","advanced":true,"desc":"provide coefficient for regularising variance of streamline weighting coefficient to fixels along its length (Total Variation regularisation) (default: 0.1)","default":0.1,"_order":8,"pid":0.6372269753751916},"min_td_frac":{"id":"min_td_frac","type":"number","placeholder":"","advanced":true,"desc":"minimum fraction of the FOD integral reconstructed by streamlines; if the reconstructed streamline density is below this fraction, the fixel is excluded from optimisation (default: 0.1)","default":0.1,"_order":9,"pid":0.02739037539469591,"min":"","max":""},"min_iters":{"id":"min_iters","type":"number","placeholder":"","advanced":true,"desc":"minimum number of iterations to run before testing for convergence; this can prevent premature termination at early iterations if the cost function increases slightly (default: 10)","default":10,"_order":10,"pid":0.2049896013934075},"max_iters":{"id":"max_iters","type":"number","placeholder":"","advanced":true,"desc":"maximum number of iterations to run before terminating program","default":null,"_order":12,"pid":0.5423120949731209},"min_factor":{"id":"min_factor","type":"string","placeholder":"","advanced":true,"desc":"minimum weighting factor for an individual streamline; if the factor falls below this number the streamline will be rejected entirely (factor set to zero) (default: 0)","default":"0","_order":13,"pid":0.9346600405830824},"min_coeff":{"id":"min_coeff","type":"string","placeholder":"","advanced":true,"desc":"minimum weighting coefficient for an individual streamline; similar to the ‘-min_factor’ option, but using the exponential coefficient basis of the SIFT2 model; these parameters are related as: factor = e^(coeff). Note that the -min_factor and -min_coeff options are mutually exclusive - you can only provide one. (default: -inf)","default":"-inf","_order":14,"pid":0.943301387099068},"max_factor":{"id":"max_factor","type":"string","placeholder":"","advanced":true,"desc":"maximum weighting factor that can be assigned to any one streamline (default: inf)","default":"inf","_order":15,"pid":0.6970214399693466},"max_coeff":{"id":"max_coeff","type":"string","placeholder":"","advanced":true,"desc":"maximum weighting coefficient for an individual streamline; similar to the ‘-max_factor’ option, but using the exponential coefficient basis of the SIFT2 model; these parameters are related as: factor = e^(coeff). Note that the -max_factor and -max_coeff options are mutually exclusive - you can only provide one. (default: inf)","default":"inf","_order":16,"pid":0.3154253110647415},"max_coeff_step":{"id":"max_coeff_step","type":"number","placeholder":"","advanced":true,"desc":"maximum change to a streamline’s weighting coefficient in a single iteration (default: 1)","default":1,"_order":17,"pid":0.4817326600863977},"min_cf_decrease":{"id":"min_cf_decrease","type":"number","placeholder":"","advanced":true,"desc":" minimum decrease in the cost function (as a fraction of the initial value) that must occur each iteration for the algorithm to continue (default: 2.5e-05)","default":0.000025,"_order":18,"pid":0.9009553431669493},"premask":{"id":"premask","type":"boolean","placeholder":"","advanced":true,"desc":"If T1 has already been masked, set to true","default":false,"_order":19,"pid":0.0945772412583159}},"inputs":[{"id":"track","desc":"path to the input tractogram","datatype":"5907d922436ee50ffde9c549","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"62681cd2f3858674a29f554f"},{"id":"csd","desc":"paths to the individual FOD files","datatype":"5c536bf0f9109beac46adb45","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"62681cd2f3858674a29f5550"},{"id":"mask","datatype":"5a281aee2c214c9ba83ce620","datatype_tags":["5tt_masks"],"optional":true,"multi":false,"advanced":false,"_id":"62681cd2f3858674a29f5551"},{"id":"anat","desc":"This is only needed if a tissue type mask (5tt) was not inputted. Will generate internally with this T1","datatype":"58c33bcee13a50849b25879a","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"626b1722f3858674a2a5b2ad"}],"outputs":[{"id":"weights","desc":"weights file containing the weights for each streamline from SIFT2","datatype":"5dcecaffc4ae284155298383","datatype_tags":["sift2"],"datatype_tags_pass":"track","output_on_root":false,"files":null,"archive":true,"_id":"62681d36f3858674a29f5a97"},{"id":"raw","desc":"contains the derivative files generated during the sift process, including the weights and proportionality coefficient and relative statistics files","datatype":"59c3eae633fc1cf9ead71679","datatype_tags":["sift2"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"62681d36f3858674a29f5a98"}],"stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a43f462f3d3800f130933"}],"examples":1,"success_rate":53.333333333333336,"users":2,"groups":2,"runtime_mean":1753199.75,"runtime_std":581686.8902920948,"requested":15},"removed":false,"contributors":[{"name":"Brad Caron","email":null,"_id":"634a43f562f3d3800f130934"}],"create_date":"2022-04-26T16:24:50.295Z","desc":null,"__v":465,"doi":"10.25663/brainlife.app.615","_canedit":true},{"_id":"61099a0db991115733beac81","projects":[],"admins":["16"],"tags":[],"removed":false,"stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a41d762f3d3800f12efbb"}],"success_rate":80.6976418279337,"users":84,"runtime_mean":566450.48,"runtime_std":1502852.264375946,"requested":118550,"examples":0,"groups":168},"config":{"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"fa":{"type":"input","file_id":"fa","input_id":"tensor"},"md":{"type":"input","file_id":"md","input_id":"tensor"},"rd":{"type":"input","file_id":"rd","input_id":"tensor"},"ad":{"type":"input","file_id":"ad","input_id":"tensor"},"cl":{"type":"input","file_id":"cl","input_id":"tensor"},"cp":{"type":"input","file_id":"cp","input_id":"tensor"},"cs":{"type":"input","file_id":"cs","input_id":"tensor"},"tensors":{"type":"input","file_id":"tensors","input_id":"tensor"},"kurtosis":{"type":"input","file_id":"kurtosis","input_id":"tensor"},"dir":{"type":"input","file_id":"dir","input_id":"noddi"},"ndi":{"type":"input","file_id":"ndi","input_id":"noddi"},"isovf":{"type":"input","file_id":"isovf","input_id":"noddi"},"odi":{"type":"input","file_id":"odi","input_id":"noddi"},"myelin":{"type":"input","file_id":"map","input_id":"myelin"},"T1":{"type":"input","file_id":"T1map","input_id":"qmri"},"T1_json":{"type":"input","file_id":"T1map_json","input_id":"qmri"},"R1":{"type":"input","file_id":"R1map","input_id":"qmri"},"R1_json":{"type":"input","file_id":"R1map_json","input_id":"qmri"},"M0":{"type":"input","file_id":"M0map","input_id":"qmri"},"M0_json":{"type":"input","file_id":"M0map_json","input_id":"qmri"},"PD":{"type":"input","file_id":"PD","input_id":"qmri"},"MTV":{"type":"input","file_id":"MTV","input_id":"qmri"},"VIP":{"type":"input","file_id":"VIP","input_id":"qmri"},"SIR":{"type":"input","file_id":"SIR","input_id":"qmri"},"WF":{"type":"input","file_id":"WF","input_id":"qmri"},"parcellation":{"id":"parcellation","type":"enum","placeholder":"","advanced":false,"desc":"This is the freesurfer parcellation to use to compute statistics within","default":"aparc.a2009s","_order":2,"pid":0.19328379109416127,"options":[{"desc":"aparc","label":"aparc","value":"aparc"},{"desc":"aparc.a2009s","label":"aparc.a2009s","value":"aparc.a2009s"},{"desc":"aparc.DKTatlas","label":"aparc.DKTatlas","value":"aparc.DKTatlas"}]}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ef66ba5c67a0d230e29d98b","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ef66ba5c67a0d629a29d98c","id":"tensor","datatype":"5a79df48d071a1753f1d661b"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5ef66ba5c67a0dfaba29d98d","id":"noddi","datatype":"5ed02a620a8ed8e39c482a61"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"610993adb991117f0dbe991e","id":"myelin","datatype":"5fad54c27e8ecba2c3aa0c24"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"6115eb35a5a04c419df9fc43","id":"qmri","datatype":"608ac8b089df43e33c758fa1"}],"outputs":[{"datatype_tags":["diffusion_metrics"],"output_on_root":false,"archive":true,"_id":"5ef66ba5c67a0d5bf429d98e","id":"parc-stats","datatype":"5edd3b77c5972b8c47b3a2c3","datatype_tags_pass":"freesurfer","files":null}],"github_branch":"freesurfer-stats-diffusion-v1.0","github":"brainlife/app-freesurfer-stats","name":"Compute summary statistics of diffusion measures from Freesurfer Parcellation (volume)","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a41d762f3d3800f12efbc"}],"desc":null,"__v":2149,"desc_override":"This app will compute statistics from diffusion measures inside a parcellation generated by freesurfer. Will return volume, thickness, and mean diffusion measures for each ROI in a parcellation.","create_date":"2021-08-03T19:33:33.272Z","doi":"10.25663/brainlife.app.554","_canedit":true},{"_id":"610993adb991116691be9916","projects":[],"admins":["16"],"tags":[],"removed":false,"stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a41cd62f3d3800f12eeca"}],"success_rate":80.6976418279337,"users":84,"runtime_mean":566450.48,"runtime_std":1502852.264375946,"requested":118550,"examples":2,"groups":168},"config":{"parcellation":{"type":"input","file_id":"parc","input_id":"parc"},"key":{"type":"input","file_id":"key","input_id":"parc"},"label":{"type":"input","file_id":"label","input_id":"parc"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"fa":{"type":"input","file_id":"fa","input_id":"tensor"},"md":{"type":"input","file_id":"md","input_id":"tensor"},"rd":{"type":"input","file_id":"rd","input_id":"tensor"},"ad":{"type":"input","file_id":"ad","input_id":"tensor"},"cl":{"type":"input","file_id":"cl","input_id":"tensor"},"cp":{"type":"input","file_id":"cp","input_id":"tensor"},"cs":{"type":"input","file_id":"cs","input_id":"tensor"},"tensors":{"type":"input","file_id":"tensors","input_id":"tensor"},"kurtosis":{"type":"input","file_id":"kurtosis","input_id":"tensor"},"dir":{"type":"input","file_id":"dir","input_id":"noddi"},"ndi":{"type":"input","file_id":"ndi","input_id":"noddi"},"isovf":{"type":"input","file_id":"isovf","input_id":"noddi"},"odi":{"type":"input","file_id":"odi","input_id":"noddi"},"myelin":{"type":"input","file_id":"map","input_id":"myelin"},"T1":{"type":"input","file_id":"T1map","input_id":"qmri"},"T1_json":{"type":"input","file_id":"T1map_json","input_id":"qmri"},"R1":{"type":"input","file_id":"R1map","input_id":"qmri"},"R1_json":{"type":"input","file_id":"R1map_json","input_id":"qmri"},"M0":{"type":"input","file_id":"M0map","input_id":"qmri"},"M0_json":{"type":"input","file_id":"M0map_json","input_id":"qmri"},"PD":{"type":"input","file_id":"PD","input_id":"qmri"},"MTV":{"type":"input","file_id":"MTV","input_id":"qmri"},"VIP":{"type":"input","file_id":"VIP","input_id":"qmri"},"SIR":{"type":"input","file_id":"SIR","input_id":"qmri"},"WF":{"type":"input","file_id":"WF","input_id":"qmri"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"610993adb99111fd41be991a","id":"parc","datatype":"5c1a7489f9109beac4a88a1f"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ef66ba5c67a0d230e29d98b","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ef66ba5c67a0d629a29d98c","id":"tensor","datatype":"5a79df48d071a1753f1d661b"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5ef66ba5c67a0dfaba29d98d","id":"noddi","datatype":"5ed02a620a8ed8e39c482a61"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"610993adb991117f0dbe991e","id":"myelin","datatype":"5fad54c27e8ecba2c3aa0c24"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"6115ebe6a5a04c2f38f9fe1b","id":"qmri","datatype":"608ac8b089df43e33c758fa1"}],"outputs":[{"datatype_tags":["diffusion_metrics"],"output_on_root":false,"archive":true,"_id":"5ef66ba5c67a0d5bf429d98e","id":"parc-stats","datatype":"5edd3b77c5972b8c47b3a2c3","datatype_tags_pass":"parc","files":null},{"datatype_tags":["diffusion_metrics"],"output_on_root":false,"archive":true,"_id":"5ef66ba5c67a0d844e29d98f","id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":"parc","files":null}],"github_branch":"parc-stats-volume-diffusion-v1.0","github":"brainlife/app-freesurfer-stats","name":"Compute summary statistics of diffusion measures from Parcellation (volume)","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a41cd62f3d3800f12eecb"}],"desc":null,"__v":2150,"create_date":"2021-08-03T19:06:21.038Z","desc_override":"This app will compute statistics from diffusion measures inside a parcellation volume datatype. Will return volume, thickness, and mean diffusion measures for each ROI in a parcellation.","doi":"10.25663/brainlife.app.553","_canedit":true},{"_id":"5ef66ba5c67a0dd33d29d98a","stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3c4762f3d3800f12801b"}],"success_rate":80.6976418279337,"users":84,"runtime_mean":566450.48,"runtime_std":1502852.264375946,"requested":118550,"examples":4,"groups":168},"projects":[],"admins":["16"],"tags":[],"removed":false,"config":{"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"fa":{"type":"input","file_id":"fa","input_id":"tensor"},"md":{"type":"input","file_id":"md","input_id":"tensor"},"rd":{"type":"input","file_id":"rd","input_id":"tensor"},"ad":{"type":"input","file_id":"ad","input_id":"tensor"},"cl":{"type":"input","file_id":"cl","input_id":"tensor"},"cp":{"type":"input","file_id":"cp","input_id":"tensor"},"cs":{"type":"input","file_id":"cs","input_id":"tensor"},"tensors":{"type":"input","file_id":"tensors","input_id":"tensor"},"kurtosis":{"type":"input","file_id":"kurtosis","input_id":"tensor"},"dir":{"type":"input","file_id":"dir","input_id":"noddi"},"ndi":{"type":"input","file_id":"ndi","input_id":"noddi"},"isovf":{"type":"input","file_id":"isovf","input_id":"noddi"},"odi":{"type":"input","file_id":"odi","input_id":"noddi"},"myelin":{"type":"input","file_id":"map","input_id":"myelin"},"T1":{"type":"input","file_id":"T1map","input_id":"qmri"},"T1_json":{"type":"input","file_id":"T1map_json","input_id":"qmri"},"R1":{"type":"input","file_id":"R1map","input_id":"qmri"},"R1_json":{"type":"input","file_id":"R1map_json","input_id":"qmri"},"M0":{"type":"input","file_id":"M0map","input_id":"qmri"},"M0_json":{"type":"input","file_id":"M0map_json","input_id":"qmri"},"PD":{"type":"input","file_id":"PD","input_id":"qmri"},"MTV":{"type":"input","file_id":"MTV","input_id":"qmri"},"VIP":{"type":"input","file_id":"VIP","input_id":"qmri"},"SIR":{"type":"input","file_id":"SIR","input_id":"qmri"},"WF":{"type":"input","file_id":"WF","input_id":"qmri"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ef66ba5c67a0d230e29d98b","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ef66ba5c67a0d629a29d98c","id":"tensor","datatype":"5a79df48d071a1753f1d661b"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5ef66ba5c67a0dfaba29d98d","id":"noddi","datatype":"5ed02a620a8ed8e39c482a61"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"6109950db99111fb28be9e38","id":"myelin","datatype":"5fad54c27e8ecba2c3aa0c24"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"6115ebcea5a04cccc4f9fd6f","id":"qmri","datatype":"608ac8b089df43e33c758fa1"}],"outputs":[{"datatype_tags":["subcort_stats"],"output_on_root":false,"archive":true,"_id":"5ef66ba5c67a0d5bf429d98e","id":"parc-stats","datatype":"5edd3b77c5972b8c47b3a2c3","datatype_tags_pass":null,"files":null},{"datatype_tags":["subcort_stats_derivatives"],"output_on_root":false,"archive":true,"_id":"5ef66ba5c67a0d844e29d98f","id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null}],"github_branch":"subcort-stats-v1.0","github":"brainlife/app-freesurfer-stats","name":"Compute summary statistics of diffusion measures from subcortical segmentation","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3c4862f3d3800f12801c"}],"create_date":"2020-06-26T21:41:57.775Z","desc":null,"doi":"10.25663/brainlife.app.389","__v":4534,"_canedit":true},{"_id":"603b030878e65d363cd1b3d0","projects":[],"admins":["16"],"tags":[],"removed":false,"stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3f4762f3d3800f12cc84"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3f4762f3d3800f12cc85"}],"success_rate":46.752233956133225,"users":12,"runtime_mean":1696316.03,"runtime_std":1955289.3661379511,"requested":36654,"examples":1,"groups":26},"config":{"cortexmap":{"type":"input","file_id":"cortexmap","input_id":"cortexmap"},"lh_annot":{"type":"input","file_id":"left","input_id":"parc_surface"},"rh_annot":{"type":"input","file_id":"right","input_id":"parc_surface"},"label":{"type":"input","file_id":"label","input_id":"parc_surface"},"right":{"type":"input","file_id":"right","input_id":"parc_surf_vertices"},"left":{"type":"input","file_id":"left","input_id":"parc_surf_vertices"},"fsaparc":{"id":"fsaparc","type":"enum","placeholder":"","advanced":false,"desc":"This is the name of the freesurfer aparc to use. Must be located in the cortexmap/label directory for this to work.","default":"aparc.a2009s","_order":2,"pid":0.8937544808202765,"options":[{"desc":"aparc","label":"aparc","value":"aparc"},{"desc":"aparc.a2009s","label":"aparc.a2009s","value":"aparc.a2009s"},{"desc":"aparc.DKTatlas","label":"aparc.DKTatlas","value":"aparc.DKTatlas"}]},"validator_csv":{"id":"validator_csv","type":"enum","placeholder":"","advanced":true,"desc":"Choose which csv you would like to use for the validator","default":"aparc_MEAN","_order":3,"pid":0.9384966292433613,"options":[{"desc":"aparc_MEAN","label":"aparc_MEAN","value":"aparc_MEAN"},{"desc":"aparc_MAX","label":"aparc_MAX","value":"aparc_MAX"},{"desc":"aparc_MIN","label":"aparc_MIN","value":"aparc_MIN"},{"desc":"aparc_MEDIAN","label":"aparc_MEDIAN","value":"aparc_MEDIAN"},{"desc":"aparc_MODE","label":"aparc_MODE","value":"aparc_MODE"},{"desc":"aparc_SAMPSTDEV","label":"aparc_SAMPSTDEV","value":"aparc_SAMPSTDEV"},{"desc":"aparc_STDEV","label":"aparc_STDEV","value":"aparc_STDEV"},{"desc":"parc_MEAN","label":"parc_MEAN","value":"parc_MEAN"},{"desc":"parc_MIN","label":"parc_MIN","value":"parc_MIN"},{"desc":"parc_MAX","label":"parc_MAX","value":"parc_MAX"},{"desc":"parc_MEDIAN","label":"parc_MEDIAN","value":"parc_MEDIAN"},{"desc":"parc_MODE","label":"parc_MODE","value":"parc_MODE"},{"desc":"parc_SAMPSTDEV","label":"parc_SAMPSTDEV","value":"parc_SAMPSTDEV"},{"desc":"parc_STDEV","label":"parc_STDEV","value":"parc_STDEV"}]}},"inputs":[{"id":"cortexmap","desc":"Path to the cortexmap datatype folder","datatype":"5c58aa5ef9109beac4b52f61","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5eed5e9dd39ceb6ce1a0ed19"},{"id":"parc_surface","datatype":"5f78b377268f76598c29b27a","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"603b030878e65d6a6fd1b3d5"},{"id":"parc_surf_vertices","datatype":"5f78b255268f764bdd29b254","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"603b030878e65d3f89d1b3d6"}],"outputs":[{"id":"parc-stats","desc":"Csv files for each summary statistic and parcellation","datatype":"5edd3b77c5972b8c47b3a2c3","datatype_tags":["cortex_mapping_stats"],"datatype_tags_pass":"cortexmap","output_on_root":false,"files":null,"archive":true,"_id":"5eed5e9dd39ceb532aa0ed1b"},{"id":"raw","desc":"Derivatives generated during run for debugging","datatype":"59c3eae633fc1cf9ead71679","datatype_tags":["cortex_mapping_stats_derivatives"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5eed5e9dd39ceb3ca4a0ed1a"}],"github_branch":"updated-surface-dtype-v1.1","github":"brainlife/app-cortex-tissue-mapping-stats","name":"Compute summary statistics of diffusion measures mapped to cortical surface","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3f4862f3d3800f12cc86"},{"name":"Franco Pestilli","email":null,"_id":"634a3f4862f3d3800f12cc87"}],"desc":null,"__v":3183,"desc_override":"This app will This app will compute multiple summary statistics from measures mapped to the cortical midthickness surface on a per-ROI basis. This app takes in a cortexmap datatype and an optional parcellation/surface datatype. This app will compute the following summary statistics: minimum, maximum, mean, median, mode, standard deviation, sample standard deviation (n-1), and nonzero vertex count. The app will output a csv for each summary measure summarizing the diffusion measures in each ROI parcellation. If no parcellation surface is inputted, the app will just compute stats from the labels file found in the cortexmap datatype (usually aparc.a2009s.labels.gii). These csvs can be used for computing group averages and for performing machine learning analyses.","create_date":"2021-02-28T02:42:16.720Z","doi":"10.25663/brainlife.app.483","_canedit":true},{"_id":"5eed5e9dd39ceb225da0ed17","stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3c0f62f3d3800f127b9a"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3c0f62f3d3800f127b9b"}],"success_rate":46.752233956133225,"users":12,"runtime_mean":1696316.03,"runtime_std":1955289.3661379511,"requested":36654,"examples":4,"groups":26},"projects":[],"admins":["16"],"tags":[],"removed":false,"config":{"cortexmap":{"type":"input","file_id":"cortexmap","input_id":"cortexmap"},"lh_annot":{"type":"input","file_id":"lh_annot","input_id":"parc"},"rh_annot":{"type":"input","file_id":"rh_annot","input_id":"parc"},"lh_pial_surf":{"type":"input","file_id":"lh_pial_surf","input_id":"parc"},"rh_pial_surf":{"type":"input","file_id":"rh_pial_surf","input_id":"parc"},"fsaparc":{"id":"fsaparc","type":"enum","placeholder":"","advanced":false,"desc":"This is the freesurfer aparc you want to compute stats within. Needs to be within the cortexmap/lable dir.","default":"aparc.a2009s","_order":2,"pid":0.0589407716683078,"options":[{"desc":"aparc","label":"aparc","value":"aparc"},{"desc":"aparc.a2009s","label":"aparc.a2009s","value":"aparc.a2009s"},{"desc":"aparc.DKTatlas","label":"aparc.DKTatlas","value":"aparc.DKTatlas"}]},"validator_csv":{"id":"validator_csv","type":"enum","placeholder":"","advanced":false,"desc":"","default":"aparc_MEAN","_order":3,"pid":0.8309583469435928,"options":[{"desc":"aparc_MEAN","label":"aparc_MEAN","value":"aparc_MEAN"},{"desc":"aparc_MAX","label":"aparc_MAX","value":"aparc_MAX"},{"desc":"aparc_MIN","label":"aparc_MIN","value":"aparc_MIN"},{"desc":"aparc_MEDIAN","label":"aparc_MEDIAN","value":"aparc_MEDIAN"},{"desc":"aparc_MODE","label":"aparc_MODE","value":"aparc_MODE"},{"desc":"aparc_SAMPSTDEV","label":"aparc_SAMPSTDEV","value":"aparc_SAMPSTDEV"},{"desc":"aparc_STDEV","label":"aparc_STDEV","value":"aparc_STDEV"},{"desc":"parc_MEAN","label":"parc_MEAN","value":"parc_MEAN"},{"desc":"parc_MIN","label":"parc_MIN","value":"parc_MIN"},{"desc":"parc_MAX","label":"parc_MAX","value":"parc_MAX"},{"desc":"parc_MEDIAN","label":"parc_MEDIAN","value":"parc_MEDIAN"},{"desc":"parc_MODE","label":"parc_MODE","value":"parc_MODE"},{"desc":"parc_SAMPSTDEV","label":"parc_SAMPSTDEV","value":"parc_SAMPSTDEV"},{"desc":"parc_STDEV","label":"parc_STDEV","value":"parc_STDEV"}]}},"inputs":[{"id":"cortexmap","desc":"Path to the cortexmap datatype folder","datatype":"5c58aa5ef9109beac4b52f61","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5eed5e9dd39ceb6ce1a0ed19"},{"id":"parc","desc":"Path to individual parcellation and annotation files for parcellation/surface datatype. Files: lh_annot: lh.parc.annot.gii; rh_annot: rh.parc.annot.gii; lh_pial_surf: lh.parc.pial.gii; rh_pial_surf: rh.parc.pial.gii","datatype":"5c478b7bf9109beac4520be6","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5eed5e9dd39ceb083da0ed18"}],"outputs":[{"id":"parc-stats","desc":"Csv files for each summary statistic and parcellation","datatype":"5edd3b77c5972b8c47b3a2c3","datatype_tags":["cortex_mapping_stats"],"datatype_tags_pass":"cortexmap","output_on_root":false,"files":null,"archive":true,"_id":"5eed5e9dd39ceb532aa0ed1b"},{"id":"raw","desc":"Derivatives generated during run for debugging","datatype":"59c3eae633fc1cf9ead71679","datatype_tags":["cortex_mapping_stats_derivatives"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5eed5e9dd39ceb3ca4a0ed1a"}],"github_branch":"v1.1","github":"brainlife/app-cortex-tissue-mapping-stats","name":"Compute summary statistics of diffusion measures mapped to cortical surface - Deprecated Surface","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3c0f62f3d3800f127b9c"},{"name":"Franco Pestilli","email":null,"_id":"634a3c0f62f3d3800f127b9d"}],"create_date":"2020-06-20T00:55:57.544Z","desc":null,"doi":"10.25663/brainlife.app.383","__v":4594,"desc_override":"This app will This app will compute multiple summary statistics from measures mapped to the cortical midthickness surface on a per-ROI basis. This app takes in a cortexmap datatype and an optional parcellation/surface datatype. This app will compute the following summary statistics: minimum, maximum, mean, median, mode, standard deviation, sample standard deviation (n-1), and nonzero vertex count. The app will output a csv for each summary measure summarizing the diffusion measures in each ROI parcellation. If no parcellation surface is inputted, the app will just compute stats from the labels file found in the cortexmap datatype (usually aparc.a2009s.labels.gii). These csvs can be used for computing group averages and for performing machine learning analyses.","deprecated_by":"62c20fc9f3194eded6fb2254","_canedit":true},{"_id":"62c20d12f3194eded6fb203c","user_id":"16","projects":[],"admins":["16"],"name":"Compute summary statistics of diffusion measures mapped to cortical surface - Freesurfer computations","github":"brainlife/app-cortex-tissue-mapping-stats","github_branch":"updated-surface-dtype-v1.2","desc":null,"desc_override":"This app will This app will compute multiple summary statistics from measures mapped to the cortical midthickness surface on a per-ROI basis. This app takes in a cortexmap datatype and an optional parcellation/surface datatype. This app will compute the following summary statistics: minimum, maximum, mean, median, mode, standard deviation, sample standard deviation (n-1), and nonzero vertex count. The app will output a csv for each summary measure summarizing the diffusion measures in each ROI parcellation. If no parcellation surface is inputted, the app will just compute stats from the labels file found in the cortexmap datatype (usually aparc.a2009s.labels.gii). These csvs can be used for computing group averages and for performing machine learning analyses.","tags":[],"contributors":[{"name":"Brad Caron","email":null,"_id":"634a456562f3d3800f1310c4"},{"name":"Franco Pestilli","email":null,"_id":"634a456562f3d3800f1310c5"}],"config":{"cortexmap":{"type":"input","file_id":"cortexmap","input_id":"cortexmap"},"lh_annot":{"type":"input","file_id":"left","input_id":"parc_surface"},"rh_annot":{"type":"input","file_id":"right","input_id":"parc_surface"},"label":{"type":"input","file_id":"label","input_id":"parc_surface"},"right_surf":{"type":"input","file_id":"right","input_id":"parc_surf_vertices"},"left_surf":{"type":"input","file_id":"left","input_id":"parc_surf_vertices"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"}},"inputs":[{"id":"cortexmap","desc":"Path to the cortexmap datatype folder","datatype":"5c58aa5ef9109beac4b52f61","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5eed5e9dd39ceb6ce1a0ed19"},{"id":"parc_surface","datatype":"5f78b377268f76598c29b27a","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"603b030878e65d6a6fd1b3d5"},{"id":"parc_surf_vertices","datatype":"5f78b255268f764bdd29b254","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"603b030878e65d3f89d1b3d6"},{"id":"freesurfer","datatype":"58cb22c8e13a50849b25882e","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"62c20d12f3194eded6fb2042"}],"outputs":[{"id":"parc-stats","desc":"Csv files for each summary statistic and parcellation","datatype":"5edd3b77c5972b8c47b3a2c3","datatype_tags":["cortex_mapping_stats","mri_segstats","freesurfer"],"datatype_tags_pass":"cortexmap","output_on_root":false,"files":null,"archive":true,"_id":"5eed5e9dd39ceb532aa0ed1b"},{"id":"raw","desc":"Derivatives generated during run for debugging","datatype":"59c3eae633fc1cf9ead71679","datatype_tags":["cortex_mapping_stats_derivatives"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5eed5e9dd39ceb3ca4a0ed1a"}],"stats":{"success_rate":46.752233956133225,"groups":26,"users":12,"runtime_mean":1696316.03,"runtime_std":1955289.3661379511,"requested":36654,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a456462f3d3800f1310c2"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a456462f3d3800f1310c3"}],"examples":0},"removed":false,"__v":166,"create_date":"2022-07-03T21:41:38.022Z","doi":"10.25663/brainlife.app.656","_canedit":true},{"_id":"62c20fc9f3194eded6fb2254","user_id":"16","projects":[],"admins":["16"],"name":"Compute summary statistics of diffusion measures mapped to cortical surface - Freesurfer stats - Deprecated Surface","github":"brainlife/app-cortex-tissue-mapping-stats","github_branch":"v1.3","desc":null,"desc_override":"This app will This app will compute multiple summary statistics from measures mapped to the cortical midthickness surface on a per-ROI basis. This app takes in a cortexmap datatype and an optional parcellation/surface datatype. This app will compute the following summary statistics: minimum, maximum, mean, median, mode, standard deviation, sample standard deviation (n-1), and nonzero vertex count. The app will output a csv for each summary measure summarizing the diffusion measures in each ROI parcellation. If no parcellation surface is inputted, the app will just compute stats from the labels file found in the cortexmap datatype (usually aparc.a2009s.labels.gii). These csvs can be used for computing group averages and for performing machine learning analyses.","tags":[],"contributors":[{"name":"Brad Caron","email":null,"_id":"634a456e62f3d3800f131101"},{"name":"Franco Pestilli","email":null,"_id":"634a456e62f3d3800f131102"}],"config":{"cortexmap":{"type":"input","file_id":"cortexmap","input_id":"cortexmap"},"lh_annot":{"type":"input","file_id":"lh_annot","input_id":"parc"},"rh_annot":{"type":"input","file_id":"rh_annot","input_id":"parc"},"lh_white_surf":{"type":"input","file_id":"lh_white_surf","input_id":"parc"},"rh_white_surf":{"type":"input","file_id":"rh_white_surf","input_id":"parc"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"}},"inputs":[{"id":"cortexmap","desc":"Path to the cortexmap datatype folder","datatype":"5c58aa5ef9109beac4b52f61","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5eed5e9dd39ceb6ce1a0ed19"},{"id":"parc","desc":"Path to individual parcellation and annotation files for parcellation/surface datatype. Files: lh_annot: lh.parc.annot.gii; rh_annot: rh.parc.annot.gii; lh_pial_surf: lh.parc.pial.gii; rh_pial_surf: rh.parc.pial.gii","datatype":"5c478b7bf9109beac4520be6","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5eed5e9dd39ceb083da0ed18"},{"id":"freesurfer","datatype":"58cb22c8e13a50849b25882e","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"62c21068f3194eded6fb236d"}],"outputs":[{"id":"parc-stats","desc":"Csv files for each summary statistic and parcellation","datatype":"5edd3b77c5972b8c47b3a2c3","datatype_tags":["cortex_mapping_stats","mri_segstats","freesurfer"],"datatype_tags_pass":"cortexmap","output_on_root":false,"files":null,"archive":true,"_id":"5eed5e9dd39ceb532aa0ed1b"},{"id":"raw","desc":"Derivatives generated during run for debugging","datatype":"59c3eae633fc1cf9ead71679","datatype_tags":["cortex_mapping_stats_derivatives"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5eed5e9dd39ceb3ca4a0ed1a"}],"stats":{"success_rate":46.752233956133225,"groups":26,"users":12,"runtime_mean":1696316.03,"runtime_std":1955289.3661379511,"requested":36654,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a456d62f3d3800f1310ff"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a456d62f3d3800f131100"}],"examples":1},"removed":false,"deprecated_by":"62c20d12f3194eded6fb203c","__v":166,"create_date":"2022-07-03T21:53:13.410Z","doi":"10.25663/brainlife.app.657","_canedit":true},{"_id":"62abfcd7ab3e66978063bf43","user_id":"16","projects":[],"admins":["16"],"name":"Compute summary statistics of diffusion measures mapped to visual regions binned by eccentricity - Benson14","github":"brainlife/app-cortex-tissue-mapping-stats","github_branch":"benson14-prf-eccentricity-stats","desc":null,"desc_override":"This app will compute the average diffusion metrics, and anatomical measures from Freesurfer including thickness, surface area, and volume, within the visual areas returned by the prf - Benson14 app. Will return a parc-stats datatype for each eccentricity-binned visual area parcellation.","tags":[],"contributors":[{"name":"Brad Caron","email":null,"_id":"634a453762f3d3800f130ff5"},{"name":"Franco Pestilli","email":null,"_id":"634a453762f3d3800f130ff6"}],"config":{"cortexmap":{"type":"input","file_id":"cortexmap","input_id":"cortexmap"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"prf_surfaces":{"type":"input","file_id":"prf_surfaces","input_id":"prf"},"minDegree":{"id":"minDegree","type":"string","placeholder":"","advanced":false,"desc":"string of minimum eccentricity degrees for binning.\n\nFor example, if you wanted to compute stats between eccentricities 0-5 and 7-90, this field would be '0 7'","default":"","_order":2,"pid":0.32040349095994203},"maxDegree":{"id":"maxDegree","type":"string","placeholder":"","advanced":false,"desc":"string of maximum eccentricity degrees for binning.\n\nFor example, if you wanted to compute stats between eccentricities 0-5 and 7-90, this field would be '5 90'","default":"","_order":3,"pid":0.9198176602449399}},"inputs":[{"id":"cortexmap","desc":"Path to the cortexmap datatype folder","datatype":"5c58aa5ef9109beac4b52f61","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5eed5e9dd39ceb6ce1a0ed19"},{"id":"freesurfer","datatype":"58cb22c8e13a50849b25882e","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"62abfcd7ab3e66978063bf47"},{"id":"prf","datatype":"5d9d18d8e30ae43bb0612715","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"62abfcd7ab3e66978063bf48"}],"outputs":[{"id":"parc_stats","desc":"Csv files for each summary statistic and parcellation","datatype":"5edd3b77c5972b8c47b3a2c3","datatype_tags":["cortex_mapping_stats","eccentricity-binned","benson14_visual_areas"],"datatype_tags_pass":"cortexmap","output_on_root":false,"files":null,"archive":true,"_id":"5eed5e9dd39ceb532aa0ed1b"},{"id":"raw","desc":"Derivatives generated during run for debugging","datatype":"59c3eae633fc1cf9ead71679","datatype_tags":["cortex_mapping_stats_derivatives","eccentricity-binned","benson14_visual_areas"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5eed5e9dd39ceb3ca4a0ed1a"}],"stats":{"success_rate":46.752233956133225,"groups":26,"users":12,"runtime_mean":1696316.03,"runtime_std":1955289.3661379511,"requested":36654,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a453662f3d3800f130ff3"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a453662f3d3800f130ff4"}],"examples":0},"removed":false,"__v":247,"create_date":"2022-06-17T04:02:31.639Z","doi":"10.25663/brainlife.app.651","_canedit":true},{"_id":"5f1fa182beafe9548f622a7e","stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3c5c62f3d3800f128597"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3c5c62f3d3800f128598"}],"success_rate":94.02452415812591,"users":32,"runtime_mean":27266.98,"runtime_std":22342.225256665915,"requested":11132,"examples":5,"groups":48},"projects":[],"admins":["704"],"tags":["network"],"removed":false,"config":{"index":{"type":"input","file_id":"index","input_id":"conmat"},"label":{"type":"input","file_id":"label","input_id":"conmat"},"csv":{"type":"input","file_id":"csv","input_id":"conmat"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5f1fa182beafe99b5f622a7f","id":"conmat","datatype":"5d34d9f744947d8aea0e0d2f","desc":"Connectivity matrix  file to be converted to a network"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5f1fa182beafe91c13622a80","id":"output","datatype":"5ed0352de3f453b13b267dae","datatype_tags_pass":"conmat","files":null,"desc":"Network file converted from a conmat (connectivity matrix) datatype. All metadata is preserved."}],"github_branch":"0.2","github":"filipinascimento/bl-conmat2network","name":"Conmat to network","avatar":"https://raw.githubusercontent.com/filipinascimento/bl-conmat2network/master/Media/Icon.png","user_id":"704","contributors":[{"name":"Filipi Nascimento Silva","email":"filipinascimento@gmail.com","_id":"634a3c5d62f3d3800f128599"}],"create_date":"2020-07-28T03:54:42.203Z","desc":"Simple brainlife app to create a network from a conmat matrix.","doi":"10.25663/brainlife.app.393","__v":4282,"_canedit":true},{"_id":"6143a6a57a38b00ad39f50e9","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a428762f3d3800f12f643"}],"success_rate":71.43932267168391,"users":1,"runtime_mean":22400,"runtime_std":10712.487023095991,"requested":6881,"examples":2,"groups":6},"projects":[],"admins":["386"],"tags":[],"removed":false,"config":{"left":{"type":"input","file_id":"left","input_id":"input"},"right":{"type":"input","file_id":"right","input_id":"input"},"label":{"type":"input","file_id":"label","input_id":"input"},"confounds":{"type":"input","file_id":"regressors","input_id":"regressors"},"json":{"type":"input","file_id":"json","input_id":"regressors"},"approach":{"id":"approach","type":"enum","placeholder":"","advanced":true,"desc":"","default":"diffusion-maps","_order":2,"pid":0.001755943808763094,"options":[{"desc":"","label":"diffusion-maps","value":"diffusion-maps"},{"desc":"","label":"laplacian-eigenmaps","value":"laplacian-eigenmaps"},{"desc":"","label":"pca-maps","value":"pca-maps"}],"optional":false,"readonly":null},"kernel":{"id":"kernel","type":"enum","placeholder":"","advanced":true,"desc":"","default":"normalized-angle","_order":3,"pid":0.5678016356992894,"options":[{"desc":"","label":"pearson","value":"pearson"},{"desc":"","label":"spearman","value":"spearman"},{"desc":"","label":"normalized-angle","value":"normalized-angle"},{"desc":"","label":"cosine","value":"cosine"},{"desc":"","label":"gaussian","value":"gaussian"}],"optional":false,"readonly":null},"n_components":{"id":"n_components","type":"number","placeholder":"","advanced":true,"desc":"","default":2,"_order":4,"pid":0.7740173745226671,"optional":true,"min":1},"random_state":{"id":"random_state","type":"number","placeholder":"","advanced":true,"desc":"","default":0,"_order":5,"pid":0.5533847635811513,"optional":true},"threshold":{"id":"threshold","type":"number","placeholder":"","advanced":false,"desc":"","default":0,"_order":6,"pid":0.7145611035553188,"optional":true,"min":0,"max":1}},"inputs":[{"id":"input","datatype":"5f78b377268f76598c29b27a","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"6143a6a57a38b058f79f50ea"},{"id":"regressors","datatype":"5c4f6a8af9109beac4b3dae0","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"61884e73e8be76b34cb8209f"}],"outputs":[{"id":"gradients","datatype":"6174c1ba4fd85c74b153fddd","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"6143a6a57a38b010609f50eb"}],"github_branch":"main","github":"anibalsolon/app-connectivity-gradient","name":"Connectivity Gradients","user_id":"386","contributors":[{"name":"Anibal Sólon","email":"anibalsolon@gmail.com","_id":"634a428762f3d3800f12f644"}],"create_date":"2021-09-16T20:18:45.540Z","desc":null,"__v":1807,"doi":"10.25663/brainlife.app.574","_canedit":true},{"_id":"59559aafd9f0e20021415cb6","name":"Connectome Evaluator ","desc":"Estimate the quality of your diffusion-weighted data to map human connectomes.","avatar":"https://raw.githubusercontent.com/brain-life/app-connectome-evaluator/master/docs/comparison.png","github":"brainlife/app-connectome-evaluator","github_branch":"master","config":{"input_fe":{"file_id":"fe","input_id":"life","type":"input"}},"user_id":"30","removed":false,"_rate":0,"create_date":"2017-06-30T00:26:23.064Z","outputs":[{"datatype_tags":[],"output_on_root":true,"archive":true,"_id":"595a72c3d9f0e20021415cb7","id":"output","datatype":"594c688bfa1d2e5a1f0e33f1","files":null}],"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"59559aafd9f0e20021415cb5","id":"life","datatype":"58d15eaee13a50849b258844"}],"tags":["quality-check"],"admins":["1"],"__v":14293,"contributors":[{"name":"Franco Pestilli","email":null,"_id":"634a30cf62f3d3800f11651e"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a30cf62f3d3800f11651f"}],"projects":[],"references":[],"stats":{"stars":1,"requested":1,"users":1,"serviceinfo":{"_id":"5d729e1f78356a109788b2c5","counts":{"_id":"5e5c687e87cac7c990ab1ba2","failed":56,"finished":174,"removed":239,"requested":263,"running":199,"running_sync":0,"stop_requested":15},"success_rate":75.65217391304347,"users":14,"readme_status":"too short","runtime_mean":171274.32,"runtime_std":45939.28686622811,"service":"brain-life/app-connectome-evaluator","__v":0},"gitinfo":{"desc":"Estimate the quality of your diffusion-weighted data to map human connectomes.","tags":["quality-check"],"stats":{"stars":0},"contributors":[{"name":"Franco Pestilli","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"resources":[],"examples":0,"groups":1},"doi":"10.25663/bl.app.102","deprecated_by":"5baa44b1d0be8b002776b8f7","_canedit":true},{"_id":"5b083f9341711001e958b2b7","projects":[],"admins":["43"],"tags":["convert"],"removed":false,"name":"Convert Pial (Cortical) and White Matter Surfaces from Freesurfer","desc":"This application converts Freesurfer's pial and white matter surfaces to different file types. It will convert the lh/rh.pial, lh/rh.white, lh/rh.smoothwm, lh/rh.inflated files into your choice of file type (stl, vtk, gii, mgz)","citation":null,"references":[],"avatar":"https://raw.githubusercontent.com/kitchell/app-3DPialWM_freesurfer/master/pialwm-01.png","github":"kitchell/app-3DPialWM_freesurfer","config":{"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"filetype":{"type":"enum","placeholder":"","desc":"","default":"vtk","options":[{"desc":"vtk filetype","label":"vtk","value":"vtk"},{"desc":"stl filetype","label":"stl","value":"stl"},{"desc":"gii filetype","label":"gii","value":"gii"},{"desc":"mgz filetype","label":"mgz","value":"mgz"}],"id":"filetype","pid":0.6274108835879617,"_order":2,"readonly":false}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5b083f9341711001e958b2b8","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e"}],"outputs":[{"datatype_tags":["pial_wm_inflated"],"output_on_root":true,"archive":true,"_id":"5b083f9341711001e958b2b9","id":"surfaces","datatype":"59307a08436ee50ffd973278","datatype_tags_pass":null,"files":null}],"user_id":"43","contributors":[{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a32fd62f3d3800f117b2f"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a32fd62f3d3800f117b30"},{"name":null,"email":null,"_id":"634a32fd62f3d3800f117b31"}],"create_date":"2018-05-25T16:53:39.754Z","stats":{"stars":0,"requested":1336,"users":14,"success_rate":91.33383571966843,"serviceinfo":{"_id":"5d729e1f78356a109788b29b","counts":{"_id":"5e5c3da587cac7ddc0ab13b6","failed":95,"finished":1127,"removed":1124,"requested":1228,"running":1144,"running_sync":0,"stop_requested":0},"success_rate":92.22585924713584,"users":10,"readme_status":"ok","runtime_mean":1504967.96,"runtime_std":3072887.269125021,"service":"kitchell/app-3DPialWM_freesurfer","__v":0},"gitinfo":{"desc":"This application converts Freesurfer's pial and white matter surfaces to different file types. It will convert the lh/rh.pial, lh/rh.white, lh/rh.smoothwm, lh/rh.inflated files into your choice of file type (stl, vtk, gii, mgz)","tags":["convert"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null}]},"runtime_mean":5275247.54,"runtime_std":11936274.070740825,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a32fd62f3d3800f117b2e"}],"examples":1,"groups":12},"doi":"10.25663/bl.app.38","__v":13211,"_canedit":true},{"_id":"5c6391dcf2362b00318046b8","stats":{"stars":0,"requested":77,"users":2,"success_rate":60.37735849056604,"serviceinfo":{"_id":"5d729e1f78356a109788b243","counts":{"_id":"5e5c3de387cac77701ab13f6","failed":3,"finished":20,"removed":46,"requested":47,"running":29,"running_sync":0,"stop_requested":5},"success_rate":86.95652173913044,"users":1,"readme_status":"too short","runtime_mean":458576.45,"runtime_std":293098.24109340453,"service":"brainlife/app-make-mask-from-dtiinit","__v":0},"gitinfo":{"desc":null,"tags":[],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null}]},"runtime_mean":1230559.34375,"runtime_std":1839912.9367781356,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a352562f3d3800f11959a"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a352562f3d3800f11959b"}],"examples":1,"groups":2},"projects":[],"admins":["16"],"tags":[],"removed":false,"config":{"dtiinit":{"type":"input","file_id":"output","input_id":"dtiinit"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c6391dcf2362b00318046b9","id":"dtiinit","datatype":"58cb234be13a50849b25882f","desc":"The path to the top directory containing the output from DTIINIT"}],"outputs":[{"datatype_tags":["dwi","brain"],"output_on_root":false,"archive":true,"_id":"5c6391dcf2362b00318046ba","id":"mask","datatype":"5a281aee2c214c9ba83ce620","datatype_tags_pass":null,"files":null,"desc":"The braimask of the DWI data in the DTIINIT input"}],"github_branch":"v1.0.0","github":"brainlife/app-make-mask-from-dtiinit","name":"Convert brainmask from dtiinit","desc_override":"temp app to convert brainmask from dtiinit to mask datatype","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a352562f3d3800f11959c"}],"create_date":"2019-02-13T03:41:16.567Z","desc":null,"doi":"10.25663/brainlife.app.162","__v":8743,"_canedit":true},{"_id":"609aaa4a408e3c907bd56c27","stats":{"resources":[],"success_rate":100,"users":1,"runtime_mean":50429.333333333336,"runtime_std":14681.773674260963,"requested":3,"examples":1,"groups":2},"projects":["5d64733db29ac960ca2e797f","5ff32b04116c5cbba4d1929b"],"admins":["1342","670"],"tags":[],"removed":false,"config":{"ds":{"type":"input","file_id":"ds","input_id":"ctf"},"headshape":{"type":"input","file_id":"headshape","input_id":"ctf"},"channels":{"type":"input","file_id":"channels","input_id":"ctf"},"coordsystem":{"type":"input","file_id":"coordsystem","input_id":"ctf"},"events":{"type":"input","file_id":"events","input_id":"ctf"},"events_json":{"type":"input","file_id":"events_json","input_id":"ctf"},"subject":{"id":"subject","type":"string","placeholder":"","advanced":false,"desc":"The subject ID. Corresponds to “sub” in BIDS structure.","default":"","_order":2,"pid":0.5113727096331595,"optional":true},"session":{"id":"session","type":"string","placeholder":"","advanced":false,"desc":"The session for a item. Corresponds to “ses” in BIDS structure. ","default":"","_order":3,"pid":0.5167638639790492,"optional":true},"task":{"id":"task","type":"string","placeholder":"","advanced":false,"desc":"The task for a item. Corresponds to “task” in BIDS structure.","default":"","_order":4,"pid":0.21630370783245856,"optional":true},"run":{"id":"run","type":"string","placeholder":"","advanced":false,"desc":"he run number for this item. Corresponds to “run” in BIDS structure.","default":"","_order":5,"pid":0.15847138568358377,"optional":true},"acquisition":{"id":"acquisition","type":"string","placeholder":"","advanced":false,"desc":"The acquisition parameters for the item. Corresponds to “acq” in BIDS structure.","default":"","_order":6,"pid":0.9402817828239846,"optional":true},"processing":{"id":"processing","type":"string","placeholder":"","advanced":false,"desc":"The processing label for this item. Corresponds to “proc\" in BIDS structure.","default":"","_order":7,"pid":0.08539871594313286,"optional":true},"recording":{"id":"recording","type":"string","placeholder":"","advanced":false,"desc":"The recording name for this item. Corresponds to “rec” in BIDS structure.","default":"","_order":8,"pid":0.8585064460050444,"optional":true},"space":{"id":"space","type":"string","placeholder":"","advanced":false,"desc":"The coordinate space for an anatomical or sensor position files. Corresponds to “space” in BIDS structure.","default":"","_order":9,"pid":0.7431670222061121,"optional":true},"suffix":{"id":"suffix","type":"string","placeholder":"","advanced":false,"desc":"The filename suffix. This is the entity after the last _ before the extension in BIDS structure.","default":"","_order":10,"pid":0.8396034166393146,"optional":true}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"609aaa4a408e3ce648d56c28","id":"ctf","datatype":"6000714baacf9e22a6a691c8","desc":"The ctf file you want to convert into fif"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"609aaa4a408e3c492ad56c29","id":"out_dir","datatype":"6000737faacf9ee51fa691cb","datatype_tags_pass":null,"files":null,"desc":"The MEG file in fif format"}],"github_branch":"main","github":"brainlife/app-ctf2fif","name":"Convert ctf file to fif","user_id":"1342","contributors":[{"name":null,"email":null,"_id":"634a408d62f3d3800f12d791"}],"create_date":"2021-05-11T16:01:14.908Z","desc":"Convert ctf files into fif format","__v":2672,"doi":"10.25663/brainlife.app.519","_canedit":true},{"_id":"5eb0a0650d21177fad4287d9","stats":{"success_rate":97.6054454843807,"users":24,"runtime_mean":287614.32,"runtime_std":1070949.9821393797,"requested":9448,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3a5262f3d3800f123b76"}],"examples":5,"groups":35},"projects":[],"admins":["16"],"tags":[],"removed":false,"config":{"matrices":{"type":"input","file_id":"output","input_id":"raw"},"parc":{"type":"input","file_id":"parc","input_id":"parc"},"key":{"type":"input","file_id":"key","input_id":"parc"},"label":{"type":"input","file_id":"label","input_id":"parc"},"measure":{"id":"measure","type":"enum","placeholder":"","advanced":false,"desc":"The network matrix measure wanting to be converted","default":"","_order":2,"pid":0.5978501505078628,"options":[{"desc":"streamline density","label":"density","value":"density"},{"desc":"streamline count","label":"count","value":"count"},{"desc":"mean fa","label":"fa_mean","value":"fa_mean"},{"desc":"standard deviation fa","label":"fa_std","value":"fa_std"},{"desc":"streamline length","label":"length","value":"length"},{"desc":"curvature","label":"curv","value":"curv"},{"desc":"torsion","label":"tors","value":"tors"},{"desc":"fa_tp","label":"fa_tp","value":"fa_tp"},{"desc":"denlen","label":"denlen","value":"denlen"},{"desc":"centers","label":"centers","value":"centers"},{"desc":"mean md","label":"md_mean","value":"md_mean"},{"desc":"mean rd","label":"rd_mean","value":"rd_mean"},{"desc":"mean ad","label":"ad_mean","value":"ad_mean"},{"desc":"mean ndi","label":"ndi_mean","value":"ndi_mean"},{"desc":"mean odi","label":"odi_mean","value":"odi_mean"},{"desc":"mean isovf","label":"isovf_mean","value":"isovf_mean"},{"desc":"mean ad scaled by inverse volume of nodes","label":"ad_mean_density","value":"ad_mean_density"},{"desc":"mean fa scaled by inverse volume of nodes","label":"fa_mean_density","value":"fa_mean_density"},{"desc":"mean md scaled by inverse volume of nodes","label":"md_mean_density","value":"md_mean_density"},{"desc":"mean rd scaled by inverse volume of nodes","label":"rd_mean_density","value":"rd_mean_density"},{"desc":"mean ndi scaled by inverse volume of nodes","label":"ndi_mean_density","value":"ndi_mean_density"},{"desc":"mean odi scaled by inverse volume of nodes","label":"odi_mean_density","value":"odi_mean_density"},{"desc":"mean isovf scaled by inverse volume of nodes","label":"isovf_mean_density","value":"isovf_mean_density"}]}},"inputs":[{"datatype_tags":["networkmatrices"],"optional":false,"multi":false,"advanced":false,"_id":"5eb0a0650d2117fc614287da","id":"raw","datatype":"59c3eae633fc1cf9ead71679","desc":"The path to the top directory of the network matrices app"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5eb0a0650d21175d6b4287db","id":"parc","datatype":"5c1a7489f9109beac4a88a1f","desc":"The path to the parcellation/volume datatype used to generate the network matrices"}],"outputs":[{"datatype_tags":["networkmatrices","preprocessed"],"output_on_root":false,"archive":true,"_id":"5eb0a0650d211720144287dc","id":"cm","datatype":"5d34d9f744947d8aea0e0d2f","datatype_tags_pass":null,"files":null,"desc":"The conmat data output"}],"github_branch":"v1.0.0","github":"brainlife/app-network-matrices-2-mat","name":"Convert network neuro matrix to conmat","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3a5362f3d3800f123b77"},{"name":"Franco Pestilli","email":null,"_id":"634a3a5362f3d3800f123b78"}],"create_date":"2020-05-04T23:08:21.463Z","desc":null,"doi":"10.25663/brainlife.app.335","__v":4961,"desc_override":"This app will converts a network matrix of a measure of interest (i.e. density, count) found in the raw:networkmatrices datatype output of Network Neuro app and a parcellation used to generate the matrix to a conmat datatype. This is a temporary app until the Network Neuro app outputs a conmat datatype. This conmat datatype is main datatype for a majority of the network processing apps currently on the website. May be deprecated in the future.","_canedit":true},{"_id":"6230bbbb5d8ab5d5f038b43a","user_id":"16","projects":[],"admins":["16"],"name":"Convert quality control (qc) data from eddy to regressors datatype","github":"brainlife/app-convert-eddyqc-to-regressor","github_branch":"main","desc_override":"This app will convert the quality control (qc) data from eddy to a regressors datatype to be used as a nuisance matrix for statistical analyses","tags":[],"config":{"topPath":{"type":"input","file_id":"output","input_id":"topPath"}},"inputs":[{"id":"topPath","datatype":"59c3eae633fc1cf9ead71679","datatype_tags":["eddyqc"],"optional":false,"multi":false,"advanced":false,"_id":"6230bbbb5d8ab5d5f038b43b"}],"outputs":[{"id":"regressors","datatype":"5c4f6a8af9109beac4b3dae0","datatype_tags":["eddyqc"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"6230bbbb5d8ab5d5f038b43c"}],"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a43cf62f3d3800f1307f6"}],"examples":1,"success_rate":33.33333333333333,"users":1,"runtime_mean":11709,"runtime_std":0,"requested":3,"groups":1},"removed":false,"contributors":[{"name":"Brad Caron","email":null,"_id":"634a43cf62f3d3800f1307f7"}],"create_date":"2022-03-15T16:15:55.131Z","desc":null,"__v":687,"doi":"10.25663/brainlife.app.610","_canedit":true},{"_id":"6144b8987a38b0c6c8a05697","stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a429962f3d3800f12f654"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a429962f3d3800f12f655"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"634a429962f3d3800f12f656"}],"success_rate":76.42612120442129,"users":15,"runtime_mean":966510.03,"runtime_std":1250650.5328230064,"requested":19020,"examples":1,"groups":42},"projects":[],"admins":["16"],"tags":["postprocessing"],"removed":false,"config":{"surf_data_left":{"type":"input","file_id":"left","input_id":"surf_data"},"surf_data_right":{"type":"input","file_id":"right","input_id":"surf_data"},"label":{"type":"input","file_id":"label","input_id":"surf_data"},"surf_verts_right":{"type":"input","file_id":"right","input_id":"surf_verts"},"surf_verts_left":{"type":"input","file_id":"left","input_id":"surf_verts"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"6144b8987a38b0875fa05698","id":"surf_data","datatype":"5f78b377268f76598c29b27a"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"6144b8987a38b034b3a05699","id":"surf_verts","datatype":"5f78b255268f764bdd29b254"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"6144b8987a38b03b85a0569a","id":"cortexmap","datatype":"5c58aa5ef9109beac4b52f61","datatype_tags_pass":"surf_data","files":null}],"github_branch":"convert-surface-datatype","github":"brainlife/app-cortex-tissue-mapping","name":"Convert surface datatypes to cortexmap datatype","desc_override":"This app will convert the surface/data and surface/vertices datatypes into a cortexmap datatype. This is intended for easier use with Connectome Workbench, including the viewers.","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a429962f3d3800f12f657"},{"name":"Franco Pestilli","email":null,"_id":"634a429962f3d3800f12f658"}],"create_date":"2021-09-17T15:47:36.141Z","desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","__v":1798,"doi":"10.25663/brainlife.app.576","_canedit":true},{"_id":"5c0ab6e6f9b4a2002efc1618","stats":{"stars":0,"requested":4429,"users":20,"success_rate":61.30204890945142,"serviceinfo":{"_id":"5d729e1f78356a109788b269","counts":{"_id":"5e5c3dcf87cac71b7fab13e4","failed":1151,"finished":1476,"removed":3587,"requested":3708,"running":2547,"running_sync":0,"stop_requested":27},"success_rate":56.18576322801675,"users":9,"readme_status":"ok","runtime_mean":569326.2,"runtime_std":2650461.83215067,"service":"brainlife/app-convert-tck-to-trk","__v":0},"gitinfo":{"desc":"Convert a tractogram in tck format to a trk format file","tags":["convert"],"stats":{"stars":0},"contributors":[{"name":"Paolo Avesani","email":null}]},"runtime_mean":2742703.86,"runtime_std":10849853.533831676,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a349062f3d3800f118c0e"}],"examples":3,"groups":26},"projects":[],"admins":["45"],"tags":[],"removed":false,"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"tck":{"type":"input","file_id":"track","input_id":"tck"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c0ab6e6f9b4a2002efc161a","id":"dwi","datatype":"58c33c5fe13a50849b25879b","desc":"The DWI file will provide the reference space for the tractogram in output stored according to the TRK specifications."},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c0ab6e6f9b4a2002efc1619","id":"tck","datatype":"5907d922436ee50ffde9c549","desc":"A tractogram encoded according to the Mrtrix specifications."}],"outputs":[{"datatype_tags":["dwi"],"output_on_root":false,"archive":true,"_id":"5c0ab6e6f9b4a2002efc161b","id":"trk","datatype":"5b956f6cd7b3f1e24e9121ce","datatype_tags_pass":"tck","files":null,"desc":"The tractogram encoded following the TRK specifications. The reference space of streamlines is redefined according to the space of the DWI file given in input."}],"name":"Convert tck to trk in DWI space","github":"brainlife/app-convert-tck-to-trk","user_id":"45","references":[],"contributors":[{"name":"Paolo Avesani","email":null,"_id":"634a349162f3d3800f118c0f"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a349162f3d3800f118c10"}],"create_date":"2018-12-07T18:07:34.180Z","doi":"10.25663/brainlife.app.132","__v":9287,"desc_override":"Convert a tractogram in tck format to a trk format file in dwi space","github_branch":"1.0","desc":"Convert a tractogram in tck format to a trk format file","_canedit":true},{"_id":"5c0e7f30f9b4a2002efc16ab","stats":{"stars":0,"serviceinfo":{"_id":"5d729e1f78356a109788b269","counts":{"_id":"5e5c3dd087cac73c86ab13e5","failed":1151,"finished":1476,"removed":3587,"requested":3708,"running":2547,"running_sync":0,"stop_requested":27},"success_rate":56.18576322801675,"users":9,"readme_status":"ok","runtime_mean":569326.2,"runtime_std":2650461.83215067,"service":"brainlife/app-convert-tck-to-trk","__v":0},"gitinfo":{"desc":"Convert a tractogram in tck format to a trk format file","tags":["convert"],"stats":{"stars":0},"contributors":[{"name":"Paolo Avesani","email":null}]},"success_rate":61.30204890945142,"users":20,"runtime_mean":2742703.86,"runtime_std":10849853.533831676,"requested":4429,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a349a62f3d3800f118c77"}],"examples":1,"groups":26},"projects":[],"admins":["1","45"],"tags":[],"removed":false,"config":{"dwi":{"type":"input","file_id":"t1","input_id":"t1"},"tck":{"type":"input","file_id":"track","input_id":"tck"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c0e7f30f9b4a2002efc16ad","id":"t1","datatype":"58c33bcee13a50849b25879a","desc":"The T1 nifti file will provide the reference space for the tractogram in output stored according to the TRK specifications."},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c0e7f30f9b4a2002efc16ac","id":"tck","datatype":"5907d922436ee50ffde9c549","desc":"A tractogram encoded according to the Mrtrix specifications."}],"outputs":[{"datatype_tags":["t1"],"output_on_root":false,"archive":true,"_id":"5c0e7f30f9b4a2002efc16ae","id":"trk","datatype":"5b956f6cd7b3f1e24e9121ce","datatype_tags_pass":"tck","files":null,"desc":"The tractogram encoded following the TRK specifications. The reference space of streamlines is redefined according to the space of the T1 file given in input."}],"name":"Convert tck to trk in T1 space","desc_override":"Convert a tractogram in tck format to a trk format file in T1 space","github":"brainlife/app-convert-tck-to-trk","github_branch":"1.0","user_id":"1","references":[],"contributors":[{"name":"Paolo Avesani","email":null,"_id":"634a349a62f3d3800f118c78"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a349a62f3d3800f118c79"}],"create_date":"2018-12-10T14:58:56.860Z","doi":"10.25663/brainlife.app.133","__v":9279,"desc":"Convert a tractogram in tck format to a trk format file","_canedit":true},{"_id":"5a5cc14cd6e6ac00400249ed","name":"Convert tck+dwi to trk (MRtrix 2)","desc":"Convert MRtrix TCK to TrackVis TRK files.","citation":null,"github":"brainlife/app-converttck2trk","github_branch":"v1.0","config":{"tracks":{"type":"input","file_id":"track","input_id":"tck file"},"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"}},"user_id":"43","create_date":"2018-01-15T14:57:16.410Z","removed":false,"_rate":0,"outputs":[{"datatype_tags":[],"output_on_root":true,"archive":true,"_id":"5a5cc14cd6e6ac00400249ee","id":"output","datatype":"5b956f6cd7b3f1e24e9121ce","files":null,"datatype_tags_pass":"tck file","desc":"Converted .trk file in dwi space"}],"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5a5cc14cd6e6ac00400249ef","id":"tck file","datatype":"5907d922436ee50ffde9c549","desc":".tck file to be converted"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ac6b77571d0210718658ed6","id":"dwi","datatype":"58c33c5fe13a50849b25879b","desc":"dwi image to use as the reference space"}],"contributors":[{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a31f062f3d3800f116a9f"},{"name":"Franco Pestilli","email":null,"_id":"634a31f062f3d3800f116aa0"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a31f062f3d3800f116aa1"}],"tags":[],"references":[],"admins":["16","41","146","43","1"],"projects":[],"__v":14263,"stats":{"stars":0,"requested":1706,"users":11,"success_rate":77.31958762886599,"serviceinfo":{"_id":"5d729e1f78356a109788b271","counts":{"_id":"5e5c689a87cac712e3ab1bc4","failed":374,"finished":1270,"removed":1486,"requested":1665,"running":1629,"running_sync":0,"stop_requested":9},"success_rate":77.25060827250608,"users":6,"readme_status":"ok","runtime_mean":477573.73,"runtime_std":529016.4441536738,"service":"brainlife/app-converttck2trk","__v":0},"gitinfo":{"desc":"Convert MRtrix TCK to TrackVis TRK files.","tags":[],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Franco Pestilli","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":463332.89,"runtime_std":530255.8169405009,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a31f062f3d3800f116a9e"}],"examples":0,"groups":8},"doi":"10.25663/bl.app.22","desc_override":"Converts a tck that was made using MRtrix 2 into a trk in the dwi space. ","deprecated_by":"5c0ab6e6f9b4a2002efc1618","_canedit":true},{"_id":"629a7dd17f60950a54ccc68f","user_id":"56","projects":[],"admins":["56"],"name":"Convert tcks to tck and WMC","github":"DanNBullock/app-tcks_to_tck_and_WMC","tags":[],"config":{"tcks":{"type":"input","file_id":"tcks","input_id":"tcks"},"tcks_json":{"type":"input","file_id":"tcks_json","input_id":"tcks"}},"inputs":[{"id":"tcks","datatype":"5dcf0047c4ae28d7f2298f48","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"629a7dfa7f60950a54ccc9c6"}],"outputs":[{"id":"tck","datatype":"5907d922436ee50ffde9c549","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"629a7e6f7f60950a54ccd076"},{"id":"wmc","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"629a7e6f7f60950a54ccd077"}],"stats":{"resources":[],"success_rate":100,"users":1,"groups":1,"runtime_mean":20091.666666666668,"runtime_std":3651.07676659305,"requested":7,"examples":1},"removed":false,"contributors":[{"name":"Daniel Bullock","email":"iisdanbul@gmail.com","_id":"634a44dc62f3d3800f130ed0"}],"create_date":"2022-06-03T21:32:01.714Z","desc":"Simple converter for the multi-tck format, tcks, which combines these into a single tck file and produces an associated WMC file.","__v":299,"doi":"10.25663/brainlife.app.641","_canedit":true},{"_id":"60a6ce3d22b42a2f7f701fa7","stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a40bb62f3d3800f12d835"}],"examples":0,"success_rate":0,"users":1,"requested":1,"groups":1},"projects":[],"admins":["16"],"tags":[],"removed":false,"config":{"tractmeasures":{"type":"input","file_id":"csv","input_id":"tractmeasures"}},"inputs":[{"id":"tractmeasures","datatype":"599f305ad1f46fec1759f363","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"60a6ce3d22b42a1504701fa8"}],"outputs":[{"id":"profiles","datatype":"5965467cb09297d8d81bdbcd","datatype_tags":[],"datatype_tags_pass":"tractmeasures","output_on_root":false,"files":null,"archive":true,"_id":"60a6ce3d22b42a6768701fa9"}],"github_branch":"v1.1","github":"brainlife/app-convert-tractmeasures-2-tractprofile","name":"Convert tractmeasures datatype to tractprofile datatype","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a40bb62f3d3800f12d836"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a40bb62f3d3800f12d837"}],"create_date":"2021-05-20T21:01:49.111Z","desc":null,"__v":2612,"doi":"10.25663/brainlife.app.524","_canedit":true},{"_id":"5b9940206e02fb0028e11626","projects":[],"admins":["16","41","146","1"],"tags":["convert"],"removed":false,"config":{"trk":{"type":"input","file_id":"track","input_id":"track"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5b9940206e02fb0028e11627","id":"track","datatype":"5b956f6cd7b3f1e24e9121ce"}],"outputs":[{"datatype_tags":[],"output_on_root":true,"archive":true,"_id":"5b9940206e02fb0028e11628","id":"output","datatype":"5907d922436ee50ffde9c549","datatype_tags_pass":"track","files":null}],"github":"brainlife/app-trk2tck","name":"Convert trk to tck","user_id":"1","references":[],"contributors":[{"name":"Giulia Bertò","email":null,"_id":"634a33cd62f3d3800f118278"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a33cd62f3d3800f118279"}],"create_date":"2018-09-12T16:34:40.208Z","desc":"Convert trk (trackvis) file to tck (mrtrix) format","stats":{"stars":0,"requested":272,"users":18,"success_rate":91.82156133828995,"serviceinfo":{"_id":"5d729e1f78356a109788b295","counts":{"_id":"5e5c3dba87cac776b1ab13cf","failed":2,"finished":62,"removed":64,"requested":66,"running":63,"running_sync":0,"stop_requested":0},"success_rate":96.875,"users":6,"readme_status":"too short","runtime_mean":502999.4032258064,"runtime_std":790245.7297544911,"service":"brainlife/app-trk2tck","__v":0},"gitinfo":{"desc":"Convert trk (trackvis) file to tck (mrtrix) format","tags":["convert"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":98129.67,"runtime_std":124057.20928120661,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a33cc62f3d3800f118277"}],"examples":3,"groups":19},"doi":"10.25663/bl.app.100","__v":10671,"_canedit":true},{"_id":"60538a6038fe12718ef0cd87","stats":{"resources":[],"success_rate":83.33333333333334,"users":2,"runtime_mean":544266.8,"runtime_std":207687.733902029,"requested":13,"examples":0,"groups":2},"projects":["5a78c177340591004da75e6f"],"admins":["146"],"tags":[],"removed":false,"config":{"classification":{"type":"input","file_id":"classification","input_id":"0"},"tractID_list":{"id":"tractID_list","type":"string","placeholder":"","advanced":true,"desc":"ID list of the bundles of interest, separated by commas (by default, all bundles will be converted)","default":"all","_order":2,"pid":0.8743676248699641}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"60538a6038fe12a06cf0cd88","id":"0","datatype":"5cc1d64c44947d8aea6b2d8b"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"60538a6038fe12b2caf0cd89","id":"output","datatype":"606345ade4a8347b6f337de4","datatype_tags_pass":"0","files":null}],"github_branch":"main","github":"brainlife/app-convert-wmc2labels","name":"Convert wmc to labels","user_id":"146","contributors":[{"name":"Giulia Bertò","email":null,"_id":"634a3f9c62f3d3800f12d0f7"}],"create_date":"2021-03-18T17:14:08.761Z","desc":"Convert wmc to labels","__v":3049,"doi":"10.25663/brainlife.app.492","_canedit":true},{"_id":"5bf5f6158fd1cc1134215180","stats":{"stars":0,"requested":7785,"users":11,"success_rate":33.306972452879926,"serviceinfo":{"_id":"5d729e1f78356a109788b267","counts":{"_id":"5e5c3dca87cac74394ab13e0","failed":258,"finished":2521,"removed":2717,"requested":2955,"running":2713,"running_sync":0,"stop_requested":23},"success_rate":90.71608492263404,"users":8,"readme_status":"ok","runtime_mean":143537.25,"runtime_std":65204.11269028588,"service":"brainlife/app-wmctotrk","__v":0},"gitinfo":{"desc":"Convert a white matter classification (wmc) structure to a tractogram as a single trk file","tags":["convert"],"stats":{"stars":0},"contributors":[{"name":"David Hunt","email":"davhunt@indiana.edu"},{"name":"Paolo Avesani","email":null},{"name":"Franco Pestilli","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":372977.27,"runtime_std":2209230.190685474,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a346a62f3d3800f118ace"}],"examples":1,"groups":11},"projects":[],"admins":["1","45"],"tags":["convert"],"removed":false,"config":{"wmc":{"type":"input","file_id":"output","input_id":"wmc"},"t1":{"type":"input","file_id":"t1","input_id":"t1"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5bf5f6158fd1cc1134215182","id":"wmc","datatype":"58f10a90436ee50ffd9063c5","desc":""},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5bf5f6158fd1cc1134215181","id":"t1","datatype":"58c33bcee13a50849b25879a"}],"outputs":[{"datatype_tags":["wmc"],"output_on_root":true,"archive":true,"_id":"5bf5f6158fd1cc1134215183","id":"trk","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":"wmc","files":{"output":"output"}}],"name":"Convert wmc to multiple trk","github":"brainlife/app-wmctotrk","desc_override":"Takes a white matter classification resulting from a tract segmentation app and outputs one trk file for each segmented tract.","user_id":"45","references":[],"contributors":[{"name":"David Hunt","email":"davhunt@iu.edu","_id":"634a346b62f3d3800f118acf"},{"name":"Paolo Avesani","email":null,"_id":"634a346b62f3d3800f118ad0"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a346b62f3d3800f118ad1"},{"name":"Giulia Bertò","email":null,"_id":"634a346b62f3d3800f118ad2"},{"name":"Franco Pestilli","email":null,"_id":"634a346b62f3d3800f118ad3"}],"create_date":"2018-11-22T00:19:33.964Z","doi":"10.25663/brainlife.app.127","__v":9415,"github_branch":"1.0","desc":"Convert a white matter classification (wmc) structure to a tractogram as a single trk file","deprecated_by":"5c06c3764ed1ac00273e68e3","_canedit":true},{"_id":"5c06c3764ed1ac00273e68e3","stats":{"stars":0,"requested":7785,"users":11,"success_rate":33.306972452879926,"serviceinfo":{"_id":"5d729e1f78356a109788b267","counts":{"_id":"5e5c3dcd87cac77665ab13e2","failed":258,"finished":2521,"removed":2717,"requested":2955,"running":2713,"running_sync":0,"stop_requested":23},"success_rate":90.71608492263404,"users":8,"readme_status":"ok","runtime_mean":143537.25,"runtime_std":65204.11269028588,"service":"brainlife/app-wmctotrk","__v":0},"gitinfo":{"desc":"Convert a white matter classification (wmc) structure to a tractogram as a single trk file","tags":["convert"],"stats":{"stars":0},"contributors":[{"name":"David Hunt","email":"davhunt@indiana.edu"},{"name":"Paolo Avesani","email":null},{"name":"Franco Pestilli","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":372977.27,"runtime_std":2209230.190685474,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a347d62f3d3800f118adc"}],"examples":0,"groups":11},"projects":[],"admins":["45"],"tags":["convert"],"removed":false,"config":{"wmc":{"type":"input","file_id":"output","input_id":"wmc"},"t1":{"type":"input","file_id":"t1","input_id":"t1"}},"inputs":[{"id":"wmc","datatype":"58f10a90436ee50ffd9063c5","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c06c3764ed1ac00273e68e5"},{"id":"t1","datatype":"58c33bcee13a50849b25879a","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c06c3764ed1ac00273e68e4"}],"outputs":[{"id":"trk","datatype":"5b956f6cd7b3f1e24e9121ce","datatype_tags":["wmc"],"datatype_tags_pass":"wmc","output_on_root":false,"files":null,"archive":true,"_id":"5c06c3764ed1ac00273e68e6"}],"name":"Convert wmc to trk","github":"brainlife/app-wmctotrk","github_branch":"1.1","user_id":"45","references":[],"contributors":[{"name":"David Hunt","email":"davhunt@iu.edu","_id":"634a347e62f3d3800f118add"},{"name":"Paolo Avesani","email":null,"_id":"634a347e62f3d3800f118ade"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a347e62f3d3800f118adf"},{"name":"Giulia Bertò","email":null,"_id":"634a347e62f3d3800f118ae0"},{"name":"Franco Pestilli","email":null,"_id":"634a347e62f3d3800f118ae1"}],"create_date":"2018-12-04T18:12:06.670Z","doi":"10.25663/brainlife.app.129","__v":9329,"desc_override":"Convert a white matter classification (wmc) structure to a tractogram as a single trk file","desc":"Convert a white matter classification (wmc) structure to a tractogram as a single trk file","deprecated_by":"5d89980e9842202a887ec261","_canedit":true},{"_id":"5d89980e9842202a887ec261","projects":[],"admins":["1"],"tags":["convert"],"removed":false,"stats":{"stars":0,"requested":7785,"users":11,"success_rate":33.306972452879926,"serviceinfo":{"_id":"5d729e1f78356a109788b267","counts":{"_id":"5e5c3e1787cac72f19ab142f","failed":258,"finished":2521,"removed":2717,"requested":2955,"running":2713,"running_sync":0,"stop_requested":23},"success_rate":90.71608492263404,"users":8,"readme_status":"ok","runtime_mean":143537.25,"runtime_std":65204.11269028588,"service":"brainlife/app-wmctotrk","__v":0},"gitinfo":{"desc":"Convert a white matter classification (wmc) structure to a tractogram as a single trk file","tags":["convert"],"stats":{"stars":0},"contributors":[{"name":"David Hunt","email":"davhunt@indiana.edu"},{"name":"Paolo Avesani","email":null},{"name":"Franco Pestilli","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":372977.27,"runtime_std":2209230.190685474,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a371362f3d3800f11d35e"}],"examples":0,"groups":11},"config":{"wmc":{"type":"input","file_id":"classification","input_id":"wmc"},"t1":{"type":"input","file_id":"t1","input_id":"t1"},"tck":{"type":"input","file_id":"track","input_id":"tck"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c06c3764ed1ac00273e68e5","id":"wmc","datatype":"5cc1d64c44947d8aea6b2d8b"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c06c3764ed1ac00273e68e4","id":"t1","datatype":"58c33bcee13a50849b25879a"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d89980e984220347c7ec262","id":"tck","datatype":"5907d922436ee50ffde9c549"}],"outputs":[{"datatype_tags":["wmc"],"output_on_root":false,"archive":true,"_id":"5c06c3764ed1ac00273e68e6","id":"trk","datatype":"5b956f6cd7b3f1e24e9121ce","datatype_tags_pass":"wmc","files":null}],"name":"Convert wmc to trk","github":"brainlife/app-wmctotrk","github_branch":"1.2","user_id":"1","contributors":[{"name":"David Hunt","email":"davhunt@iu.edu","_id":"634a371462f3d3800f11d35f"},{"name":"Paolo Avesani","email":null,"_id":"634a371462f3d3800f11d360"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a371462f3d3800f11d361"},{"name":"Giulia Bertò","email":null,"_id":"634a371462f3d3800f11d362"},{"name":"Franco Pestilli","email":null,"_id":"634a371462f3d3800f11d363"}],"__v":6896,"desc_override":"Convert a white matter classification (wmc) structure to a tractogram as a single trk file. Segmentation ID will be used to set bundle_code inside the .trk. You can access it with trk.tractogram.data_per_streamline[0][\"bundle_code\"] with nibabel","desc":"Convert a white matter classification (wmc) structure to a tractogram as a single trk file","create_date":"2019-09-24T04:14:06.432Z","doi":"10.25663/brainlife.app.231","_canedit":true},{"_id":"5ce30cda40363b00353677ec","stats":{"stars":0,"requested":1493,"users":4,"success_rate":98.26388888888889,"serviceinfo":{"_id":"5d729e1e78356a109788b207","counts":{"_id":"5e5c3e0087cac71ee9ab1416","failed":2,"finished":982,"removed":1254,"requested":1261,"running":991,"running_sync":0,"stop_requested":8},"success_rate":99.79674796747967,"users":3,"readme_status":"no README.md","runtime_mean":80080.4,"runtime_std":30559.238362563952,"service":"brainlife/app-convert-wmc2wmc","__v":0},"gitinfo":{"desc":"App to convert the old wmc-deprecated datatype to the new wmc datatype","tags":[],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":209618.79,"runtime_std":109550.99221251214,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a365962f3d3800f11cd3d"}],"examples":1,"groups":5},"projects":[],"admins":["16","41","146","1"],"tags":[],"removed":false,"config":{"segmentation":{"type":"input","file_id":"output","input_id":"0"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ce30cda40363b00353677ed","id":"0","datatype":"58f10a90436ee50ffd9063c5","desc":"wmc deprecated structure"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5ce30cda40363b00353677ee","id":"wmc","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags_pass":"0","files":null,"desc":"new wmc classification structure"}],"github_branch":"1.0","github":"brainlife/app-convert-wmc2wmc","name":"Convert wmc-deprecated to wmc","user_id":"146","contributors":[{"name":"Giulia Bertò","email":null,"_id":"634a365a62f3d3800f11cd3e"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a365a62f3d3800f11cd3f"}],"create_date":"2019-05-20T20:23:54.331Z","desc":"App to convert the old wmc-deprecated datatype to the new wmc datatype","doi":"10.25663/brainlife.app.201","__v":7858,"_canedit":true},{"_id":"5eea8548d39ceb4a30a090eb","projects":[],"admins":["16"],"tags":["postprocessing"],"removed":false,"stats":{"requested":19020,"users":15,"success_rate":76.42612120442129,"gitinfo":{"desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","tags":["postprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"runtime_mean":966510.03,"runtime_std":1250650.5328230064,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3be062f3d3800f126d79"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3be062f3d3800f126d7a"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"634a3be062f3d3800f126d7b"}],"examples":5,"groups":42},"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"dir":{"type":"input","file_id":"dir","input_id":"noddi"},"ndi":{"type":"input","file_id":"ndi","input_id":"noddi"},"isovf":{"type":"input","file_id":"isovf","input_id":"noddi"},"odi":{"type":"input","file_id":"odi","input_id":"noddi"},"fa":{"type":"input","file_id":"fa","input_id":"tensor"},"md":{"type":"input","file_id":"md","input_id":"tensor"},"rd":{"type":"input","file_id":"rd","input_id":"tensor"},"ad":{"type":"input","file_id":"ad","input_id":"tensor"},"ga":{"type":"input","file_id":"ga","input_id":"tensor"},"ak":{"type":"input","file_id":"ak","input_id":"tensor"},"mk":{"type":"input","file_id":"mk","input_id":"tensor"},"rk":{"type":"input","file_id":"rk","input_id":"tensor"},"warp":{"type":"input","file_id":"warp","input_id":"warp"},"inverse_warp":{"type":"input","file_id":"inverse-warp","input_id":"warp"},"brainmask":{"type":"input","file_id":"mask","input_id":"brainmask"},"cortexmap":{"type":"input","file_id":"cortexmap","input_id":"cortexmap"},"fsurfparc":{"id":"fsurfparc","type":"enum","placeholder":"","advanced":true,"desc":"Parcellation from freesurfer wanted to for future stats","default":"aparc.a2009s","_order":2,"pid":0.8974673675843151,"options":[{"desc":"Desikan-Killiany","label":"aparc","value":"aparc"},{"desc":"Destrieux Atlas ","label":"aparc.a2009s","value":"aparc.a2009s"},{"desc":"DKT Atlas","label":"aparc.DKTatlas","value":"aparc.DKTatlas"}]},"snr":{"id":"snr","type":"boolean","placeholder":"","advanced":true,"desc":"controls whether bad vertices are masked out based on temporal SNR of dwi. if true, will mask. default == true","default":true,"_order":3,"pid":0.4894008407188616}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c61bbe114027a01b14adc98","id":"dwi","datatype":"58c33c5fe13a50849b25879b","desc":"The path to the DWI datatype"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c61bbe114027a01b14adc97","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e","desc":"The path to the top directory containing the output from Freesurfer"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5c61bbe114027a01b14adc95","id":"noddi","datatype":"5ed02a620a8ed8e39c482a61","desc":"The path to the NODDI datatype files (optional)"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c61be3d14027a01b14adca7","id":"tensor","datatype":"5a79df48d071a1753f1d661b","desc":"The path to the tensor datatype files"},{"datatype_tags":["!linear"],"optional":false,"multi":false,"advanced":false,"_id":"5eea8548d39ceb71bda090f1","id":"warp","datatype":"5bbfb28071454db2a890fbce","desc":"These files are needed to generate surfaces in template space (usually MNI). If you need to generate these files, please look at brainlife app FSL Anat. A version of this app not requiring this input is being generated"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5eea8c9ed39ceb0ecfa09613","id":"brainmask","datatype":"5a281aee2c214c9ba83ce620","desc":"The path to the dwi brainmask. optional. will be computed internally if not provided"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"613a74ea201273f23ac87cb3","id":"cortexmap","datatype":"5c58aa5ef9109beac4b52f61"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5c61bbe114027a01b14adc99","id":"cortexmap","datatype":"5c58aa5ef9109beac4b52f61","datatype_tags_pass":null,"files":null,"desc":"The cortexmap output, containing the surfaces and mapped data"},{"datatype_tags":["cortexmap_derivatives"],"output_on_root":false,"archive":true,"_id":"5eea8548d39ceb9bcca090f3","id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null,"desc":"A directory containing all of the derivatives generated. Useful for QA and debugging"}],"github_branch":"v1.3-snr-input","github":"brainlife/app-cortex-tissue-mapping","name":"Cortex Tissue Mapping (Native & Template Space)","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3be162f3d3800f126d7c"},{"name":"Franco Pestilli","email":null,"_id":"634a3be162f3d3800f126d7d"}],"desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","__v":4621,"create_date":"2020-06-17T21:04:08.534Z","doi":"10.25663/brainlife.app.379","avatar":"https://raw.githubusercontent.com/brainlife/app-cortex-tissue-mapping/v1.1/cropped_glasser_ndi.png","_canedit":true},{"_id":"5eea858dd39ceb8483a09252","projects":[],"admins":["16"],"tags":["postprocessing"],"removed":false,"stats":{"requested":19020,"users":15,"success_rate":76.42612120442129,"gitinfo":{"desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","tags":["postprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"runtime_mean":966510.03,"runtime_std":1250650.5328230064,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3be962f3d3800f126dbd"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3be962f3d3800f126dbe"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"634a3be962f3d3800f126dbf"}],"examples":0,"groups":42},"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"dir":{"type":"input","file_id":"dir","input_id":"noddi"},"ndi":{"type":"input","file_id":"ndi","input_id":"noddi"},"isovf":{"type":"input","file_id":"isovf","input_id":"noddi"},"odi":{"type":"input","file_id":"odi","input_id":"noddi"},"warp":{"type":"input","file_id":"warp","input_id":"warp"},"inverse_warp":{"type":"input","file_id":"inverse-warp","input_id":"warp"},"brainmask":{"type":"input","file_id":"mask","input_id":"brainmask"},"cortexmap":{"type":"input","file_id":"cortexmap","input_id":"cortexmap"},"fsurfparc":{"id":"fsurfparc","type":"enum","placeholder":"","advanced":true,"desc":"Parcellation from freesurfer wanted for future stats","default":"aparc.a2009s","_order":2,"pid":0.21117122196453442,"options":[{"desc":"Desikan-Killiany","label":"aparc","value":"aparc"},{"desc":"Destrieux","label":"aparc.a2009s","value":"aparc.a2009s"},{"desc":"DKT","label":"aparc.DKTatlas","value":"aparc.DKTatlas"}]},"snr":{"id":"snr","type":"boolean","placeholder":"","advanced":true,"desc":"controls whether bad vertices are masked out based on temporal SNR of dwi. if true, will mask. default == true","default":true,"_order":3,"pid":0.2048259698100131}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c61bbe114027a01b14adc98","id":"dwi","datatype":"58c33c5fe13a50849b25879b","desc":"The path to the DWI datatype"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c61bbe114027a01b14adc97","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e","desc":"The path to the top directory containing the output from freesurfer"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c61bbe114027a01b14adc95","id":"noddi","datatype":"5ed02a620a8ed8e39c482a61","desc":"The path to the NODDI datatype files"},{"datatype_tags":["!linear"],"optional":false,"multi":false,"advanced":false,"_id":"5eea8548d39ceb71bda090f1","id":"warp","datatype":"5bbfb28071454db2a890fbce","desc":"These files are needed to generate surfaces in template space (usually MNI). If you need to generate these files, please look at brainlife app FSL Anat. A version of this app not requiring this input is being generated"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5eea8cbdd39ceb6314a096a3","id":"brainmask","datatype":"5a281aee2c214c9ba83ce620","desc":"The path to the mask datatype brainmask of the DWI. optional. will compute internally if not provided"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"613a7504201273151cc87d6a","id":"cortexmap","datatype":"5c58aa5ef9109beac4b52f61"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5c61bbe114027a01b14adc99","id":"cortexmap","datatype":"5c58aa5ef9109beac4b52f61","datatype_tags_pass":null,"files":null,"desc":"Output containing the surfaces and mapped data generated during the app"},{"datatype_tags":["cortexmap_derivatives"],"output_on_root":false,"archive":true,"_id":"5eea8548d39ceb9bcca090f3","id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null,"desc":"The derivatives generated during the app. Useful for debugging and QA"}],"github_branch":"v1.3-snr-input","github":"brainlife/app-cortex-tissue-mapping","name":"Cortex Tissue Mapping (Native & Template Space) (Noddi)","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3bea62f3d3800f126dc0"},{"name":"Franco Pestilli","email":null,"_id":"634a3bea62f3d3800f126dc1"}],"desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","__v":4615,"create_date":"2020-06-17T21:05:17.586Z","doi":"10.25663/brainlife.app.380","avatar":"https://raw.githubusercontent.com/brainlife/app-cortex-tissue-mapping/v1.1/cropped_glasser_ndi.png","_canedit":true},{"_id":"60356cdd3a0011c55f52e65c","projects":[],"admins":["16"],"tags":["postprocessing"],"removed":false,"stats":{"requested":19020,"users":15,"success_rate":76.42612120442129,"gitinfo":{"desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","tags":["postprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"runtime_mean":966510.03,"runtime_std":1250650.5328230064,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3f2a62f3d3800f12c932"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3f2a62f3d3800f12c933"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"634a3f2a62f3d3800f12c934"}],"examples":0,"groups":42},"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"brainmask":{"type":"input","file_id":"mask","input_id":"brainmask"},"myelinmap":{"type":"input","file_id":"map","input_id":"myelinmap"},"warp":{"type":"input","file_id":"warp","input_id":"warp"},"inverse-warp":{"type":"input","file_id":"inverse-warp","input_id":"warp"},"affine":{"type":"input","file_id":"affine","input_id":"warp"},"cortexmap":{"type":"input","file_id":"cortexmap","input_id":"cortexmap"},"fsurfparc":{"id":"fsurfparc","type":"enum","placeholder":"","advanced":true,"desc":"Parcellation from freesurfer wanted for future stats","default":"aparc.a2009s","_order":2,"pid":0.11866244819486338,"options":[{"desc":"Desikan-Killiany","label":"aparc","value":"aparc"},{"desc":"Destrieux Atlas","label":"aparc.a2009s","value":"aparc.a2009s"},{"desc":"DKT Atlas","label":"aparc.DKTatlas","value":"aparc.DKTatlas"}]}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c61bbe114027a01b14adc98","id":"dwi","datatype":"58c33c5fe13a50849b25879b"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c61bbe114027a01b14adc97","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5eea8cd1d39ceb7233a09733","id":"brainmask","datatype":"5a281aee2c214c9ba83ce620","desc":"dwi brainmask. optional. will compute internally if not provided"},{"datatype_tags":["t1-t2-ratio"],"optional":false,"multi":false,"advanced":false,"_id":"60356c413a001144ed52e4ea","id":"myelinmap","datatype":"5fad54c27e8ecba2c3aa0c24"},{"datatype_tags":["!linear"],"optional":false,"multi":false,"advanced":false,"_id":"60356cdd3a0011705d52e662","id":"warp","datatype":"5bbfb28071454db2a890fbce"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"613a757a201273e201c880f3","id":"cortexmap","datatype":"5c58aa5ef9109beac4b52f61"}],"outputs":[{"datatype_tags":["myelin_mapping","t1-t2-ratio"],"output_on_root":false,"archive":true,"_id":"5c61bbe114027a01b14adc99","id":"cortexmap","datatype":"5c58aa5ef9109beac4b52f61","datatype_tags_pass":null,"files":null},{"datatype_tags":["cortexmap_derivatives","myelin_mapping","t1-t2-ratio"],"output_on_root":false,"archive":true,"_id":"5eea8548d39ceb9bcca090f3","id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null}],"github_branch":"t1-t2-ratio-v1.1","github":"brainlife/app-cortex-tissue-mapping","name":"Cortex Tissue Mapping (Native & Template Space) - Myelin Mapping (T1w/T2w ratio)","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3f2a62f3d3800f12c935"},{"name":"Franco Pestilli","email":null,"_id":"634a3f2a62f3d3800f12c936"}],"desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","__v":3212,"avatar":"https://raw.githubusercontent.com/brainlife/app-cortex-tissue-mapping/v1.1/cropped_glasser_ndi.png","create_date":"2021-02-23T21:00:13.754Z","doi":"10.25663/brainlife.app.480","_canedit":true},{"_id":"608da87c8fe49f54761a9455","projects":[],"admins":["16"],"tags":["postprocessing"],"removed":false,"stats":{"requested":19020,"users":15,"success_rate":76.42612120442129,"gitinfo":{"desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","tags":["postprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"runtime_mean":966510.03,"runtime_std":1250650.5328230064,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a407262f3d3800f12d765"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a407262f3d3800f12d766"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"634a407262f3d3800f12d767"}],"examples":0,"groups":42},"config":{"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"myelinmap":{"type":"input","file_id":"map","input_id":"myelinmap"},"warp":{"type":"input","file_id":"warp","input_id":"warp"},"inverse-warp":{"type":"input","file_id":"inverse-warp","input_id":"warp"},"affine":{"type":"input","file_id":"affine","input_id":"warp"},"cortexmap":{"type":"input","file_id":"cortexmap","input_id":"cortexmap"},"fsurfparc":{"id":"fsurfparc","type":"enum","placeholder":"","advanced":true,"desc":"Parcellation from freesurfer wanted for future stats","default":"aparc.a2009s","_order":2,"pid":0.1858854983504442,"options":[{"desc":"Desikan-Killiany","label":"aparc","value":"aparc"},{"desc":"Destrieux Atlas","label":"aparc.a2009s","value":"aparc.a2009s"},{"desc":"DKT Atlas","label":"aparc.DKTatlas","value":"aparc.DKTatlas"}]}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c61bbe114027a01b14adc97","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e"},{"datatype_tags":["t1-t2-ratio"],"optional":false,"multi":false,"advanced":false,"_id":"60356c413a001144ed52e4ea","id":"myelinmap","datatype":"5fad54c27e8ecba2c3aa0c24"},{"datatype_tags":["!linear"],"optional":false,"multi":false,"advanced":false,"_id":"60356cdd3a0011705d52e662","id":"warp","datatype":"5bbfb28071454db2a890fbce"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"613a75a52012735b08c881ff","id":"cortexmap","datatype":"5c58aa5ef9109beac4b52f61"}],"outputs":[{"datatype_tags":["myelin_mapping","t1-t2-ratio"],"output_on_root":false,"archive":true,"_id":"5c61bbe114027a01b14adc99","id":"cortexmap","datatype":"5c58aa5ef9109beac4b52f61","datatype_tags_pass":null,"files":null},{"datatype_tags":["cortexmap_derivatives","myelin_mapping","t1-t2-ratio"],"output_on_root":false,"archive":true,"_id":"5eea8548d39ceb9bcca090f3","id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null}],"github_branch":"t1-t2-ratio-v1.1-nosnr","github":"brainlife/app-cortex-tissue-mapping","name":"Cortex Tissue Mapping (Native & Template Space) - Myelin Mapping (T1w/T2w ratio) (No SNR masking)","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a407262f3d3800f12d768"},{"name":"Franco Pestilli","email":null,"_id":"634a407262f3d3800f12d769"}],"desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","__v":2749,"avatar":"https://raw.githubusercontent.com/brainlife/app-cortex-tissue-mapping/v1.1/cropped_glasser_ndi.png","create_date":"2021-05-01T19:14:04.388Z","doi":"10.25663/brainlife.app.516","_canedit":true},{"_id":"6115dd26a5a04cb2b8f9f32f","projects":[],"admins":["16"],"tags":["postprocessing"],"removed":false,"stats":{"requested":19020,"users":15,"success_rate":76.42612120442129,"gitinfo":{"desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","tags":["postprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"runtime_mean":966510.03,"runtime_std":1250650.5328230064,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a421062f3d3800f12f2f6"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a421062f3d3800f12f2f7"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"634a421062f3d3800f12f2f8"}],"examples":0,"groups":42},"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"brainmask":{"type":"input","file_id":"mask","input_id":"brainmask"},"T1":{"type":"input","file_id":"T1map","input_id":"qmri"},"T1_json":{"type":"input","file_id":"T1map_json","input_id":"qmri"},"R1":{"type":"input","file_id":"R1map","input_id":"qmri"},"R1_json":{"type":"input","file_id":"R1map_json","input_id":"qmri"},"M0":{"type":"input","file_id":"M0map","input_id":"qmri"},"M0_json":{"type":"input","file_id":"M0map_json","input_id":"qmri"},"PD":{"type":"input","file_id":"PD","input_id":"qmri"},"MTV":{"type":"input","file_id":"MTV","input_id":"qmri"},"VIP":{"type":"input","file_id":"VIP","input_id":"qmri"},"SIR":{"type":"input","file_id":"SIR","input_id":"qmri"},"WF":{"type":"input","file_id":"WF","input_id":"qmri"},"warp":{"type":"input","file_id":"warp","input_id":"warp"},"inverse-warp":{"type":"input","file_id":"inverse-warp","input_id":"warp"},"affine":{"type":"input","file_id":"affine","input_id":"warp"},"cortexmap":{"type":"input","file_id":"cortexmap","input_id":"cortexmap"},"fsurfparc":{"id":"fsurfparc","type":"enum","placeholder":"","advanced":true,"desc":"Parcellation from freesurfer wanted for future stats","default":"aparc.a2009s","_order":2,"pid":0.6909484807843229,"options":[{"desc":"Desikan-Killiany","label":"aparc","value":"aparc"},{"desc":"Destrieux Atlas","label":"aparc.a2009s","value":"aparc.a2009s"},{"desc":"DKT Atlas","label":"aparc.DKTatlas","value":"aparc.DKTatlas"}]}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c61bbe114027a01b14adc98","id":"dwi","datatype":"58c33c5fe13a50849b25879b"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c61bbe114027a01b14adc97","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5eea8cd1d39ceb7233a09733","id":"brainmask","datatype":"5a281aee2c214c9ba83ce620","desc":"dwi brainmask. optional. will compute internally if not provided"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"6115dd26a5a04c1c3bf9f335","id":"qmri","datatype":"608ac8b089df43e33c758fa1"},{"datatype_tags":["!linear"],"optional":false,"multi":false,"advanced":false,"_id":"60356cdd3a0011705d52e662","id":"warp","datatype":"5bbfb28071454db2a890fbce"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"613a75be201273ffa8c882b4","id":"cortexmap","datatype":"5c58aa5ef9109beac4b52f61"}],"outputs":[{"datatype_tags":["qmri"],"output_on_root":false,"archive":true,"_id":"5c61bbe114027a01b14adc99","id":"cortexmap","datatype":"5c58aa5ef9109beac4b52f61","datatype_tags_pass":null,"files":null},{"datatype_tags":["cortexmap_derivatives","qmri"],"output_on_root":false,"archive":true,"_id":"5eea8548d39ceb9bcca090f3","id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null}],"github_branch":"qmri-v1.1","github":"brainlife/app-cortex-tissue-mapping","name":"Cortex Tissue Mapping (Native & Template Space) - qMRI","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a421162f3d3800f12f2f9"},{"name":"Franco Pestilli","email":null,"_id":"634a421162f3d3800f12f2fa"}],"desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","__v":2075,"avatar":"https://raw.githubusercontent.com/brainlife/app-cortex-tissue-mapping/v1.1/cropped_glasser_ndi.png","create_date":"2021-08-13T02:47:02.139Z","desc_override":"This app will map volumated measure files (i.e. qmri) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","doi":"10.25663/brainlife.app.560","_canedit":true},{"_id":"5eea88a5d39cebf15aa0948c","projects":[],"admins":["16"],"tags":["postprocessing"],"removed":false,"stats":{"requested":19020,"users":15,"success_rate":76.42612120442129,"gitinfo":{"desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","tags":["postprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"runtime_mean":966510.03,"runtime_std":1250650.5328230064,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3bf762f3d3800f12738a"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3bf762f3d3800f12738b"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"634a3bf762f3d3800f12738c"}],"examples":5,"groups":42},"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"dir":{"type":"input","file_id":"dir","input_id":"noddi"},"ndi":{"type":"input","file_id":"ndi","input_id":"noddi"},"isovf":{"type":"input","file_id":"isovf","input_id":"noddi"},"odi":{"type":"input","file_id":"odi","input_id":"noddi"},"fa":{"type":"input","file_id":"fa","input_id":"tensor"},"md":{"type":"input","file_id":"md","input_id":"tensor"},"rd":{"type":"input","file_id":"rd","input_id":"tensor"},"ad":{"type":"input","file_id":"ad","input_id":"tensor"},"ga":{"type":"input","file_id":"ga","input_id":"tensor"},"ak":{"type":"input","file_id":"ak","input_id":"tensor"},"mk":{"type":"input","file_id":"mk","input_id":"tensor"},"rk":{"type":"input","file_id":"rk","input_id":"tensor"},"brainmask":{"type":"input","file_id":"mask","input_id":"brainmask"},"cortexmap":{"type":"input","file_id":"cortexmap","input_id":"cortexmap"},"fsurfparc":{"id":"fsurfparc","type":"enum","placeholder":"","advanced":true,"desc":"Parcellation from freesurfer wanted for future stats","default":"aparc.a2009s","_order":2,"pid":0.3445015714179509,"options":[{"desc":"Desikan-Killiany","label":"aparc","value":"aparc"},{"desc":"Destrieux Atlas","label":"aparc.a2009s","value":"aparc.a2009s"},{"desc":"DKT Atlas","label":"aparc.DKTatlas","value":"aparc.DKTatlas"},{"desc":"aparc.DKTatlas40","label":"aparc.DKTatlas40","value":"aparc.DKTatlas40"}]},"snr":{"id":"snr","type":"boolean","placeholder":"","advanced":true,"desc":"controls whether bad vertices are masked out based on temporal SNR of dwi image. if true, will mask. default == true","default":true,"_order":3,"pid":0.6350917096476251}},"inputs":[{"id":"dwi","desc":"The path to the DWI datatype","datatype":"58c33c5fe13a50849b25879b","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c61bbe114027a01b14adc98"},{"id":"freesurfer","desc":"The path to the top directory containing the output from freesurfer","datatype":"58cb22c8e13a50849b25882e","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c61bbe114027a01b14adc97"},{"id":"noddi","desc":"The path to the NODDI datatype files (optional)","datatype":"5ed02a620a8ed8e39c482a61","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5c61bbe114027a01b14adc95"},{"id":"tensor","desc":"The path to the DTI datatype files","datatype":"5a79df48d071a1753f1d661b","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c61be3d14027a01b14adca7"},{"id":"brainmask","desc":"The path to the mask datatype brainmask of the DWI. optional. will compute internally if not provided","datatype":"5a281aee2c214c9ba83ce620","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5eea8cd1d39ceb7233a09733"},{"id":"cortexmap","datatype":"5c58aa5ef9109beac4b52f61","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"613a751d2012732760c87e53"}],"outputs":[{"id":"cortexmap","desc":"Output containing the surfaces and mapped data generated during the app","datatype":"5c58aa5ef9109beac4b52f61","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5c61bbe114027a01b14adc99"},{"id":"raw","desc":"The derivatives generated during the app. Useful for debugging and QA","datatype":"59c3eae633fc1cf9ead71679","datatype_tags":["cortexmap_derivatives"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5eea8548d39ceb9bcca090f3"}],"github_branch":"v1.3-snr-input","github":"brainlife/app-cortex-tissue-mapping","name":"Cortex Tissue Mapping (Native Space)","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3bf762f3d3800f12738d"},{"name":"Franco Pestilli","email":null,"_id":"634a3bf762f3d3800f12738e"}],"desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","__v":4616,"create_date":"2020-06-17T21:18:29.740Z","doi":"10.25663/brainlife.app.381","avatar":"https://raw.githubusercontent.com/brainlife/app-cortex-tissue-mapping/v1.1/cropped_glasser_ndi.png","_canedit":true},{"_id":"5eea88bed39ceb789aa09510","projects":[],"admins":["16"],"tags":["postprocessing"],"removed":false,"stats":{"requested":19020,"users":15,"success_rate":76.42612120442129,"gitinfo":{"desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","tags":["postprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"runtime_mean":966510.03,"runtime_std":1250650.5328230064,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3c0162f3d3800f127421"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3c0162f3d3800f127422"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"634a3c0162f3d3800f127423"}],"examples":0,"groups":42},"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"dir":{"type":"input","file_id":"dir","input_id":"noddi"},"ndi":{"type":"input","file_id":"ndi","input_id":"noddi"},"isovf":{"type":"input","file_id":"isovf","input_id":"noddi"},"odi":{"type":"input","file_id":"odi","input_id":"noddi"},"brainmask":{"type":"input","file_id":"mask","input_id":"brainmask"},"cortexmap":{"type":"input","file_id":"cortexmap","input_id":"cortexmap"},"fsurfparc":{"id":"fsurfparc","type":"enum","placeholder":"","advanced":true,"desc":"Parcellation from freesurfer wanted for future stats","default":"aparc.a2009s","_order":2,"pid":0.5031568340904206,"options":[{"desc":"Desikan-Killiany","label":"aparc","value":"aparc"},{"desc":"Destrieux Atlas","label":"aparc.a2009s","value":"aparc.a2009s"},{"desc":"DKT Atlas","label":"aparc.DKTatlas","value":"aparc.DKTatlas"}]},"snr":{"id":"snr","type":"boolean","placeholder":"","advanced":true,"desc":"controls whether bad vertices are masked out based on temporal SNR of dwi. if true, will mask. default == true","default":true,"_order":3,"pid":0.6403040343083332}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c61bbe114027a01b14adc98","id":"dwi","datatype":"58c33c5fe13a50849b25879b","desc":"The path to the DWI datatype"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c61bbe114027a01b14adc97","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e","desc":"The path to the top directory containing the output from freesurfer"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c61bbe114027a01b14adc95","id":"noddi","datatype":"5ed02a620a8ed8e39c482a61","desc":"The path to the NODDI datatype files"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5eea8cf8d39ceba375a098d9","id":"brainmask","datatype":"5a281aee2c214c9ba83ce620","desc":"The path to the mask datatype brainmask of the DWI. optional. will compute internally if not provided"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"613a7531201273839dc87efa","id":"cortexmap","datatype":"5c58aa5ef9109beac4b52f61"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5c61bbe114027a01b14adc99","id":"cortexmap","datatype":"5c58aa5ef9109beac4b52f61","datatype_tags_pass":null,"files":null,"desc":"Output containing the surfaces and mapped data generated during the app"},{"datatype_tags":["cortexmap_derivatives"],"output_on_root":false,"archive":true,"_id":"5eea8548d39ceb9bcca090f3","id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null,"desc":"The derivatives generated during the app. Useful for debugging and QA"}],"github_branch":"v1.3-snr-input","github":"brainlife/app-cortex-tissue-mapping","name":"Cortex Tissue Mapping (Native Space) (Noddi)","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3c0162f3d3800f127424"},{"name":"Franco Pestilli","email":null,"_id":"634a3c0162f3d3800f127425"}],"desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","__v":4611,"create_date":"2020-06-17T21:18:54.071Z","doi":"10.25663/brainlife.app.382","avatar":"https://raw.githubusercontent.com/brainlife/app-cortex-tissue-mapping/v1.1/cropped_glasser_ndi.png","_canedit":true},{"_id":"5f6cdaae6bbee32c629a2904","projects":[],"admins":["16"],"tags":["postprocessing"],"removed":false,"stats":{"requested":19020,"users":15,"success_rate":76.42612120442129,"gitinfo":{"desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","tags":["postprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"runtime_mean":966510.03,"runtime_std":1250650.5328230064,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3d7262f3d3800f12a4b7"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3d7262f3d3800f12a4b8"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"634a3d7262f3d3800f12a4b9"}],"examples":2,"groups":42},"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"brainmask":{"type":"input","file_id":"mask","input_id":"brainmask"},"mask":{"type":"input","file_id":"mask","input_id":"5tt"},"cortexmap":{"type":"input","file_id":"cortexmap","input_id":"cortexmap"},"fsurfparc":{"id":"fsurfparc","type":"enum","placeholder":"","advanced":true,"desc":"Parcellation from freesurfer wanted for future stats","default":"aparc.a2009s","_order":2,"pid":0.413845846370935,"options":[{"desc":"Desikan-Killiany","label":"aparc","value":"aparc"},{"desc":"Destrieux Atlas","label":"aparc.a2009s","value":"aparc.a2009s"},{"desc":"DKT Atlas","label":"aparc.DKTatlas","value":"aparc.DKTatlas"}]}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c61bbe114027a01b14adc98","id":"dwi","datatype":"58c33c5fe13a50849b25879b"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c61bbe114027a01b14adc97","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5eea8cd1d39ceb7233a09733","id":"brainmask","datatype":"5a281aee2c214c9ba83ce620","desc":"dwi brainmask. optional. will compute internally if not provided"},{"datatype_tags":["5tt_masks"],"optional":false,"multi":false,"advanced":false,"_id":"5f6cdaae6bbee381619a2909","id":"5tt","datatype":"5a281aee2c214c9ba83ce620"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"613a754b20127382b3c87f9c","id":"cortexmap","datatype":"5c58aa5ef9109beac4b52f61"}],"outputs":[{"datatype_tags":["gray_matter_density"],"output_on_root":false,"archive":true,"_id":"5c61bbe114027a01b14adc99","id":"cortexmap","datatype":"5c58aa5ef9109beac4b52f61","datatype_tags_pass":null,"files":null},{"datatype_tags":["cortexmap_derivatives","gray_matter_density"],"output_on_root":false,"archive":true,"_id":"5eea8548d39ceb9bcca090f3","id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null}],"github_branch":"gmd-v1.1","github":"brainlife/app-cortex-tissue-mapping","name":"Cortex Tissue Mapping (Native Space) - Gray Matter Density","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3d7262f3d3800f12a4ba"},{"name":"Franco Pestilli","email":null,"_id":"634a3d7262f3d3800f12a4bb"}],"desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","__v":4151,"avatar":"https://raw.githubusercontent.com/brainlife/app-cortex-tissue-mapping/v1.1/cropped_glasser_ndi.png","create_date":"2020-09-24T17:43:10.869Z","doi":"10.25663/brainlife.app.431","_canedit":true},{"_id":"60356c413a00110c6952e4e5","projects":[],"admins":["16"],"tags":["postprocessing"],"removed":false,"stats":{"requested":19020,"users":15,"success_rate":76.42612120442129,"gitinfo":{"desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","tags":["postprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"runtime_mean":966510.03,"runtime_std":1250650.5328230064,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3f2162f3d3800f12c92c"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3f2162f3d3800f12c92d"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"634a3f2162f3d3800f12c92e"}],"examples":1,"groups":42},"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"brainmask":{"type":"input","file_id":"mask","input_id":"brainmask"},"myelinmap":{"type":"input","file_id":"map","input_id":"myelinmap"},"cortexmap":{"type":"input","file_id":"cortexmap","input_id":"cortexmap"},"fsurfparc":{"id":"fsurfparc","type":"enum","placeholder":"","advanced":true,"desc":"Parcellation from freesurfer wanted for future stats","default":"aparc.a2009s","_order":2,"pid":0.30158910016768015,"options":[{"desc":"Desikan-Killiany","label":"aparc","value":"aparc"},{"desc":"Destrieux Atlas","label":"aparc.a2009s","value":"aparc.a2009s"},{"desc":"DKT Atlas","label":"aparc.DKTatlas","value":"aparc.DKTatlas"}]}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c61bbe114027a01b14adc98","id":"dwi","datatype":"58c33c5fe13a50849b25879b"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c61bbe114027a01b14adc97","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5eea8cd1d39ceb7233a09733","id":"brainmask","datatype":"5a281aee2c214c9ba83ce620","desc":"dwi brainmask. optional. will compute internally if not provided"},{"datatype_tags":["t1-t2-ratio"],"optional":false,"multi":false,"advanced":false,"_id":"60356c413a001144ed52e4ea","id":"myelinmap","datatype":"5fad54c27e8ecba2c3aa0c24"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"613a75602012739ea5c8803e","id":"cortexmap","datatype":"5c58aa5ef9109beac4b52f61"}],"outputs":[{"datatype_tags":["myelin_mapping","t1-t2-ratio"],"output_on_root":false,"archive":true,"_id":"5c61bbe114027a01b14adc99","id":"cortexmap","datatype":"5c58aa5ef9109beac4b52f61","datatype_tags_pass":null,"files":null},{"datatype_tags":["cortexmap_derivatives","myelin_mapping","t1-t2-ratio"],"output_on_root":false,"archive":true,"_id":"5eea8548d39ceb9bcca090f3","id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null}],"github_branch":"t1-t2-ratio-v1.1","github":"brainlife/app-cortex-tissue-mapping","name":"Cortex Tissue Mapping (Native Space) - Myelin Mapping (T1w/T2w ratio)","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3f2162f3d3800f12c92f"},{"name":"Franco Pestilli","email":null,"_id":"634a3f2162f3d3800f12c930"}],"desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","__v":3211,"avatar":"https://raw.githubusercontent.com/brainlife/app-cortex-tissue-mapping/v1.1/cropped_glasser_ndi.png","create_date":"2021-02-23T20:57:37.747Z","doi":"10.25663/brainlife.app.479","_canedit":true},{"_id":"608da73d8fe49ff0f31a929d","projects":[],"admins":["16"],"tags":["postprocessing"],"removed":false,"stats":{"requested":19020,"users":15,"success_rate":76.42612120442129,"gitinfo":{"desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","tags":["postprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"runtime_mean":966510.03,"runtime_std":1250650.5328230064,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a406962f3d3800f12d75f"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a406962f3d3800f12d760"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"634a406962f3d3800f12d761"}],"examples":0,"groups":42},"config":{"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"myelinmap":{"type":"input","file_id":"map","input_id":"myelinmap"},"cortexmap":{"type":"input","file_id":"cortexmap","input_id":"cortexmap"},"fsurfparc":{"id":"fsurfparc","type":"enum","placeholder":"","advanced":true,"desc":"Parcellation from freesurfer wanted for future stats","default":"aparc.a2009s","_order":2,"pid":0.28273920561721755,"options":[{"desc":"Desikan-Killiany","label":"aparc","value":"aparc"},{"desc":"Destrieux Atlas","label":"aparc.a2009s","value":"aparc.a2009s"},{"desc":"DKT Atlas","label":"aparc.DKTatlas","value":"aparc.DKTatlas"}]}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c61bbe114027a01b14adc97","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e"},{"datatype_tags":["t1-t2-ratio"],"optional":false,"multi":false,"advanced":false,"_id":"60356c413a001144ed52e4ea","id":"myelinmap","datatype":"5fad54c27e8ecba2c3aa0c24"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"613a759120127354e7c8816f","id":"cortexmap","datatype":"5c58aa5ef9109beac4b52f61"}],"outputs":[{"datatype_tags":["myelin_mapping","t1-t2-ratio"],"output_on_root":false,"archive":true,"_id":"5c61bbe114027a01b14adc99","id":"cortexmap","datatype":"5c58aa5ef9109beac4b52f61","datatype_tags_pass":null,"files":null},{"datatype_tags":["cortexmap_derivatives","myelin_mapping","t1-t2-ratio"],"output_on_root":false,"archive":true,"_id":"5eea8548d39ceb9bcca090f3","id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null}],"github_branch":"t1-t2-ratio-v1.1-nosnr","github":"brainlife/app-cortex-tissue-mapping","name":"Cortex Tissue Mapping (Native Space) - Myelin Mapping (T1w/T2w ratio) (No SNR masking)","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a406962f3d3800f12d762"},{"name":"Franco Pestilli","email":null,"_id":"634a406962f3d3800f12d763"}],"desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","__v":2752,"avatar":"https://raw.githubusercontent.com/brainlife/app-cortex-tissue-mapping/v1.1/cropped_glasser_ndi.png","create_date":"2021-05-01T19:08:45.840Z","desc_override":"","doi":"10.25663/brainlife.app.515","_canedit":true},{"_id":"6115dd7aa5a04cc30cf9f3fe","projects":[],"admins":["16"],"tags":["postprocessing"],"removed":false,"stats":{"requested":19020,"users":15,"success_rate":76.42612120442129,"gitinfo":{"desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","tags":["postprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"runtime_mean":966510.03,"runtime_std":1250650.5328230064,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a421a62f3d3800f12f3f8"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a421a62f3d3800f12f3f9"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"634a421a62f3d3800f12f3fa"}],"examples":2,"groups":42},"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"brainmask":{"type":"input","file_id":"mask","input_id":"brainmask"},"T1":{"type":"input","file_id":"T1map","input_id":"qmri"},"T1_json":{"type":"input","file_id":"T1map_json","input_id":"qmri"},"R1":{"type":"input","file_id":"R1map","input_id":"qmri"},"R1_json":{"type":"input","file_id":"R1map_json","input_id":"qmri"},"M0":{"type":"input","file_id":"M0map","input_id":"qmri"},"M0_json":{"type":"input","file_id":"M0map_json","input_id":"qmri"},"PD":{"type":"input","file_id":"PD","input_id":"qmri"},"MTV":{"type":"input","file_id":"MTV","input_id":"qmri"},"VIP":{"type":"input","file_id":"VIP","input_id":"qmri"},"SIR":{"type":"input","file_id":"SIR","input_id":"qmri"},"WF":{"type":"input","file_id":"WF","input_id":"qmri"},"cortexmap":{"type":"input","file_id":"cortexmap","input_id":"cortexmap"},"fsurfparc":{"id":"fsurfparc","type":"enum","placeholder":"","advanced":true,"desc":"Parcellation from freesurfer wanted for future stats","default":"aparc.a2009s","_order":2,"pid":0.2855546795785455,"options":[{"desc":"Desikan-Killiany","label":"aparc","value":"aparc"},{"desc":"Destrieux Atlas","label":"aparc.a2009s","value":"aparc.a2009s"},{"desc":"DKT Atlas","label":"aparc.DKTatlas","value":"aparc.DKTatlas"}]}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c61bbe114027a01b14adc98","id":"dwi","datatype":"58c33c5fe13a50849b25879b"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c61bbe114027a01b14adc97","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5eea8cd1d39ceb7233a09733","id":"brainmask","datatype":"5a281aee2c214c9ba83ce620","desc":"dwi brainmask. optional. will compute internally if not provided"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"6115dd7aa5a04c438df9f404","id":"qmri","datatype":"608ac8b089df43e33c758fa1"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"613a75d72012735c73c88356","id":"cortexmap","datatype":"5c58aa5ef9109beac4b52f61"}],"outputs":[{"datatype_tags":["qmri"],"output_on_root":false,"archive":true,"_id":"5c61bbe114027a01b14adc99","id":"cortexmap","datatype":"5c58aa5ef9109beac4b52f61","datatype_tags_pass":null,"files":null},{"datatype_tags":["cortexmap_derivatives","qmri"],"output_on_root":false,"archive":true,"_id":"5eea8548d39ceb9bcca090f3","id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null}],"github_branch":"qmri-v1.1","github":"brainlife/app-cortex-tissue-mapping","name":"Cortex Tissue Mapping (Native Space) - qMRI","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a421a62f3d3800f12f3fb"},{"name":"Franco Pestilli","email":null,"_id":"634a421a62f3d3800f12f3fc"}],"desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","__v":2076,"avatar":"https://raw.githubusercontent.com/brainlife/app-cortex-tissue-mapping/v1.1/cropped_glasser_ndi.png","create_date":"2021-08-13T02:48:26.747Z","desc_override":"This app will map volumated measure files (i.e. qmri) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","doi":"10.25663/brainlife.app.561","_canedit":true},{"_id":"6115e055a5a04ca30df9f71e","projects":[],"admins":["16"],"tags":["postprocessing"],"removed":false,"stats":{"requested":19020,"users":15,"success_rate":76.42612120442129,"gitinfo":{"desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","tags":["postprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"runtime_mean":966510.03,"runtime_std":1250650.5328230064,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a422362f3d3800f12f3fe"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a422362f3d3800f12f3ff"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"634a422362f3d3800f12f400"}],"examples":0,"groups":42},"config":{"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"myelinmap":{"type":"input","file_id":"map","input_id":"myelinmap"},"cortexmap":{"type":"input","file_id":"cortexmap","input_id":"cortexmap"},"fsurfparc":{"id":"fsurfparc","type":"enum","placeholder":"","advanced":true,"desc":"Parcellation from freesurfer wanted for future stats","default":"aparc.a2009s","_order":2,"pid":0.7623038016137872,"options":[{"desc":"Desikan-Killiany","label":"aparc","value":"aparc"},{"desc":"Destrieux Atlas","label":"aparc.a2009s","value":"aparc.a2009s"},{"desc":"DKT Atlas","label":"aparc.DKTatlas","value":"aparc.DKTatlas"}]}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c61bbe114027a01b14adc97","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e"},{"datatype_tags":["t1-t2-ratio"],"optional":false,"multi":false,"advanced":false,"_id":"60356c413a001144ed52e4ea","id":"myelinmap","datatype":"5fad54c27e8ecba2c3aa0c24"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"613a75fd201273724ec883d3","id":"cortexmap","datatype":"5c58aa5ef9109beac4b52f61"}],"outputs":[{"datatype_tags":["myelin_mapping","t1-t2-ratio"],"output_on_root":false,"archive":true,"_id":"5c61bbe114027a01b14adc99","id":"cortexmap","datatype":"5c58aa5ef9109beac4b52f61","datatype_tags_pass":null,"files":null},{"datatype_tags":["cortexmap_derivatives","myelin_mapping","t1-t2-ratio"],"output_on_root":false,"archive":true,"_id":"5eea8548d39ceb9bcca090f3","id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null}],"github_branch":"qmri-v1.1-nosnr","github":"brainlife/app-cortex-tissue-mapping","name":"Cortex Tissue Mapping (Native Space) - qMRI (No SNR masking)","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a422462f3d3800f12f401"},{"name":"Franco Pestilli","email":null,"_id":"634a422462f3d3800f12f402"}],"desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","__v":2075,"avatar":"https://raw.githubusercontent.com/brainlife/app-cortex-tissue-mapping/v1.1/cropped_glasser_ndi.png","desc_override":"","create_date":"2021-08-13T03:00:37.816Z","doi":"10.25663/brainlife.app.562","_canedit":true},{"_id":"5f6cc1836bbee392069a19a6","projects":[],"admins":["16"],"tags":[],"removed":false,"stats":{"requested":802,"users":1,"success_rate":75.45787545787546,"gitinfo":{"desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","tags":["postprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"runtime_mean":509812.48,"runtime_std":419863.4260586525,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3d6862f3d3800f12a40a"}],"examples":0,"groups":2},"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"postfreesurfer":{"type":"input","file_id":"output","input_id":"postfreesurfer"},"fa":{"type":"input","file_id":"fa","input_id":"tensor"},"md":{"type":"input","file_id":"md","input_id":"tensor"},"rd":{"type":"input","file_id":"rd","input_id":"tensor"},"ad":{"type":"input","file_id":"ad","input_id":"tensor"},"dir":{"type":"input","file_id":"dir","input_id":"noddi"},"ndi":{"type":"input","file_id":"ndi","input_id":"noddi"},"isovf":{"type":"input","file_id":"isovf","input_id":"noddi"},"odi":{"type":"input","file_id":"odi","input_id":"noddi"},"anat":{"type":"input","file_id":"t1","input_id":"anat"},"brainmask":{"type":"input","file_id":"mask","input_id":"brainmask"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c61bbe114027a01b14adc98","id":"dwi","datatype":"58c33c5fe13a50849b25879b"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c61bbe114027a01b14adc97","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e8109c5dd840e33b0e930df","id":"postfreesurfer","datatype":"5e767ddcde643b260e2a8a52"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c61be3d14027a01b14adca7","id":"tensor","datatype":"5a79df48d071a1753f1d661b"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5f6cc1836bbee357529a19ae","id":"noddi","datatype":"5ed02a620a8ed8e39c482a61"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e8109c5dd840ed7e6e930e2","id":"anat","datatype":"58c33bcee13a50849b25879a"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5f7249206bbee3f53a9af4ba","id":"brainmask","datatype":"5a281aee2c214c9ba83ce620","desc":"dwi brainmask"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5c61bbe114027a01b14adc99","id":"cortexmap","datatype":"5c58aa5ef9109beac4b52f61","datatype_tags_pass":null,"files":null},{"datatype_tags":["hcp-cortexmap-derivatives"],"output_on_root":false,"archive":false,"_id":"5e8109c5dd840e78cbe930e4","id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null}],"github_branch":"v1.0","github":"brainlife/app-hcp-cortex-mapping-replication","name":"Cortex Tissue Mapping - Fukutomi et al  2018 Replication","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3d6962f3d3800f12a40b"}],"desc":null,"__v":4152,"desc_override":"This application is a port of the NODDI Cortex Mapping code (https://github.com/RIKEN-BCIL/NoddiSurfaceMapping) developed by Fukutomi et al. The description of methodologies can be found in their 2018 Neuroimage paper (https://www.sciencedirect.com/science/article/pii/S1053811918301058?via%3Dihub). \n\nIf used, please cite:\nFukutomi, H., Glasser, M.F., Zhang, H., Autio, J.A., Coalson, T.S., Okada, T., Togashi, K., Van Essen, D.C., Hayashi, T., 2018. Neurite imaging reveals microstructural variations in human cerebral cortical gray matter. Neuroimage.","create_date":"2020-09-24T15:55:47.239Z","doi":"10.25663/brainlife.app.430","_canedit":true},{"_id":"5e8109c5dd840ee057e930dc","projects":[],"admins":["16"],"tags":[],"removed":false,"stats":{"requested":802,"users":1,"success_rate":75.45787545787546,"gitinfo":{"desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","tags":["postprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"runtime_mean":509812.48,"runtime_std":419863.4260586525,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a38d362f3d3800f11fe59"}],"examples":0,"groups":2},"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"postfreesurfer":{"type":"input","file_id":"output","input_id":"postfreesurfer"},"dir":{"type":"input","file_id":"dir","input_id":"noddi"},"icvf":{"type":"input","file_id":"icvf","input_id":"noddi"},"isovf":{"type":"input","file_id":"isovf","input_id":"noddi"},"od":{"type":"input","file_id":"od","input_id":"noddi"},"fa":{"type":"input","file_id":"fa","input_id":"tensor"},"md":{"type":"input","file_id":"md","input_id":"tensor"},"rd":{"type":"input","file_id":"rd","input_id":"tensor"},"ad":{"type":"input","file_id":"ad","input_id":"tensor"},"anat":{"type":"input","file_id":"t1","input_id":"anat"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c61bbe114027a01b14adc98","id":"dwi","datatype":"58c33c5fe13a50849b25879b"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c61bbe114027a01b14adc97","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e8109c5dd840e33b0e930df","id":"postfreesurfer","datatype":"5e767ddcde643b260e2a8a52"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c61bbe114027a01b14adc95","id":"noddi","datatype":"5bd77a8615a8683a39440dab"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c61be3d14027a01b14adca7","id":"tensor","datatype":"5a79df48d071a1753f1d661b"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e8109c5dd840ed7e6e930e2","id":"anat","datatype":"58c33bcee13a50849b25879a"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5c61bbe114027a01b14adc99","id":"cortexmap","datatype":"5c58aa5ef9109beac4b52f61","datatype_tags_pass":null,"files":null},{"datatype_tags":["hcp-cortexmap-derivatives"],"output_on_root":false,"archive":false,"_id":"5e8109c5dd840e78cbe930e4","id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null}],"github_branch":"master","github":"brainlife/app-hcp-cortex-mapping-replication","name":"Cortex Tissue Mapping - Fukutomi et al  2018 Replication - DEPRECATED","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a38d462f3d3800f11fe5a"}],"desc":null,"__v":4660,"create_date":"2020-03-29T20:49:09.935Z","doi":"10.25663/brainlife.app.293","desc_override":"This application is a port of the NODDI Cortex Mapping code (https://github.com/RIKEN-BCIL/NoddiSurfaceMapping) developed by Fukutomi et al. The description of methodologies can be found in their 2018 Neuroimage paper (https://www.sciencedirect.com/science/article/pii/S1053811918301058?via%3Dihub). \n\nIf used, please cite:\nFukutomi, H., Glasser, M.F., Zhang, H., Autio, J.A., Coalson, T.S., Okada, T., Togashi, K., Van Essen, D.C., Hayashi, T., 2018. Neurite imaging reveals microstructural variations in human cerebral cortical gray matter. Neuroimage.","deprecated_by":"5f6cc1836bbee392069a19a6","_canedit":true},{"_id":"5fbc2d627e8ecb4e35abe62f","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3e2862f3d3800f12ba2b"}],"success_rate":0,"users":1,"requested":8,"examples":0,"groups":1},"projects":[],"admins":["952"],"tags":[],"removed":false,"config":{"ts":{"type":"input","file_id":"timeseries","input_id":"Time Series"},"number_time_points":{"id":"number_time_points","type":"string","placeholder":"","advanced":false,"desc":"Number of time points in the time series.  If this is not selected, the code will assume that there are more time points than nodes.","default":"","_order":2,"pid":0.9989230264014435,"optional":true}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5fbc2d627e8ecb64b4abe630","id":"Time Series","datatype":"5ed834cdda66453cde8edfb7","desc":"ts: this is the initial time series of node activation\n"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5fbd440f7e8ecb3f7eac07cc","id":"Edge Time Series","datatype":"58e6e21e6cd4e826de4537ee","datatype_tags_pass":"Time Series","files":null}],"github":"JacobColbyTanner/bnbl_brainlife","name":"Create Edge Time Series","desc_override":"This app creates an edge by time matrix referred to as Edge Time Series.  Input should be a time series, either node by time, or time by node as well as a scalar for the number of time points in the time series.  Number of edges will be determined by the following equation:\n\nN = number of nodes\n\nNumber of Edges = N(N-1)/2\n\n\nFor reference to the original paper, see below:\n\nFaskowitz, J., Esfahlani, F. Z., Jo, Y., Sporns, O., & Betzel, R. F. (2020). Edge-centric functional network representations of human cerebral cortex reveal overlapping system-level architecture (pp. 1-11). Nature Publishing Group.","user_id":"952","contributors":[{"name":null,"email":null,"_id":"634a3e2962f3d3800f12ba2c"},{"name":"Franco Pestilli","email":null,"_id":"634a3e2962f3d3800f12ba2d"}],"create_date":"2020-11-23T21:45:06.913Z","desc":null,"doi":"10.25663/brainlife.app.450","__v":3905,"_canedit":true},{"_id":"6286a9ced0697cf1eae44a76","user_id":"56","projects":[],"admins":["56"],"name":"Create MNI coordinate-based ROIS and warp to subject space","github":"DanNBullock/app-createMNI_ROIS_and_warp2subj","github_branch":"master","desc_override":"Create spherical or planar ROIS based on MNI coordinates and then warp them to a given subject's reference space.","tags":[],"config":{"t1":{"type":"input","file_id":"t1","input_id":"AnatomicalT1"},"mask":{"type":"input","file_id":"mask","input_id":"brainMask"},"spheres":{"id":"spheres","type":"string","placeholder":"\"0,0,0,3;5,5,5,5\"","advanced":false,"desc":"Any number of sphere requests, with each request delimited by a semicolon (;).\n\nWithin each request, the first three (3) numbers correspond to the X, Y, and Z coordinates of the sphere centroid.  The final (fourth) number corresponds to the sphere radius.  Coordinates can be delimited by commas (,) or spaces ( ).","default":"","_order":2,"pid":0.02244497161932535},"planes":{"id":"planes","type":"string","placeholder":"\"x=5; y=-7\"","advanced":false,"desc":"Any number of planar requests, with each request delimited by a semicolon (;).\n\nWithin each request, the first value is a letter (x, y, or z) corresponding to the planar slice the ROI should correspond to.  In this way, x will return a sagittal slice, y will return a coronal slice, and z will return a transverse slice.  The value following the equals (=) symbol corresponds to the spatial coordinate that the plane should occur at along the specified axis. ","default":"","_order":3,"pid":0.6503811087135134}},"inputs":[{"id":"AnatomicalT1","datatype":"58c33bcee13a50849b25879a","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"6286a9ced0697cf1eae44a77"},{"id":"brainMask","datatype":"5a281aee2c214c9ba83ce620","datatype_tags":["brain"],"optional":false,"multi":false,"advanced":false,"_id":"6286a9ced0697cf1eae44a78"}],"outputs":[{"id":"output","desc":"The requested spherical and planar ROIs, contained within a directory named \"rois\".","datatype":"5be9ea0315a8683a39a1ebd9","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"6286a9ced0697cf1eae44a79"}],"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a446f62f3d3800f130e11"}],"examples":1,"success_rate":30,"users":1,"groups":1,"runtime_mean":1429286.3333333333,"runtime_std":397663.8813171523,"requested":10},"removed":false,"contributors":[{"name":"Daniel Bullock","email":"iisdanbul@gmail.com","_id":"634a446f62f3d3800f130e12"}],"create_date":"2022-05-19T20:34:22.883Z","desc":null,"__v":334,"doi":"10.25663/brainlife.app.629","_canedit":true},{"_id":"5ef1211e78d63f25fbd39e02","stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3c3362f3d3800f127c54"}],"success_rate":0,"users":7,"requested":22,"examples":0,"groups":7},"projects":[],"admins":["16"],"tags":[],"removed":false,"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ef1211e78d63f4a9ad39e03","id":"dwi","datatype":"58c33c5fe13a50849b25879b"}],"outputs":[{"datatype_tags":["dwi","brain"],"output_on_root":false,"archive":true,"_id":"5ef1211e78d63f08c6d39e04","id":"mask","datatype":"5a281aee2c214c9ba83ce620","datatype_tags_pass":"dwi","files":null}],"github_branch":"v1.0","github":"brainlife/app-mrtrix3-dwi-brainmask","name":"Create brainmask of DWI using MrTrix3","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3c3362f3d3800f127c55"}],"create_date":"2020-06-22T21:22:38.918Z","desc":null,"doi":"10.25663/brainlife.app.387","__v":4564,"_canedit":true},{"_id":"607959e198cade1e649b2183","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a401862f3d3800f12d53d"}],"success_rate":80.48780487804879,"users":1,"runtime_mean":28526.21212121212,"runtime_std":12694.015000534404,"requested":41,"examples":1},"projects":[],"admins":["1342","664","670"],"tags":[],"removed":false,"config":{"fif":{"type":"input","file_id":"fif","input_id":"fif0"},"headshape":{"type":"input","file_id":"headshape","input_id":"fif0"},"calibration":{"type":"input","file_id":"calibration","input_id":"fif0"},"crosstalk":{"type":"input","file_id":"crosstalk","input_id":"fif0"},"destination":{"type":"input","file_id":"destination","input_id":"fif0"},"events":{"type":"input","file_id":"events","input_id":"fif0"},"channels":{"type":"input","file_id":"channels","input_id":"fif0"},"param_make_events":{"id":"param_make_events","type":"boolean","placeholder":"","advanced":false,"desc":"If True, fixed length events will be created, else existing events from the fif file will be extracted.\nThe parameters you can change when creating fixed length events contain \"make_events\". The other parameters contain \"find_events\" and can be changed when you extract events from the MEG/EEG file.","default":true,"_order":2,"pid":0.5594848389379345},"param_make_events_id":{"id":"param_make_events_id","type":"number","placeholder":"","advanced":true,"desc":"The id to use when creating events. This value must be an integer.","default":1,"_order":4,"pid":0.42061158000912857},"param_make_events_start":{"id":"param_make_events_start","type":"number","placeholder":"","advanced":false,"desc":"Time of first event when creating events. This value can be a float.","default":0,"_order":5,"pid":0.7894485213590245},"param_make_events_stop":{"id":"param_make_events_stop","type":"number","placeholder":"","advanced":true,"desc":"Maximum time of last event when creating events. This value can be a float.","default":null,"_order":6,"pid":0.5869133731100329,"optional":true},"param_make_events_duration":{"id":"param_make_events_duration","type":"number","placeholder":"","advanced":false,"desc":"The duration in seconds to separate events by when creating events. This value can be a float.","default":1,"_order":7,"pid":0.08131185591318912},"param_make_events_first_samp":{"id":"param_make_events_first_samp","type":"boolean","placeholder":"","advanced":true,"desc":"If True, times will have raw.first_samp added to them when creating events.","default":true,"_order":8,"pid":0.9343300377353168},"param_make_events_overlap":{"id":"param_make_events_overlap","type":"number","placeholder":"","advanced":false,"desc":"The overlap between events when creating events. Must be 0 <= overlap < duration. This value can be a float.","default":0,"_order":9,"pid":0.9159801088340744},"param_find_events_stim_channels":{"id":"param_find_events_stim_channels","type":"string","placeholder":"","advanced":true,"desc":"Name of the stim channel or all the stim channels affected by triggers when extracting existing events. This value can be a list of strings (e.g., [STIM02, STIM03]). Please don't forget the square brackets and the \" around each name.","default":"","_order":10,"pid":0.0705970634576849,"optional":true},"param_find_events_output":{"id":"param_find_events_output","type":"enum","placeholder":"","advanced":true,"desc":"Whether to report when events start, when events end, or both when extracting existing events.","default":"onset","_order":11,"pid":0.6520642482261714,"options":[{"desc":"","label":"","value":"onset"},{"desc":"","label":"","value":"offset"},{"desc":"","label":"","value":"step"}]},"param_find_events_consecutive":{"id":"param_find_events_consecutive","type":"enum","placeholder":"","advanced":true,"desc":"If True, consider instances where the value of the events channel changes without first returning to zero as multiple events (when extracting existing events). If False, report only instances where the value of the events channel changes from/to zero. If ‘increasing’ , report adjacent events only when the second event code is greater than the first.","default":"increasing","_order":12,"pid":0.9224933799556854,"options":[{"desc":"","label":"","value":"true"},{"desc":"","label":"","value":"false"},{"desc":"","label":"","value":"increasing"}]},"param_find_events_min_duration":{"id":"param_find_events_min_duration","type":"number","placeholder":"","advanced":true,"desc":"The minimum duration of a change in the events channel required to consider it as an event (in seconds) when extracting existing events. This value can be a float.","default":0,"_order":13,"pid":0.32913996210761387},"param_find_events_shortest_event":{"id":"param_find_events_shortest_event","type":"number","placeholder":"","advanced":true,"desc":"Minimum number of samples an event must last when extracting existing events. This value must be an integer. ","default":2,"_order":14,"pid":0.687671188442257},"param_find_events_mask":{"id":"param_find_events_mask","type":"number","placeholder":"","advanced":true,"desc":"The value of the digital mask to apply to the stim channel values when extracting existing events. This value must be an int. ","default":null,"_order":15,"pid":0.22234438202987117,"optional":true},"param_find_events_uint_cast":{"id":"param_find_events_uint_cast","type":"boolean","placeholder":"","advanced":true,"desc":"If True, do a cast to uint16 on the channel data when extracting existing events.","default":false,"_order":16,"pid":0.9380846585966305},"param_find_events_mask_type":{"id":"param_find_events_mask_type","type":"enum","placeholder":"","advanced":true,"desc":"The type of operation between the mask and the trigger when extracting existing events.","default":"and","_order":17,"pid":0.31425232847581785,"options":[{"desc":"","label":"","value":"and"},{"desc":"","label":"","value":"not_and"}]},"param_find_events_initial_event":{"id":"param_find_events_initial_event","type":"boolean","placeholder":"","advanced":true,"desc":"If True, an event is created if the stim channel has a value different from 0 as its first sample (when extracting existing events).","default":false,"_order":18,"pid":0.4924086175645517}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"607959e198cadec1a19b2184","id":"fif0","datatype":"6000737faacf9ee51fa691cb","desc":"MEG data from which the events will be extracted or created."}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"607959e198cade39f89b2185","id":"out_dir_get_events","datatype":"608195ce89df435fd26893c1","datatype_tags_pass":null,"files":null,"desc":"BIDS compliant events file."}],"github_branch":"master","github":"brainlife/app-get-events","name":"Create fixed length events or extract them from MEG signals","user_id":"1342","contributors":[{"name":null,"email":null,"_id":"634a401962f3d3800f12d53e"}],"create_date":"2021-04-16T09:33:21.385Z","desc":"Extract existing events from a fif file or create new events and store them in a .tsv file.","__v":2776,"doi":"10.25663/brainlife.app.507","_canedit":true},{"_id":"626bf253f3858674a2a6c9fb","user_id":"16","projects":[],"admins":["16"],"name":"Create networkneuro datatype for visualization","github":"brainlife/app-create-networkneuro","github_branch":"labels-v1.0","desc":null,"desc_override":"This app is purely designed to generate a datatype that will work with the tractvis networkneuro visualizer.","tags":[],"contributors":[{"name":"Brad Caron","email":null,"_id":"634a442662f3d3800f130c65"}],"config":{"track":{"type":"input","file_id":"track","input_id":"tract"},"parc":{"type":"input","file_id":"parc","input_id":"parc"},"label":{"type":"input","file_id":"label","input_id":"parc"},"index":{"type":"input","file_id":"index","input_id":"labels"},"names":{"type":"input","file_id":"names","input_id":"labels"},"count":{"type":"input","file_id":"csv","input_id":"count"},"density":{"type":"input","file_id":"csv","input_id":"density"},"length":{"type":"input","file_id":"csv","input_id":"length"},"denlen":{"type":"input","file_id":"csv","input_id":"denlen"}},"inputs":[{"id":"tract","datatype":"5907d922436ee50ffde9c549","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"61310849584a7642843cb741"},{"id":"parc","desc":"Parcellation used for generating network. Purely here to generate vtks","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"61310849584a76e3f03cb746"},{"id":"labels","datatype":"606345ade4a8347b6f337de4","datatype_tags":["!binary"],"optional":false,"multi":false,"advanced":false,"_id":"626bf253f3858674a2a6c9ff"},{"id":"count","datatype":"5d34d9f744947d8aea0e0d2f","datatype_tags":["count"],"optional":false,"multi":false,"advanced":false,"_id":"626bf253f3858674a2a6ca00"},{"id":"density","datatype":"5d34d9f744947d8aea0e0d2f","datatype_tags":["density"],"optional":false,"multi":false,"advanced":false,"_id":"626bf253f3858674a2a6ca01"},{"id":"length","datatype":"5d34d9f744947d8aea0e0d2f","datatype_tags":["length"],"optional":false,"multi":false,"advanced":false,"_id":"626bf253f3858674a2a6ca02"},{"id":"denlen","datatype":"5d34d9f744947d8aea0e0d2f","datatype_tags":["denlen"],"optional":false,"multi":false,"advanced":false,"_id":"626bf253f3858674a2a6ca03"}],"outputs":[{"id":"netneuro","datatype":"58e6e21e6cd4e826de4537ee","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"61310849584a76dfdb3cb749"}],"stats":{"success_rate":37.096774193548384,"groups":3,"users":1,"runtime_mean":4389710.0869565215,"runtime_std":10140172.72877778,"requested":73,"resources":[],"examples":1},"removed":false,"__v":442,"create_date":"2022-04-29T14:12:35.665Z","doi":"10.25663/brainlife.app.620","_canedit":true},{"_id":"61310849584a7676723cb740","stats":{"resources":[],"success_rate":37.096774193548384,"users":1,"runtime_mean":4389710.0869565215,"runtime_std":10140172.72877778,"requested":73,"examples":0,"groups":3},"projects":["5fb1ccf37e8ecb8242aaca75","5ffc884d2ba0fba7a7e89132"],"admins":["16"],"tags":[],"removed":false,"config":{"track":{"type":"input","file_id":"track","input_id":"tract"},"parc":{"type":"input","file_id":"parc","input_id":"parc"},"label":{"type":"input","file_id":"label","input_id":"parc"},"raw_netmat":{"type":"input","file_id":"output","input_id":"raw_netmat"},"raw_mat":{"type":"input","file_id":"output","input_id":"raw_mat"}},"inputs":[{"id":"tract","datatype":"5907d922436ee50ffde9c549","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"61310849584a7642843cb741"},{"id":"parc","desc":"Parcellation used for generating network. Purely here to generate vtks","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"61310849584a76e3f03cb746"},{"id":"raw_netmat","desc":"This is used if there exists an \"assignments.csv\" file within the datatype, usually from the SCMRT and SCMT apps. Needed to identify edges for visualizer","datatype":"59c3eae633fc1cf9ead71679","datatype_tags":["networkmatrices"],"optional":true,"multi":false,"advanced":false,"_id":"61310849584a763ada3cb747"},{"id":"raw_mat","desc":"This is used if there exists a file within the datatype containing edge information, usually from Structural Networks (count) app. Needed to identify edges for visualizer","datatype":"59c3eae633fc1cf9ead71679","datatype_tags":["matlab"],"optional":true,"multi":false,"advanced":false,"_id":"61310849584a767b583cb748"}],"outputs":[{"id":"netneuro","datatype":"58e6e21e6cd4e826de4537ee","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"61310849584a76dfdb3cb749"}],"github_branch":"raw-v1.0","github":"brainlife/app-create-networkneuro","name":"Create networkneuro datatype for visualization (Raw Datatypes)","desc_override":"This app is purely designed to generate a datatype that will work with the tractvis networkneuro visualizer.","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a425a62f3d3800f12f515"}],"create_date":"2021-09-02T17:22:17.606Z","desc":null,"__v":1921,"doi":"10.25663/brainlife.app.568","_canedit":true},{"_id":"613a78182012731985c885a5","projects":[],"admins":["16"],"tags":["postprocessing"],"removed":false,"stats":{"requested":19020,"users":15,"success_rate":76.42612120442129,"gitinfo":{"desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","tags":["postprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"runtime_mean":966510.03,"runtime_std":1250650.5328230064,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a427e62f3d3800f12f5c8"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a427e62f3d3800f12f5c9"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"634a427e62f3d3800f12f5ca"}],"examples":0,"groups":42},"config":{"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"warp":{"type":"input","file_id":"warp","input_id":"warp"},"inverse_warp":{"type":"input","file_id":"inverse-warp","input_id":"warp"},"fsurfparc":{"id":"fsurfparc","type":"enum","placeholder":"","advanced":true,"desc":"Parcellation from freesurfer wanted to for future stats","default":"aparc.a2009s","_order":2,"pid":0.018533301126992696,"options":[{"desc":"Desikan-Killiany","label":"aparc","value":"aparc"},{"desc":"Destrieux Atlas ","label":"aparc.a2009s","value":"aparc.a2009s"},{"desc":"DKT Atlas","label":"aparc.DKTatlas","value":"aparc.DKTatlas"}]}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c61bbe114027a01b14adc97","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e","desc":"The path to the top directory containing the output from Freesurfer"},{"datatype_tags":["!linear"],"optional":false,"multi":false,"advanced":false,"_id":"5eea8548d39ceb71bda090f1","id":"warp","datatype":"5bbfb28071454db2a890fbce","desc":"These files are needed to generate surfaces in template space (usually MNI). If you need to generate these files, please look at brainlife app FSL Anat. A version of this app not requiring this input is being generated"}],"outputs":[{"datatype_tags":["structural_derivatives"],"output_on_root":false,"archive":true,"_id":"5c61bbe114027a01b14adc99","id":"cortexmap","datatype":"5c58aa5ef9109beac4b52f61","datatype_tags_pass":null,"files":null,"desc":"The cortexmap output, containing the surfaces and mapped data"},{"datatype_tags":["cortexmap_derivatives"],"output_on_root":false,"archive":true,"_id":"5eea8548d39ceb9bcca090f3","id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null,"desc":"A directory containing all of the derivatives generated. Useful for QA and debugging"}],"github_branch":"create-cortexmap-datatype-v1.0","github":"brainlife/app-cortex-tissue-mapping","name":"Create structural derivatives for cortexmap datatype","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a427f62f3d3800f12f5cb"},{"name":"Franco Pestilli","email":null,"_id":"634a427f62f3d3800f12f5cc"}],"desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","__v":1858,"avatar":"https://raw.githubusercontent.com/brainlife/app-cortex-tissue-mapping/v1.1/cropped_glasser_ndi.png","create_date":"2021-09-09T21:09:44.254Z","doi":"10.25663/brainlife.app.573","_canedit":true},{"_id":"5a0f38bf31769f1e4d46cc58","name":"Crop and Reorient T1","desc":"This application will crop and reorient the T1 image to standard orientation and FOV using FSL's fslreorient2std and robustfov. ","github":"brainlife/app-crop_reorient","github_branch":"1.0","config":{"input":{"type":"input","file_id":"t1","input_id":"input"},"reorient":{"type":"boolean","placeholder":"","desc":"Run fslreorient2std. This command reorients an image to match the orientation of the standard template images (MNI152) so that they appear \"the same way around\" in FSLView. It requires that the image labels are correct in FSLView before this is run. It is also not a registration tool, so it will not align the image to standard space, it will only apply 90, 180 or 270 degree rotations about the different axes as necessary to get the labels in the same position as the standard template.","default":false,"id":"reorient","pid":0.3107867198517935,"_order":2},"crop":{"type":"boolean","placeholder":"","desc":"Run robustfov to reduce field-of-view of image to remove lower head and neck.\n","default":false,"id":"crop","pid":0.9396289685534254,"_order":3}},"user_id":"43","create_date":"2017-11-17T19:30:07.422Z","removed":false,"_rate":0,"outputs":[{"datatype_tags":["crop_reorient"],"output_on_root":true,"archive":true,"_id":"5a0f38bf31769f1e4d46cc59","id":"output","datatype":"58c33bcee13a50849b25879a","files":{"t1":"out.nii.gz"},"datatype_tags_pass":"input","desc":"The crop and/or reoriented T1"}],"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5a0f38bf31769f1e4d46cc5a","id":"input","datatype":"58c33bcee13a50849b25879a","desc":"The path to the anat/t1w datatype"}],"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a319662f3d3800f116834"},{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a319662f3d3800f116835"},{"name":"Brad Caron","email":null,"_id":"634a319662f3d3800f116836"}],"tags":[],"admins":["1","16"],"projects":[],"__v":14269,"references":[],"stats":{"stars":0,"requested":9743,"users":98,"success_rate":95.85716278420979,"serviceinfo":{"_id":"5d729e1e78356a109788b1d9","counts":{"_id":"5e5c688f87cac72589ab1bb8","failed":41,"finished":876,"removed":739,"requested":991,"running":923,"running_sync":0,"stop_requested":35},"success_rate":95.5288985823337,"users":21,"readme_status":"ok","runtime_mean":53647.3,"runtime_std":18009.497550181684,"service":"brainlife/app-crop_reorient","__v":0},"gitinfo":{"desc":"This application will crop and reorient the T1 image to standard orientation and FOV using FSL's fslreorient2std and robustfov. ","tags":[],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":596052.68,"runtime_std":2204038.0885753445,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a319562f3d3800f116832"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a319562f3d3800f116833"}],"examples":2,"groups":141},"doi":"10.25663/bl.app.15","deprecated_by":"60707f8bc7f80a0cb895d6ca","_canedit":true},{"_id":"5bc0e221afd0bc0027efccef","projects":[],"admins":["1","19","16"],"tags":[],"removed":false,"config":{"input":{"type":"input","file_id":"t2","input_id":"input"},"reorient":{"id":"reorient","type":"boolean","placeholder":"","desc":"reorient the T2","default":false,"_order":2,"pid":0.2931914183584923},"crop":{"id":"crop","type":"boolean","placeholder":"","desc":"crop the T2","default":false,"_order":3,"pid":0.8392625920440393}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5bc0e221afd0bc0027efccf0","id":"input","datatype":"594c0325fa1d2e5a1f0beda5"}],"outputs":[{"datatype_tags":["crop_reorient"],"output_on_root":true,"archive":true,"_id":"5bc0e221afd0bc0027efccf1","id":"output","datatype":"594c0325fa1d2e5a1f0beda5","datatype_tags_pass":"input","files":{"t2":"out.nii.gz"}}],"name":"Crop and Reorient T2","github":"brainlife/app-crop_reorient","github_branch":"1.0","user_id":"1","references":[],"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a341762f3d3800f1184fc"},{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a341762f3d3800f1184fd"},{"name":"Brad Caron","email":null,"_id":"634a341762f3d3800f1184fe"}],"create_date":"2018-10-12T18:04:17.247Z","desc":"This application will crop and reorient the T1 image to standard orientation and FOV using FSL's fslreorient2std and robustfov. ","stats":{"stars":0,"requested":9743,"users":98,"success_rate":95.85716278420979,"serviceinfo":{"_id":"5d729e1e78356a109788b1d9","counts":{"_id":"5e5c3dc287cac72d7cab13d7","failed":41,"finished":875,"removed":737,"requested":989,"running":921,"running_sync":0,"stop_requested":34},"success_rate":95.52401746724891,"users":21,"readme_status":"ok","runtime_mean":53713.3,"runtime_std":18049.17478473739,"service":"brainlife/app-crop_reorient","__v":0},"gitinfo":{"desc":"This application will crop and reorient the T1 image to standard orientation and FOV using FSL's fslreorient2std and robustfov. ","tags":[],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":596052.68,"runtime_std":2204038.0885753445,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a341762f3d3800f1184fa"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a341762f3d3800f1184fb"}],"examples":1,"groups":141},"doi":"10.25663/brainlife.app.114","__v":10016,"deprecated_by":"6070841ec7f80a148795d7c4","_canedit":true},{"_id":"60ef07acddc2dff22965f239","stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a415662f3d3800f12e27f"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a415662f3d3800f12e280"}],"success_rate":50,"users":4,"runtime_mean":2179465.6666666665,"runtime_std":1434055.4931397256,"requested":7,"examples":1,"groups":5},"projects":[],"admins":["1662"],"tags":[],"removed":false,"config":{"t1":{"type":"input","file_id":"t1","input_id":"t1"},"mask":{"type":"input","file_id":"mask","input_id":"mask"}},"inputs":[{"id":"t1","datatype":"58c33bcee13a50849b25879a","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"60ef07acddc2df73f565f23a"},{"id":"mask","desc":"brain mask","datatype":"5a281aee2c214c9ba83ce620","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"61abf35b7577fd30682cf802"}],"outputs":[{"id":"segmentation","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"60ef07acddc2dfb67f65f23b"}],"github_branch":"2.5.5","github":"FBK-NILab/bl_app_dbb_ANTsCTSeg","name":"DBB_ANTsCortThickSeg","user_id":"1662","contributors":[{"name":"Gabriele","email":null,"_id":"634a415762f3d3800f12e281"}],"create_date":"2021-07-14T15:50:04.885Z","desc":"A tool that performs the antsCorticalThickness.sh script on a T1-w image using PTBP priors in order to obtain the brain tissue segmentation.","__v":2316,"doi":"10.25663/brainlife.app.541","desc_override":"A tool that performs the antsCorticalThickness.sh script on a T1-w image using PTBP priors in order to obtain the brain tissue segmentation. The script is customized so that a previously estimated brain mask can also be input.","_canedit":true},{"_id":"61645a25fc8eb9c745fa2f2e","projects":[],"admins":["1662"],"tags":[],"removed":false,"stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a42b562f3d3800f12f75c"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a42b562f3d3800f12f75d"}],"success_rate":25,"users":1,"runtime_mean":10845,"runtime_std":213,"requested":8,"examples":1,"groups":1},"config":{"computed":{"type":"input","file_id":"parc","input_id":"computed"},"groud_truth":{"type":"input","file_id":"parc","input_id":"groud_truth"}},"inputs":[{"id":"computed","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"61645a25fc8eb942a9fa2f30"},{"id":"groud_truth","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"61645a72fc8eb9af6bfa2f7a"}],"outputs":[{"id":"dice_score","desc":"dice score of the different labels","datatype":"59c3eae633fc1cf9ead71679","datatype_tags":["dice_score"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":false,"_id":"61ac000d7577fd30682d1969"}],"github_branch":"1.2.2","github":"FBK-NILab/bl_app_dbb_DiceScore","name":"DBB_DiceScore","desc_override":"Computes the Dice similarity coefficient (DSC) between two segmentations (parcellations)","user_id":"1662","contributors":[],"desc":"Tool that performs the dice score between two 3D segmentations","__v":433,"create_date":"2021-10-11T15:37:09.901Z","doi":"10.25663/brainlife.app.579","_canedit":true},{"_id":"60f83394b99111089ab55f80","stats":{"resources":[{"resource_id":"5ffc99da0df8ff7fc740c95a","name":"Bridges2 @ PSC (GPU-Shared)","_id":"634a419662f3d3800f12e3a2"}],"success_rate":75.38461538461539,"users":2,"runtime_mean":213074.3469387755,"runtime_std":391114.53703077574,"requested":74,"examples":1,"groups":1},"projects":[],"admins":["1662","45"],"tags":[],"removed":false,"config":{"t1":{"type":"input","file_id":"t1","input_id":"t1"},"mask":{"type":"input","file_id":"mask","input_id":"mask"}},"inputs":[{"id":"t1","datatype":"58c33bcee13a50849b25879a","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"60f83394b991116920b55f81"},{"id":"mask","datatype":"5a281aee2c214c9ba83ce620","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"61b365e352911e175a22887b"}],"outputs":[{"id":"segmentation","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":false,"_id":"60f83394b9911168f9b55f82"}],"github_branch":"1.4.2","github":"FBK-NILab/bl_app_dbb_DisSeg","name":"DBB_DisSeg","desc_override":"3D U-Net for brain tissue segmentation","user_id":"1662","contributors":[{"name":"Gabriele","email":null,"_id":"634a419662f3d3800f12e3a3"}],"create_date":"2021-07-21T14:47:48.675Z","desc":"3D U-Net for brain tissue segmentation","__v":2271,"doi":"10.25663/brainlife.app.548","_canedit":true},{"_id":"60cb69e0cdfdb50220fee1c3","stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a412062f3d3800f12e1b7"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a412062f3d3800f12e1b8"}],"success_rate":100,"users":2,"runtime_mean":65167,"runtime_std":187,"requested":2,"examples":1,"groups":2},"projects":[],"admins":["1662","1574","45"],"tags":[],"removed":false,"config":{"t1":{"type":"input","file_id":"t1","input_id":"t1"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"affine":{"type":"input","file_id":"affine","input_id":"affine"}},"inputs":[{"id":"t1","datatype":"58c33bcee13a50849b25879a","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"60cb69e0cdfdb51412fee1c4"},{"id":"mask","desc":"brain mask","datatype":"5a281aee2c214c9ba83ce620","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"60d3684bcdfdb550cdffc70d"},{"id":"affine","desc":"reorientation matrix ","datatype":"5bbfb28071454db2a890fbce","datatype_tags":["linear"],"optional":false,"multi":false,"advanced":false,"_id":"60d3684bcdfdb5ecc7ffc70e"}],"outputs":[{"id":"T1_reoriented_N4","datatype":"58c33bcee13a50849b25879a","datatype_tags":["acpc_aligned","bias_corrected"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":false,"_id":"60cb69e0cdfdb52824fee1c6"}],"github_branch":"1.5.2","github":"FBK-NILab/bl_app_dbb_preproc_t1w","name":"DBB_preprocessing_t1w","desc_override":"Preprocessing app for the Distorted Brain Benchmark: ACPC alignment and Bias Field Correction","user_id":"1574","contributors":[{"name":"Gabriele","email":null,"_id":"634a412062f3d3800f12e1b9"},{"name":"Matteo","email":null,"_id":"634a412062f3d3800f12e1ba"}],"create_date":"2021-06-17T15:27:28.243Z","desc":"Brainlife App for the preprocessing of T1w MRI data of Distorted Brain Benchmark ","__v":2519,"doi":"10.25663/brainlife.app.535","_canedit":true},{"_id":"5d2882b742ed0707bd305676","projects":[],"admins":["146"],"tags":["postprocessing"],"removed":false,"stats":{"stars":0,"requested":333,"users":1,"success_rate":89.55696202531645,"serviceinfo":{"_id":"5d729e1f78356a109788b2f3","counts":{"_id":"5e5c3e0987cac7ea51ab1421","failed":69,"finished":676,"removed":739,"requested":926,"running":792,"running_sync":0,"stop_requested":45},"success_rate":90.73825503355705,"users":1,"readme_status":"too short","runtime_mean":638839.76,"runtime_std":456262.49373193324,"service":"giulia-berto/app-compute-dsc4hcp","__v":0},"gitinfo":{"desc":"Compute the Dice Similarity Coefficient (DSC) between corresponding tracts of the given segmentation and the ground truth when using HCP data.","tags":[],"stats":{"stars":0},"contributors":[{"name":"Giulia Bertò","email":null}]},"runtime_mean":247796.59,"runtime_std":174904.9157032526,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a36b662f3d3800f11d078"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a36b662f3d3800f11d079"}],"examples":1,"groups":4},"name":"DSC evaluation (mask - mask)","desc":"Compute the degree of overlap between two bundle masks using the Dice Similarity Coefficient (DSC) score.","github":"giulia-berto/app-compute-dsc","github_branch":"1.1","config":{"seg_est":{"type":"input","file_id":"masks","input_id":"0"},"seg_true":{"type":"input","file_id":"masks","input_id":"1"}},"desc_override":"","user_id":"146","outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5d18c8952daec10035f3f967","id":"csv","datatype":"599f305ad1f46fec1759f363","datatype_tags_pass":"0","files":null,"desc":".csv file with the following scores: DSC, J, sensitivity, TP, FP, FN"}],"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ad79504363fd5002759a6b8","id":"0","datatype":"592dded1436ee50ffd88f5d0","desc":"a collection of estimated bundle masks"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ad79504363fd5002759a6b7","id":"1","datatype":"592dded1436ee50ffd88f5d0","desc":"a collection of ground truth bundle masks"}],"contributors":[{"name":"Giulia Bertò","email":null,"_id":"634a36b762f3d3800f11d07a"}],"__v":7565,"create_date":"2019-07-12T12:53:11.189Z","doi":"10.25663/brainlife.app.212","_canedit":true},{"_id":"5ad79504363fd5002759a6b5","stats":{"stars":0,"requested":333,"users":1,"success_rate":89.55696202531645,"serviceinfo":{"_id":"5d729e1f78356a109788b2f3","counts":{"_id":"5e5c3d9887cac745b2ab13a7","failed":69,"finished":676,"removed":739,"requested":926,"running":792,"running_sync":0,"stop_requested":45},"success_rate":90.73825503355705,"users":1,"readme_status":"too short","runtime_mean":638839.76,"runtime_std":456262.49373193324,"service":"giulia-berto/app-compute-dsc4hcp","__v":0},"gitinfo":{"desc":"Compute the Dice Similarity Coefficient (DSC) between corresponding tracts of the given segmentation and the ground truth when using HCP data.","tags":[],"stats":{"stars":0},"contributors":[{"name":"Giulia Bertò","email":null}]},"runtime_mean":247796.59,"runtime_std":174904.9157032526,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a327e62f3d3800f1176bf"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a327e62f3d3800f1176c0"}],"examples":1,"groups":4},"name":"DSC evaluation (wmc - wmc)","desc":"Compute the degree of overlap between two bundle masks using the Dice Similarity Coefficient (DSC) score.","citation":null,"github":"giulia-berto/app-compute-dsc","github_branch":"1.0","config":{"tractogram":{"type":"input","file_id":"track","input_id":"0"},"seg_est":{"type":"input","file_id":"classification","input_id":"1"},"seg_true":{"type":"input","file_id":"classification","input_id":"2"},"t1":{"type":"input","file_id":"t1","input_id":"3"},"tractID_list":{"id":"tractID_list","type":"string","placeholder":"","desc":"ID list of the bundles of interest, separated by commas","default":"","_order":2,"pid":0.3653785884274485}},"desc_override":"","user_id":"146","create_date":"2018-04-18T18:57:08.840Z","removed":false,"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5d18c8952daec10035f3f967","id":"csv","datatype":"599f305ad1f46fec1759f363","datatype_tags_pass":"1","files":null,"desc":"CSV containing the following scalars: DSC, wDSC, Jaccard, sensitivity, TP, FP, FN\n"}],"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ad79504363fd5002759a6b9","id":"0","datatype":"5907d922436ee50ffde9c549","desc":"Tractogram associated with the white matter classification (WMC) structure"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ad79504363fd5002759a6b8","id":"1","datatype":"5cc1d64c44947d8aea6b2d8b","desc":"Estimated bundles in form of white matter classification (WMC) structure"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ad79504363fd5002759a6b7","id":"2","datatype":"5cc1d64c44947d8aea6b2d8b","desc":"Ground truth bundles in form of white matter classification (WMC) structure"},{"datatype_tags":["acpc_aligned"],"optional":false,"multi":false,"advanced":false,"_id":"5ad79504363fd5002759a6b6","id":"3","datatype":"58c33bcee13a50849b25879a","desc":"T1 image"}],"contributors":[{"name":"Giulia Bertò","email":null,"_id":"634a327e62f3d3800f1176c1"}],"tags":["postprocessing"],"references":[],"admins":["146"],"projects":[],"__v":14098,"doi":"10.25663/bl.app.57","_canedit":true},{"_id":"611301a3a5a04c0a6df90472","projects":[],"admins":["16"],"tags":[],"removed":false,"stats":{"success_rate":77.1356783919598,"users":4,"runtime_mean":76426.87,"runtime_std":81864.22165606353,"requested":406,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a41f462f3d3800f12f25c"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a41f462f3d3800f12f25d"}],"examples":2,"groups":7},"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"type":{"id":"type","type":"enum","placeholder":"","advanced":false,"desc":"The debiasing algorithm to use","default":"ants","_order":2,"pid":0.9893840628177379,"options":[{"desc":"fsl's debiasing algorithm","label":"fsl","value":"fsl"},{"desc":"ant's debiasing algorithm","label":"ants","value":"ants"}]},"antsb":{"id":"antsb","type":"string","placeholder":"","advanced":true,"desc":"","default":"[150,3]","_order":3,"pid":0.3931856828453719},"antsc":{"id":"antsc","type":"string","placeholder":"","advanced":true,"desc":"","default":"[200x200,1e-6]","_order":4,"pid":0.0929571898098458},"antss":{"id":"antss","type":"string","placeholder":"","advanced":true,"desc":"","default":"2","_order":5,"pid":0.3939683138881458}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d9e9b8a2b4f675258e670b2","id":"dwi","datatype":"58c33c5fe13a50849b25879b","desc":"The path to the DWI datatype"},{"datatype_tags":["brain","dwi"],"optional":true,"multi":false,"advanced":false,"_id":"611301a3a5a04c220ff90476","id":"mask","datatype":"5a281aee2c214c9ba83ce620"}],"outputs":[{"datatype_tags":["debiased"],"output_on_root":false,"archive":true,"_id":"5d9e9b8a2b4f67d8c4e670b3","id":"dwi","datatype":"58c33c5fe13a50849b25879b","datatype_tags_pass":null,"files":null,"desc":"The debiased DWI"}],"github_branch":"v1.1","github":"brainlife/app-dwi-debias","name":"DWI Debias","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a41f462f3d3800f12f25e"}],"desc":"Performs mrtrix's dwibiascorrect on dwi data","__v":2091,"create_date":"2021-08-10T22:45:55.245Z","doi":"10.25663/brainlife.app.557","_canedit":true},{"_id":"5d9e9b8a2b4f67c7b8e670b1","stats":{"stars":0,"serviceinfo":{"_id":"5d9fca22f8e42548a397d340","counts":{"_id":"5e5c3e1987cac76c55ab1432","failed":3,"finished":77,"removed":81,"requested":84,"running":79,"running_sync":0,"stop_requested":1},"success_rate":96.25,"users":2,"readme_status":"too short","runtime_mean":1234820.974025974,"runtime_std":1892409.1523325774,"service":"brainlife/app-dwi-debias","__v":0},"success_rate":77.1356783919598,"users":4,"runtime_mean":76426.87,"runtime_std":81864.22165606353,"requested":406,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a373062f3d3800f11d57e"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a373062f3d3800f11d57f"}],"examples":0,"groups":7},"projects":[],"admins":["16"],"tags":[],"removed":false,"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"type":{"id":"type","type":"enum","placeholder":"","advanced":false,"desc":"The debiasing algorithm to use","default":"","_order":2,"pid":0.6211324895123942,"options":[{"desc":"fsl's debiasing algorithm","label":"fsl","value":"fsl"},{"desc":"ant's debiasing algorithm","label":"ants","value":"ants"}]}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d9e9b8a2b4f675258e670b2","id":"dwi","datatype":"58c33c5fe13a50849b25879b","desc":"The path to the DWI datatype"}],"outputs":[{"datatype_tags":["debiased"],"output_on_root":false,"archive":true,"_id":"5d9e9b8a2b4f67d8c4e670b3","id":"dwi","datatype":"58c33c5fe13a50849b25879b","datatype_tags_pass":null,"files":null,"desc":"The debiased DWI"}],"github_branch":"v1.0.0","github":"brainlife/app-dwi-debias","name":"DWI Debias - Deprecated","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a373062f3d3800f11d580"}],"create_date":"2019-10-10T02:46:34.488Z","desc":"Performs mrtrix's dwibiascorrect on dwi data","doi":"10.25663/brainlife.app.234","__v":6769,"deprecated_by":"611301a3a5a04c0a6df90472","_canedit":true},{"_id":"5b1efecd73279e0028adfc1f","projects":[],"admins":["41","285","87","1"],"tags":["diffusion-mri","dipy"],"removed":false,"name":"DWI Info","desc":"Brainlife wrapper app for dipy_info workflows.","citation":null,"references":[],"avatar":"https://raw.githubusercontent.com/brain-life/brainlife.github.io/master/images/app-logos/dipy_info.png","github":"dipy/bl_apps_dipy_info","github_branch":"1.1.1","config":{"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvecs_tol":{"type":"number","placeholder":"","desc":"Threshold used to check that norm(bvec) = 1 +/- bvecs_tol b-vectors are unit vectors (default 0.01).","default":0.01,"id":"bvecs_tol","pid":0.12403225175768351,"_order":2},"b0_threshold":{"type":"number","placeholder":"","desc":"","default":50,"id":"b0_threshold","pid":0.3975695673525643,"_order":3},"bshell_thr":{"type":"number","placeholder":"","desc":"The threshold for distinguishing b-values in different shells (default 100).","default":100,"id":"bshell_thr","pid":0.9557671019185205,"_order":4}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5b1efecd73279e0028adfc20","id":"dwi","datatype":"58c33c5fe13a50849b25879b"}],"outputs":[{"datatype_tags":["info_output"],"output_on_root":false,"archive":false,"_id":"5b1efecd73279e0028adfc21","id":"output","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null}],"desc_override":"Provides useful information about different files used in medical imaging. ","user_id":"61","contributors":[{"name":"Javier Guaje","email":null,"_id":"634a333662f3d3800f117e2e"},{"name":"Serge Koudoro","email":null,"_id":"634a333662f3d3800f117e2f"}],"create_date":"2018-06-11T22:59:25.625Z","stats":{"stars":0,"requested":7,"users":2,"success_rate":100,"serviceinfo":{"_id":"5d729e1f78356a109788b2dd","counts":{"_id":"5e5c3dac87cac721ceab13bd","failed":1372,"finished":2816,"removed":5103,"requested":5301,"running":3198,"running_sync":0,"stop_requested":12},"success_rate":67.23973256924546,"users":20,"readme_status":"ok","runtime_mean":5885857.53,"runtime_std":14501545.618587041,"service":"brain-life/app-dipy-workflows","__v":0},"gitinfo":{"desc":"Brainlife wrapper app for Dipy workflows.","tags":["dipy"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Serge Koudoro","email":null},{"name":"Aman Arya","email":"aman.arya524@gmail.com"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":64824,"runtime_std":38893.390218219174,"resources":[],"examples":0,"groups":2},"doi":"10.25663/bl.app.63","__v":12817,"_canedit":true},{"_id":"5bbf8a5cfcb14c00272a4971","projects":[],"admins":["1"],"tags":["pipeline"],"removed":false,"config":{"t1":{"type":"input","file_id":"t1","input_id":"t1"},"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5bbf8a5cfcb14c00272a4973","id":"t1","datatype":"58c33bcee13a50849b25879a"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5bbf8a5cfcb14c00272a4972","id":"dwi","datatype":"58c33c5fe13a50849b25879b"}],"outputs":[{"datatype_tags":["t1_aligned","preprocessed"],"output_on_root":true,"archive":true,"_id":"5bbf8a5cfcb14c00272a4974","id":"odwi","datatype":"58c33c5fe13a50849b25879b","datatype_tags_pass":"dwi","files":null},{"datatype_tags":["warp"],"output_on_root":true,"archive":true,"_id":"5bbfae1df680600027503504","id":"output","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":{"output":"output"}}],"name":"DWI preproc and nonlinear registration to T1","github":"brainlife/app-dwi2t1-nonlinear","user_id":"121","references":[],"contributors":[{"name":null,"email":null,"_id":"634a33fc62f3d3800f118472"}],"create_date":"2018-10-11T17:37:32.183Z","desc":"App for running mrtrix3 dwipreproc and then performing nonlinear registration of dwi to T1 (by running ANTs affine+nonlinear registration of CSF masks of mean b0 and T1). Bvectors are rotated with the affine transform. App is recommended for bringing dwi to T1 space if no phase encoding contrast between b=0 images was collected (so mrtrix3 dwipreproc cannot perform inhomogeneity field estimation).","stats":{"stars":0,"requested":64,"users":6,"success_rate":0,"serviceinfo":{"_id":"5d729e1f78356a109788b291","counts":{"_id":"5e5c3dc087cac77c0cab13d4","failed":31,"finished":100,"removed":122,"requested":142,"running":130,"running_sync":0,"stop_requested":1},"success_rate":76.33587786259542,"users":9,"readme_status":"no README.md","runtime_mean":3905717.72,"runtime_std":1050945.3065085365,"service":"kathrynalpert/app-dwi2t1-nonlinear","__v":0},"gitinfo":{"desc":"App for running mrtrix3 dwipreproc and then performing nonlinear registration of dwi to T1 (by running ANTs affine+nonlinear registration of CSF masks of mean b0 and T1). Bvectors are rotated with the affine transform. App is recommended for bringing dwi to T1 space if no phase encoding contrast between b=0 images was collected (so mrtrix3 dwipreproc cannot perform inhomogeneity field estimation).","tags":["pipeline"],"stats":{"stars":0},"contributors":[{"name":null,"email":null}]},"resources":[],"examples":0,"groups":6},"doi":"10.25663/brainlife.app.111","__v":10041,"github_branch":"v0","_canedit":true},{"_id":"59fa4fec98d5fa005dc3d55b","name":"Decimate and/or Convert 3D surfaces","desc":"This application will reduce the number of vertices and faces on 3D surfaces by the percent reduction chosen. It can also be used to convert between filetypes.","avatar":"https://raw.githubusercontent.com/kitchell/app-decimatemesh/master/decimatemeshs-01.png","github":"kitchell/app-decimatemesh","github_branch":"v2.0","config":{"surfdir":{"type":"input","file_id":"surfaces","input_id":"0"},"reduction":{"type":"number","placeholder":"percentage to reduce the surface","desc":"percentage you would like to reduce the surface by","default":0.1,"min":0,"max":1,"id":"reduction","pid":0.7357007599201522,"_order":2},"infiletype":{"type":"enum","placeholder":"","desc":"input data filetype","default":"vtk","options":[{"desc":"use .stl format","label":".stl","value":"stl"},{"desc":"use .ply format","label":".ply","value":"ply"},{"desc":"use .vtk format","label":".vtk","value":"vtk"}],"id":"infiletype","pid":0.7233431103626444,"_order":3,"readonly":false},"outfiletype":{"id":"outfiletype","type":"enum","placeholder":"","advanced":false,"desc":"output data filetype","default":"vtk","_order":4,"pid":0.7976561585560542,"options":[{"desc":"use .stl format","label":".stl","value":"stl"},{"desc":"use .ply format","label":".ply","value":"ply"},{"desc":"use .vtk format","label":".vtk","value":"vtk"},{"desc":"use .glb format","label":".glb","value":"glb"}],"readonly":false}},"user_id":"43","create_date":"2017-11-01T22:51:24.123Z","removed":false,"_rate":0,"outputs":[{"datatype_tags":["reduced"],"output_on_root":true,"archive":true,"_id":"59fa4fec98d5fa005dc3d55c","id":"0","datatype":"59307a08436ee50ffd973278","files":null}],"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"59fa4fec98d5fa005dc3d55d","id":"0","datatype":"59307a08436ee50ffd973278"}],"tags":["postprocessing"],"admins":["43"],"projects":[],"__v":14276,"contributors":[{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a316962f3d3800f1166cb"},{"name":null,"email":null,"_id":"634a316962f3d3800f1166cc"}],"references":[],"stats":{"stars":0,"requested":3566,"users":3,"success_rate":95.58907228229937,"serviceinfo":{"_id":"5d729e1f78356a109788b2bd","counts":{"_id":"5e5c688b87cac77bf7ab1bb3","failed":154,"finished":3355,"removed":3381,"requested":3559,"running":3504,"running_sync":0,"stop_requested":7},"success_rate":95.61128526645768,"users":2,"readme_status":"ok","runtime_mean":163652.24,"runtime_std":265994.92539693776,"service":"kitchell/app-decimatemesh","__v":0},"gitinfo":{"desc":"This application will reduce the number of vertices and faces on 3D surfaces by the percent reduction chosen.","tags":["postprocessing"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null}]},"runtime_mean":180971.35,"runtime_std":291314.2735854312,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a316862f3d3800f1166ca"}],"examples":1,"groups":3},"doi":"10.25663/brainlife.app.148","_canedit":true},{"_id":"607f1682932bd76bbbfdffda","stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a402a62f3d3800f12d5fb"}],"success_rate":95.20348837209302,"users":4,"runtime_mean":175744.11,"runtime_std":444924.67103798356,"requested":850,"examples":2,"groups":3},"projects":[],"admins":["126"],"removed":false,"config":{"mag_inv1":{"type":"input","file_id":"mag_inv1","input_id":"neuro/anat/mp2rage"},"mag_inv2":{"type":"input","file_id":"mag_inv2","input_id":"neuro/anat/mp2rage"},"unit1":{"type":"input","file_id":"unit1","input_id":"neuro/anat/mp2rage"},"json_inv1":{"type":"input","file_id":"mag_inv1_json","input_id":"neuro/anat/mp2rage"},"json_inv2":{"type":"input","file_id":"mag_inv2_json","input_id":"neuro/anat/mp2rage"},"json_unit1":{"type":"input","file_id":"unit1_json","input_id":"neuro/anat/mp2rage"},"mask":{"type":"input","file_id":"mask","input_id":"neuro/mask"},"reg_param":{"id":"reg_param","type":"string","placeholder":"Enter the regularization parameter that is best for your dataset.","advanced":false,"desc":"The regularization parameter that is best for your dataset depends on several factors. If you are not sure what regularization parameter to select, leave this field blank and we will select the best parameter for your dataset.","default":"16","_order":2,"pid":0.833474359129875,"optional":true},"slicesperslab":{"id":"slicesperslab","type":"number","placeholder":"Enter the Slices Per Slab parameter.","advanced":false,"desc":"Slices Per Slab should be available in the MRI sequence protocol. It is not always available in the image's header information. If you are sure that Slices Per Slab is available in the image's header information, you can leave this blank and we will get the value from there. Otherwise, please look up this value in the MRI sequence protocol and enter it here.","default":null,"_order":3,"pid":0.614283268644495,"optional":true}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"607f1682932bd701b5fdffdb","id":"neuro/anat/mp2rage","datatype":"60634f0de4a8347569337f97"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"608b1f1489df43043d75ba4c","id":"neuro/mask","datatype":"5a281aee2c214c9ba83ce620"}],"outputs":[{"datatype_tags":["denoised"],"output_on_root":false,"archive":true,"_id":"607f1682932bd7713ffdffdc","id":"output","datatype":"60634f0de4a8347569337f97","datatype_tags_pass":null,"files":null,"desc":"UNI image with noise removed, for use in estimating T1 and R1 values"}],"github_branch":"main","github":"svincibo/app-mp2rage-denoiseUNI","name":"Denoise MP2RAGE UNI ","avatar":"https://paperswithcode.com/media/thumbnails/task/task-0000000813-398eae41.jpg","user_id":"126","contributors":[{"name":"Sophia Vinci-Booher","email":null,"_id":"634a402a62f3d3800f12d5fc"}],"create_date":"2021-04-20T17:59:30.897Z","__v":2774,"doi":"10.25663/brainlife.app.506","desc":"Removes noise in an MP2RAGE_UNI.nii.gz image given a user-provided regularization parameter (see app-mp2rage-selectregparam).","tags":[],"_canedit":true},{"_id":"5dc307567f55b883d2bd4daf","stats":{"stars":0,"serviceinfo":{"_id":"5dc363c45b365f708c60d52f","counts":{"_id":"5e5c3e2387cac7a867ab143c","failed":42,"finished":334,"removed":283,"requested":432,"running":372,"running_sync":0,"stop_requested":3},"success_rate":88.82978723404256,"users":3,"readme_status":"too short","runtime_mean":64581.13,"runtime_std":59343.03596255503,"service":"brainlife/app-denoise-tensorflow","__v":0},"success_rate":86.74418604651163,"users":3,"runtime_mean":50443.32,"runtime_std":7793.5852479844,"requested":973,"resources":[],"examples":0,"groups":5},"projects":["5dc304237f55b8913bbd4cfd"],"admins":["16","126"],"tags":[],"removed":false,"config":{"dwi_noise":{"type":"input","file_id":"dwi","input_id":"dwi_noise"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi_noise"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi_noise"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"iters":{"id":"iters","type":"number","placeholder":"","advanced":false,"desc":"Number of iterations used in the training of the models.\n\nOptions: 100, 1000, 1500, 2000, 5000, 10000, 20000","default":20000,"_order":2,"pid":0.019480461804948668},"batch_size":{"id":"batch_size","type":"number","placeholder":"","advanced":false,"desc":"batch size used in the training of the models.\n\nOptions: 2000, 40000","default":40000,"_order":3,"pid":0.26003294623085416},"trainingSubj":{"id":"trainingSubj","type":"enum","placeholder":"","advanced":false,"desc":"The training subject used to generate the model.\n\nOptions:\nfull_encode/subj1\nfull_encode/subj2\nAP/subj3","default":"","_order":4,"pid":0.38939847320320364,"options":[{"desc":"Subject 1 with full AP and PA phase encoding","label":"full_encode/subj1","value":"full_encode/subj1"},{"desc":"Subject 2 with full AP and PA phase encoding","label":"full_encode/subj2","value":"full_encode/subj2"},{"desc":"Subject 3 with only AP phase encoding","label":"AP/subj1","value":"AP/subj3"},{"desc":"Trained on only sub-001 AP-PAb0, contains 1000, 1500, and 2000 iterations","label":"sub-001","value":"sub-001"},{"desc":"Trained on only subs 001 and 002 AP-PAb0, contains 1000 iterations","label":"sub-001002","value":"sub-001002"},{"desc":"Trained on only subs 001, 002, and 003 AP-PAb0, contains 1000 iterations","label":"sub-001002003","value":"sub-001002003"},{"desc":"Trained on only subs 001, 002, 003, and 004 AP-PAb0, contains 1000 iterations","label":"sub-001002003004","value":"sub-001002003004"},{"desc":"Trained on only sub-002 AP-PAb0, contains only 1000 iterations","label":"sub-002","value":"sub-002"},{"desc":"Trained on only sub-003 AP-PAb0, contains only 1000 iterations","label":"sub-003","value":"sub-003"},{"desc":"Trained on only sub-004 AP-PAb0, contains only 1000 iterations","label":"sub-004","value":"sub-004"},{"desc":"Trained on only subs 002, 003, and 004 AP-PAb0, contains 1000 iterations","label":"sub-002003004","value":"sub-002003004"},{"desc":"Trained on only subs 003, 004, and 001 AP-PAb0, contains 1000 iterations","label":"sub-003004001","value":"sub-003004001"},{"desc":"Trained on only subs 004, 001, and 002 AP-PAb0, contains 1000 iterations","label":"sub-004001002","value":"sub-004001002"},{"desc":"Trained on only subs 001 and 003 AP-PAb0, contains 1000 iterations","label":"sub-001003","value":"sub-001003"},{"desc":"Trained on only subs 001 and 004 AP-PAb0, contains 1000 iterations","label":"sub-001004","value":"sub-001004"},{"desc":"Trained on only subs 002 and 003 AP-PAb0, contains 1000 iterations","label":"sub-002003","value":"sub-002003"},{"desc":"Trained on only subs 002 and 004 AP-PAb0, contains 1000 iterations","label":"sub-002004","value":"sub-002004"},{"desc":"Trained on only subs 003 and 004 AP-PAb0, contains 1000 iterations","label":"sub-003004","value":"sub-003004"},{"desc":"Trained on two subjects from Brie Larson's stroke study","label":"bs2sub","value":"bs2sub"},{"desc":"Trained on only sub-001 AP-PAb0 after removing the b0 volumes, contains only 100 iterations","label":"sub-001-nob0","value":"sub-001-nob0"},{"desc":"Trained on only sub-002 AP-PAb0 after removing the b0 volumes, contains only 100 iterations","label":"sub-002-nob0","value":"sub-002-nob0"},{"desc":"Trained on only sub-003 AP-PAb0 after removing the b0 volumes, contains only 100 iterations","label":"sub-003-nob0","value":"sub-003-nob0"},{"desc":"Trained on only sub-004 AP-PAb0 after removing the b0 volumes, contains only 100 iterations","label":"sub-004-nob0","value":"sub-004-nob0"},{"desc":"Trained on only sub-001 AP-PAb0 on only b0 volumes, contains only 100 iterations","label":"sub-001-b0only","value":"sub-001-b0only"},{"desc":"Trained on only sub-002 AP-PAb0 on only b0 volumes, contains only 100 iterations","label":"sub-002-b0only","value":"sub-002-b0only"},{"desc":"Trained on only sub-003 AP-PAb0 on only b0 volumes, contains only 100 iterations","label":"sub-003-b0only","value":"sub-003-b0only"},{"desc":"Trained on only sub-004 AP-PAb0 on only b0 volumes, contains only 100 iterations","label":"sub-004-b0only","value":"sub-004-b0only"},{"desc":"Trained on only subs 001 and 002 AP (note: raw data, no topup), contains 100 iterations","label":"sub-001002-raw","value":"sub-001002-raw"},{"desc":"","label":"bs2sub/AP","value":"bs2sub/AP"},{"desc":"","label":"bs2sub/PA","value":"bs2sub/PA"},{"desc":"Trained on child subs K005 and K006, 1000 iterations","label":"sub-K005K006","value":"sub-K005K006"},{"desc":"Trained on sub-004-tilt, 1000 iterations","label":"sub-004-tilt","value":"sub-004-tilt"},{"desc":"Trained on sub-002-tilt and sub-004-tilt, 1000 iterations","label":"sub-002tilt004tilt","value":"sub-002tilt004tilt"},{"desc":"Trained on 3_038 and 3_039 from acute concussion study. randomized voxels","label":"full_encode_2_subj","value":"full_encode_2_subj"},{"desc":"Trained on 3_038 and 3_039 from acute concussion study. non_randomized voxels","label":"full_encode_2_subj/non_random","value":"full_encode_2_subj/non_random"},{"desc":"Trained on 3_046 and 3_047 from acute concussion study","label":"ac-two-sub","value":"ac-two-sub"},{"desc":"models trained on data from Hu at 100, 1k, 10k, and 20k iter","label":"data-hu-train-1subject","value":"data-hu-train-1subject"},{"desc":"models trained on APPAfull for sub-002 at 100, 1k, 10k, and 20k","label":"sub-002-full","value":"sub-002-full"},{"desc":"models trained on APPAfull for sub-003 at 100, 1k, 10k, and 20k","label":"sub-003-full","value":"sub-003-full"},{"desc":"","label":"sub-002-trn-batch40k","value":"sub-002-trn-batch40k"},{"desc":"","label":"sub-003-trn-batch40k","value":"sub-003-trn-batch40k"},{"desc":"","label":"sub-004-trn-batch40k","value":"sub-004-trn-batch40k"},{"desc":"","label":"sub-002003-trn-batch40k","value":"sub-002003-trn-batch40k"},{"desc":"","label":"sub-002004-trn-batch40k","value":"sub-002004-trn-batch40k"},{"desc":"","label":"sub-003004-trn-batch40k","value":"sub-003004-trn-batch40k"},{"desc":"","label":"sub-002-tilt-trn-batch40k","value":"sub-002-tilt-trn-batch40k"},{"desc":"","label":"sub-004-tilt-trn-batch40k","value":"sub-004-tilt-trn-batch40k"},{"desc":"","label":"sub-002004-tilt-trn-batch40k","value":"sub-002004-tilt-trn-batch40k"},{"desc":"","label":"sub-002004-tilt-trn-batch40k-iter40k","value":"sub-002004-tilt-trn-batch40k-iter40k"}]}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5dc307567f55b880f1bd4db0","id":"dwi_noise","datatype":"58c33c5fe13a50849b25879b"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5dc308d37f55b87236bd4e94","id":"mask","datatype":"5a281aee2c214c9ba83ce620","desc":"Brain mask of dwi"}],"outputs":[{"datatype_tags":["denoised"],"output_on_root":false,"archive":true,"_id":"5dc307567f55b800c5bd4db1","id":"dwi","datatype":"58c33c5fe13a50849b25879b","datatype_tags_pass":"dwi_noise","files":null}],"github_branch":"master","github":"brainlife/app-denoise-tensorflow","name":"Denoise SOS-reconstructed DWI data","user_id":"16","contributors":[{"name":"Sophia Vinci-Booher","email":null,"_id":"634a378862f3d3800f11e2c6"},{"name":"Brad Caron","email":null,"_id":"634a378862f3d3800f11e2c7"}],"create_date":"2019-11-06T17:48:06.851Z","desc":null,"doi":"10.25663/brainlife.app.247","__v":6592,"_canedit":true},{"_id":"5ea7bf49f1745d5b2ff80319","stats":{"success_rate":36.36363636363637,"users":7,"runtime_mean":4343217.916666667,"runtime_std":3827611.97031982,"requested":253,"resources":[{"resource_id":"5e309300e017b06c99948e0a","name":"stampede2(knl) @ TACC/UT","_id":"634a39f362f3d3800f123515"}],"examples":1,"groups":7},"projects":[],"admins":["285","87"],"tags":["diffusion-denoising","diffusion-mri","diffusion-preprocessing","dipy"],"removed":false,"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"sigma":{"id":"sigma","type":"number","placeholder":"","advanced":false,"desc":"Standard deviation of the noise estimated from the data. A value of 0 means sigma value estimation with the Manjon2013 algorithm","default":0,"_order":2,"pid":0.6832791650370467},"patch_radius":{"id":"patch_radius","type":"number","placeholder":"","advanced":false,"desc":"The radius of the local patch to be taken around each voxel (in voxels). Default: 2 (denoise in blocks of 5x5x5 voxels).","default":2,"_order":3,"pid":0.1524567867666018},"pca_method":{"id":"pca_method","type":"string","placeholder":"","advanced":false,"desc":"Use either eigenvalue decomposition ('eig') or singular value decomposition ('svd') for principal component analysis. The default method is 'eig' which is faster. However, occasionally 'svd' might be more accurate.","default":"eig","_order":4,"pid":0.5942182624476013},"tau_factor":{"id":"tau_factor","type":"number","placeholder":"","advanced":false,"desc":"Thresholding of PCA eigenvalues","default":2.3,"_order":5,"pid":0.6609085901450968}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ea7bf49f1745d7874f8031a","id":"dwi","datatype":"58c33c5fe13a50849b25879b"}],"outputs":[{"datatype_tags":["denoised"],"output_on_root":false,"archive":true,"_id":"5ea7bf49f1745dadddf8031b","id":"output","datatype":"58c33c5fe13a50849b25879b","datatype_tags_pass":"dwi","files":null}],"github_branch":"1.1.1","github":"dipy/bl_apps_dipy_denoise_lpca","name":"Denoising using LPCA","user_id":"87","contributors":[{"name":"Serge Koudoro","email":null,"_id":"634a39f462f3d3800f123516"},{"name":"Franco Pestilli","email":null,"_id":"634a39f462f3d3800f123517"}],"create_date":"2020-04-28T05:29:45.634Z","desc":"Brainlife wrapper app for dipy_denoise_lpca workflows.","__v":4994,"doi":"10.25663/brainlife.app.454","_canedit":true},{"_id":"5ea7c33bf1745d4582f803e1","stats":{"success_rate":88.73239436619718,"users":7,"runtime_mean":4141947.1746031744,"runtime_std":7171631.511355943,"requested":74,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a39fc62f3d3800f123543"}],"examples":2,"groups":7},"projects":[],"admins":["285","87"],"tags":["diffusion-denoising","diffusion-mri","diffusion-preprocessing","dipy"],"removed":false,"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"patch_radius":{"id":"patch_radius","type":"number","placeholder":"","advanced":false,"desc":"The radius of the local patch to be taken around each voxel (in\n            voxels)","default":2,"_order":2,"pid":0.4294719703988872},"pca_method":{"id":"pca_method","type":"string","placeholder":"","advanced":false,"desc":"Use either eigenvalue decomposition ('eig') or singular value decomposition ('svd') for principal component analysis. The default method is 'eig' which is faster. However, occasionally 'svd' might be more accurate.","default":"eig","_order":3,"pid":0.722210541347001}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ea7c33bf1745d732ff803e2","id":"dwi","datatype":"58c33c5fe13a50849b25879b"}],"outputs":[{"datatype_tags":["denoised"],"output_on_root":false,"archive":true,"_id":"5ea7c33bf1745dc679f803e3","id":"output","datatype":"58c33c5fe13a50849b25879b","datatype_tags_pass":"dwi","files":null}],"github_branch":"1.1.1","github":"dipy/bl_apps_dipy_denoise_mppca","name":"Denoising using Marcenko-Pastur PCA (MP-PCA)","user_id":"87","contributors":[{"name":"Serge Koudoro","email":null,"_id":"634a39fd62f3d3800f123544"},{"name":"Javier Guaje","email":null,"_id":"634a39fd62f3d3800f123545"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a39fd62f3d3800f123546"}],"create_date":"2020-04-28T05:46:35.790Z","desc":"Brainlife wrapper app for dipy_denoise_mppca workflows.","doi":"10.25663/brainlife.app.326","__v":4996,"_canedit":true},{"_id":"5a271f814e57c077cf5e3476","name":"Denoising using Non Local Means (NLM)","desc":"Brainlife wrapper app for dipy_denoise_nlmeans workflows.","github":"dipy/bl_apps_dipy_denoise_nlmeans","github_branch":"1.1.1","config":{"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"sigma":{"id":"sigma","type":"number","placeholder":"","advanced":false,"desc":"Sigma parameter to pass to the nlmeans algorithm","default":0,"_order":3,"pid":0.5828053852311417},"patch_radius":{"id":"patch_radius","type":"number","placeholder":"","advanced":false,"desc":"patch size is ``2 x patch_radius + 1``","default":1,"_order":5,"pid":0.840640145004127},"block_radius":{"id":"block_radius","type":"number","placeholder":"","advanced":false,"desc":"block size is ``2 x block_radius + 1``","default":5,"_order":6,"pid":0.2220423298415597},"rician":{"id":"rician","type":"boolean","placeholder":"","advanced":false,"desc":"If True the noise is estimated as Rician, otherwise Gaussian noise is assumed.","default":true,"_order":7,"pid":0.7087186996597277}},"user_id":"87","create_date":"2017-12-05T22:36:49.530Z","removed":false,"_rate":0,"outputs":[{"datatype_tags":["denoised"],"output_on_root":false,"archive":true,"_id":"5a271f814e57c077cf5e3477","id":"output","datatype":"58c33c5fe13a50849b25879b","files":null,"datatype_tags_pass":"dwi"}],"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5a271f814e57c077cf5e3479","id":"dwi","datatype":"58c33c5fe13a50849b25879b"}],"contributors":[{"name":"Serge Koudoro","email":null,"_id":"634a319f62f3d3800f116858"},{"name":"Javier Guaje","email":null,"_id":"634a319f62f3d3800f116859"}],"tags":["diffusion-mri","diffusion-preprocessing","dipy"],"admins":["285","87"],"projects":[],"__v":14269,"references":[],"stats":{"stars":0,"requested":286,"users":8,"success_rate":93.04347826086956,"serviceinfo":{"_id":"5d729e1f78356a109788b2dd","counts":{"_id":"5e5c689187cac7fc01ab1bba","failed":1372,"finished":2816,"removed":5103,"requested":5301,"running":3198,"running_sync":0,"stop_requested":12},"success_rate":67.23973256924546,"users":20,"readme_status":"ok","runtime_mean":5885857.53,"runtime_std":14501545.618587041,"service":"brain-life/app-dipy-workflows","__v":0},"gitinfo":{"desc":"Brainlife wrapper app for Dipy workflows.","tags":["dipy"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Serge Koudoro","email":null},{"name":"Aman Arya","email":"aman.arya524@gmail.com"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":6520005.64,"runtime_std":2053521.3976843606,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a319e62f3d3800f116857"}],"examples":0,"groups":7},"doi":"10.25663/bl.app.72","desc_override":"","_canedit":true},{"_id":"5e46ff4e1eafff7a00f9899e","stats":{"stars":0,"serviceinfo":{"_id":"5e4739df0f910e3b89b16b18","counts":{"_id":"5e5c3e3987cac74e98ab1453","failed":10,"finished":5,"removed":0,"requested":15,"running":14,"running_sync":0,"stop_requested":0},"success_rate":33.33333333333333,"users":1,"readme_status":"no README.md","service":"davhunt/app-darts","__v":0,"runtime_mean":1282854.8,"runtime_std":274717.04116009985},"success_rate":6.0606060606060606,"users":6,"runtime_mean":1277702,"runtime_std":369348.62696428155,"requested":314,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a384162f3d3800f11ee2f"}],"examples":0,"groups":7},"projects":[],"admins":["283"],"tags":[],"removed":false,"config":{"t1":{"type":"input","file_id":"t1","input_id":"t1"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e4af68e1eafff7cf4f9dfd8","id":"t1","datatype":"58c33bcee13a50849b25879a"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5e46ff4e1eafff96e5f989a0","id":"parc","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags_pass":null,"files":null}],"github_branch":"master","github":"davhunt/app-darts","name":"DenseUnet-based Automatic Rapid Tool for brain Segmentation (DARTS)","user_id":"283","contributors":[{"name":"David Hunt","email":"davhunt@iu.edu","_id":"634a384162f3d3800f11ee30"}],"create_date":"2020-02-14T20:13:02.448Z","desc":null,"doi":"10.25663/brainlife.app.276","__v":5585,"_canedit":true},{"_id":"605e0a9616c60638446315ee","stats":{"resources":[],"success_rate":94.73299195318215,"users":2,"runtime_mean":209953.17,"runtime_std":104105.50366278001,"requested":2892,"examples":2,"groups":5},"projects":[],"admins":["1342","1348","670"],"tags":[],"removed":false,"config":{"fif":{"type":"input","file_id":"fif","input_id":"fif01"},"calibration":{"type":"input","file_id":"calibration","input_id":"fif01"},"crosstalk":{"type":"input","file_id":"crosstalk","input_id":"fif01"},"channels":{"type":"input","file_id":"channels","input_id":"fif01"},"headshape":{"type":"input","file_id":"headshape","input_id":"fif01"},"headshape_override":{"type":"input","file_id":"headshape","input_id":"opt01"},"destination_override":{"type":"input","file_id":"destination","input_id":"opt01"},"param_origin":{"id":"param_origin","type":"string","placeholder":"","advanced":true,"desc":"Origin of internal and external multipolar moment space in meters. Can be \"auto\" or three numbers separated by a comma (example: 0, 0, 0).","default":"auto","_order":2,"pid":0.09752950839340757,"readonly":false},"param_duration":{"id":"param_duration","type":"number","placeholder":"","advanced":false,"desc":"Duration of the segments into which to slice the data for processing, in seconds. It can be a float.","default":5,"_order":3,"pid":0.7989023690439038},"param_min_count":{"id":"param_min_count","type":"number","placeholder":"","advanced":false,"desc":"Minimum number of times a channel must show up as bad in a chunk. This value must be an integer.","default":5,"_order":4,"pid":0.516154313244248},"param_limit":{"id":"param_limit","type":"number","placeholder":"","advanced":false,"desc":"Detection limit for noisy segments. This value can be a float.","default":7,"_order":5,"pid":0.011434152571896283},"param_h_freq":{"id":"param_h_freq","type":"number","placeholder":"","advanced":false,"desc":"Optional the cutoff frequency (in Hz) of the low-pass filter that will be applied before processing the data. This value can be a float.","default":40,"_order":6,"pid":0.4300581402554653,"optional":true},"param_return_scores":{"id":"param_return_scores","type":"boolean","placeholder":"","advanced":true,"desc":"If True, return a dictionary with scoring information for each evaluated segment of the data. Default in MNE is False but here it must be True.","default":true,"_order":7,"pid":0.049519199874057396,"readonly":true},"param_int_order":{"id":"param_int_order","type":"number","placeholder":"","advanced":true,"desc":"Order of internal component of spherical expansion. This value is an integer.","default":8,"_order":8,"pid":0.3983793765646674},"param_ext_order":{"id":"param_ext_order","type":"number","placeholder":"","advanced":true,"desc":"order of external component of spherical expansion. This value is an integer.","default":3,"_order":9,"pid":0.6917760318478162},"param_coord_frame":{"id":"param_coord_frame","type":"enum","placeholder":"","advanced":true,"desc":"The coordinate frame that the origin is specified in, either 'meg' or 'head'. ","default":"head","_order":10,"pid":0.7399841012264265,"options":[{"desc":"","label":"","value":"meg"},{"desc":"","label":"","value":"head"}]},"param_regularize":{"id":"param_regularize","type":"enum","placeholder":"","advanced":true,"desc":"The destination location for the head, either in or None.","default":"in","_order":11,"pid":0.13166404097406736,"options":[{"desc":"","label":"","value":"in"}]},"param_ignore_ref":{"id":"param_ignore_ref","type":"boolean","placeholder":"","advanced":true,"desc":"If True, do not include reference channels in compensation.","default":false,"_order":12,"pid":0.09378823615388265},"param_bad_condition":{"id":"param_bad_condition","type":"enum","placeholder":"","advanced":true,"desc":"How to deal with ill-conditioned SSS matrices, either 'error', 'warning', 'info' , 'ignore'.","default":"error","_order":14,"pid":0.7539840473921622,"options":[{"desc":"","label":"","value":"error"},{"desc":"","label":"","value":"warning"},{"desc":"","label":"","value":"info"},{"desc":"","label":"","value":"ignore"}]},"param_mag_scale":{"id":"param_mag_scale","type":"string","placeholder":"","advanced":true,"desc":"The magenetometer scale-factor used to bring the magnetometers to approximately the same order of magnitude as the gradiometers, as they have different units (T vs T/m). This value can be a float or \"auto\".","default":"100","_order":14,"pid":0.41655930821797604,"optional":false},"param_skip_by_annotation":{"id":"param_skip_by_annotation","type":"string","placeholder":"","advanced":true,"desc":"Any annotation segment that begins with the given string will not be included in filtering, and segments on either side of the given excluded annotated segment will be filtered separately. Can be an empty list [].","default":"[edge, bad acq skip]","_order":17,"pid":0.24341117954003388},"param_extended_proj":{"id":"param_extended_proj","type":"string","placeholder":"","advanced":true,"desc":"The empty-room projection vectors used to extend the external SSS basis (i.e., use eSSS).","default":"[]","_order":18,"pid":0.5859348444081233,"readonly":true}},"inputs":[{"id":"fif01","desc":"MEG data in fif format in which we want to find bad channels.","datatype":"6000737faacf9ee51fa691cb","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"605e0a9616c6065ec76315ef"},{"id":"opt01","desc":"Optional head positions stored in a headshape.pos file and destination file in fif format, containing the mean transformation matrix. The headshape.pos file is obtained with app-head-pos and the destination.fif file is obtained with app-mean-transformation-matrix. This headshape.pos will override the headshape.pos linked to the neuro/meg/fif datatype.","datatype":"608195ce89df435fd26893c1","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"609aa84d408e3c952bd56add"}],"outputs":[{"id":"out_dir_bad_channels","desc":"channels.tsv file (in a BIDS compliant structure) in which bad channels detected by the App are marked as bad.","datatype":"608195ce89df435fd26893c1","datatype_tags":[],"datatype_tags_pass":"fif01","output_on_root":false,"files":null,"archive":true,"_id":"605e0a9616c60614976315f0"},{"id":"out_dir_report","desc":"HTML report with plots of the signals in time and frequency domains.","datatype":"5e56dc330f7fa604cc3cc291","datatype_tags":[],"datatype_tags_pass":"fif01","output_on_root":false,"files":null,"archive":true,"_id":"605e0a9616c606445e6315f1"}],"github_branch":"master","github":"guiomar/app-bad-channels","name":"Detect bad channels in MEG signals using Maxwell Filtering","user_id":"1342","contributors":[{"name":null,"email":null,"_id":"634a3fad62f3d3800f12d169"},{"name":"Julia Guiomar Niso Galán","email":null,"_id":"634a3fad62f3d3800f12d16a"}],"create_date":"2021-03-26T16:23:50.381Z","desc":"Detect bad channels in MEG signals.","__v":3069,"doi":"10.25663/brainlife.app.494","desc_override":"","_canedit":true},{"_id":"60dc97c6cdfdb5ebe50156fb","stats":{"resources":[{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"634a413b62f3d3800f12e1d4"}],"success_rate":4.761904761904762,"users":5,"runtime_mean":10021615,"runtime_std":0,"requested":27,"examples":1,"groups":6},"projects":[],"admins":["1693"],"tags":[],"removed":false,"config":{"fdt":{"type":"input","file_id":"fdt","input_id":"input"},"set":{"type":"input","file_id":"set","input_id":"input"},"channels":{"type":"input","file_id":"channels","input_id":"input"},"electrodes":{"type":"input","file_id":"electrodes","input_id":"input"},"coordsystem":{"type":"input","file_id":"coordsystem","input_id":"input"},"events":{"type":"input","file_id":"events","input_id":"input"},"events_json":{"type":"input","file_id":"events_json","input_id":"input"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"60dc97c6cdfdb580b90156fc","id":"input","datatype":"60007410aacf9e4edda691d4","desc":"The pipeline will run on the dataset provided and output quality measures"}],"outputs":[],"github_branch":"dataqual-pipeline","github":"dungscout96/app-test-brainlife","name":"EEG Data Quality","user_id":"1693","contributors":[{"name":"Dung Truong","email":null,"_id":"634a413b62f3d3800f12e1d5"},{"name":"Arnaud Delorme","email":"arnodelorme@gmail.com","_id":"634a413b62f3d3800f12e1d6"},{"name":"Ramon Martinez-Cancino","email":null,"_id":"634a413b62f3d3800f12e1d7"}],"create_date":"2021-06-30T16:11:50.423Z","desc":null,"__v":2406,"doi":"10.25663/brainlife.app.538","_canedit":true},{"_id":"628b67eed0697cf1eaeb5031","user_id":"1348","projects":[],"admins":["1348"],"name":"EEG bdf to mne/raw","github":"guiomar/app_bdf2mne","github_branch":"main","desc":null,"desc_override":"Converts EEG bdf data to MNE Raw (fif)","tags":[],"contributors":[{"name":"Julia Guiomar Niso Galán","email":null,"_id":"634a44a562f3d3800f130e4f"}],"config":{"bdf":{"type":"input","file_id":"bdf","input_id":"bdf1"},"channels":{"type":"input","file_id":"channels","input_id":"bdf1"},"electrodes":{"type":"input","file_id":"electrodes","input_id":"bdf1"},"coordsystem":{"type":"input","file_id":"coordsystem","input_id":"bdf1"},"events":{"type":"input","file_id":"events","input_id":"bdf1"},"events_json":{"type":"input","file_id":"events_json","input_id":"bdf1"}},"inputs":[{"id":"bdf1","datatype":"60007567aacf9e1615a691dd","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"628b5c89d0697cf1eaeaffae"}],"outputs":[{"id":"out_dir","desc":"MNE Raw data in FIF format","datatype":"61893398e8be76b34cb9826e","datatype_tags":["eeg"],"datatype_tags_pass":"bdf1","output_on_root":false,"files":null,"archive":true,"_id":"628b5c89d0697cf1eaeaffaf"}],"stats":{"resources":[],"examples":1,"success_rate":50,"users":1,"groups":1,"runtime_mean":21669,"runtime_std":0,"requested":2},"removed":false,"__v":315,"create_date":"2022-05-23T10:54:38.164Z","doi":"10.25663/brainlife.app.635","_canedit":true},{"_id":"628b6938d0697cf1eaeb6077","user_id":"1348","projects":[],"admins":["1348"],"name":"EEG brainvision to mne/raw","github":"guiomar/app_brainvision2mne","github_branch":"main","desc":null,"desc_override":"Converts EEG brainvision data to MNE Raw (fif)","tags":[],"contributors":[{"name":"Julia Guiomar Niso Galán","email":null,"_id":"634a44ae62f3d3800f130e51"}],"config":{"eeg":{"type":"input","file_id":"eeg","input_id":"bv1"},"vhdr":{"type":"input","file_id":"vhdr","input_id":"bv1"},"vmrk":{"type":"input","file_id":"vmrk","input_id":"bv1"},"channels":{"type":"input","file_id":"channels","input_id":"bv1"},"electrodes":{"type":"input","file_id":"electrodes","input_id":"bv1"},"coordsystem":{"type":"input","file_id":"coordsystem","input_id":"bv1"},"events":{"type":"input","file_id":"events","input_id":"bv1"},"events_json":{"type":"input","file_id":"events_json","input_id":"bv1"}},"inputs":[{"id":"bv1","datatype":"6000753eaacf9e6591a691d9","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"628b5c89d0697cf1eaeaffae"}],"outputs":[{"id":"out_dir","desc":"MNE Raw data in FIF format","datatype":"61893398e8be76b34cb9826e","datatype_tags":["eeg"],"datatype_tags_pass":"bv1","output_on_root":false,"files":null,"archive":true,"_id":"628b5c89d0697cf1eaeaffaf"}],"stats":{"resources":[],"examples":0,"success_rate":0,"users":1,"groups":1,"requested":2},"removed":false,"__v":313,"create_date":"2022-05-23T11:00:09.003Z","doi":"10.25663/brainlife.app.636","_canedit":true},{"_id":"628b6b3ed0697cf1eaeb70e9","user_id":"1348","projects":[],"admins":["1348"],"name":"EEG edf to mne/raw","github":"guiomar/app_edf2mne","github_branch":"main","desc":null,"desc_override":"Converts EEG edf data to MNE Raw (fif)","tags":[],"contributors":[{"name":"Julia Guiomar Niso Galán","email":null,"_id":"634a44b762f3d3800f130e56"}],"config":{"edf":{"type":"input","file_id":"edf","input_id":"edf1"},"channels":{"type":"input","file_id":"channels","input_id":"edf1"},"electrodes":{"type":"input","file_id":"electrodes","input_id":"edf1"},"coordsystem":{"type":"input","file_id":"coordsystem","input_id":"edf1"},"events":{"type":"input","file_id":"events","input_id":"edf1"},"events_json":{"type":"input","file_id":"events_json","input_id":"edf1"}},"inputs":[{"id":"edf1","datatype":"600074f6aacf9e7acda691d7","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"628b5c89d0697cf1eaeaffae"}],"outputs":[{"id":"out_dir","desc":"MNE Raw data in FIF format","datatype":"61893398e8be76b34cb9826e","datatype_tags":["eeg"],"datatype_tags_pass":"edf1","output_on_root":false,"files":null,"archive":true,"_id":"628b5c89d0697cf1eaeaffaf"}],"stats":{"resources":[],"examples":1,"success_rate":50,"users":2,"groups":2,"runtime_mean":10933,"runtime_std":0,"requested":2},"removed":false,"__v":314,"create_date":"2022-05-23T11:08:46.291Z","doi":"10.25663/brainlife.app.637","_canedit":true},{"_id":"628b6340d0697cf1eaeb2a74","user_id":"1348","projects":[],"admins":["1348"],"name":"EEG eeglab to mne/raw","github":"guiomar/app_eeglab2mne","github_branch":"main","desc":null,"desc_override":"Converts EEG eeglab data to MNE Raw (fif)","tags":[],"contributors":[{"name":"Julia Guiomar Niso Galán","email":null,"_id":"634a449c62f3d3800f130e4a"}],"config":{"fdt":{"type":"input","file_id":"fdt","input_id":"eeglab1"},"set":{"type":"input","file_id":"set","input_id":"eeglab1"},"channels":{"type":"input","file_id":"channels","input_id":"eeglab1"},"electrodes":{"type":"input","file_id":"electrodes","input_id":"eeglab1"},"coordsystem":{"type":"input","file_id":"coordsystem","input_id":"eeglab1"},"events":{"type":"input","file_id":"events","input_id":"eeglab1"},"events_json":{"type":"input","file_id":"events_json","input_id":"eeglab1"}},"inputs":[{"id":"eeglab1","datatype":"60007410aacf9e4edda691d4","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"628b5c89d0697cf1eaeaffae"}],"outputs":[{"id":"out_dir","desc":"MNE Raw data in FIF format","datatype":"61893398e8be76b34cb9826e","datatype_tags":["eeg"],"datatype_tags_pass":"eeglab1","output_on_root":false,"files":null,"archive":true,"_id":"628b5c89d0697cf1eaeaffaf"}],"stats":{"resources":[],"examples":0,"success_rate":0,"users":1,"groups":1,"requested":6},"removed":false,"__v":315,"create_date":"2022-05-23T10:34:40.073Z","doi":"10.25663/brainlife.app.633","_canedit":true},{"_id":"5e6a8ebd8740673152a3d18f","projects":[],"admins":["1","16"],"tags":["diffusion-preprocessing"],"removed":false,"name":"EPI T1 Registration","desc":"Align a Diffusion weighted MRI image to a T1 image using FSL's epi_reg. INPUTS: DWI data and a T1 image. OUTPUTS aligned DWI filed","github":"brainlife/app-epi-t1-registration","github_branch":"v1.0","config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"t1":{"type":"input","file_id":"t1","input_id":"t1"},"resolution":{"default":"","desc":"The isotropic resolution to reslice the data. If you want to leave the DWI in the native DWI space, leave this empty","placeholder":"","type":"string","optional":true,"id":"resolution","pid":0.4416452322141393,"_order":2},"maskt1":{"id":"maskt1","type":"boolean","placeholder":"","advanced":true,"desc":"","default":true,"_order":3,"pid":0.4264016450095578}},"user_id":"16","outputs":[{"id":"dwi","desc":"The T1-aligned DWI","datatype":"58c33c5fe13a50849b25879b","datatype_tags":["t1_aligned"],"datatype_tags_pass":"dwi","output_on_root":false,"files":null,"archive":true,"_id":"5bc5aed744f3980027a7aac7"},{"id":"transform","datatype":"5bbfb28071454db2a890fbce","datatype_tags":["affine","dwi-to-t1"],"datatype_tags_pass":"dwi","output_on_root":false,"files":null,"archive":true,"_id":"60ef3204ddc2df6444660316"}],"inputs":[{"id":"dwi","desc":"The path to the DWI datatype","datatype":"58c33c5fe13a50849b25879b","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5a101f5e765df1005977d1a9"},{"id":"t1","desc":"The path to the anat/t1w datatype","datatype":"58c33bcee13a50849b25879a","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5a101f5e765df1005977d1a8"}],"contributors":[{"name":"Brad Caron","email":null,"_id":"634a388f62f3d3800f11f614"},{"name":"Franco Pestilli","email":null,"_id":"634a388f62f3d3800f11f615"}],"__v":5382,"stats":{"requested":3745,"users":13,"success_rate":77.41935483870968,"gitinfo":{"desc":"Preprocess a Diffusion weighted MRI image and aligne it to a T1 image. This App will also: (A) Fit a diffusion tensor model to the DWI data, (B) ... and (C) Create a dt6.mat compatibe with AFQ and VISTA SOFT. INPUTS: DWI data and a T1 image. OUTPUTS dt6.mat, and dt6.json, in addition to processed DWI files.","tags":["diffusion-preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"runtime_mean":3395599.32,"runtime_std":6817982.997886841,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a388e62f3d3800f11f611"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a388e62f3d3800f11f612"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"634a388e62f3d3800f11f613"}],"examples":5,"groups":34},"create_date":"2020-03-12T19:34:21.503Z","doi":"10.25663/brainlife.app.286","_canedit":true},{"_id":"6197cbd45464ddc6f09a3a98","user_id":"1542","projects":[],"admins":[],"name":"ERGMs for Brain Networks","github":"dichio/bl-ERGM","github_branch":"main","tags":["network"],"config":{"network":{"type":"input","file_id":"network","input_id":"bnet"},"my_formula":{"id":"my_formula","type":"string","placeholder":"Specify the desired ERGM formula.","advanced":false,"desc":"The ERGM formula includes information about the model to estimate and control parameters for the fitting procedure. Besides the \"ergm\" package documentation, see e.g. http://statnet.org/Workshops/ergm_tutorial.html for a tutorial.","default":"gwesp(0.75,fixed=TRUE) + gwdegree(0.75,fixed=TRUE), constraints = ~edges, control=control.ergm(init=c(1.0,1.0), MCMLE.maxit=40)","_order":2,"pid":0.05660218256470728,"readonly":false,"optional":false},"nsim_gof":{"id":"nsim_gof","type":"number","placeholder":"","advanced":false,"desc":"Number of networks to simulate from the estimated ERGM for the GoF assessment.","default":100,"_order":3,"pid":0.5772828326369939,"min":100,"max":""},"unfiltered":{"id":"unfiltered","type":"boolean","placeholder":"","advanced":false,"desc":"TRUE if input network data is unfiltered (connectivity matrix), FALSE if source data are already binarized.","default":true,"_order":4,"pid":0.029338763002770496}},"inputs":[{"id":"bnet","desc":"Source information for ERGM analysis: connectivity matrix, nodal attributes, edge covariates.","datatype":"5ed0352de3f453b13b267dae","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"6197cbd45464ddc6f09a3a99"}],"outputs":[{"id":"ergmout","desc":"1. Result of the ERGM fit 2. Log of the computation 3. MCMC-diagnostic 4. GOF model assessment","datatype":"59c3eae633fc1cf9ead71679","datatype_tags":["ergm_fit_results"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"6197cbd45464ddc6f09a3a9a"}],"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a433662f3d3800f12ff5f"}],"examples":1,"success_rate":41.30434782608695,"users":3,"runtime_mean":32430.21052631579,"runtime_std":47486.663986715874,"requested":56,"groups":4},"removed":false,"contributors":[{"name":"Vito Dichio","email":null,"_id":"634a433762f3d3800f12ff60"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a433762f3d3800f12ff61"}],"create_date":"2021-11-19T16:07:48.059Z","desc":"Source code for ERGM app in BrainLife.io","__v":1318,"doi":"10.25663/brainlife.app.594","_canedit":true},{"_id":"6048fde5ebfe45fb1b3acdda","stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3f7f62f3d3800f12cf82"},{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"634a3f7f62f3d3800f12cf83"}],"success_rate":22.58064516129032,"users":1,"runtime_mean":368615.14285714284,"runtime_std":503110.14175183454,"requested":38,"examples":2,"groups":1},"projects":[],"admins":["1447"],"tags":[],"removed":false,"config":{"tsv":{"type":"input","file_id":"tsv","input_id":"ts"},"json":{"type":"input","file_id":"json","input_id":"ts"}},"inputs":[{"id":"ts","datatype":"604a4553ebfe4559de3af944","datatype_tags":["time series"],"optional":false,"multi":false,"advanced":false,"_id":"6048fde5ebfe457baa3acddb"}],"outputs":[{"id":"output","datatype":"5ed834cdda66453cde8edfb7","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"6048fde5ebfe45370b3acddc"}],"github_branch":"main","github":"FarnazZE/bnbl-brainlife-create-edge-time-series","name":"Edge time series","user_id":"1447","contributors":[{"name":"Farnaz Zamani Esfahlani","email":null,"_id":"634a3f8062f3d3800f12cf84"},{"name":"Filipi Nascimento Silva","email":"filipinascimento@gmail.com","_id":"634a3f8062f3d3800f12cf85"}],"create_date":"2021-03-10T17:12:05.446Z","desc":null,"__v":3102,"doi":"10.25663/brainlife.app.489","_canedit":true},{"_id":"62a3246aab3e66978060531f","user_id":"1348","projects":[],"admins":["1348"],"name":"Emptyroom projs","github":"guiomar/app-emptyroom-proj","github_branch":"main","desc":null,"desc_override":"","tags":[],"contributors":[{"name":"Julia Guiomar Niso Galán","email":null,"_id":"634a450062f3d3800f130ef8"}],"config":{"fif":{"type":"input","file_id":"fif","input_id":"raw01"},"channels":{"type":"input","file_id":"channels","input_id":"raw01"},"headshape":{"type":"input","file_id":"headshape","input_id":"raw01"},"coordsystem":{"type":"input","file_id":"coordsystem","input_id":"raw01"},"calibration":{"type":"input","file_id":"calibration","input_id":"raw01"},"crosstalk":{"type":"input","file_id":"crosstalk","input_id":"raw01"},"destination":{"type":"input","file_id":"destination","input_id":"raw01"},"events":{"type":"input","file_id":"events","input_id":"raw01"},"events_json":{"type":"input","file_id":"events_json","input_id":"raw01"},"start":{"id":"start","type":"number","placeholder":"","advanced":true,"desc":"Time (in sec) to start computing SSP.\n","default":0,"_order":2,"pid":0.8979670895157723,"optional":true,"min":0,"max":"","readonly":null},"stop":{"id":"stop","type":"number","placeholder":"","advanced":true,"desc":"Time (in sec) to stop computing SSP. \nDefault (empty): None ->  will go to the end of the file.","default":null,"_order":3,"pid":0.07976426659688607,"optional":true},"duration":{"id":"duration","type":"number","placeholder":"","advanced":true,"desc":"Duration (in sec) to chunk data into for SSP \nIf duration is None, data will not be chunked.","default":1,"_order":4,"pid":0.27875030583241023,"optional":true,"min":0},"n_grad":{"id":"n_grad","type":"number","placeholder":"","advanced":false,"desc":"Number of vectors for gradiometers.\n","default":2,"_order":5,"pid":0.6066175885622838,"min":0},"n_mag":{"id":"n_mag","type":"number","placeholder":"","advanced":false,"desc":"Number of vectors for magnetometers.\n","default":2,"_order":6,"pid":0.3209279503437563,"min":0},"n_eeg":{"id":"n_eeg","type":"number","placeholder":"","advanced":false,"desc":"    Number of vectors for EEG channels.\n","default":0,"_order":7,"pid":0.8061336504428124,"min":0},"reject":{"id":"reject","type":"string","placeholder":"","advanced":true,"desc":"    Epoch rejection configuration (see Epochs).\n","default":"","_order":8,"pid":0.24758464811199232,"optional":true},"flat":{"id":"flat","type":"string","placeholder":"","advanced":true,"desc":"    Epoch flat configuration (see Epochs).\n","default":"","_order":9,"pid":0.7681194237991456,"optional":true},"n_jobs":{"id":"n_jobs","type":"number","placeholder":"","advanced":true,"desc":"The number of jobs to run in parallel. If -1, it is set to the number of CPU cores. Requires the joblib package. None (default) is a marker for ‘unset’ that will be interpreted as n_jobs=1 (sequential execution) unless the call is performed under a joblib.parallel_backend() context manager that sets another value for n_jobs. Number of jobs to use to compute covariance.","default":1,"_order":10,"pid":0.9536344598690114,"optional":true},"meg":{"id":"meg","type":"enum","placeholder":"","advanced":true,"desc":"Can be ‘separate’ (default) or ‘combined’ to compute projectors for magnetometers and gradiometers separately or jointly. If ‘combined’, n_mag == n_grad is required and the number of projectors computed for MEG will be n_mag.","default":"separate","_order":12,"pid":0.43052582933188954,"options":[{"desc":"compute projectors for magnetometers and gradiometers separately ","label":"Separate (grad, mag)","value":"separate"},{"desc":"compute projectors for magnetometers and gradiometers  jointly","label":"Combined (grad, mag)","value":"combined"}],"optional":true}},"inputs":[{"id":"raw01","datatype":"6000737faacf9ee51fa691cb","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"616e7fd8fc8eb9dccfff8eab"}],"outputs":[{"id":"out_dir","desc":"Emptyroom projector","datatype":"6283e7e9d0697cf1eade9bda","datatype_tags":["proj","emptyroom"],"datatype_tags_pass":"raw01","output_on_root":false,"files":null,"archive":true,"_id":"616e7fd8fc8eb9b2b3ff8eac"},{"id":"out_figs","datatype":"59c3eae633fc1cf9ead71679","datatype_tags":["proj_image"],"datatype_tags_pass":"raw01","output_on_root":false,"files":null,"archive":true,"_id":"62a3266aab3e669780605472"}],"stats":{"success_rate":92.3076923076923,"groups":3,"users":2,"runtime_mean":18286.416666666668,"runtime_std":20583.971508831546,"requested":14,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a44ff62f3d3800f130ef6"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a44ff62f3d3800f130ef7"}],"examples":1},"removed":false,"__v":287,"create_date":"2022-06-10T11:00:58.376Z","doi":"10.25663/brainlife.app.645","_canedit":true},{"_id":"5baa3fc9d0be8b002776b8de","projects":[],"admins":["1","43","19","16"],"tags":["tracking"],"removed":false,"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"stepsize":{"type":"number","placeholder":"","desc":"set the step size of the tracking","default":0.2,"id":"stepsize","pid":0.5805425640656903,"_order":2},"minlength":{"type":"number","placeholder":"","desc":"set the minimum length of the streamlines generated","default":10,"id":"minlength","pid":0.13435092165127394,"_order":3},"maxlength":{"type":"number","placeholder":"","desc":"set the maximum length of the streamlines generated","default":200,"id":"maxlength","pid":0.08702786301287535,"_order":4},"num_or_fibers":{"type":"number","placeholder":"","desc":"Number of streamlines to track the optic radiation (probabilistic tracking only)","default":0,"readonly":false,"max":25,"min":0,"id":"num_or_fibers","pid":0.7417364761964518,"_order":5},"num_mt_fibers":{"type":"number","placeholder":"","desc":"(temporarily disabled as this tracking gets stuck) Number of streamlines to track the cortico-spinal tract","default":0,"readonly":true,"id":"num_mt_fibers","pid":0.30579255797279625,"_order":6},"num_vz_fibers":{"type":"number","placeholder":"","desc":"Number of streamlines to track the visual-associative tracts","default":0,"readonly":false,"min":0,"max":2000,"id":"num_vz_fibers","pid":0.22390172396987773,"_order":7},"detr_curvs":{"type":"string","placeholder":"","desc":"Range of curvature parameters used for deterministic tracking","default":"0.25 0.5 1 2 4","id":"detr_curvs","pid":0.5164574325012994,"_order":8},"prob_curvs":{"type":"string","placeholder":"","desc":"Range of curvature parameters used for probabilistic tracking","default":"0.25 0.5 1 2 4","id":"prob_curvs","pid":0.41871045080159264,"_order":9},"num_cc_fibers":{"type":"number","placeholder":"","desc":"Number of streamlines to track seeding the corpus callosum","default":2500,"min":0,"max":5000,"id":"num_cc_fibers","pid":0.3994151993073469,"_order":10},"num_fibers":{"type":"integer","default":12500,"placeholder":"","desc":"Total number of streamlines requested per individual streamline output file (.tck)","min":0,"max":25000,"id":"num_fibers","pid":0.04389083678847827,"_order":11},"max_lmax":{"placeholder":"Auto Calculate","type":"integer","desc":"Maximum number of parameters for the constrained spherical deconvolution. Leave it empty to auto calculate from the number of available directions in bvecs/bvals.","optional":true,"id":"max_lmax","pid":0.41506553033462734,"_order":12},"do_tensor":{"type":"boolean","default":true,"id":"do_tensor","pid":0.9894625675816087,"_order":13},"do_probabilistic":{"type":"boolean","default":true,"id":"do_probabilistic","pid":0.6045901839587526,"_order":14},"do_deterministic":{"type":"boolean","default":true,"id":"do_deterministic","pid":0.3457784946363398,"_order":15}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5baa3fc9d0be8b002776b8e0","id":"dwi","datatype":"58c33c5fe13a50849b25879b"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5baa3fc9d0be8b002776b8df","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e"}],"outputs":[{"datatype_tags":["ensemble"],"output_on_root":true,"archive":true,"_id":"5baa3fc9d0be8b002776b8e2","id":"output","datatype":"5907d922436ee50ffde9c549","datatype_tags_pass":null,"files":null},{"datatype_tags":["white_matter","anat"],"output_on_root":true,"archive":true,"_id":"5baa3fc9d0be8b002776b8e1","id":"mask_dwi","datatype":"5a281aee2c214c9ba83ce620","datatype_tags_pass":null,"files":{"mask":"wm_anat.nii.gz"},"desc":"(despite the odd output directory name \"mask_dwi\") A brain mask created from freesurfer aparc+aseg converted to .nii.gz using input t1 as output template volume (--temp). It uses all white matter segments (--match 2 41 16 17 28 60 51 53 12 52 13 18 54 50 11 251 252 253 254 255 10 49 46 7) see FreeSurferColorLUT"}],"name":"Ensemble Tracking (dwi)","github":"brainlife/app-ensembletracking","user_id":"1","references":[],"contributors":[{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a33d762f3d3800f118328"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a33d762f3d3800f118329"},{"name":"Brent McPherson","email":"bcmcpher@gmail.com","_id":"634a33d762f3d3800f11832a"},{"name":"Franco Pestilli","email":null,"_id":"634a33d762f3d3800f11832b"}],"create_date":"2018-09-25T14:01:45.332Z","desc":"This App creates a large set of candidate streamlines using an ensemble of algorithms and parameter values. All outputs will be then combined into a single track.tck output.","stats":{"stars":0,"requested":2011,"users":13,"success_rate":34.61945031712473,"serviceinfo":{"_id":"5d729e1f78356a109788b2cf","counts":{"_id":"5e5c3dbb87cac795c6ab13d0","failed":3486,"finished":8001,"removed":13974,"requested":22462,"running":16310,"running_sync":0,"stop_requested":341},"success_rate":69.6526508226691,"users":61,"readme_status":"ok","runtime_mean":6517627.81,"runtime_std":3750518.3309636554,"service":"brain-life/app-ensembletracking","__v":0},"gitinfo":{"desc":"This service uses MRtrix 0.2.12 to do ensemble tracking using tensor and constrained spherical deconvolution (csd) algorithms. It generates a large set of candidate streamlines using a tensor-based deterministic model, csd-based deterministic model, and csd-based probabilistic model. The csd-based models can be computed at lmax values of 2, 4, 6, 8, 10, and 12. All candidate streamlines are combined into a single track.mat file. If you know the max lmax value for your data input the value for max_lmax, otherwise leave it blank and it will be calculated for you. If you wish to use just deterministic tracking (MRtrix streamtrack parameter SD_STREAM) check do_deterministic. If you wish to use just probabilistic tracking (MRtrix streamtrack parameter SD_PROB) check do_probabilistic If you wish to use the tensor tracking (MRtrix streamtrack parameter DT_STREAM) check do_tensor. By default it will use all three tracking methods. For more information about Ensemble Tractography see Takemura, H., Caiafa, C. F., Wandell, B. A., & Pestilli, F. (2016). Ensemble tractography. PLoS computational biology, 12(2), e1004692.","tags":["brain-connectome","diffusion-mri","mri","tracking","tractography","white-matter"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Brent McPherson","email":null},{"name":"Franco Pestilli","email":null}]},"runtime_mean":1206734.29,"runtime_std":2026412.4706887305,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a33d662f3d3800f118326"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a33d662f3d3800f118327"}],"examples":1,"groups":12},"doi":"10.25663/bl.app.103","__v":10403,"avatar":"https://raw.githubusercontent.com/brain-life/app-ensembletracking/master/ensemble.png","github_branch":"1.5","desc_override":"","_canedit":true},{"_id":"592dbbccb3cd7c00211dc235","name":"Ensemble Tracking with dtiInit","desc":"This App creates a large set of candidate streamlines using an ensemble of algorithms and parameter values. All outputs will be then combined into a single track.tck output.","github":"brainlife/app-ensembletracking","github_branch":"1.5","config":{"dtiinit":{"type":"input","file_id":"output","input_id":"dwi"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"stepsize":{"type":"number","placeholder":"","desc":"set the step size of the tracking","default":0.2,"id":"stepsize","pid":0.7429578200156848,"_order":2},"minlength":{"type":"number","placeholder":"","desc":"set the minimum length of the streamlines generated","default":10,"id":"minlength","pid":0.23203110275545336,"_order":3},"maxlength":{"type":"number","placeholder":"","desc":"set the maximum length of the streamlines generated","default":200,"id":"maxlength","pid":0.8237568548463527,"_order":4},"num_or_fibers":{"type":"number","placeholder":"","desc":"Number of streamlines to track the optic radiation (probabilistic tracking only)","default":0,"readonly":false,"max":25,"min":0,"id":"num_or_fibers","pid":0.9824895942653993,"_order":5},"num_mt_fibers":{"type":"number","placeholder":"","desc":"(temporarily disabled as this tracking gets stuck) Number of streamlines to track the cortico-spinal tract","default":0,"readonly":true,"id":"num_mt_fibers","pid":0.08871343723184899,"_order":6},"num_vz_fibers":{"type":"number","placeholder":"","desc":"Number of streamlines to track the visual-associative tracts","default":0,"readonly":false,"min":0,"max":2000,"id":"num_vz_fibers","pid":0.3860173895443768,"_order":7},"detr_curvs":{"type":"string","placeholder":"","desc":"Range of curvature parameters used for deterministic tracking","default":"0.25 0.5 1 2 4","id":"detr_curvs","pid":0.9664362087196585,"_order":8},"prob_curvs":{"type":"string","placeholder":"","desc":"Range of curvature parameters used for probabilistic tracking","default":"0.25 0.5 1 2 4","id":"prob_curvs","pid":0.823818836069822,"_order":9},"num_cc_fibers":{"type":"number","placeholder":"","desc":"Number of streamlines to track seeding the corpus callosum","default":2500,"min":0,"max":5000,"id":"num_cc_fibers","pid":0.461661616171013,"_order":10},"num_fibers":{"type":"integer","default":12500,"placeholder":"","desc":"Total number of streamlines requested per individual streamline output file (.tck)","min":0,"max":25000,"id":"num_fibers","pid":0.2025901782728814,"_order":11},"max_lmax":{"placeholder":"Auto Calculate","type":"integer","desc":"Maximum number of parameters for the constrained spherical deconvolution. Leave it empty to auto calculate from the number of available directions in bvecs/bvals.","optional":true,"id":"max_lmax","pid":0.06991640668581889,"_order":12},"do_tensor":{"type":"boolean","default":true,"id":"do_tensor","pid":0.4523772382892035,"_order":13},"do_probabilistic":{"type":"boolean","default":true,"id":"do_probabilistic","pid":0.5925924729615908,"_order":14},"do_deterministic":{"type":"boolean","default":true,"id":"do_deterministic","pid":0.08520602512476705,"_order":15}},"user_id":"43","create_date":"2017-05-30T18:37:00.962Z","outputs":[{"datatype_tags":["ensemble"],"output_on_root":true,"archive":true,"_id":"592dbbccb3cd7c00211dc232","id":"output","datatype":"5907d922436ee50ffde9c549","files":null},{"datatype_tags":["white_matter","anat"],"output_on_root":true,"archive":true,"_id":"5b1eaf8573279e0028adfbe2","id":"mask_dwi","datatype":"5a281aee2c214c9ba83ce620","datatype_tags_pass":null,"files":{"mask":"wm_anat.nii.gz"},"desc":"(despite the odd output directory name \"mask_dwi\") A brain mask created from freesurfer aparc+aseg converted to .nii.gz using input t1 as output template volume (--temp). It uses all white matter segments (--match 2 41 16 17 28 60 51 53 12 52 13 18 54 50 11 251 252 253 254 255 10 49 46 7) see FreeSurferColorLUT"}],"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"592dbbccb3cd7c00211dc234","id":"dwi","datatype":"58cb234be13a50849b25882f"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"592dbbccb3cd7c00211dc233","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e"}],"admins":["43","41","19","16"],"__v":14361,"_rate":5,"tags":["tracking"],"removed":false,"contributors":[{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a309962f3d3800f116484"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a309962f3d3800f116485"},{"name":"Brent McPherson","email":"bcmcpher@gmail.com","_id":"634a309962f3d3800f116486"},{"name":"Franco Pestilli","email":null,"_id":"634a309962f3d3800f116487"}],"projects":[],"references":[],"retry":2,"stats":{"stars":0,"requested":2011,"users":13,"success_rate":34.61945031712473,"serviceinfo":{"_id":"5d729e1f78356a109788b2cf","counts":{"_id":"5e5c687887cac7753eab1b9a","failed":3487,"finished":8002,"removed":13974,"requested":22463,"running":16311,"running_sync":0,"stop_requested":341},"success_rate":69.64922969797198,"users":61,"readme_status":"ok","runtime_mean":6502764.34,"runtime_std":3757949.399415393,"service":"brain-life/app-ensembletracking","__v":0},"gitinfo":{"desc":"This service uses MRtrix 0.2.12 to do ensemble tracking using tensor and constrained spherical deconvolution (csd) algorithms. It generates a large set of candidate streamlines using a tensor-based deterministic model, csd-based deterministic model, and csd-based probabilistic model. The csd-based models can be computed at lmax values of 2, 4, 6, 8, 10, and 12. All candidate streamlines are combined into a single track.mat file. If you know the max lmax value for your data input the value for max_lmax, otherwise leave it blank and it will be calculated for you. If you wish to use just deterministic tracking (MRtrix streamtrack parameter SD_STREAM) check do_deterministic. If you wish to use just probabilistic tracking (MRtrix streamtrack parameter SD_PROB) check do_probabilistic If you wish to use the tensor tracking (MRtrix streamtrack parameter DT_STREAM) check do_tensor. By default it will use all three tracking methods. For more information about Ensemble Tractography see Takemura, H., Caiafa, C. F., Wandell, B. A., & Pestilli, F. (2016). Ensemble tractography. PLoS computational biology, 12(2), e1004692.","tags":["brain-connectome","diffusion-mri","mri","tracking","tractography","white-matter"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Brent McPherson","email":null},{"name":"Franco Pestilli","email":null}]},"runtime_mean":1206734.29,"runtime_std":2026412.4706887305,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a309862f3d3800f116482"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a309862f3d3800f116483"}],"examples":2,"groups":12},"doi":"10.25663/bl.app.33","desc_override":"","_canedit":true},{"_id":"616e7fd8fc8eb90a21ff8eaa","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a42e462f3d3800f12fc66"}],"success_rate":99.49945593035908,"users":2,"runtime_mean":24796.16,"runtime_std":10354.143488207994,"requested":4709,"examples":2,"groups":8},"projects":[],"admins":["1348"],"tags":[],"removed":false,"config":{"mne":{"type":"input","file_id":"mne","input_id":"raw01"},"duration":{"id":"duration","type":"number","placeholder":"","advanced":false,"desc":"Duration of each epoch in seconds.","default":4,"_order":2,"pid":0.5820160770934711,"optional":false,"min":1,"max":100,"readonly":null}},"inputs":[{"id":"raw01","datatype":"61893398e8be76b34cb9826e","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"616e7fd8fc8eb9dccfff8eab"}],"outputs":[{"id":"out_dir","desc":"Epoched data (equal length)","datatype":"61797fc39538685e5db952b0","datatype_tags":["epochs","equal"],"datatype_tags_pass":"raw01","output_on_root":false,"files":null,"archive":true,"_id":"616e7fd8fc8eb9b2b3ff8eac"}],"github_branch":"main","github":"guiomar/app-epoch-equal","name":"Epoch - equal length (MNE)","desc_override":"MNE Epoch - equal length","user_id":"1348","contributors":[{"name":"Julia Guiomar Niso Galán","email":null,"_id":"634a42e462f3d3800f12fc67"}],"create_date":"2021-10-19T08:20:40.386Z","desc":null,"__v":1557,"doi":"10.25663/brainlife.app.584","_canedit":true},{"_id":"60799b9f98cade729e9b281c","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a402162f3d3800f12d57b"}],"success_rate":42.62295081967213,"users":1,"runtime_mean":33877.03846153846,"runtime_std":12824.343553392657,"requested":61,"examples":1},"projects":[],"admins":["1342","664","670"],"tags":[],"removed":false,"config":{"fif":{"type":"input","file_id":"fif","input_id":"fif0"},"headshape":{"type":"input","file_id":"headshape","input_id":"fif0"},"calibration":{"type":"input","file_id":"calibration","input_id":"fif0"},"crosstalk":{"type":"input","file_id":"crosstalk","input_id":"fif0"},"destination":{"type":"input","file_id":"destination","input_id":"fif0"},"events":{"type":"input","file_id":"events","input_id":"fif0"},"channels":{"type":"input","file_id":"channels","input_id":"fif0"},"events_override":{"type":"input","file_id":"events","input_id":"Opt file"},"param_event_id":{"id":"param_event_id","type":"number","placeholder":"","advanced":true,"desc":"The id of the event to consider. This value must be an integer or a list of integers (e.g. [0, 2, 4]).","default":null,"_order":2,"pid":0.5002085718349645,"optional":true},"param_tmin":{"id":"param_tmin","type":"number","placeholder":"","advanced":false,"desc":"Start time before event. This value can be a float.","default":-0.2,"_order":3,"pid":0.5779604415044002,"readonly":false,"optional":false},"param_tmax":{"id":"param_tmax","type":"number","placeholder":"","advanced":false,"desc":"End time after event. This value can be a float.","default":0.5,"_order":4,"pid":0.45712547329953757},"param_baseline":{"id":"param_baseline","type":"string","placeholder":"","advanced":false,"desc":"The time interval to consider as “baseline” when applying baseline correction. Can be None or two floats (or None) separated by a coma (e.g. 0, None).","default":"None, 0","_order":5,"pid":0.2635138805613748,"optional":true},"param_picks_by_channel_types_or_names":{"id":"param_picks_by_channel_types_or_names","type":"string","placeholder":"","advanced":false,"desc":"Channels to include. In lists, channel type strings (e.g., [meg, eeg]) will pick channels of those types, channel name strings (e.g., [MEG0111, MEG2623]) will pick the given channels. When you use a list, don't forget to use the square brackets and surround the channel type or name with simple quotes. Can also be the string values “all” to pick all channels, or “data” to pick data channels. \nNone (default) will pick all data channels. \nNote that channels in info['bads'] will be included if their names are explicitly provided.","default":"","_order":6,"pid":0.5726161770970455,"optional":true},"param_picks_by_channel_indices":{"id":"param_picks_by_channel_indices","type":"string","placeholder":"","advanced":true,"desc":"Channels to include. Slices (e.g., 0, 10, 2 or 0, 10 if you don't want a step) and lists of integers (e.g., [10, 12]) are interpreted as channel indices. For slices, enter the start index, the end index and optionaly the step and separate them by a coma. For list, don't forget the square brackets.\nNone (default) will pick all data channels. This parameter must be set to None if param_picks_by_channel_types_or_names is not None. Note that channels in info['bads'] will be included if their indices are explicitly provided.","default":"","_order":7,"pid":0.7767214883134341,"optional":true},"param_preload":{"id":"param_preload","type":"boolean","placeholder":"","advanced":true,"desc":"If True, load all epochs from disk when creating the object or wait before accessing each epoch.","default":false,"_order":8,"pid":0.24362509424075274},"param_proj":{"id":"param_proj","type":"enum","placeholder":"","advanced":true,"desc":"Apply SSP projection vectors. If proj is ‘delayed’ and reject is not None the single epochs will be projected before the rejection decision, but used in unprojected state if they are kept.","default":"delayed","_order":12,"pid":0.3124700446923885,"options":[{"desc":"","label":"","value":"True"},{"desc":"","label":"","value":"False"},{"desc":"","label":"","value":"delayed"}]},"param_decim":{"id":"param_decim","type":"number","placeholder":"","advanced":true,"desc":"Factor by which to subsample the data. This value must be an integer.","default":1,"_order":13,"pid":0.2532271377048765},"param_reject_tmin":{"id":"param_reject_tmin","type":"number","placeholder":"","advanced":true,"desc":"Start of the time window used to reject epochs (with None, the window will start with tmin). This value can be a float.","default":null,"_order":14,"pid":0.6210441076287883,"optional":true},"param_reject_tmax":{"id":"param_reject_tmax","type":"number","placeholder":"","advanced":true,"desc":"End of the time window used to reject epochs (with None, the window will end with tmax). This value can be a float.","default":null,"_order":15,"pid":0.25801080886167926,"optional":true},"param_detrend":{"id":"param_detrend","type":"enum","placeholder":"","advanced":true,"desc":"If 0 or 1, the data channels (MEG and EEG) will be detrended when loaded. 0 is a constant (DC) detrend, 1 is a linear detrend. This value must be an integer or None (default).","default":"","_order":17,"pid":0.32328399038601674,"options":[{"desc":"","label":"","value":"0"},{"desc":"","label":"","value":"1"}],"optional":true},"param_on_missing":{"id":"param_on_missing","type":"enum","placeholder":"","advanced":true,"desc":" What to do if one or several event ids are not found in the recording.","default":"raise","_order":18,"pid":0.5014128166128349,"options":[{"desc":"","label":"","value":"raise"},{"desc":"","label":"","value":"warn"},{"desc":"","label":"","value":"ignore"}]},"param_reject_by_annotation":{"id":"param_reject_by_annotation","type":"boolean","placeholder":"","advanced":true,"desc":"Whether to reject based on annotations. If True, epochs overlapping with segments whose description begins with 'bad' are rejected.","default":true,"_order":20,"pid":0.6502558537348047},"param_event_repeated":{"id":"param_event_repeated","type":"enum","placeholder":"","advanced":true,"desc":"How to handle duplicates in events[:, 0].","default":"error","_order":21,"pid":0.08938612825599934,"options":[{"desc":"","label":"","value":"error"},{"desc":"","label":"","value":"drop"},{"desc":"","label":"","value":"merge"}]},"param_reject":{"id":"param_reject","type":"number","placeholder":"","advanced":true,"desc":"Reject epochs based on peak-to-peak signal amplitude, i.e. the absolute difference between the lowest and the highest signal value.","default":null,"_order":22,"pid":0.6853907256749279,"readonly":true},"param_flat":{"id":"param_flat","type":"number","placeholder":"","advanced":true,"desc":"Rejection parameters based on flatness of signal. Valid keys are 'grad', 'mag', 'eeg', 'eog', 'ecg'. The values are floats that set the minimum acceptable peak-to-peak amplitude.","default":null,"_order":23,"pid":0.3588574986380271,"optional":false,"readonly":true},"param_metadata":{"id":"param_metadata","type":"number","placeholder":"","advanced":true,"desc":"A pandas.DataFrame specifying metadata about each epoch. ","default":null,"_order":24,"pid":0.7342527282241287,"readonly":true}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"60799b9f98cadefb239b281d","id":"fif0","datatype":"6000737faacf9ee51fa691cb","desc":"Data to be epoched."},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"60a79d5522b42a282d704c41","id":"Opt file","datatype":"608195ce89df435fd26893c1","desc":"BIDS compliant events file (computed with app-get-events). This file will override the events.tsv linked to the neuro/meg/fif datatype."}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"60799b9f98cadea1539b281e","id":"out_dir_make_epochs","datatype":"6000737faacf9ee51fa691cb","datatype_tags_pass":null,"files":null,"desc":"The epoched data."}],"github_branch":"master","github":"brainlife/app-make-epochs","name":"Epoch continuous MEG signals","user_id":"1342","contributors":[{"name":null,"email":null,"_id":"634a402262f3d3800f12d57c"}],"create_date":"2021-04-16T14:13:51.508Z","desc":"Create epochs in MEG data","__v":2780,"doi":"10.25663/brainlife.app.508","_canedit":true},{"_id":"6144aa977a38b05b4ba047f6","projects":[],"admins":["16"],"tags":[],"removed":false,"stats":{"success_rate":98.44559585492227,"users":2,"runtime_mean":452247.07,"runtime_std":793552.1110190719,"requested":596,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a429062f3d3800f12f646"}],"examples":0,"groups":4},"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"vols":{"id":"vols","type":"string","placeholder":"","advanced":false,"desc":"This field is intended to specify the volumes of interest. IMPORTANT: this uses 0 indexing. So the first volume is 0, and the remaining volumes are N-1.\n\nIf a selection of non-consecutive volumes are desired, list the volume numbers and include commas between them (ex. 0,2,4,24,99)\n\nIf a series of volumes is desired, use a start:step:end format, where \"start\" is the starting volume, \"step\" is the number of steps before the next volume selected, and \"end\" is the ending volume. For example, if you want every volume from the first volume to the 40th volume, do 0:1:39\n\nYou can also use the keyword \"end\" to specify that you want all volumes from a starting volume to the end of the nifti (ex. 24:1:end would be the 25th volume and then all the remaining volumes). This should also follow the start:step:end format.\n\nThese can be combined. For example, if a user wants the 2nd, 4th, 40th-60th, and 70th to end, you would specify this field as '1,3,39:1:59,69:1:end\"","default":"","_order":2,"pid":0.7380328434680435}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5edc6366c5972b6014b39504","id":"dwi","datatype":"58c33c5fe13a50849b25879b"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5edc6366c5972bd5b2b39505","id":"output","datatype":"58c33c5fe13a50849b25879b","datatype_tags_pass":"dwi","files":null}],"github_branch":"mrtrix3-v1.0","github":"brainlife/app-split-dwi-volumes","name":"Extract DWI volumes of choice","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a429062f3d3800f12f647"}],"desc":null,"__v":1800,"create_date":"2021-09-17T14:47:51.973Z","desc_override":"This app will extract volumes of interest from DWI data","doi":"10.25663/brainlife.app.575","_canedit":true},{"_id":"5edc6366c5972b5814b39503","stats":{"success_rate":98.44559585492227,"users":2,"runtime_mean":452247.07,"runtime_std":793552.1110190719,"requested":596,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3ba662f3d3800f1267d3"}],"examples":3,"groups":4},"projects":[],"admins":["16"],"tags":[],"removed":false,"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"start_volume":{"id":"start_volume","type":"number","placeholder":"","advanced":false,"desc":"start volume you would like to extract","default":1,"_order":2,"pid":0.34077173013565876},"end_volume":{"id":"end_volume","type":"number","placeholder":"","advanced":false,"desc":"end volume you would like to extract","default":50,"_order":3,"pid":0.6380888399114877}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5edc6366c5972b6014b39504","id":"dwi","datatype":"58c33c5fe13a50849b25879b"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5edc6366c5972bd5b2b39505","id":"dwi","datatype":"58c33c5fe13a50849b25879b","datatype_tags_pass":"dwi","files":null}],"github_branch":"v1.0","github":"brainlife/app-split-dwi-volumes","name":"Extract DWI volumes of choice - Deprecated","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3ba762f3d3800f1267d4"}],"create_date":"2020-06-07T03:47:50.820Z","desc":null,"doi":"10.25663/brainlife.app.371","__v":4686,"deprecated_by":"6144aa977a38b05b4ba047f6","_canedit":true},{"_id":"5df431a62dac9b59e0ae1355","stats":{"stars":0,"serviceinfo":{"_id":"5df57c3c0eb5d62908c5722b","counts":{"_id":"5e5c3e3187cac7d65aab1446","failed":0,"finished":15,"removed":10,"requested":20,"running":18,"running_sync":0,"stop_requested":3},"success_rate":100,"users":2,"readme_status":"too short","runtime_mean":386645.13333333336,"runtime_std":579727.6980455413,"service":"brainlife/app-mrtrix3-split-b0s","__v":0},"success_rate":90.66666666666666,"users":4,"runtime_mean":679756.8970588235,"runtime_std":717464.7838774992,"requested":86,"resources":[],"examples":0,"groups":7},"projects":[],"admins":["16","126"],"tags":[],"removed":false,"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5df431a62dac9b9d52ae1356","id":"dwi","datatype":"58c33c5fe13a50849b25879b","desc":"The path to the DWI datatype"}],"outputs":[{"datatype_tags":["non_b0"],"output_on_root":false,"archive":true,"_id":"5df431a62dac9bbad5ae1358","id":"dwi","datatype":"58c33c5fe13a50849b25879b","datatype_tags_pass":null,"files":null,"desc":"The diffusion-weighted DWI volumes"},{"datatype_tags":["b0"],"output_on_root":false,"archive":true,"_id":"5df431a62dac9b617eae1357","id":"nodif","datatype":"58c33c5fe13a50849b25879b","datatype_tags_pass":null,"files":null,"desc":"The b0 DWI volumes"}],"github_branch":"v1.0","github":"brainlife/app-mrtrix3-split-b0s","name":"Extract b0 images from DWI","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a37f162f3d3800f11e608"}],"create_date":"2019-12-14T00:49:42.372Z","desc":null,"doi":"10.25663/brainlife.app.263","__v":6525,"desc_override":"This app will extract the b0 images from a DWI image using MrTrix3’s dwiextract function. Will output both the b0 and the non b0 images.","_canedit":true},{"_id":"60a8125122b42a158170e126","projects":[],"admins":["16"],"tags":[],"removed":false,"stats":{"success_rate":95.79349904397706,"users":7,"runtime_mean":273055.13,"runtime_std":911261.5527963601,"requested":568,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a40c662f3d3800f12db93"}],"examples":1,"groups":20},"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"fa":{"type":"input","file_id":"fa","input_id":"tensor"},"md":{"type":"input","file_id":"md","input_id":"tensor"},"rd":{"type":"input","file_id":"rd","input_id":"tensor"},"ad":{"type":"input","file_id":"ad","input_id":"tensor"},"cl":{"type":"input","file_id":"cl","input_id":"tensor"},"cp":{"type":"input","file_id":"cp","input_id":"tensor"},"cs":{"type":"input","file_id":"cs","input_id":"tensor"},"tensors":{"type":"input","file_id":"tensors","input_id":"tensor"},"kurtosis":{"type":"input","file_id":"kurtosis","input_id":"tensor"},"ga":{"type":"input","file_id":"ga","input_id":"tensor"},"ak":{"type":"input","file_id":"ak","input_id":"tensor"},"mk":{"type":"input","file_id":"mk","input_id":"tensor"},"rk":{"type":"input","file_id":"rk","input_id":"tensor"},"dir":{"type":"input","file_id":"dir","input_id":"noddi"},"ndi":{"type":"input","file_id":"ndi","input_id":"noddi"},"isovf":{"type":"input","file_id":"isovf","input_id":"noddi"},"odi":{"type":"input","file_id":"odi","input_id":"noddi"},"myelin":{"type":"input","file_id":"map","input_id":"myelin"},"rois":{"type":"input","file_id":"rois","input_id":"rois"},"inflate":{"id":"inflate","type":"boolean","placeholder":"","advanced":false,"desc":"whether or not to inflate the data","default":false,"_order":2,"pid":0.6404748164091429},"smooth":{"id":"smooth","type":"number","placeholder":"","advanced":false,"desc":"if you want to inflate, provide a value by which to inflate the voxels (must by odd number)","default":1,"_order":3,"pid":0.9963849653290171,"optional":true}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e5d6cfe82b37f6d9e8f3166","id":"dwi","datatype":"58c33c5fe13a50849b25879b","desc":"The path to the DWI datatype"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e5d6d5282b37f60598f32a4","id":"tensor","datatype":"5a79df48d071a1753f1d661b","desc":"The path to the tensor datatype files"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5e5d6cfe82b37f80ab8f3167","id":"noddi","datatype":"5ed02a620a8ed8e39c482a61","desc":"The path to the NODDI datatype files"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"60a8125122b42ace2170e12b","id":"myelin","datatype":"5fad54c27e8ecba2c3aa0c24"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e5d6cd482b37f5be28f310e","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9","desc":"The path to the top directory containing the ROIs within which diffusion metrics will be extracted"}],"outputs":[{"datatype_tags":["rois","diffusion"],"output_on_root":false,"archive":true,"_id":"60a8125122b42a577070e12d","id":"parc-stats","datatype":"5edd3b77c5972b8c47b3a2c3","datatype_tags_pass":null,"files":null}],"github_branch":"v1.2","github":"brainlife/app-extract-diffusion-metrics-rois","name":"Extract diffusion metrics inside ROIs","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a40c762f3d3800f12db94"}],"desc":null,"__v":2613,"desc_override":"This app will extracts diffusion metrics (tensor, NODDI, meylin) from within ROIs for ROI-level analysis using Connectome Workbench. Will output csv with pertinent info for each roi, including min max average sd for each input metric. Takes in DWI, tensor, NODDI, myelin-map and ROIs inputs and outputs a directory of csvs. Inflation can be performed on the ROIs using SPM.","create_date":"2021-05-21T20:04:33.542Z","doi":"10.25663/brainlife.app.525","_canedit":true},{"_id":"5e5d6cd482b37f75bd8f310c","stats":{"success_rate":95.79349904397706,"users":7,"runtime_mean":273055.13,"runtime_std":911261.5527963601,"requested":568,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a387262f3d3800f11f35a"}],"examples":1,"groups":20},"projects":[],"admins":["16"],"tags":[],"removed":false,"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"fa":{"type":"input","file_id":"fa","input_id":"tensor"},"md":{"type":"input","file_id":"md","input_id":"tensor"},"rd":{"type":"input","file_id":"rd","input_id":"tensor"},"ad":{"type":"input","file_id":"ad","input_id":"tensor"},"cl":{"type":"input","file_id":"cl","input_id":"tensor"},"cp":{"type":"input","file_id":"cp","input_id":"tensor"},"cs":{"type":"input","file_id":"cs","input_id":"tensor"},"tensors":{"type":"input","file_id":"tensors","input_id":"tensor"},"kurtosis":{"type":"input","file_id":"kurtosis","input_id":"tensor"},"ga":{"type":"input","file_id":"ga","input_id":"tensor"},"ak":{"type":"input","file_id":"ak","input_id":"tensor"},"mk":{"type":"input","file_id":"mk","input_id":"tensor"},"rk":{"type":"input","file_id":"rk","input_id":"tensor"},"rois":{"type":"input","file_id":"rois","input_id":"rois"},"inflate":{"id":"inflate","type":"boolean","placeholder":"","advanced":false,"desc":"whether or not to inflate the data","default":false,"_order":2,"pid":0.49497054454187683},"smooth":{"id":"smooth","type":"number","placeholder":"","advanced":false,"desc":"if you want to inflate, provide a value by which to inflate the voxels (must by odd number)","default":1,"_order":3,"pid":0.6603047554008048,"optional":true}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e5d6d1382b37fcb1b8f31b2","id":"dwi","datatype":"58c33c5fe13a50849b25879b","desc":"The path to the DWI datatype"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e5d6cd482b37fd9218f310d","id":"tensor","datatype":"5a79df48d071a1753f1d661b","desc":"The path to the tensor datatype files"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e5d6cd482b37f5be28f310e","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9","desc":"The path to the top directory containing the ROIs within which diffusion metrics will be extracted"}],"outputs":[{"datatype_tags":["tensor_metrics"],"output_on_root":false,"archive":true,"_id":"5e5d6cd482b37f28738f310f","id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null,"desc":"Directory with NIFTI images of each diffusion metrics extracted in each ROI"}],"github_branch":"v1.1","github":"brainlife/app-extract-diffusion-metrics-rois","name":"Extract diffusion metrics inside ROIs (DTI)","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a387362f3d3800f11f35b"}],"create_date":"2020-03-02T20:30:12.944Z","desc":null,"doi":"10.25663/brainlife.app.283","__v":5458,"desc_override":"This app will extracts diffusion metrics (tensor) from within ROIs for ROI-level analysis using FSL. Will output metric x ROI NIFTI images. Takes in DWI, tensor, NODDI, and ROIs inputs and outputs a directory with the metric x ROI NIFTI images. Inflation can be performed on the ROIs using SPM.","deprecated_by":"60a8125122b42a158170e126","_canedit":true},{"_id":"5ed02be70a8ed8f33f482e4f","projects":[],"admins":["16"],"tags":[],"removed":false,"stats":{"success_rate":95.79349904397706,"users":7,"runtime_mean":273055.13,"runtime_std":911261.5527963601,"requested":568,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3b5562f3d3800f125a14"}],"examples":1,"groups":20},"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"dir":{"type":"input","file_id":"dir","input_id":"noddi"},"ndi":{"type":"input","file_id":"ndi","input_id":"noddi"},"isovf":{"type":"input","file_id":"isovf","input_id":"noddi"},"odi":{"type":"input","file_id":"odi","input_id":"noddi"},"rois":{"type":"input","file_id":"rois","input_id":"rois"},"inflate":{"id":"inflate","type":"boolean","placeholder":"","advanced":false,"desc":"whether or not to inflate the data","default":false,"_order":2,"pid":0.25166435270756926},"smooth":{"id":"smooth","type":"number","placeholder":"","advanced":false,"desc":"if you want to inflate, provide a value by which to inflate the voxels (must by odd number)","default":1,"_order":3,"pid":0.06493343305522936,"optional":true}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e5d6cfe82b37f6d9e8f3166","id":"dwi","datatype":"58c33c5fe13a50849b25879b","desc":"The path to the DWI datatype"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e5d6cfe82b37f80ab8f3167","id":"noddi","datatype":"5ed02a620a8ed8e39c482a61","desc":"The path to the NODDI datatype files"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e5d6cd482b37f5be28f310e","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9","desc":"The path to the top directory containing the ROIs within which diffusion metrics will be extracted"}],"outputs":[{"datatype_tags":["noddi_metrics"],"output_on_root":false,"archive":true,"_id":"5e5d6cd482b37f28738f310f","id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null,"desc":"Directory with NIFTI images of each diffusion metrics extracted in each ROI"}],"github_branch":"v1.1","github":"brainlife/app-extract-diffusion-metrics-rois","name":"Extract diffusion metrics inside ROIs (NODDI)","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3b5662f3d3800f125a15"}],"desc":null,"__v":4765,"create_date":"2020-05-28T21:23:51.617Z","doi":"10.25663/brainlife.app.363","desc_override":"This app will extracts diffusion metrics (NODDI) from within ROIs for ROI-level analysis using FSL. Will output metric x ROI NIFTI images. Takes in DWI, tensor, NODDI, and ROIs inputs and outputs a directory with the metric x ROI NIFTI images. Inflation can be performed on the ROIs using SPM.","deprecated_by":"60a8125122b42a158170e126","_canedit":true},{"_id":"5e5d6cfe82b37fe8808f3165","projects":[],"admins":["16"],"tags":[],"removed":false,"stats":{"success_rate":95.79349904397706,"users":7,"runtime_mean":273055.13,"runtime_std":911261.5527963601,"requested":568,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a387b62f3d3800f11f35d"}],"examples":0,"groups":20},"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"dir":{"type":"input","file_id":"dir","input_id":"noddi"},"icvf":{"type":"input","file_id":"icvf","input_id":"noddi"},"isovf":{"type":"input","file_id":"isovf","input_id":"noddi"},"od":{"type":"input","file_id":"od","input_id":"noddi"},"rois":{"type":"input","file_id":"rois","input_id":"rois"},"inflate":{"id":"inflate","type":"boolean","placeholder":"","advanced":false,"desc":"whether or not to inflate the data","default":false,"_order":2,"pid":0.21447179625231416},"smooth":{"id":"smooth","type":"number","placeholder":"","advanced":false,"desc":"if you want to inflate, provide a value by which to inflate the voxels (must by odd number)","default":1,"_order":3,"pid":0.6024584690493795,"optional":true}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e5d6cfe82b37f6d9e8f3166","id":"dwi","datatype":"58c33c5fe13a50849b25879b","desc":"The path to the DWI datatype"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e5d6cfe82b37f80ab8f3167","id":"noddi","datatype":"5bd77a8615a8683a39440dab","desc":"The path to the NODDI (deprecated) datatype file"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e5d6cd482b37f5be28f310e","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9","desc":"The path to the top directory containing the ROIs within which diffusion metrics will be extracted"}],"outputs":[{"datatype_tags":["noddi_metrics"],"output_on_root":false,"archive":true,"_id":"5e5d6cd482b37f28738f310f","id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null,"desc":"Directory with NIFTI images of each diffusion metrics extracted in each ROI"}],"github_branch":"v1.0","github":"brainlife/app-extract-diffusion-metrics-rois","name":"Extract diffusion metrics inside ROIs (NODDI) - Deprecated","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a387c62f3d3800f11f35e"}],"desc":null,"__v":5455,"create_date":"2020-03-02T20:30:54.395Z","doi":"10.25663/brainlife.app.284","deprecated_by":"5ed02be70a8ed8f33f482e4f","_canedit":true},{"_id":"5e5d6d5282b37f5cfa8f32a2","projects":[],"admins":["16"],"tags":[],"removed":false,"stats":{"success_rate":95.79349904397706,"users":7,"runtime_mean":273055.13,"runtime_std":911261.5527963601,"requested":568,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a388462f3d3800f11f360"}],"examples":0,"groups":20},"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"fa":{"type":"input","file_id":"fa","input_id":"tensor"},"md":{"type":"input","file_id":"md","input_id":"tensor"},"rd":{"type":"input","file_id":"rd","input_id":"tensor"},"ad":{"type":"input","file_id":"ad","input_id":"tensor"},"cl":{"type":"input","file_id":"cl","input_id":"tensor"},"cp":{"type":"input","file_id":"cp","input_id":"tensor"},"cs":{"type":"input","file_id":"cs","input_id":"tensor"},"tensors":{"type":"input","file_id":"tensors","input_id":"tensor"},"kurtosis":{"type":"input","file_id":"kurtosis","input_id":"tensor"},"dir":{"type":"input","file_id":"dir","input_id":"noddi"},"icvf":{"type":"input","file_id":"icvf","input_id":"noddi"},"isovf":{"type":"input","file_id":"isovf","input_id":"noddi"},"od":{"type":"input","file_id":"od","input_id":"noddi"},"rois":{"type":"input","file_id":"rois","input_id":"rois"},"inflate":{"id":"inflate","type":"boolean","placeholder":"","advanced":false,"desc":"whether or not to inflate the data","default":false,"_order":2,"pid":0.6971461811330655},"smooth":{"id":"smooth","type":"number","placeholder":"","advanced":false,"desc":"if you want to inflate, provide a value by which to inflate the voxels (must by odd number)","default":1,"_order":3,"pid":0.3884785009438514,"optional":true}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e5d6cfe82b37f6d9e8f3166","id":"dwi","datatype":"58c33c5fe13a50849b25879b","desc":"The path to the DWI datatype"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e5d6d5282b37f60598f32a4","id":"tensor","datatype":"5a79df48d071a1753f1d661b","desc":"The path to the tensor datatype files"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e5d6cfe82b37f80ab8f3167","id":"noddi","datatype":"5bd77a8615a8683a39440dab","desc":"The path to the NODDI (deprecated) datatype files"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e5d6cd482b37f5be28f310e","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9","desc":"The path to the top directory containing the ROIs within which diffusion metrics will be extracted"}],"outputs":[{"datatype_tags":["dti_noddi_metrics"],"output_on_root":false,"archive":true,"_id":"5e5d6cd482b37f28738f310f","id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null,"desc":"Directory with NIFTI images of each diffusion metrics extracted in each ROI"}],"github_branch":"v1.0","github":"brainlife/app-extract-diffusion-metrics-rois","name":"Extract diffusion metrics inside ROIs - Deprecated","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a388562f3d3800f11f361"}],"desc":null,"__v":5454,"create_date":"2020-03-02T20:32:18.900Z","doi":"10.25663/brainlife.app.285","deprecated_by":"5ed02c160a8ed81c69482f0f","_canedit":true},{"_id":"5ed02c160a8ed81c69482f0f","projects":[],"admins":["16"],"tags":[],"removed":false,"stats":{"success_rate":95.79349904397706,"users":7,"runtime_mean":273055.13,"runtime_std":911261.5527963601,"requested":568,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3b5e62f3d3800f125a17"}],"examples":0,"groups":20},"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"fa":{"type":"input","file_id":"fa","input_id":"tensor"},"md":{"type":"input","file_id":"md","input_id":"tensor"},"rd":{"type":"input","file_id":"rd","input_id":"tensor"},"ad":{"type":"input","file_id":"ad","input_id":"tensor"},"cl":{"type":"input","file_id":"cl","input_id":"tensor"},"cp":{"type":"input","file_id":"cp","input_id":"tensor"},"cs":{"type":"input","file_id":"cs","input_id":"tensor"},"tensors":{"type":"input","file_id":"tensors","input_id":"tensor"},"kurtosis":{"type":"input","file_id":"kurtosis","input_id":"tensor"},"ga":{"type":"input","file_id":"ga","input_id":"tensor"},"ak":{"type":"input","file_id":"ak","input_id":"tensor"},"mk":{"type":"input","file_id":"mk","input_id":"tensor"},"rk":{"type":"input","file_id":"rk","input_id":"tensor"},"dir":{"type":"input","file_id":"dir","input_id":"noddi"},"ndi":{"type":"input","file_id":"ndi","input_id":"noddi"},"isovf":{"type":"input","file_id":"isovf","input_id":"noddi"},"odi":{"type":"input","file_id":"odi","input_id":"noddi"},"rois":{"type":"input","file_id":"rois","input_id":"rois"},"inflate":{"id":"inflate","type":"boolean","placeholder":"","advanced":false,"desc":"whether or not to inflate the data","default":false,"_order":2,"pid":0.4022262294366896},"smooth":{"id":"smooth","type":"number","placeholder":"","advanced":false,"desc":"if you want to inflate, provide a value by which to inflate the voxels (must by odd number)","default":1,"_order":3,"pid":0.8432709057545877,"optional":true}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e5d6cfe82b37f6d9e8f3166","id":"dwi","datatype":"58c33c5fe13a50849b25879b","desc":"The path to the DWI datatype"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e5d6d5282b37f60598f32a4","id":"tensor","datatype":"5a79df48d071a1753f1d661b","desc":"The path to the tensor datatype files"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e5d6cfe82b37f80ab8f3167","id":"noddi","datatype":"5ed02a620a8ed8e39c482a61","desc":"The path to the NODDI datatype files"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e5d6cd482b37f5be28f310e","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9","desc":"The path to the top directory containing the ROIs within which diffusion metrics will be extracted"}],"outputs":[{"datatype_tags":["dti_noddi_metrics"],"output_on_root":false,"archive":true,"_id":"5e5d6cd482b37f28738f310f","id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null,"desc":"Directory with NIFTI images of each diffusion metrics extracted in each ROI"}],"github_branch":"v1.1","github":"brainlife/app-extract-diffusion-metrics-rois","name":"Extract diffusion metrics inside ROIs - Deprecated","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3b5e62f3d3800f125a18"}],"desc":null,"__v":4770,"create_date":"2020-05-28T21:24:38.792Z","doi":"10.25663/brainlife.app.364","desc_override":"This app will extracts diffusion metrics (tensor, NODDI) from within ROIs for ROI-level analysis using FSL. Will output metric x ROI NIFTI images. Takes in DWI, tensor, NODDI, and ROIs inputs and outputs a directory with the metric x ROI NIFTI images. Inflation can be performed on the ROIs using SPM.","deprecated_by":"60a8125122b42a158170e126","_canedit":true},{"_id":"5ee27b0fc5972b1866b46f10","projects":[],"admins":["16"],"tags":[],"removed":false,"stats":{"success_rate":75,"users":3,"runtime_mean":32585.666666666668,"runtime_std":22776.019411262852,"requested":6,"resources":[],"examples":1,"groups":3},"config":{"fa":{"type":"input","file_id":"fa","input_id":"tensor"},"md":{"type":"input","file_id":"md","input_id":"tensor"},"rd":{"type":"input","file_id":"rd","input_id":"tensor"},"ad":{"type":"input","file_id":"ad","input_id":"tensor"},"cl":{"type":"input","file_id":"cl","input_id":"tensor"},"cp":{"type":"input","file_id":"cp","input_id":"tensor"},"cs":{"type":"input","file_id":"cs","input_id":"tensor"},"tensors":{"type":"input","file_id":"tensors","input_id":"tensor"},"kurtosis":{"type":"input","file_id":"kurtosis","input_id":"tensor"},"dir":{"type":"input","file_id":"dir","input_id":"noddi"},"ndi":{"type":"input","file_id":"ndi","input_id":"noddi"},"isovf":{"type":"input","file_id":"isovf","input_id":"noddi"},"odi":{"type":"input","file_id":"odi","input_id":"noddi"},"mask":{"type":"input","file_id":"mask","input_id":"mask"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e5d6cd482b37fd9218f310d","id":"tensor","datatype":"5a79df48d071a1753f1d661b"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ee27b0fc5972b9ec8b46f12","id":"noddi","datatype":"5ed02a620a8ed8e39c482a61"},{"datatype_tags":["5tt_masks"],"optional":false,"multi":false,"advanced":false,"_id":"5ee27b0fc5972b3fb8b46f13","id":"mask","datatype":"5a281aee2c214c9ba83ce620"}],"outputs":[{"datatype_tags":["diffusion_metrics"],"output_on_root":false,"archive":true,"_id":"5ee27b0fc5972bff3fb46f14","id":"output","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":"tensor","files":null},{"datatype_tags":["derivatives"],"output_on_root":false,"archive":true,"_id":"5e5d6cd482b37f28738f310f","id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null}],"github_branch":"v1.0","github":"brainlife/app-extract-diffusion-metrics-tissue-types","name":"Extract diffusion metrics inside tissue types","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3bcb62f3d3800f126840"}],"desc":null,"__v":4652,"create_date":"2020-06-11T18:42:23.648Z","doi":"10.25663/brainlife.app.377","deprecated_by":"60a8125122b42a158170e126","_canedit":true},{"_id":"62e96a0af320d93f5ef9accd","user_id":"16","projects":[],"admins":["16"],"name":"Extract individual tractograms for each segmented white matter tract","github":"bacaron/app-extractTCKfromWMC","github_branch":"mrtrix3-v1.0","tags":[],"config":{"track":{"type":"input","file_id":"track","input_id":"track"},"classification":{"type":"input","file_id":"classification","input_id":"wmc"},"tracts":{"type":"input","file_id":"tracts","input_id":"wmc"},"surfaces":{"type":"input","file_id":"surfaces","input_id":"wmc"}},"inputs":[{"id":"track","datatype":"5907d922436ee50ffde9c549","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"62e96a0af320d93f5ef9acce"},{"id":"wmc","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"62e96a0af320d93f5ef9accf"}],"outputs":[{"id":"tcks","datatype":"5dcf0047c4ae28d7f2298f48","datatype_tags":[],"datatype_tags_pass":"wmc","output_on_root":false,"files":null,"archive":true,"_id":"62e96a0af320d93f5ef9acd0"}],"stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a45a462f3d3800f131168"}],"success_rate":45.94594594594595,"users":1,"groups":1,"runtime_mean":296755.23529411765,"runtime_std":61412.15528036718,"requested":37,"examples":1},"removed":false,"contributors":[{"name":"Daniel Bullock","email":"iisdanbul@gmail.com","_id":"634a45a462f3d3800f131169"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a45a462f3d3800f13116a"}],"create_date":"2022-08-02T18:16:42.674Z","desc":"This application takes an input tractography amalgam (i.e. whole brain fiber group (WBFG) or composite) and, using the categories designated in the associated White Matter Classification (WMC) structure input, extracts and outputs a Tck file for each category into the output directory. ","__v":20,"doi":"10.25663/brainlife.app.663","_canedit":true},{"_id":"5dd06111c4ae28135d29adae","stats":{"stars":0,"serviceinfo":{"_id":"5dd092b5b28ec72c245d624b","counts":{"_id":"5e5c3e2b87cac72972ab143f","failed":2,"finished":25,"removed":5,"requested":30,"running":27,"running_sync":0,"stop_requested":0},"success_rate":92.5925925925926,"users":4,"readme_status":"no README.md","runtime_mean":471206.92,"runtime_std":244162.40282368127,"service":"brainlife/app-extractTCKfromWMC","__v":0},"success_rate":94.08602150537635,"users":8,"runtime_mean":46409.06,"runtime_std":18170.935822251973,"requested":200,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a37b062f3d3800f11e41f"}],"examples":1,"groups":11},"projects":[],"admins":["56"],"tags":[],"removed":false,"config":{"track":{"type":"input","file_id":"track","input_id":"wbfg"},"classification":{"type":"input","file_id":"classification","input_id":"classification"},"tracts":{"type":"input","file_id":"tracts","input_id":"classification"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5dd06111c4ae286e4c29adb0","id":"wbfg","datatype":"5907d922436ee50ffde9c549"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5dd06111c4ae286a6329adaf","id":"classification","datatype":"5cc1d64c44947d8aea6b2d8b"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5dd06111c4ae28672c29adb1","id":"output","datatype":"5dcf0047c4ae28d7f2298f48","datatype_tags_pass":"classification","files":null}],"github_branch":"1.0","github":"brainlife/app-extractTCKfromWMC","name":"Extract multi-tcks from wmc + wbfg or composite tck","user_id":"56","contributors":[{"name":"Daniel Bullock","email":"iisdanbul@gmail.com","_id":"634a37b062f3d3800f11e420"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a37b062f3d3800f11e421"}],"create_date":"2019-11-16T20:50:25.746Z","desc":"This application takes an input tractography amalgam (i.e. whole brain fiber group (WBFG) or composite) and, using the categories designated in the associated White Matter Classification (WMC) structure input, extracts and outputs a Tck file for each category into the output directory. ","doi":"10.25663/brainlife.app.251","__v":6564,"desc_override":"This application takes an input tractography amalgum (i.e. whole brain fiber group (WBFG) or composite) and, using the categories designated in the White Matter Category (WMC) input, extracts and outputs a tck file for each category into the output directory.  Intended to facilitate users performing analyses offline/outside of the brainlife platform.\n\nWARNING:  Submitting mismatched input TCK and WMC will result in an error, but may also result in garbage output in the event that the mismatch cannot be inferred by the checks implemented by the code (i.e. matching streamline numbers)","_canedit":true},{"_id":"60282ffddea2e28693797e57","projects":[],"admins":["16","126"],"tags":[],"removed":false,"stats":{"success_rate":90.66666666666666,"users":4,"runtime_mean":679756.8970588235,"runtime_std":717464.7838774992,"requested":86,"resources":[],"examples":1,"groups":7},"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"shell":{"id":"shell","type":"number","placeholder":"","advanced":false,"desc":"Value of the gradient shell to extract","default":null,"_order":2,"pid":0.43298903704294567},"with_bzero":{"id":"with_bzero","type":"boolean","placeholder":"","advanced":false,"desc":"If true (default), will include bzero volumes in extracted output. If false, will exclude.","default":true,"_order":3,"pid":0.8371202984513129}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5df431a62dac9b9d52ae1356","id":"dwi","datatype":"58c33c5fe13a50849b25879b","desc":"The path to the DWI datatype"}],"outputs":[{"datatype_tags":["single_shell"],"output_on_root":false,"archive":true,"_id":"5df431a62dac9bbad5ae1358","id":"dwi","datatype":"58c33c5fe13a50849b25879b","datatype_tags_pass":"dwi","files":null,"desc":"The output dwi volumes"}],"github_branch":"extract-shell-v1.0","github":"brainlife/app-mrtrix3-split-b0s","name":"Extract shell from DWI image","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3efd62f3d3800f12c707"}],"desc":null,"__v":3289,"desc_override":"This app will extract diffusion gradient (i.e. shell) volumes from a DWI image using MrTrix3’s dwiextract function. Based on user input, will either include or exclude bzero volumes.","create_date":"2021-02-13T20:01:01.159Z","doi":"10.25663/brainlife.app.475","_canedit":true},{"_id":"5f76303c268f76393329775a","projects":[],"admins":["16"],"tags":[],"removed":false,"stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3daf62f3d3800f12b469"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3daf62f3d3800f12b46a"}],"success_rate":46.752233956133225,"users":12,"runtime_mean":1696316.03,"runtime_std":1955289.3661379511,"requested":36654,"examples":5,"groups":26},"config":{"cortexmap":{"type":"input","file_id":"cortexmap","input_id":"cortexmap"},"rois":{"type":"input","file_id":"rois","input_id":"rois"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"aparc":{"id":"aparc","type":"enum","placeholder":"","advanced":false,"desc":"","default":"","_order":2,"pid":0.6051331383533318,"options":[{"desc":"","label":"aparc","value":"aparc"},{"desc":"","label":"aparc.a2009s","value":"aparc.a2009s"}]},"reslice":{"id":"reslice","type":"boolean","placeholder":"","advanced":true,"desc":"","default":true,"_order":3,"pid":0.2470261735203485},"weight":{"id":"weight","type":"boolean","placeholder":"","advanced":true,"desc":"","default":false,"_order":4,"pid":0.26040868993767763}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5eed5e9dd39ceb6ce1a0ed19","id":"cortexmap","datatype":"5c58aa5ef9109beac4b52f61","desc":"Path to the cortexmap datatype folder"},{"datatype_tags":["tractEndpointDensity"],"optional":false,"multi":false,"advanced":false,"_id":"5f76303c268f76c5b329775f","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5f76369c268f7647b52978ec","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e"}],"outputs":[{"datatype_tags":["cortex_mapping_stats","tract_endpoints"],"output_on_root":false,"archive":true,"_id":"5eed5e9dd39ceb532aa0ed1b","id":"parc-stats","datatype":"5edd3b77c5972b8c47b3a2c3","datatype_tags_pass":"cortexmap","files":null,"desc":"Csv files for each summary statistic and parcellation"},{"datatype_tags":["cortex_mapping_stats_derivatives","tract_endpoints"],"output_on_root":false,"archive":true,"_id":"5eed5e9dd39ceb3ca4a0ed1a","id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null,"desc":"Derivatives generated during run for debugging"}],"github_branch":"endpoints-v1.1","github":"brainlife/app-cortex-tissue-mapping-stats","name":"Extract summary statistics of diffusion measures mapped to cortical surface inside tract endpoints","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3daf62f3d3800f12b46b"},{"name":"Franco Pestilli","email":null,"_id":"634a3daf62f3d3800f12b46c"}],"desc":null,"__v":4150,"desc_override":"This app will compute multiple summary statistics from measures mapped to the cortical midthickness surface on a per-endpoint ROI basis. This app takes in a cortexmap datatype and an optional parcellation/surface datatype. This app will compute the following summary statistics: minimum, maximum, mean, median, mode, standard deviation, and nonzero vertex count. The app will output a csv for each summary measure summarizing the diffusion measures in each endpoint ROI. These csvs can be used for computing group averages and for performing machine learning analyses.","create_date":"2020-10-01T19:38:36.536Z","doi":"10.25663/brainlife.app.437","_canedit":true},{"_id":"5fda7ccb57aacd1b0e2f1c91","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3e7562f3d3800f12bb12"}],"examples":0},"projects":[],"admins":["1299"],"tags":[],"removed":false,"config":{},"inputs":[],"outputs":[],"github_branch":"main","github":"joy-neuro/bnbl_brainlife","name":"FC Identifiability/Fingerprinting Analyses","user_id":"1299","contributors":[{"name":null,"email":null,"_id":"634a3e7562f3d3800f12bb13"}],"create_date":"2020-12-16T21:31:55.331Z","desc":"App on processing, analyzing eFC","__v":3737,"doi":"10.25663/brainlife.app.460","_canedit":true},{"_id":"5e3c87ae9362b7166cf9c7f4","stats":{"stars":0,"serviceinfo":{"_id":"5e3cad3c50444e3beb536144","counts":{"_id":"5e5c3e3887cac75014ab1450","failed":10,"finished":2,"removed":4,"requested":14,"running":14,"running_sync":0,"stop_requested":2},"success_rate":16.666666666666664,"users":1,"readme_status":"too short","service":"brainlife/app-fsl-anat","__v":0,"runtime_mean":3168917.5,"runtime_std":1128485.5},"success_rate":56.35828386660875,"users":71,"runtime_mean":2213287.55,"runtime_std":535730.8309888908,"requested":25341,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a382f62f3d3800f11eda4"},{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"634a382f62f3d3800f11eda5"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a382f62f3d3800f11eda6"}],"examples":1,"groups":139},"projects":[],"admins":["16"],"tags":[],"removed":false,"config":{"input":{"type":"input","file_id":"t1","input_id":"t1"},"reorient":{"id":"reorient","type":"boolean","placeholder":"","advanced":false,"desc":"Reorient the image to FSL's standard (reorient2std). Leave as false if already done","default":false,"_order":2,"pid":0.8381545796048748},"crop":{"id":"crop","type":"boolean","placeholder":"","advanced":false,"desc":"Crop the non-brain material using FSL's robustfov. Leave as false if already done","default":false,"_order":3,"pid":0.4224696343989045},"bias":{"id":"bias","type":"boolean","placeholder":"","advanced":false,"desc":"Debias the anatomical image. Leave as false if not wanted or already done","default":false,"_order":4,"pid":0.48359611617341725},"seg":{"id":"seg","type":"boolean","placeholder":"","advanced":false,"desc":"Segment the tissue types using FSLs FAST. Leave as false if not wanted","default":false,"_order":5,"pid":0.07456958526195345},"subcortseg":{"id":"subcortseg","type":"boolean","placeholder":"","advanced":false,"desc":"Segment the subcortical structures using FSLs FAST. Leave as false if not wanted","default":false,"_order":6,"pid":0.5690175264337534},"input_type":{"id":"input_type","type":"enum","placeholder":"","advanced":true,"desc":"This controls the datatype (T1 or T2) to use. This should not be changed. Only used to keep the github repository between the two apps the same","default":"T1","_order":7,"pid":0.9580991826812977,"options":[{"desc":"T1","label":"T1","value":"T1"}]},"template":{"id":"template","type":"enum","placeholder":"","advanced":false,"desc":"The template to which to align the T1","default":"MNI152_1mm","_order":8,"pid":0.15231660104626465,"options":[{"desc":"1.0 mm MNI 152 template","label":"MNI152_1mm","value":"MNI152_1mm"},{"desc":"4.5–8.5 y.o Asymmetric (natural) templates","label":"4.5–8.5 y.o Asymmetric (natural) templates","value":"nihpd_asym_04.5-08.5"},{"desc":"4.5-18.5 y.o Asymmetric (natural) templates","label":"4.5-18.5 y.o Asymmetric (natural) templates","value":"nihpd_asym_04.5-18.5"},{"desc":"7.0-11.0 y.o Asymmetric (natural) templates","label":"7.0-11.0 y.o Asymmetric (natural) templates","value":"nihpd_asym_07.0-11.0"},{"desc":"7.5-13.5 y.o Asymmetric (natural) templates","label":"7.5-13.5 y.o Asymmetric (natural) templates","value":"nihpd_asym_07.5-13.5"},{"desc":"10.0-14.0 y.o Asymmetric (natural) templates","label":"10.0-14.0 y.o Asymmetric (natural) templates","value":"nihpd_asym_10.0-14.0"},{"desc":"13.0-18.5 y.o Asymmetric (natural) templates","label":"13.0-18.5 y.o Asymmetric (natural) templates","value":"nihpd_asym_13.0-18.5"},{"desc":"0.7 mm MNI 152 template","label":"MNI152_0.7mm","value":"MNI152_0.7mm"},{"desc":"0.8 mm MNI 152 template","label":"MNI152_0.8mm","value":"MNI152_0.8mm"},{"desc":"2.0 mm MNI 152 template","label":"MNI152_2mm","value":"MNI152_2mm"}]}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e3c87ae9362b7d9a5f9c7f5","id":"t1","datatype":"58c33bcee13a50849b25879a","desc":"The path to the anat/1tw datatype"}],"outputs":[{"datatype_tags":["preprocessed","acpc_aligned"],"output_on_root":false,"archive":true,"_id":"5e3c87ae9362b70c0bf9c7f6","id":"acpc","datatype":"58c33bcee13a50849b25879a","datatype_tags_pass":"t1","files":null,"desc":"ACPC aligned data in 1mm space"},{"datatype_tags":["preprocessed","standard"],"output_on_root":false,"archive":false,"_id":"5e3c87ae9362b7e38bf9c7f7","id":"standard","datatype":"58c33bcee13a50849b25879a","datatype_tags_pass":"t1","files":null,"desc":"T1 nonlinearly warped to standard space"},{"datatype_tags":["preprocessed","debiased"],"output_on_root":false,"archive":false,"_id":"5e3c87ae9362b7a509f9c7f8","id":"bias","datatype":"58c33bcee13a50849b25879a","datatype_tags_pass":"t1","files":null,"desc":"bias corrected data in original input space"},{"datatype_tags":["preprocessed","standard"],"output_on_root":false,"archive":true,"_id":"5e3c87ae9362b72555f9c7f9","id":"standard_nonlin_warp","datatype":"5bbfb28071454db2a890fbce","datatype_tags_pass":"t1","files":null,"desc":"Nonlinear warp generated from T1 to standard via fnirt"},{"datatype_tags":["preprocessed"],"output_on_root":false,"archive":false,"_id":"5e3c87ae9362b713def9c7fa","id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":"t1","files":null,"desc":"Output directory for all the data derivatives generated"}],"github_branch":"v1.0","github":"brainlife/app-fsl-anat","name":"FSL Anat (T1)","desc_override":"fsl_anat (https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/fsl_anat) provides a general pipeline for processing anatomical images (e.g. T1-weighted scans). ","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a382f62f3d3800f11eda7"}],"create_date":"2020-02-06T21:39:58.946Z","desc":null,"doi":"10.25663/brainlife.app.273","__v":5658,"_canedit":true},{"_id":"5ec6eda01f4464acbc9e54ec","projects":[],"admins":["16"],"tags":[],"removed":false,"stats":{"success_rate":56.35828386660875,"users":71,"runtime_mean":2213287.55,"runtime_std":535730.8309888908,"requested":25341,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3ada62f3d3800f1247a2"},{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"634a3ada62f3d3800f1247a3"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3ada62f3d3800f1247a4"}],"examples":1,"groups":139},"config":{"input":{"type":"input","file_id":"t2","input_id":"t2"},"reorient":{"id":"reorient","type":"boolean","placeholder":"","advanced":false,"desc":"Reorient the image to FSL's standard (reorient2std). Leave as false if already done","default":false,"_order":2,"pid":0.9817569421825316},"crop":{"id":"crop","type":"boolean","placeholder":"","advanced":false,"desc":"Crop the non-brain material using FSL's robustfov. Leave as false if already done","default":false,"_order":3,"pid":0.35881500439028047},"bias":{"id":"bias","type":"boolean","placeholder":"","advanced":false,"desc":"Debias the anatomical image. Leave as false if not wanted or already done","default":false,"_order":4,"pid":0.36314248874548993},"seg":{"id":"seg","type":"boolean","placeholder":"","advanced":false,"desc":"Segment the tissue types using FSLs FAST. Leave as false if not wanted","default":false,"_order":7,"pid":0.2407192265135254},"subcortseg":{"id":"subcortseg","type":"boolean","placeholder":"","advanced":true,"desc":"(This is T1 only option) Segment the subcortical structures using FSLs FAST.","default":false,"_order":8,"pid":0.638002247660642,"readonly":true},"input_type":{"id":"input_type","type":"enum","placeholder":"","advanced":false,"desc":"This controls the datatype (T1 or T2) to use. This should not be changed. Only used to keep the github repository between the two apps the same","default":"T2","_order":9,"pid":0.6760994437487315,"options":[{"desc":"T2","label":"T2","value":"T2"}]},"template":{"id":"template","type":"enum","placeholder":"","advanced":false,"desc":"The template to which to align the T2","default":"MNI152_1mm","_order":10,"pid":0.9557783580042034,"options":[{"desc":"1.0 mm MNI 152 template","label":"MNI152_1mm","value":"MNI152_1mm"},{"desc":"4.5–8.5 y.o Asymmetric (natural) templates","label":"4.5–8.5 y.o Asymmetric (natural) templates","value":"nihpd_asym_04.5-08.5"},{"desc":"4.5-18.5 y.o Asymmetric (natural) templates","label":"4.5-18.5 y.o Asymmetric (natural) templates","value":"nihpd_asym_04.5-18.5"},{"desc":"7.0-11.0 y.o Asymmetric (natural) templates","label":"7.0-11.0 y.o Asymmetric (natural) templates","value":"nihpd_asym_07.0-11.0"},{"desc":"7.5-13.5 y.o Asymmetric (natural) templates","label":"7.5-13.5 y.o Asymmetric (natural) templates","value":"nihpd_asym_07.5-13.5"},{"desc":"10.0-14.0 y.o Asymmetric (natural) templates","label":"10.0-14.0 y.o Asymmetric (natural) templates","value":"nihpd_asym_10.0-14.0"},{"desc":"13.0-18.5 y.o Asymmetric (natural) templates","label":"13.0-18.5 y.o Asymmetric (natural) templates","value":"nihpd_asym_13.0-18.5"},{"desc":"0.7 mm MNI 152 template","label":"MNI152_0.7mm","value":"MNI152_0.7mm"},{"desc":"0.8 mm MNI 152 template","label":"MNI152_0.8mm","value":"MNI152_0.8mm"},{"desc":"2.0 mm MNI 152 template","label":"MNI152_2mm","value":"MNI152_2mm"}]}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e3c87ae9362b7d9a5f9c7f5","id":"t2","datatype":"594c0325fa1d2e5a1f0beda5","desc":"The path to the anat/t2w datatype"}],"outputs":[{"datatype_tags":["preprocessed","acpc_aligned"],"output_on_root":false,"archive":true,"_id":"5e3c87ae9362b70c0bf9c7f6","id":"acpc","datatype":"594c0325fa1d2e5a1f0beda5","datatype_tags_pass":"t2","files":null,"desc":"ACPC aligned data in 1mm space"},{"datatype_tags":["preprocessed","standard"],"output_on_root":false,"archive":false,"_id":"5e3c87ae9362b7e38bf9c7f7","id":"standard","datatype":"594c0325fa1d2e5a1f0beda5","datatype_tags_pass":"t2","files":null,"desc":"T2 nonlinearly warped to standard space"},{"datatype_tags":["preprocessed","debiased"],"output_on_root":false,"archive":false,"_id":"5e3c87ae9362b7a509f9c7f8","id":"bias","datatype":"594c0325fa1d2e5a1f0beda5","datatype_tags_pass":"t2","files":null,"desc":"bias corrected data in original input space"},{"datatype_tags":["preprocessed","standard"],"output_on_root":false,"archive":true,"_id":"5e3c87ae9362b72555f9c7f9","id":"standard_nonlin_warp","datatype":"5bbfb28071454db2a890fbce","datatype_tags_pass":"t2","files":null,"desc":"Nonlinear warp generated from T2 to standard via fnirt"},{"datatype_tags":["preprocessed"],"output_on_root":false,"archive":false,"_id":"5e3c87ae9362b713def9c7fa","id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":"t2","files":null,"desc":"Output directory for all the data derivatives generated"}],"github_branch":"v1.0","github":"brainlife/app-fsl-anat","name":"FSL Anat (T2)","desc_override":"This app will perform fsl_anat (https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/fsl_anat)","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3ada62f3d3800f1247a5"}],"desc":null,"__v":4825,"create_date":"2020-05-21T21:07:44.423Z","doi":"10.25663/brainlife.app.350","_canedit":true},{"_id":"6083329689df4317546dd88a","projects":[],"admins":["16"],"tags":[],"removed":false,"stats":{"success_rate":56.35828386660875,"users":71,"runtime_mean":2213287.55,"runtime_std":535730.8309888908,"requested":25341,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a404e62f3d3800f12d67e"},{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"634a404e62f3d3800f12d67f"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a404e62f3d3800f12d680"}],"examples":0,"groups":139},"config":{"mag_inv1":{"type":"input","file_id":"mag_inv1","input_id":"mp2rage"},"phase_inv1":{"type":"input","file_id":"phase_inv1","input_id":"mp2rage"},"mag_inv2":{"type":"input","file_id":"mag_inv2","input_id":"mp2rage"},"phase_inv2":{"type":"input","file_id":"phase_inv2","input_id":"mp2rage"},"unit1":{"type":"input","file_id":"unit1","input_id":"mp2rage"},"mag_inv1_json":{"type":"input","file_id":"mag_inv1_json","input_id":"mp2rage"},"phase_inv1_json":{"type":"input","file_id":"phase_inv1_json","input_id":"mp2rage"},"mag_inv2_json":{"type":"input","file_id":"mag_inv2_json","input_id":"mp2rage"},"phase_inv2_json":{"type":"input","file_id":"phase_inv2_json","input_id":"mp2rage"},"unit1_json":{"type":"input","file_id":"unit1_json","input_id":"mp2rage"},"reorient":{"id":"reorient","type":"boolean","placeholder":"","advanced":false,"desc":"Reorient the image to FSL's standard (reorient2std). Leave as false if already done","default":false,"_order":2,"pid":0.5397153404588642},"crop":{"id":"crop","type":"boolean","placeholder":"","advanced":false,"desc":"Crop the non-brain material using FSL's robustfov. Leave as false if already done","default":false,"_order":3,"pid":0.6235681138727722},"template":{"id":"template","type":"enum","placeholder":"","advanced":false,"desc":"The template to which to align the T1","default":"MNI152_1mm","_order":8,"pid":0.7274281873527222,"options":[{"desc":"1.0 mm MNI 152 template","label":"MNI152_1mm","value":"MNI152_1mm"},{"desc":"4.5–8.5 y.o Asymmetric (natural) templates","label":"4.5–8.5 y.o Asymmetric (natural) templates","value":"nihpd_asym_04.5-08.5"},{"desc":"4.5-18.5 y.o Asymmetric (natural) templates","label":"4.5-18.5 y.o Asymmetric (natural) templates","value":"nihpd_asym_04.5-18.5"},{"desc":"7.0-11.0 y.o Asymmetric (natural) templates","label":"7.0-11.0 y.o Asymmetric (natural) templates","value":"nihpd_asym_07.0-11.0"},{"desc":"7.5-13.5 y.o Asymmetric (natural) templates","label":"7.5-13.5 y.o Asymmetric (natural) templates","value":"nihpd_asym_07.5-13.5"},{"desc":"10.0-14.0 y.o Asymmetric (natural) templates","label":"10.0-14.0 y.o Asymmetric (natural) templates","value":"nihpd_asym_10.0-14.0"},{"desc":"13.0-18.5 y.o Asymmetric (natural) templates","label":"13.0-18.5 y.o Asymmetric (natural) templates","value":"nihpd_asym_13.0-18.5"},{"desc":"0.7 mm MNI 152 template","label":"MNI152_0.7mm","value":"MNI152_0.7mm"},{"desc":"0.8 mm MNI 152 template","label":"MNI152_0.8mm","value":"MNI152_0.8mm"},{"desc":"2.0 mm MNI 152 template","label":"MNI152_2mm","value":"MNI152_2mm"}]}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"6083329689df434a1a6dd88e","id":"mp2rage","datatype":"60634f0de4a8347569337f97"}],"outputs":[{"datatype_tags":["preprocessed","acpc_aligned"],"output_on_root":false,"archive":true,"_id":"5e3c87ae9362b70c0bf9c7f6","id":"acpc","datatype":"60634f0de4a8347569337f97","datatype_tags_pass":"mp2rage","files":null,"desc":"ACPC aligned data"},{"datatype_tags":["preprocessed","standard"],"output_on_root":false,"archive":false,"_id":"5e3c87ae9362b7e38bf9c7f7","id":"standard","datatype":"60634f0de4a8347569337f97","datatype_tags_pass":"mp2rage","files":null,"desc":"mp2rage nonlinearly warped to standard space"},{"datatype_tags":["preprocessed","standard"],"output_on_root":false,"archive":true,"_id":"5e3c87ae9362b72555f9c7f9","id":"standard_nonlin_warp","datatype":"5bbfb28071454db2a890fbce","datatype_tags_pass":"mp2rage","files":null,"desc":"Nonlinear warp generated from mp2rage to standard via fnirt"},{"datatype_tags":["preprocessed"],"output_on_root":false,"archive":false,"_id":"5e3c87ae9362b713def9c7fa","id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":"mp2rage","files":null,"desc":"Output directory for all the data derivatives generated"}],"github_branch":"mp2rage-v1.0","github":"brainlife/app-fsl-anat","name":"FSL Anat (mp2rage)","desc_override":"fsl_anat (https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/fsl_anat) provides a general pipeline for processing anatomical images (e.g. mp2rage  scans). ","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a404e62f3d3800f12d681"}],"desc":null,"__v":2762,"create_date":"2021-04-23T20:48:22.773Z","doi":"10.25663/brainlife.app.512","_canedit":true},{"_id":"5c63a9c3f2362b00318046c2","stats":{"stars":0,"requested":40503,"users":57,"success_rate":59.874538745387454,"serviceinfo":{"_id":"5d729e1f78356a109788b34b","counts":{"_id":"5e5c3de487cac760c9ab13f7","failed":53,"finished":1853,"removed":1955,"requested":2015,"running":1928,"running_sync":0,"stop_requested":40},"success_rate":97.2193074501574,"users":33,"readme_status":"too short","runtime_mean":964048.19,"runtime_std":2048880.6264796087,"service":"brain-life/app-FSLBET","__v":0},"gitinfo":{"desc":"Brain Extraction via FSL's BET command","tags":["anatomy-preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null}]},"runtime_mean":30502.38,"runtime_std":13015.16290084761,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a353062f3d3800f119a2c"},{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"634a353062f3d3800f119a2d"},{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"634a353062f3d3800f119a2e"}],"examples":5,"groups":91},"projects":[],"admins":["43","16"],"tags":["anatomy-preprocessing"],"removed":false,"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"0"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"0"},"bvals":{"type":"input","file_id":"bvals","input_id":"0"},"fthreshold":{"id":"fthreshold","type":"number","placeholder":"","desc":"choose the fractional intensity threshold (0 -> 1); default=0.4; smaller values give larger brain outline estimates","default":0.4,"_order":2,"pid":0.13721527036125247},"gthreshold":{"id":"gthreshold","type":"number","placeholder":"","desc":"choose the vertical gradient in fractional intensity threshold (-1->1); default=0; positive values give larger brain outline at bottom, smaller at top","default":0,"_order":3,"pid":0.2238645310422065},"robust":{"id":"robust","type":"boolean","placeholder":"","advanced":true,"desc":"if robust is set as true, will iteratively run bet2 to get better brain outlines","default":true,"_order":4,"pid":0.9724663694358747}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c63a9c3f2362b00318046c3","id":"0","datatype":"58c33c5fe13a50849b25879b","desc":"The path to the DWI datatype"}],"outputs":[{"datatype_tags":["brain_extracted"],"output_on_root":false,"archive":true,"_id":"5c63a9c3f2362b00318046c5","id":"dwi","datatype":"58c33c5fe13a50849b25879b","datatype_tags_pass":null,"files":null,"desc":"The masked DWI"},{"datatype_tags":["dwi","brain"],"output_on_root":false,"archive":true,"_id":"5c63a9c3f2362b00318046c4","id":"mask","datatype":"5a281aee2c214c9ba83ce620","datatype_tags_pass":"0","files":null,"desc":"The brainmask for the DWI image"}],"github_branch":"dwi","github":"brainlife/app-FSLBET","name":"FSL Brain Extraction (BET) on DWI","user_id":"16","contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a353062f3d3800f119a2f"},{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a353062f3d3800f119a30"}],"create_date":"2019-02-13T05:23:15.689Z","desc":"Brain Extraction via FSL's BET command","doi":"10.25663/brainlife.app.163","__v":8730,"_canedit":true},{"_id":"5a54faf541fd04003f9d488b","name":"FSL Brain Extraction (BET) on T1","desc":"Brain Extraction via FSL's BET command","citation":null,"github":"brainlife/app-FSLBET","github_branch":"2.0","config":{"input":{"type":"input","file_id":"t1","input_id":"0"},"fthreshold":{"default":0.5,"desc":"fractional intensity threshold (0->1); default=0.5; smaller values give larger brain outline estimates","placeholder":"","type":"number","id":"fthreshold","pid":0.8045955978723267,"_order":2}},"user_id":"43","create_date":"2018-01-09T17:25:09.329Z","removed":false,"_rate":0,"outputs":[{"datatype_tags":["brain_extracted"],"output_on_root":false,"archive":true,"_id":"5a54faf541fd04003f9d488d","id":"out","datatype":"58c33bcee13a50849b25879a","files":{"t1":"masked.nii.gz"},"datatype_tags_pass":"0"},{"datatype_tags":["brain","anat"],"output_on_root":false,"archive":true,"_id":"5a54faf541fd04003f9d488c","id":"mask","datatype":"5a281aee2c214c9ba83ce620","files":null}],"inputs":[{"datatype_tags":["acpc_aligned"],"optional":false,"multi":false,"advanced":false,"_id":"5a54faf541fd04003f9d488e","id":"0","datatype":"58c33bcee13a50849b25879a"}],"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a31e762f3d3800f116a6b"},{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a31e762f3d3800f116a6c"}],"tags":["anatomy-preprocessing"],"references":[],"admins":["16","41","146","43","1"],"projects":[],"__v":14264,"stats":{"stars":0,"requested":40503,"users":57,"success_rate":59.874538745387454,"serviceinfo":{"_id":"5d729e1f78356a109788b34b","counts":{"_id":"5e5c689987cac72c70ab1bc3","failed":53,"finished":1853,"removed":1955,"requested":2015,"running":1928,"running_sync":0,"stop_requested":40},"success_rate":97.2193074501574,"users":33,"readme_status":"too short","runtime_mean":964048.19,"runtime_std":2048880.6264796087,"service":"brain-life/app-FSLBET","__v":0},"gitinfo":{"desc":"Brain Extraction via FSL's BET command","tags":["anatomy-preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null}]},"runtime_mean":30502.38,"runtime_std":13015.16290084761,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a31e662f3d3800f116a68"},{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"634a31e662f3d3800f116a69"},{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"634a31e662f3d3800f116a6a"}],"examples":5,"groups":91},"doi":"10.25663/bl.app.2","_canedit":true},{"_id":"5c58b7e012cbcc01e1635b88","stats":{"stars":0,"requested":40503,"users":57,"success_rate":59.874538745387454,"serviceinfo":{"_id":"5d729e1f78356a109788b34b","counts":{"_id":"5e5c3ddf87cac7412dab13f0","failed":53,"finished":1853,"removed":1955,"requested":2015,"running":1928,"running_sync":0,"stop_requested":40},"success_rate":97.2193074501574,"users":33,"readme_status":"too short","runtime_mean":964048.19,"runtime_std":2048880.6264796087,"service":"brain-life/app-FSLBET","__v":0},"gitinfo":{"desc":"Brain Extraction via FSL's BET command","tags":["anatomy-preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null}]},"runtime_mean":30502.38,"runtime_std":13015.16290084761,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a34ff62f3d3800f118f05"},{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"634a34ff62f3d3800f118f06"},{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"634a34ff62f3d3800f118f07"}],"examples":1,"groups":91},"projects":[],"admins":["43","16"],"tags":["anatomy-preprocessing"],"removed":false,"config":{"input":{"type":"input","file_id":"t2","input_id":"0"},"fthreshold":{"id":"fthreshold","type":"number","placeholder":"","desc":"choose the fractional intensity threshold (0 -> 1); default=0.2; smaller values give larger brain outline estimates","default":0.5,"_order":2,"pid":0.6860192091842878}},"inputs":[{"datatype_tags":["acpc_aligned"],"optional":false,"multi":false,"advanced":false,"_id":"5c58b7e012cbcc01e1635b89","id":"0","datatype":"594c0325fa1d2e5a1f0beda5"}],"outputs":[{"datatype_tags":["brain_extracted"],"output_on_root":false,"archive":true,"_id":"5c58b7e012cbcc01e1635b8b","id":"out","datatype":"594c0325fa1d2e5a1f0beda5","datatype_tags_pass":"0","files":{"t2":"masked.nii.gz"},"desc":"The masked T2w image"},{"datatype_tags":["brain","anat"],"output_on_root":false,"archive":true,"_id":"5c58b7e012cbcc01e1635b8a","id":"mask","datatype":"5a281aee2c214c9ba83ce620","datatype_tags_pass":null,"files":null,"desc":"The brainmask of the T2w image"}],"github_branch":"2.0","github":"brainlife/app-FSLBET","name":"FSL Brain Extraction (BET) on T2","desc_override":"","user_id":"16","contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a350062f3d3800f118f08"},{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a350062f3d3800f118f09"}],"create_date":"2019-02-04T22:08:32.862Z","desc":"Brain Extraction via FSL's BET command","doi":"10.25663/brainlife.app.156","__v":8817,"_canedit":true},{"_id":"5cc079c54ed9df00317f61a8","projects":[],"admins":["16","41","146","1"],"tags":["anatomy-preprocessing"],"removed":false,"stats":{"stars":0,"requested":40503,"users":57,"success_rate":59.874538745387454,"serviceinfo":{"_id":"5d729e1f78356a109788b34b","counts":{"_id":"5e5c3df287cac70a68ab1407","failed":53,"finished":1853,"removed":1955,"requested":2015,"running":1928,"running_sync":0,"stop_requested":40},"success_rate":97.2193074501574,"users":33,"readme_status":"too short","runtime_mean":964048.19,"runtime_std":2048880.6264796087,"service":"brain-life/app-FSLBET","__v":0},"gitinfo":{"desc":"Brain Extraction via FSL's BET command","tags":["anatomy-preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null}]},"runtime_mean":30502.38,"runtime_std":13015.16290084761,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a35bc62f3d3800f11a276"},{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"634a35bc62f3d3800f11a277"},{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"634a35bc62f3d3800f11a278"}],"examples":1,"groups":91},"config":{"input":{"type":"input","file_id":"bold","input_id":"0"},"fthreshold":{"id":"fthreshold","type":"number","placeholder":"","desc":"choose the fractional intensity threshold (0 -> 1); default=0.4; smaller values give larger brain outline estimates","default":0.5,"_order":2,"pid":0.616344690292266}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c63a9c3f2362b00318046c3","id":"0","datatype":"59b685a08e5d38b0b331ddc5"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5d96521af6484a41ff6a8812","id":"out","datatype":"59b685a08e5d38b0b331ddc5","datatype_tags_pass":null,"files":{"bold":"masked.nii.gz"},"desc":"masked bold.nii.gz.. only bold.nii.gz is copied from the input (no events.tsv, etc..)"},{"datatype_tags":["brain","func","bold"],"output_on_root":false,"archive":true,"_id":"5c63a9c3f2362b00318046c4","id":"mask","datatype":"5a281aee2c214c9ba83ce620","datatype_tags_pass":"0","files":null}],"github_branch":"2.0","github":"brainlife/app-FSLBET","name":"FSL Brain Extraction (BET) on fMRI","user_id":"1","contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a35bc62f3d3800f11a279"},{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a35bc62f3d3800f11a27a"}],"desc":"Brain Extraction via FSL's BET command","__v":8191,"create_date":"2019-04-24T14:59:17.875Z","doi":"10.25663/brainlife.app.184","_canedit":true},{"_id":"5e7f90e9dd840e81aae91906","projects":[],"admins":["1","41","16"],"tags":["diffusion-mri"],"removed":false,"stats":{"requested":7791,"users":47,"success_rate":90.41437843235147,"gitinfo":{"desc":" This app will fit the diffusion tensor model (DTI) to a diffusion MRI image using FSL's dtifit commmand.","tags":["diffusion-mri"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null}]},"runtime_mean":731597.55,"runtime_std":2201149.4754126365,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a38ca62f3d3800f11fe55"}],"examples":5,"groups":77},"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"kurtosis":{"id":"kurtosis","type":"boolean","placeholder":"","advanced":false,"desc":"If true, will fit tensor using the -kurt flag","default":false,"_order":2,"pid":0.1057066662822973},"kurtdir":{"id":"kurtdir","type":"boolean","placeholder":"","advanced":false,"desc":"If true, will fit tensor using the -kurtdir flag","default":false,"_order":3,"pid":0.5076019587212331},"shell":{"id":"shell","type":"string","placeholder":"","advanced":false,"desc":"The gradient (i.e. shell) to use to fit the DTI model to","default":"1000","_order":4,"pid":0.7030604490827396,"optional":true},"wls":{"id":"wls","type":"boolean","placeholder":"","advanced":false,"desc":"If true, will fit tensor using the -wls flag","default":false,"_order":5,"pid":0.30139327640648883},"sse":{"id":"sse","type":"boolean","placeholder":"","advanced":false,"desc":"If true, will fit tensor using the -sse flag","default":false,"_order":6,"pid":0.044046576974935525},"gradnonlin":{"id":"gradnonlin","type":"boolean","placeholder":"","advanced":false,"desc":"If true, will fit tensor using the -gradnonlin flag","default":false,"_order":7,"pid":0.7850661386804701},"multishell":{"id":"multishell","type":"boolean","placeholder":"","advanced":false,"desc":"If true, will fit multi-shell tensor","default":false,"_order":8,"pid":0.2755216643542796}},"inputs":[{"id":"dwi","desc":"The path to the DWI datatype","datatype":"58c33c5fe13a50849b25879b","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c1d67383e9c170177733d40"},{"id":"mask","desc":"The brainmask of the DWI datatype (optional). If not inputted, will be fit using FSL BET","datatype":"5a281aee2c214c9ba83ce620","datatype_tags":["brain","dwi"],"optional":true,"multi":false,"advanced":false,"_id":"5c20bfbc94802a003240ab7d"}],"outputs":[{"id":"tensor","desc":"The tensor model fit to the input DWI","datatype":"5a79df48d071a1753f1d661b","datatype_tags":["fsl"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5c1d67383e9c170177733d41"}],"github_branch":"v1.1","github":"brainlife/app-fslDTIFIT","name":"FSL DTIFIT","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a38cb62f3d3800f11fe56"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a38cb62f3d3800f11fe57"}],"__v":5243,"desc":" This app will fit the diffusion tensor model (DTI) to a diffusion MRI image using FSL's dtifit commmand.","create_date":"2020-03-28T18:01:13.861Z","doi":"10.25663/brainlife.app.292","_canedit":true},{"_id":"5c1d67383e9c170177733d3f","stats":{"stars":0,"requested":7791,"users":47,"success_rate":90.41437843235147,"serviceinfo":{"_id":"5d729e1f78356a109788b265","counts":{"_id":"5e5c3dd387cac7433dab13e8","failed":26,"finished":422,"removed":585,"requested":758,"running":455,"running_sync":0,"stop_requested":31},"success_rate":94.19642857142857,"users":11,"readme_status":"ok","runtime_mean":68459,"runtime_std":28634.25960593359,"service":"brainlife/app-fslDTIFIT","__v":0},"gitinfo":{"desc":" This app will fit the diffusion tensor model (DTI) to a diffusion MRI image using FSL's dtifit commmand.","tags":["diffusion-mri"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null}]},"runtime_mean":731597.55,"runtime_std":2201149.4754126365,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a34b662f3d3800f118d17"}],"examples":0,"groups":77},"projects":[],"admins":["1","41","16"],"tags":["diffusion-mri"],"removed":false,"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"mask":{"type":"input","file_id":"mask","input_id":"mask"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c1d67383e9c170177733d40","id":"dwi","datatype":"58c33c5fe13a50849b25879b"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5c20bfbc94802a003240ab7d","id":"mask","datatype":"5a281aee2c214c9ba83ce620"}],"outputs":[{"datatype_tags":["fsl"],"output_on_root":true,"archive":true,"_id":"5c1d67383e9c170177733d41","id":"tensor","datatype":"5a79df48d071a1753f1d661b","datatype_tags_pass":null,"files":null}],"github_branch":"1.0","github":"brainlife/app-fslDTIFIT","name":"FSL DTIFIT - OLD","user_id":"16","references":[],"contributors":[{"name":"Brad Caron","email":null,"_id":"634a34b662f3d3800f118d18"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a34b662f3d3800f118d19"}],"create_date":"2018-12-21T22:20:40.172Z","doi":"10.25663/brainlife.app.137","__v":9173,"desc":" This app will fit the diffusion tensor model (DTI) to a diffusion MRI image using FSL's dtifit commmand.","deprecated_by":"5e7f90e9dd840e81aae91906","_canedit":true},{"_id":"60ef7997ddc2df54d26631cd","projects":[],"admins":["16"],"tags":["preprocessing"],"removed":false,"stats":{"requested":3136,"users":20,"success_rate":64.049955396967,"gitinfo":{"desc":"This app will correct for encoding, eddy currents, and motion artifacts using FSL's Topup and Eddy functions.","tags":["preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null}]},"runtime_mean":4527528.96,"runtime_std":8363821.149115121,"resources":[{"resource_id":"5ffc99da0df8ff7fc740c95a","name":"Bridges2 @ PSC (GPU-Shared)","_id":"634a417162f3d3800f12e2fc"}],"examples":1,"groups":40},"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"diff"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"diff"},"bvals":{"type":"input","file_id":"bvals","input_id":"diff"},"param":{"id":"param","type":"number","placeholder":"","desc":"This is the 'dwell time'. Please see https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/eddy/Faq#How_do_I_know_what_to_put_into_my_--acqp_file for more information about this specific parameter.","default":null,"_order":2,"pid":0.4407673806754876},"encode":{"id":"encode","type":"enum","placeholder":"","desc":"Phase encoding direction of the diff (not rdiff), i.e. first, inputted dwi.\n\nfor example, if the phase encoding direction of the first inputted dwi is 'PA', then select 'PA'. If it was 'AP', then select 'AP'","default":"PA","_order":3,"pid":0.368012934238951,"options":[{"desc":"Phase encoding direction of first input was done in posterior/anterior direction","label":"posterior-->anterior","value":"PA"},{"desc":"Phase encoding direction of first input was done in anterior/posterior","label":"anterior-->posterior","value":"AP"},{"desc":"Phase encoding direction of first input was done in left/right","label":"left-->right","value":"LR"},{"desc":"Phase encoding direction of first input was done in right/left","label":"right-->left","value":"RL"}]},"mb":{"id":"mb","type":"string","placeholder":"","advanced":true,"desc":"Eddy: Specifies multi-band factor (number of simultaneous slices)","default":"1","_order":18,"pid":0.14151507417785236},"mb_offs":{"id":"mb_offs","type":"string","placeholder":"","advanced":true,"desc":"Eddy: Specifies missing slices at top or bottom","default":"0","_order":19,"pid":0.020244268696510526},"flm":{"id":"flm","type":"enum","placeholder":"","advanced":true,"desc":"Eddy: Spatial model for the field generated by eddy currents","default":"quadratic","_order":20,"pid":0.3694919610545526,"options":[{"desc":"","label":"linear","value":"linear"},{"desc":"","label":"quadratic","value":"quadratic"},{"desc":"","label":"cubic","value":"cubic"}]},"slm":{"id":"slm","type":"enum","placeholder":"","advanced":true,"desc":"Model for how diffusion gradients generate eddy currents","default":"none","_order":21,"pid":0.5901914984086343,"options":[{"desc":"","label":"none","value":"none"},{"desc":"","label":"linear","value":"linear"},{"desc":"","label":"quadratic","value":"quadratic"}]},"eddy_fwhm":{"id":"eddy_fwhm","type":"string","placeholder":"","advanced":true,"desc":"Eddy: Filter width to use for pre-filtering of data for the estimation process","default":"0","_order":22,"pid":0.9342938061056689},"eddy_niter":{"id":"eddy_niter","type":"string","placeholder":"","advanced":false,"desc":"Eddy: Specifies how many iterations should be run","default":"5","_order":23,"pid":0.23275011246986455},"fep":{"id":"fep","type":"boolean","placeholder":"","advanced":true,"desc":"fill empty planes","default":false,"_order":24,"pid":0.8020273102938409},"eddy_interp":{"id":"eddy_interp","type":"enum","placeholder":"","advanced":true,"desc":"Eddy: Specifies interpolation model during estimation","default":"spline","_order":25,"pid":0.018132011745289667,"options":[{"desc":"","label":"spline","value":"spline"},{"desc":"","label":"trilinear","value":"trilinear"}]},"resamp":{"id":"resamp","type":"enum","placeholder":"","advanced":true,"desc":"Eddy: Specifies final resampling strategy","default":"jac","_order":26,"pid":0.5069304248499846,"options":[{"desc":"","label":"jac","value":"jac"},{"desc":"","label":"lsr","value":"lsr"}]},"nvoxhp":{"id":"nvoxhp","type":"string","placeholder":"","advanced":true,"desc":"Eddy: Specifies number of voxels to use for GP hyperparameter estimation","default":"1000","_order":27,"pid":0.14714548817731177},"ff":{"id":"ff","type":"string","placeholder":"","advanced":true,"desc":"Fudge factor that imposes Q-space smoothing during estimation","default":"10","_order":28,"pid":0.2546514392710455},"dont_sep_offs_move":{"id":"dont_sep_offs_move","type":"boolean","placeholder":"","advanced":true,"desc":"Eddy: Do not attempt to separate subject movement from field DC component","default":false,"_order":29,"pid":0.7979511059655395},"dont_peas":{"id":"dont_peas","type":"boolean","placeholder":"","advanced":true,"desc":"Eddy: Do not end with an alignment of shells to each other","default":false,"_order":30,"pid":0.38663550789334167},"repol":{"id":"repol","type":"boolean","placeholder":"","advanced":false,"desc":"Eddy: Replace outliers","default":false,"_order":31,"pid":0.5534911444449203},"ol_nstd":{"id":"ol_nstd","type":"string","placeholder":"","advanced":true,"desc":"Eddy: No. of standard deviations away a slice must be to qualify as an outlier","default":"4","_order":32,"pid":0.9529156512168154},"ol_nvox":{"id":"ol_nvox","type":"string","placeholder":"","advanced":true,"desc":"Eddy: The minimum no. of intracerebral voxels in a slice to consider it as an outlier","default":"250","_order":33,"pid":0.13563361044374123},"ol_type":{"id":"ol_type","type":"enum","placeholder":"","advanced":true,"desc":"Eddy: Base outlier detection on slices (sw) multi-band groups (mb) or both (both)","default":"sw","_order":34,"pid":0.08628693311345248,"options":[{"desc":"","label":"sw","value":"sw"},{"desc":"","label":"mb","value":"mb"},{"desc":"","label":"both","value":"both"}]},"ol_pos":{"id":"ol_pos","type":"boolean","placeholder":"","advanced":true,"desc":"Consider both positive and negative outliers","default":false,"_order":35,"pid":0.6464178076063738},"ol_sqr":{"id":"ol_sqr","type":"boolean","placeholder":"","advanced":true,"desc":"Eddy: Consider outliers in sum-of-squared distribution","default":false,"_order":36,"pid":0.8343297330781388},"mporder":{"id":"mporder","type":"string","placeholder":"","advanced":false,"desc":"Eddy: Temporal order of movement","default":"0","_order":37,"pid":0.34027060298956957},"s2v_niter":{"id":"s2v_niter","type":"string","placeholder":"","advanced":true,"desc":"Eddy: No. iterations for estimating slice-to-vol movement","default":"5","_order":38,"pid":0.06589232333604478},"s2v_lambda":{"id":"s2v_lambda","type":"string","placeholder":"","advanced":true,"desc":"Eddy: Strength of temporal regularisation of slice-to-vol movement.","default":"1","_order":39,"pid":0.4105433494600561},"s2v_interp":{"id":"s2v_interp","type":"enum","placeholder":"","advanced":true,"desc":"","default":"trilinear","_order":40,"pid":0.44409689438521827,"options":[{"desc":"","label":"trilinear","value":"trilinear"},{"desc":"","label":"spline","value":"spline"}]},"estimate_move_by_susceptibility":{"id":"estimate_move_by_susceptibility","type":"boolean","placeholder":"","advanced":true,"desc":"Eddy: When specified eddy estimates how the susceptibility field changes with subject movement.","default":false,"_order":41,"pid":0.8762501053200784},"mbs_iter":{"id":"mbs_iter","type":"string","placeholder":"","advanced":true,"desc":"Eddy: Number of iterations for susceptibility-by-movement estimation","default":"10","_order":42,"pid":0.6682071338253651},"mbs_lambda":{"id":"mbs_lambda","type":"string","placeholder":"","advanced":true,"desc":"Eddy: Specifies the balance between data and smoothness for the susceptibility rate-of-change fields","default":"10","_order":43,"pid":0.5732392259320219},"mbs_ksp":{"id":"mbs_ksp","type":"string","placeholder":"","advanced":true,"desc":"Eddy: Specifies the spline knot-spacing of the susceptibility rate-of-change fields","default":"10","_order":44,"pid":0.18849272384920768},"data_is_shelled":{"id":"data_is_shelled","type":"boolean","placeholder":"","advanced":true,"desc":"Eddy: Do not check that data is shelled. Trust the user","default":false,"_order":45,"pid":0.3383467565842997},"slspec":{"id":"slspec","type":"string","placeholder":"","advanced":false,"desc":"","default":"","_order":46,"pid":0.7087947579969918,"multiline":true,"optional":true}},"inputs":[{"id":"diff","desc":"The path to the DWI datatype","datatype":"58c33c5fe13a50849b25879b","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c54df0f12cbcc01e1635b01"}],"outputs":[{"id":"output","desc":"The preprocessed DWI","datatype":"58c33c5fe13a50849b25879b","datatype_tags":["preprocessed","eddy"],"datatype_tags_pass":"diff","output_on_root":false,"files":null,"archive":true,"_id":"5c54df0f12cbcc01e1635b03"},{"id":"raw","desc":"eddy qc files and all other generated data derivatives","datatype":"59c3eae633fc1cf9ead71679","datatype_tags":["eddy_params"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5e754703de643b614b2a7c8e"},{"id":"eddy_quad","datatype":"59c3eae633fc1cf9ead71679","datatype_tags":["eddyqc","eddy_quad"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"60ef76e8ddc2dffc996630a5"},{"id":"regressors","datatype":"5c4f6a8af9109beac4b3dae0","datatype_tags":["eddyqc"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"6230b8015d8ab5d5f0389dad"}],"github_branch":"eddy-only-cuda-v1.0","github":"brainlife/app-FSLTopupEddy","name":"FSL Eddy (CUDA)","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a417262f3d3800f12e2fd"}],"desc":"This app will correct for encoding, eddy currents, and motion artifacts using FSL's Topup and Eddy functions.","__v":2302,"create_date":"2021-07-14T23:56:07.010Z","desc_override":"This app will correct for eddy-currents and motion using FSL eddy_cuda","doi":"10.25663/brainlife.app.544","_canedit":true},{"_id":"60ef76e8ddc2df373e6630a0","projects":[],"admins":["16"],"tags":["preprocessing"],"removed":false,"stats":{"requested":3136,"users":20,"success_rate":64.049955396967,"gitinfo":{"desc":"This app will correct for encoding, eddy currents, and motion artifacts using FSL's Topup and Eddy functions.","tags":["preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null}]},"runtime_mean":4527528.96,"runtime_std":8363821.149115121,"resources":[{"resource_id":"5ffc99da0df8ff7fc740c95a","name":"Bridges2 @ PSC (GPU-Shared)","_id":"634a416862f3d3800f12e2f2"}],"examples":1,"groups":40},"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"diff"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"diff"},"bvals":{"type":"input","file_id":"bvals","input_id":"diff"},"param":{"id":"param","type":"number","placeholder":"","desc":"This is the 'dwell time'. Please see https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/eddy/Faq#How_do_I_know_what_to_put_into_my_--acqp_file for more information about this specific parameter.","default":null,"_order":2,"pid":0.6731433385102812},"encode":{"id":"encode","type":"enum","placeholder":"","desc":"Phase encoding direction of the diff (not rdiff), i.e. first, inputted dwi.\n\nfor example, if the phase encoding direction of the first inputted dwi is 'PA', then select 'PA'. If it was 'AP', then select 'AP'","default":"PA","_order":3,"pid":0.12301019770112709,"options":[{"desc":"Phase encoding direction of first input was done in posterior/anterior direction","label":"posterior-->anterior","value":"PA"},{"desc":"Phase encoding direction of first input was done in anterior/posterior","label":"anterior-->posterior","value":"AP"},{"desc":"Phase encoding direction of first input was done in left/right","label":"left-->right","value":"LR"},{"desc":"Phase encoding direction of first input was done in right/left","label":"right-->left","value":"RL"}]},"mb":{"id":"mb","type":"string","placeholder":"","advanced":true,"desc":"Eddy: Specifies multi-band factor (number of simultaneous slices)","default":"1","_order":18,"pid":0.9592110247467964},"mb_offs":{"id":"mb_offs","type":"string","placeholder":"","advanced":true,"desc":"Eddy: Specifies missing slices at top or bottom","default":"0","_order":19,"pid":0.9990618327605267},"flm":{"id":"flm","type":"enum","placeholder":"","advanced":true,"desc":"Eddy: Spatial model for the field generated by eddy currents","default":"quadratic","_order":20,"pid":0.6853763634436016,"options":[{"desc":"","label":"linear","value":"linear"},{"desc":"","label":"quadratic","value":"quadratic"},{"desc":"","label":"cubic","value":"cubic"}]},"slm":{"id":"slm","type":"enum","placeholder":"","advanced":true,"desc":"Model for how diffusion gradients generate eddy currents","default":"none","_order":21,"pid":0.17876976610141004,"options":[{"desc":"","label":"none","value":"none"},{"desc":"","label":"linear","value":"linear"},{"desc":"","label":"quadratic","value":"quadratic"}]},"eddy_fwhm":{"id":"eddy_fwhm","type":"string","placeholder":"","advanced":true,"desc":"Eddy: Filter width to use for pre-filtering of data for the estimation process","default":"0","_order":22,"pid":0.858145159247544},"eddy_niter":{"id":"eddy_niter","type":"string","placeholder":"","advanced":false,"desc":"Eddy: Specifies how many iterations should be run","default":"5","_order":23,"pid":0.9344741224003135},"fep":{"id":"fep","type":"boolean","placeholder":"","advanced":true,"desc":"fill empty planes","default":false,"_order":24,"pid":0.9905147296459615},"eddy_interp":{"id":"eddy_interp","type":"enum","placeholder":"","advanced":true,"desc":"Eddy: Specifies interpolation model during estimation","default":"spline","_order":25,"pid":0.7669559526200187,"options":[{"desc":"","label":"spline","value":"spline"},{"desc":"","label":"trilinear","value":"trilinear"}]},"resamp":{"id":"resamp","type":"enum","placeholder":"","advanced":true,"desc":"Eddy: Specifies final resampling strategy","default":"jac","_order":26,"pid":0.3624560111430819,"options":[{"desc":"","label":"jac","value":"jac"},{"desc":"","label":"lsr","value":"lsr"}]},"nvoxhp":{"id":"nvoxhp","type":"string","placeholder":"","advanced":true,"desc":"Eddy: Specifies number of voxels to use for GP hyperparameter estimation","default":"1000","_order":27,"pid":0.7804386542770201},"ff":{"id":"ff","type":"string","placeholder":"","advanced":true,"desc":"Fudge factor that imposes Q-space smoothing during estimation","default":"10","_order":28,"pid":0.34983964230980513},"dont_sep_offs_move":{"id":"dont_sep_offs_move","type":"boolean","placeholder":"","advanced":true,"desc":"Eddy: Do not attempt to separate subject movement from field DC component","default":false,"_order":29,"pid":0.616557361360264},"dont_peas":{"id":"dont_peas","type":"boolean","placeholder":"","advanced":true,"desc":"Eddy: Do not end with an alignment of shells to each other","default":false,"_order":30,"pid":0.524749071359492},"repol":{"id":"repol","type":"boolean","placeholder":"","advanced":false,"desc":"Eddy: Replace outliers","default":false,"_order":31,"pid":0.680559242948988},"ol_nstd":{"id":"ol_nstd","type":"string","placeholder":"","advanced":true,"desc":"Eddy: No. of standard deviations away a slice must be to qualify as an outlier","default":"4","_order":32,"pid":0.2850876304278329},"ol_nvox":{"id":"ol_nvox","type":"string","placeholder":"","advanced":true,"desc":"Eddy: The minimum no. of intracerebral voxels in a slice to consider it as an outlier","default":"250","_order":33,"pid":0.22666893748859263},"ol_type":{"id":"ol_type","type":"enum","placeholder":"","advanced":true,"desc":"Eddy: Base outlier detection on slices (sw) multi-band groups (mb) or both (both)","default":"sw","_order":34,"pid":0.8295778812070527,"options":[{"desc":"","label":"sw","value":"sw"},{"desc":"","label":"mb","value":"mb"},{"desc":"","label":"both","value":"both"}]},"ol_pos":{"id":"ol_pos","type":"boolean","placeholder":"","advanced":true,"desc":"Consider both positive and negative outliers","default":false,"_order":35,"pid":0.8686137423005784},"ol_sqr":{"id":"ol_sqr","type":"boolean","placeholder":"","advanced":true,"desc":"Eddy: Consider outliers in sum-of-squared distribution","default":false,"_order":36,"pid":0.603459663918551},"mporder":{"id":"mporder","type":"string","placeholder":"","advanced":false,"desc":"Eddy: Temporal order of movement","default":"0","_order":37,"pid":0.17182200395752756},"s2v_niter":{"id":"s2v_niter","type":"string","placeholder":"","advanced":true,"desc":"Eddy: No. iterations for estimating slice-to-vol movement","default":"5","_order":38,"pid":0.6879501350286659},"s2v_lambda":{"id":"s2v_lambda","type":"string","placeholder":"","advanced":true,"desc":"Eddy: Strength of temporal regularisation of slice-to-vol movement.","default":"1","_order":39,"pid":0.31432304325825955},"s2v_interp":{"id":"s2v_interp","type":"enum","placeholder":"","advanced":true,"desc":"","default":"trilinear","_order":40,"pid":0.8543273484678746,"options":[{"desc":"","label":"trilinear","value":"trilinear"},{"desc":"","label":"spline","value":"spline"}]},"estimate_move_by_susceptibility":{"id":"estimate_move_by_susceptibility","type":"boolean","placeholder":"","advanced":true,"desc":"Eddy: When specified eddy estimates how the susceptibility field changes with subject movement.","default":false,"_order":41,"pid":0.98379593393476},"mbs_iter":{"id":"mbs_iter","type":"string","placeholder":"","advanced":true,"desc":"Eddy: Number of iterations for susceptibility-by-movement estimation","default":"10","_order":42,"pid":0.9613047649459054},"mbs_lambda":{"id":"mbs_lambda","type":"string","placeholder":"","advanced":true,"desc":"Eddy: Specifies the balance between data and smoothness for the susceptibility rate-of-change fields","default":"10","_order":43,"pid":0.14923097750235392},"mbs_ksp":{"id":"mbs_ksp","type":"string","placeholder":"","advanced":true,"desc":"Eddy: Specifies the spline knot-spacing of the susceptibility rate-of-change fields","default":"10","_order":44,"pid":0.7954199442408325},"data_is_shelled":{"id":"data_is_shelled","type":"boolean","placeholder":"","advanced":true,"desc":"Eddy: Do not check that data is shelled. Trust the user","default":false,"_order":45,"pid":0.9035018733106066},"slspec":{"id":"slspec","type":"string","placeholder":"","advanced":false,"desc":"","default":"","_order":46,"pid":0.058789866000652724,"multiline":true,"optional":true}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c54df0f12cbcc01e1635b01","id":"diff","datatype":"58c33c5fe13a50849b25879b","desc":"The path to the DWI datatype"}],"outputs":[{"datatype_tags":["preprocessed","eddy"],"output_on_root":false,"archive":true,"_id":"5c54df0f12cbcc01e1635b03","id":"output","datatype":"58c33c5fe13a50849b25879b","datatype_tags_pass":"diff","files":null,"desc":"The preprocessed DWI"},{"datatype_tags":["eddy_params"],"output_on_root":false,"archive":true,"_id":"5e754703de643b614b2a7c8e","id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null,"desc":"eddy qc files and all other generated data derivatives"},{"datatype_tags":["eddyqc","eddy_quad"],"output_on_root":false,"archive":true,"_id":"60ef76e8ddc2dffc996630a5","id":"eddy_quad","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null}],"github_branch":"eddy-only-v1.0","github":"brainlife/app-FSLTopupEddy","name":"FSL Eddy (OpenMP)","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a416962f3d3800f12e2f3"}],"desc":"This app will correct for encoding, eddy currents, and motion artifacts using FSL's Topup and Eddy functions.","__v":2303,"create_date":"2021-07-14T23:44:40.707Z","desc_override":"This app will correct for eddy-currents and motion using FSL eddy_openmp. Note: since this does not use GPU multi-threading, it is much slower than FSL Eddy (CUDA).","doi":"10.25663/brainlife.app.543","_canedit":true},{"_id":"60ef1c3dddc2df157165f72b","projects":[],"admins":["16"],"tags":["preprocessing"],"removed":false,"stats":{"requested":3136,"users":20,"success_rate":64.049955396967,"gitinfo":{"desc":"This app will correct for encoding, eddy currents, and motion artifacts using FSL's Topup and Eddy functions.","tags":["preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null}]},"runtime_mean":4527528.96,"runtime_std":8363821.149115121,"resources":[{"resource_id":"5ffc99da0df8ff7fc740c95a","name":"Bridges2 @ PSC (GPU-Shared)","_id":"634a415f62f3d3800f12e2e8"}],"examples":2,"groups":40},"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"refvol":{"id":"refvol","type":"string","placeholder":"","advanced":false,"desc":"This is the volume number to use as a reference for correcting motion in the image.\n\nDefault: 0 (i.e. first volume with zero indexing)","default":"0","_order":2,"pid":0.43637899994048546}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c54df0f12cbcc01e1635b01","id":"dwi","datatype":"58c33c5fe13a50849b25879b","desc":"Input dwi to perform FSL eddy."}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5c54df0f12cbcc01e1635b03","id":"output","datatype":"58c33c5fe13a50849b25879b","datatype_tags_pass":"dwi","files":null,"desc":"The preprocessed DWI, with the corrected bvectors and bvals"},{"datatype_tags":["ecclog"],"output_on_root":false,"archive":true,"_id":"60ef1d4dddc2dffad165f7be","id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null}],"github_branch":"eddy-correct-v1.0","github":"brainlife/app-FSLTopupEddy","name":"FSL Eddy-correct","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a416062f3d3800f12e2e9"}],"desc":"This app will correct for encoding, eddy currents, and motion artifacts using FSL's Topup and Eddy functions.","__v":2305,"desc_override":"This app will run eddy_correct on a diffusion-weighted MRI (DWI) image. This app is intended to be used on datasets that have either 1) have already been corrected via top-up or 2) cannot be corrected with top-up. This will ","create_date":"2021-07-14T17:17:49.411Z","doi":"10.25663/brainlife.app.542","_canedit":true},{"_id":"607084bcc7f80a838695d8f4","projects":[],"admins":["1","19","16"],"tags":[],"removed":false,"config":{"input":{"type":"input","file_id":"bold","input_id":"input"},"events":{"type":"input","file_id":"events","input_id":"input"},"events_json":{"type":"input","file_id":"events_json","input_id":"input"},"sbref":{"type":"input","file_id":"sbref","input_id":"input"},"sbref_json":{"type":"input","file_id":"sbref_json","input_id":"input"},"physio":{"type":"input","file_id":"physio","input_id":"input"},"physio_json":{"type":"input","file_id":"physio_json","input_id":"input"},"reorient":{"id":"reorient","type":"boolean","placeholder":"","desc":"reorient the T2","default":true,"_order":2,"pid":0.3993158790145803},"crop":{"id":"crop","type":"boolean","placeholder":"","desc":"cropping only works for t1/t2","default":false,"_order":3,"pid":0.29727053725940467,"readonly":true}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5bc0e221afd0bc0027efccf0","id":"input","datatype":"59b685a08e5d38b0b331ddc5"}],"outputs":[{"datatype_tags":["crop_reorient"],"output_on_root":false,"archive":true,"_id":"5bc0e221afd0bc0027efccf1","id":"out","datatype":"59b685a08e5d38b0b331ddc5","datatype_tags_pass":"input","files":{"t2":"out.nii.gz"}}],"name":"FSL Reorient - Task","github":"brainlife/app-crop_reorient","github_branch":"2.0","user_id":"1","contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a3fff62f3d3800f12d49e"},{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a3fff62f3d3800f12d49f"},{"name":"Brad Caron","email":null,"_id":"634a3fff62f3d3800f12d4a0"}],"desc":"This application will crop and reorient the T1 image to standard orientation and FOV using FSL's fslreorient2std and robustfov. ","stats":{"requested":9743,"users":98,"success_rate":95.85716278420979,"gitinfo":{"desc":"This application will crop and reorient the T1 image to standard orientation and FOV using FSL's fslreorient2std and robustfov. ","tags":[],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":596052.68,"runtime_std":2204038.0885753445,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3ffe62f3d3800f12d49c"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3ffe62f3d3800f12d49d"}],"examples":1,"groups":141},"__v":2921,"create_date":"2021-04-09T16:45:48.597Z","desc_override":"Uses fslreorient2std to reorient an image in standard orientation.","doi":"10.25663/brainlife.app.502","_canedit":true},{"_id":"60707f8bc7f80a0cb895d6ca","projects":[],"admins":["1","16"],"tags":[],"removed":false,"name":"FSL Reorient and Crop T1","desc":"This application will crop and reorient the T1 image to standard orientation and FOV using FSL's fslreorient2std and robustfov. ","github":"brainlife/app-crop_reorient","github_branch":"2.0","config":{"input":{"type":"input","file_id":"t1","input_id":"input"},"reorient":{"type":"boolean","placeholder":"","desc":"Run fslreorient2std. This command reorients an image to match the orientation of the standard template images (MNI152) so that they appear \"the same way around\" in FSLView. It requires that the image labels are correct in FSLView before this is run. It is also not a registration tool, so it will not align the image to standard space, it will only apply 90, 180 or 270 degree rotations about the different axes as necessary to get the labels in the same position as the standard template.","default":true,"id":"reorient","pid":0.953008966213392,"_order":2},"crop":{"type":"boolean","placeholder":"","desc":"Run robustfov to reduce field-of-view of image to remove lower head and neck.\n","default":true,"id":"crop","pid":0.307246193466431,"_order":3}},"user_id":"1","outputs":[{"datatype_tags":["crop_reorient"],"output_on_root":false,"archive":true,"_id":"5a0f38bf31769f1e4d46cc59","id":"out","datatype":"58c33bcee13a50849b25879a","files":{"t1":"out.nii.gz"},"datatype_tags_pass":"input","desc":"The crop and/or reoriented T1"}],"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5a0f38bf31769f1e4d46cc5a","id":"input","datatype":"58c33bcee13a50849b25879a","desc":"The path to the anat/t1w datatype"}],"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a3fec62f3d3800f12d463"},{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a3fec62f3d3800f12d464"},{"name":"Brad Caron","email":null,"_id":"634a3fec62f3d3800f12d465"}],"__v":2919,"stats":{"requested":9743,"users":98,"success_rate":95.85716278420979,"gitinfo":{"desc":"This application will crop and reorient the T1 image to standard orientation and FOV using FSL's fslreorient2std and robustfov. ","tags":[],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":596052.68,"runtime_std":2204038.0885753445,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3fec62f3d3800f12d461"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3fec62f3d3800f12d462"}],"examples":1,"groups":141},"create_date":"2021-04-09T16:23:39.597Z","desc_override":"Uses fslreorient2std to reorient an image in standard orientation, and uses robustfov to crop the image.","doi":"10.25663/brainlife.app.500","_canedit":true},{"_id":"6070841ec7f80a148795d7c4","projects":[],"admins":["1","19","16"],"tags":[],"removed":false,"config":{"input":{"type":"input","file_id":"t2","input_id":"input"},"reorient":{"id":"reorient","type":"boolean","placeholder":"","desc":"reorient the T2","default":true,"_order":2,"pid":0.029121497866457124},"crop":{"id":"crop","type":"boolean","placeholder":"","desc":"crop the T2","default":true,"_order":3,"pid":0.6843968439886177}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5bc0e221afd0bc0027efccf0","id":"input","datatype":"594c0325fa1d2e5a1f0beda5"}],"outputs":[{"datatype_tags":["crop_reorient"],"output_on_root":false,"archive":true,"_id":"5bc0e221afd0bc0027efccf1","id":"out","datatype":"594c0325fa1d2e5a1f0beda5","datatype_tags_pass":"input","files":{"t2":"out.nii.gz"}}],"name":"FSL Reorient and Crop T2","github":"brainlife/app-crop_reorient","github_branch":"2.0","user_id":"1","contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a3ff662f3d3800f12d483"},{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a3ff662f3d3800f12d484"},{"name":"Brad Caron","email":null,"_id":"634a3ff662f3d3800f12d485"}],"desc":"This application will crop and reorient the T1 image to standard orientation and FOV using FSL's fslreorient2std and robustfov. ","stats":{"requested":9743,"users":98,"success_rate":95.85716278420979,"gitinfo":{"desc":"This application will crop and reorient the T1 image to standard orientation and FOV using FSL's fslreorient2std and robustfov. ","tags":[],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":596052.68,"runtime_std":2204038.0885753445,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3ff562f3d3800f12d481"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3ff562f3d3800f12d482"}],"examples":1,"groups":141},"__v":2920,"create_date":"2021-04-09T16:43:10.409Z","desc_override":"Uses fslreorient2std to reorient an image in standard orientation, and uses robustfov to crop the image.","doi":"10.25663/brainlife.app.501","_canedit":true},{"_id":"5c54df0f12cbcc01e1635aff","stats":{"stars":0,"requested":3136,"users":20,"success_rate":64.049955396967,"serviceinfo":{"_id":"5d729e1f78356a109788b251","counts":{"_id":"5e5c3dde87cac78efdab13ef","failed":27,"finished":181,"removed":241,"requested":276,"running":246,"running_sync":0,"stop_requested":42},"success_rate":87.01923076923077,"users":10,"readme_status":"ok","runtime_mean":9414714.88,"runtime_std":4859929.9095257055,"service":"brainlife/app-FSLTopupEddy","__v":0},"gitinfo":{"desc":"This app will correct for encoding, eddy currents, and motion artifacts using FSL's Topup and Eddy functions.","tags":["preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null}]},"runtime_mean":4527528.96,"runtime_std":8363821.149115121,"resources":[{"resource_id":"5ffc99da0df8ff7fc740c95a","name":"Bridges2 @ PSC (GPU-Shared)","_id":"634a34f662f3d3800f118ee7"}],"examples":1,"groups":40},"projects":[],"admins":["16"],"tags":["preprocessing"],"removed":false,"config":{"diff":{"type":"input","file_id":"dwi","input_id":"diff"},"bvec":{"type":"input","file_id":"bvecs","input_id":"diff"},"bval":{"type":"input","file_id":"bvals","input_id":"diff"},"rdif":{"type":"input","file_id":"dwi","input_id":"rdiff"},"rbvc":{"type":"input","file_id":"bvecs","input_id":"rdiff"},"rbvl":{"type":"input","file_id":"bvals","input_id":"rdiff"},"param":{"id":"param","type":"number","placeholder":"","desc":"This is the 'dwell time'. Please see https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/eddy/Faq#How_do_I_know_what_to_put_into_my_--acqp_file for more information about this specific parameter.","default":null,"_order":2,"pid":0.9017507649348133},"encode":{"id":"encode","type":"enum","placeholder":"","desc":"Phase encoding direction of the diff (not rdiff), i.e. first, inputted dwi.\n\nfor example, if the phase encoding direction of the first inputted dwi is 'PA', then select 'PA'. If it was 'AP', then select 'AP'","default":"PA","_order":3,"pid":0.22239034344437214,"options":[{"desc":"Phase encoding direction of first input was done in posterior/anterior direction","label":"posterior-->anterior","value":"PA"},{"desc":"Phase encoding direction of first input was done in anterior/posterior","label":"anterior-->posterior","value":"AP"},{"desc":"Phase encoding direction of first input was done in left/right","label":"left-->right","value":"LR"},{"desc":"Phase encoding direction of first input was done in right/left","label":"right-->left","value":"RL"}]}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c54df0f12cbcc01e1635b01","id":"diff","datatype":"58c33c5fe13a50849b25879b","desc":"Input dwi to perform FSL top-up/eddy."},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c54df0f12cbcc01e1635b00","id":"rdiff","datatype":"58c33c5fe13a50849b25879b","desc":"Reverse encoded dwi image needed to run top-up"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5c54df0f12cbcc01e1635b03","id":"dwi","datatype":"58c33c5fe13a50849b25879b","datatype_tags_pass":"diff","files":null,"desc":"The preprocessed DWI, with the corrected bvectors and bvals"},{"datatype_tags":["dwi","brain"],"output_on_root":false,"archive":true,"_id":"5c54df0f12cbcc01e1635b02","id":"mask","datatype":"5a281aee2c214c9ba83ce620","datatype_tags_pass":null,"files":null,"desc":"The brainmask of the DWI image"}],"github_branch":"1.1","github":"brainlife/app-FSLTopupEddy","name":"FSL Top-up & Eddy","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a34f762f3d3800f118ee8"}],"create_date":"2019-02-02T00:06:39.938Z","desc":"This app will correct for encoding, eddy currents, and motion artifacts using FSL's Topup and Eddy functions.","doi":"10.25663/brainlife.app.155","__v":8843,"_canedit":true},{"_id":"5e6e72838a20890d8a8e96af","projects":[],"admins":["16"],"tags":["preprocessing"],"removed":false,"stats":{"requested":3136,"users":20,"success_rate":64.049955396967,"gitinfo":{"desc":"This app will correct for encoding, eddy currents, and motion artifacts using FSL's Topup and Eddy functions.","tags":["preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null}]},"runtime_mean":4527528.96,"runtime_std":8363821.149115121,"resources":[{"resource_id":"5ffc99da0df8ff7fc740c95a","name":"Bridges2 @ PSC (GPU-Shared)","_id":"634a389862f3d3800f11f6bf"}],"examples":2,"groups":40},"config":{"diff":{"type":"input","file_id":"dwi","input_id":"diff"},"bvec":{"type":"input","file_id":"bvecs","input_id":"diff"},"bval":{"type":"input","file_id":"bvals","input_id":"diff"},"rdif":{"type":"input","file_id":"dwi","input_id":"rdiff"},"rbvc":{"type":"input","file_id":"bvecs","input_id":"rdiff"},"rbvl":{"type":"input","file_id":"bvals","input_id":"rdiff"},"param":{"id":"param","type":"number","placeholder":"","desc":"This is the 'dwell time'. Please see https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/eddy/Faq#How_do_I_know_what_to_put_into_my_--acqp_file for more information about this specific parameter.","default":null,"_order":2,"pid":0.47176716779749617},"encode":{"id":"encode","type":"enum","placeholder":"","desc":"Phase encoding direction of the diff (not rdiff), i.e. first, inputted dwi.\n\nfor example, if the phase encoding direction of the first inputted dwi is 'PA', then select 'PA'. If it was 'AP', then select 'AP'","default":"PA","_order":3,"pid":0.010858383388519632,"options":[{"desc":"Phase encoding direction of first input was done in posterior/anterior direction","label":"posterior-->anterior","value":"PA"},{"desc":"Phase encoding direction of first input was done in anterior/posterior","label":"anterior-->posterior","value":"AP"},{"desc":"Phase encoding direction of first input was done in left/right","label":"left-->right","value":"LR"},{"desc":"Phase encoding direction of first input was done in right/left","label":"right-->left","value":"RL"}]},"warpres":{"id":"warpres","type":"string","placeholder":"","advanced":true,"desc":"topup: (approximate) resolution (in mm) of warp basis for the different sub-sampling levels","default":"20,16,14,12,10,6,4,4,4","_order":4,"pid":0.6176985332260169},"subsamp":{"id":"subsamp","type":"string","placeholder":"","advanced":true,"desc":"topup: sub-sampling scheme","default":"2,2,2,2,2,1,1,1,1","_order":5,"pid":0.39139051102785904},"fwhm":{"id":"fwhm","type":"string","placeholder":"","advanced":true,"desc":"topup: FWHM (in mm) of gaussian smoothing kernel","default":"8,6,4,3,3,2,1,0,0","_order":6,"pid":0.6343507271081424},"miter":{"id":"miter","type":"string","placeholder":"","advanced":true,"desc":"topup: number of iterations","default":"5,5,5,5,5,10,10,20,20","_order":7,"pid":0.9117914369528686},"lambda":{"id":"lambda","type":"string","placeholder":"","advanced":false,"desc":"topup: Weight of regularisation","default":"0.005,0.001,0.0001,0.000015,0.000005,0.0000005,0.00000005,0.0000000005,0.00000000001","_order":8,"pid":0.37229709916534337},"ssqlambda":{"id":"ssqlambda","type":"string","placeholder":"","advanced":true,"desc":"topup: If set (=1), lambda is weighted by current ssq","default":"1","_order":9,"pid":0.2698159674293171},"regmod":{"id":"regmod","type":"enum","placeholder":"","advanced":true,"desc":"topup: Model for regularisation of warp-field","default":"bending_energy","_order":10,"pid":0.3322796916099898,"options":[{"desc":"","label":"membrane_energy","value":"membrane_energy"},{"desc":"","label":"bending_energy","value":"bending_energy"}]},"estmov":{"id":"estmov","type":"string","placeholder":"","advanced":true,"desc":"topup: Estimate movements if set","default":"1,1,1,1,1,0,0,0,0","_order":11,"pid":0.33232414156352286},"minmet":{"id":"minmet","type":"string","placeholder":"","advanced":true,"desc":"topup: Minimisation method 0=Levenberg-Marquardt, 1=Scaled Conjugate Gradient","default":"0,0,0,0,0,1,1,1,1","_order":12,"pid":0.5791773376292113},"splineorder":{"id":"splineorder","type":"string","placeholder":"","advanced":true,"desc":"topup: Order of spline, 2->Qadratic spline, 3->Cubic spline","default":"3","_order":13,"pid":0.19457320169838355},"numprec":{"id":"numprec","type":"enum","placeholder":"","advanced":true,"desc":"topup: Precision for representing Hessian, double or float","default":"double","_order":14,"pid":0.9039868879937837,"options":[{"desc":"","label":"double","value":"double"},{"desc":"","label":"float","value":"float"}]},"interp":{"id":"interp","type":"enum","placeholder":"","advanced":true,"desc":"topup: Image interpolation model, linear or spline","default":"spline","_order":15,"pid":0.4958398458213643,"options":[{"desc":"","label":"linear","value":"linear"},{"desc":"","label":"spline","value":"spline"}]},"scale":{"id":"scale","type":"boolean","placeholder":"","advanced":true,"desc":"topup: If set (=1), the images are individually scaled to a common mean","default":true,"_order":16,"pid":0.9457924412767379},"regrid":{"id":"regrid","type":"boolean","placeholder":"","advanced":true,"desc":"topup: If set (=1), the calculations are done in a different grid","default":true,"_order":17,"pid":0.5370352261894723},"mb":{"id":"mb","type":"string","placeholder":"","advanced":true,"desc":"Eddy: Specifies multi-band factor (number of simultaneous slices)","default":"1","_order":18,"pid":0.6330449877275185},"mb_offs":{"id":"mb_offs","type":"string","placeholder":"","advanced":true,"desc":"Eddy: Specifies missing slices at top or bottom","default":"0","_order":19,"pid":0.0898111601231939},"flm":{"id":"flm","type":"enum","placeholder":"","advanced":true,"desc":"Eddy: Spatial model for the field generated by eddy currents","default":"quadratic","_order":20,"pid":0.6944737639130367,"options":[{"desc":"","label":"linear","value":"linear"},{"desc":"","label":"quadratic","value":"quadratic"},{"desc":"","label":"cubic","value":"cubic"}]},"slm":{"id":"slm","type":"enum","placeholder":"","advanced":true,"desc":"Model for how diffusion gradients generate eddy currents","default":"none","_order":21,"pid":0.9875654259773208,"options":[{"desc":"","label":"none","value":"none"},{"desc":"","label":"linear","value":"linear"},{"desc":"","label":"quadratic","value":"quadratic"}]},"eddy_fwhm":{"id":"eddy_fwhm","type":"string","placeholder":"","advanced":true,"desc":"Eddy: Filter width to use for pre-filtering of data for the estimation process","default":"0","_order":22,"pid":0.9559609598179551},"eddy_niter":{"id":"eddy_niter","type":"string","placeholder":"","advanced":false,"desc":"Eddy: Specifies how many iterations should be run","default":"5","_order":23,"pid":0.7427579189888328},"fep":{"id":"fep","type":"boolean","placeholder":"","advanced":true,"desc":"fill empty planes","default":false,"_order":24,"pid":0.544445381914593},"eddy_interp":{"id":"eddy_interp","type":"enum","placeholder":"","advanced":true,"desc":"Eddy: Specifies interpolation model during estimation","default":"spline","_order":25,"pid":0.811756879941238,"options":[{"desc":"","label":"spline","value":"spline"},{"desc":"","label":"trilinear","value":"trilinear"}]},"resamp":{"id":"resamp","type":"enum","placeholder":"","advanced":true,"desc":"Eddy: Specifies final resampling strategy","default":"jac","_order":26,"pid":0.8960197790354171,"options":[{"desc":"","label":"jac","value":"jac"},{"desc":"","label":"lsr","value":"lsr"}]},"nvoxhp":{"id":"nvoxhp","type":"string","placeholder":"","advanced":true,"desc":"Eddy: Specifies number of voxels to use for GP hyperparameter estimation","default":"1000","_order":27,"pid":0.8303170142007275},"ff":{"id":"ff","type":"string","placeholder":"","advanced":true,"desc":"Fudge factor that imposes Q-space smoothing during estimation","default":"10","_order":28,"pid":0.1196623808557411},"dont_sep_offs_move":{"id":"dont_sep_offs_move","type":"boolean","placeholder":"","advanced":true,"desc":"Eddy: Do not attempt to separate subject movement from field DC component","default":false,"_order":29,"pid":0.08840237787361782},"dont_peas":{"id":"dont_peas","type":"boolean","placeholder":"","advanced":true,"desc":"Eddy: Do not end with an alignment of shells to each other","default":false,"_order":30,"pid":0.6458279582507854},"repol":{"id":"repol","type":"boolean","placeholder":"","advanced":false,"desc":"Eddy: Replace outliers","default":false,"_order":31,"pid":0.21537856409330114},"ol_nstd":{"id":"ol_nstd","type":"string","placeholder":"","advanced":true,"desc":"Eddy: No. of standard deviations away a slice must be to qualify as an outlier","default":"4","_order":32,"pid":0.9283961803888734},"ol_nvox":{"id":"ol_nvox","type":"string","placeholder":"","advanced":true,"desc":"Eddy: The minimum no. of intracerebral voxels in a slice to consider it as an outlier","default":"250","_order":33,"pid":0.5500721814457713},"ol_type":{"id":"ol_type","type":"enum","placeholder":"","advanced":true,"desc":"Eddy: Base outlier detection on slices (sw) multi-band groups (mb) or both (both)","default":"sw","_order":34,"pid":0.999873942002225,"options":[{"desc":"","label":"sw","value":"sw"},{"desc":"","label":"mb","value":"mb"},{"desc":"","label":"both","value":"both"}]},"ol_pos":{"id":"ol_pos","type":"boolean","placeholder":"","advanced":true,"desc":"Consider both positive and negative outliers","default":false,"_order":35,"pid":0.5596517730795828},"ol_sqr":{"id":"ol_sqr","type":"boolean","placeholder":"","advanced":true,"desc":"Eddy: Consider outliers in sum-of-squared distribution","default":false,"_order":36,"pid":0.1349933252719846},"mporder":{"id":"mporder","type":"string","placeholder":"","advanced":false,"desc":"Eddy: Temporal order of movement","default":"0","_order":37,"pid":0.98882543348141},"s2v_niter":{"id":"s2v_niter","type":"string","placeholder":"","advanced":true,"desc":"Eddy: No. iterations for estimating slice-to-vol movement","default":"5","_order":38,"pid":0.44344591818983536},"s2v_lambda":{"id":"s2v_lambda","type":"string","placeholder":"","advanced":true,"desc":"Eddy: Strength of temporal regularisation of slice-to-vol movement.","default":"1","_order":39,"pid":0.4977406774854073},"s2v_interp":{"id":"s2v_interp","type":"enum","placeholder":"","advanced":true,"desc":"","default":"trilinear","_order":40,"pid":0.07210554018629789,"options":[{"desc":"","label":"trilinear","value":"trilinear"},{"desc":"","label":"spline","value":"spline"}]},"estimate_move_by_susceptibility":{"id":"estimate_move_by_susceptibility","type":"boolean","placeholder":"","advanced":false,"desc":"Eddy: When specified eddy estimates how the susceptibility field changes with subject movement.","default":false,"_order":41,"pid":0.0032728242350702486},"mbs_iter":{"id":"mbs_iter","type":"string","placeholder":"","advanced":true,"desc":"Eddy: Number of iterations for susceptibility-by-movement estimation","default":"10","_order":42,"pid":0.8536765991357698},"mbs_lambda":{"id":"mbs_lambda","type":"string","placeholder":"","advanced":true,"desc":"Eddy: Specifies the balance between data and smoothness for the susceptibility rate-of-change fields","default":"10","_order":43,"pid":0.2868498738341725},"mbs_ksp":{"id":"mbs_ksp","type":"string","placeholder":"","advanced":true,"desc":"Eddy: Specifies the spline knot-spacing of the susceptibility rate-of-change fields","default":"10","_order":44,"pid":0.5741181177678505},"data_is_shelled":{"id":"data_is_shelled","type":"boolean","placeholder":"","advanced":true,"desc":"Eddy: Do not check that data is shelled. Trust the user","default":false,"_order":45,"pid":0.5065578453835116},"slspec":{"id":"slspec","type":"string","placeholder":"","advanced":false,"desc":"","default":"","_order":46,"pid":0.0914318404198824,"multiline":true,"optional":true},"mergefull":{"id":"mergefull","type":"boolean","placeholder":"","advanced":false,"desc":"","default":false,"_order":47,"pid":0.32621050473844704},"reslice":{"id":"reslice","type":"boolean","placeholder":"","advanced":true,"desc":"If, for wahtever reason, the two DWI images do not hae the same number of slices, set reslice to true and it will reslice the rdif image to diff","default":false,"_order":48,"pid":0.36224746606694846}},"inputs":[{"id":"diff","desc":"The path to the DWI datatype","datatype":"58c33c5fe13a50849b25879b","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c54df0f12cbcc01e1635b01"},{"id":"rdiff","desc":"Reverse encoded dwi image needed to run top-up","datatype":"58c33c5fe13a50849b25879b","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c54df0f12cbcc01e1635b00"}],"outputs":[{"id":"output","desc":"The preprocessed DWI","datatype":"58c33c5fe13a50849b25879b","datatype_tags":["preprocessed"],"datatype_tags_pass":"diff","output_on_root":false,"files":null,"archive":true,"_id":"5c54df0f12cbcc01e1635b03"},{"id":"mask","desc":"The brainmask of the preprocessed DWI","datatype":"5a281aee2c214c9ba83ce620","datatype_tags":["dwi","brain"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5c54df0f12cbcc01e1635b02"},{"id":"eddy_quad","desc":"eddy qc files and all other generated data derivatives","datatype":"59c3eae633fc1cf9ead71679","datatype_tags":["eddyqc"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5e754703de643b614b2a7c8e"},{"id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags":["derivatives"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"60fafb86b99111933cb71925"},{"id":"regressors","datatype":"5c4f6a8af9109beac4b3dae0","datatype_tags":["eddyqc"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"6230b6335d8ab5d5f0389104"}],"github_branch":"cuda-v1.0","github":"brainlife/app-FSLTopupEddy","name":"FSL Top-up & Eddy - CUDA","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a389862f3d3800f11f6c0"}],"desc":"This app will correct for encoding, eddy currents, and motion artifacts using FSL's Topup and Eddy functions.","__v":5374,"create_date":"2020-03-15T18:22:59.530Z","doi":"10.25663/brainlife.app.287","_canedit":true},{"_id":"62d1aab8f3194eded6010de9","user_id":"16","projects":[],"admins":["16"],"name":"FSL Top-up & Eddy Correct","github":"brainlife/app-FSLTopupEddy","github_branch":"topup-eddy_correct-v1.0","desc":"This app will correct for encoding, eddy currents, and motion artifacts using FSL's Topup and Eddy functions.","tags":["preprocessing"],"contributors":[{"name":"Brad Caron","email":null,"_id":"634a459b62f3d3800f131131"}],"config":{"diff":{"type":"input","file_id":"dwi","input_id":"diff"},"bvec":{"type":"input","file_id":"bvecs","input_id":"diff"},"bval":{"type":"input","file_id":"bvals","input_id":"diff"},"rdif":{"type":"input","file_id":"dwi","input_id":"rdiff"},"rbvc":{"type":"input","file_id":"bvecs","input_id":"rdiff"},"rbvl":{"type":"input","file_id":"bvals","input_id":"rdiff"},"param":{"id":"param","type":"number","placeholder":"","desc":"This is the 'dwell time'. Please see https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/eddy/Faq#How_do_I_know_what_to_put_into_my_--acqp_file for more information about this specific parameter.","default":null,"_order":2,"pid":0.32955644004097584},"encode":{"id":"encode","type":"enum","placeholder":"","desc":"Phase encoding direction of the diff (not rdiff), i.e. first, inputted dwi.\n\nfor example, if the phase encoding direction of the first inputted dwi is 'PA', then select 'PA'. If it was 'AP', then select 'AP'","default":"PA","_order":3,"pid":0.30712699692945256,"options":[{"desc":"Phase encoding direction of first input was done in posterior/anterior direction","label":"posterior-->anterior","value":"PA"},{"desc":"Phase encoding direction of first input was done in anterior/posterior","label":"anterior-->posterior","value":"AP"},{"desc":"Phase encoding direction of first input was done in left/right","label":"left-->right","value":"LR"},{"desc":"Phase encoding direction of first input was done in right/left","label":"right-->left","value":"RL"}]},"warpres":{"id":"warpres","type":"string","placeholder":"","advanced":true,"desc":"topup: (approximate) resolution (in mm) of warp basis for the different sub-sampling levels","default":"20,16,14,12,10,6,4,4,4","_order":4,"pid":0.6472231094345972},"subsamp":{"id":"subsamp","type":"string","placeholder":"","advanced":true,"desc":"topup: sub-sampling scheme","default":"2,2,2,2,2,1,1,1,1","_order":5,"pid":0.3968312750376327},"fwhm":{"id":"fwhm","type":"string","placeholder":"","advanced":true,"desc":"topup: FWHM (in mm) of gaussian smoothing kernel","default":"8,6,4,3,3,2,1,0,0","_order":6,"pid":0.8262348674447946},"miter":{"id":"miter","type":"string","placeholder":"","advanced":true,"desc":"topup: number of iterations","default":"5,5,5,5,5,10,10,20,20","_order":7,"pid":0.45051591011071757},"lambda":{"id":"lambda","type":"string","placeholder":"","advanced":false,"desc":"topup: Weight of regularisation","default":"0.005,0.001,0.0001,0.000015,0.000005,0.0000005,0.00000005,0.0000000005,0.00000000001","_order":8,"pid":0.6094497435435381},"ssqlambda":{"id":"ssqlambda","type":"string","placeholder":"","advanced":true,"desc":"topup: If set (=1), lambda is weighted by current ssq","default":"1","_order":9,"pid":0.755338919475556},"regmod":{"id":"regmod","type":"enum","placeholder":"","advanced":true,"desc":"topup: Model for regularisation of warp-field","default":"bending_energy","_order":10,"pid":0.19967483129326857,"options":[{"desc":"","label":"membrane_energy","value":"membrane_energy"},{"desc":"","label":"bending_energy","value":"bending_energy"}]},"estmov":{"id":"estmov","type":"string","placeholder":"","advanced":true,"desc":"topup: Estimate movements if set","default":"1,1,1,1,1,0,0,0,0","_order":11,"pid":0.8543607891413433},"minmet":{"id":"minmet","type":"string","placeholder":"","advanced":true,"desc":"topup: Minimisation method 0=Levenberg-Marquardt, 1=Scaled Conjugate Gradient","default":"0,0,0,0,0,1,1,1,1","_order":12,"pid":0.525519132816254},"splineorder":{"id":"splineorder","type":"string","placeholder":"","advanced":true,"desc":"topup: Order of spline, 2->Qadratic spline, 3->Cubic spline","default":"3","_order":13,"pid":0.9254322527850206},"numprec":{"id":"numprec","type":"enum","placeholder":"","advanced":true,"desc":"topup: Precision for representing Hessian, double or float","default":"double","_order":14,"pid":0.4054349758079624,"options":[{"desc":"","label":"double","value":"double"},{"desc":"","label":"float","value":"float"}]},"interp":{"id":"interp","type":"enum","placeholder":"","advanced":true,"desc":"topup: Image interpolation model, linear or spline","default":"spline","_order":15,"pid":0.8381671227744506,"options":[{"desc":"","label":"linear","value":"linear"},{"desc":"","label":"spline","value":"spline"}]},"scale":{"id":"scale","type":"boolean","placeholder":"","advanced":true,"desc":"topup: If set (=1), the images are individually scaled to a common mean","default":true,"_order":16,"pid":0.09978750418973248},"regrid":{"id":"regrid","type":"boolean","placeholder":"","advanced":true,"desc":"topup: If set (=1), the calculations are done in a different grid","default":true,"_order":17,"pid":0.620240245291879},"refvol":{"id":"refvol","type":"string","placeholder":"","advanced":true,"desc":"Eddy-correct: reference volume to align everything to","default":"0","_order":22,"pid":0.7662599810120051},"mergefull":{"id":"mergefull","type":"boolean","placeholder":"","advanced":false,"desc":"","default":false,"_order":47,"pid":0.359908648092523},"reslice":{"id":"reslice","type":"boolean","placeholder":"","advanced":true,"desc":"If, for wahtever reason, the two DWI images do not hae the same number of slices, set reslice to true and it will reslice the rdif image to diff","default":false,"_order":48,"pid":0.9579440748610994}},"inputs":[{"id":"diff","desc":"The path to the DWI datatype","datatype":"58c33c5fe13a50849b25879b","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c54df0f12cbcc01e1635b01"},{"id":"rdiff","desc":"Reverse encoded dwi image needed to run top-up","datatype":"58c33c5fe13a50849b25879b","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c54df0f12cbcc01e1635b00"}],"outputs":[{"id":"dwi","desc":"The preprocessed DWI","datatype":"58c33c5fe13a50849b25879b","datatype_tags":["preprocessed","eddy_correct"],"datatype_tags_pass":"diff","output_on_root":false,"files":null,"archive":true,"_id":"5c54df0f12cbcc01e1635b03"},{"id":"mask","desc":"The brainmask of the preprocessed DWI","datatype":"5a281aee2c214c9ba83ce620","datatype_tags":["dwi","brain"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5c54df0f12cbcc01e1635b02"},{"id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags":["derivatives","eddy_correct"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"60fafb86b99111933cb71925"}],"stats":{"success_rate":64.049955396967,"groups":40,"users":20,"runtime_mean":4527528.96,"runtime_std":8363821.149115121,"requested":3136,"gitinfo":{"desc":"This app will correct for encoding, eddy currents, and motion artifacts using FSL's Topup and Eddy functions.","tags":["preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null}]},"resources":[{"resource_id":"5ffc99da0df8ff7fc740c95a","name":"Bridges2 @ PSC (GPU-Shared)","_id":"634a459a62f3d3800f131130"}],"examples":1},"removed":false,"__v":97,"create_date":"2022-07-15T17:58:16.090Z","doi":"10.25663/brainlife.app.662","_canedit":true},{"_id":"633f3e1ffa262bbde29ea5aa","user_id":"1994","projects":[],"admins":["1994","16"],"name":"FSLmaths-app","github":"hanna-willis/app-roi-fslmaths","github_branch":"master","tags":[],"config":{"rois_1_loc":{"type":"input","file_id":"rois","input_id":"rois1"},"rois_2_loc":{"type":"input","file_id":"rois","input_id":"rois2"},"roi_1":{"id":"roi_1","type":"string","placeholder":"","advanced":false,"desc":"","default":"","_order":3,"pid":0.5440984140915108},"function":{"id":"function","type":"enum","placeholder":"","advanced":false,"desc":"","default":"sub","_order":4,"pid":0.1975848276626011,"options":[{"desc":"","label":"","value":"add"},{"desc":"","label":"","value":"sub"},{"desc":"","label":"","value":"mul"},{"desc":"","label":"","value":"div"},{"desc":"","label":"","value":"mas"}]},"roi_2":{"id":"roi_2","type":"string","placeholder":"","advanced":false,"desc":"","default":"","_order":5,"pid":0.8839220235059428},"output_roi_name":{"id":"output_roi_name","type":"string","placeholder":"","advanced":false,"desc":"","default":"","_order":6,"pid":0.42612203852764297}},"inputs":[{"id":"rois1","desc":"If you want to subtract, the order of inputs matters (first ROI is manipulated). For other functions it does not. ","datatype":"5be9ea0315a8683a39a1ebd9","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"633f3e1ffa262bbde29ea5ab"},{"id":"rois2","datatype":"5be9ea0315a8683a39a1ebd9","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"633f3e1ffa262bbde29ea5ac"}],"outputs":[{"id":"output","datatype":"5be9ea0315a8683a39a1ebd9","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"633f3e1ffa262bbde29ea5ad"}],"stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a463662f3d3800f13132e"}],"examples":0,"success_rate":62.5,"users":1,"groups":1,"runtime_mean":535815.9,"runtime_std":1656415.0738552487,"requested":35},"removed":false,"contributors":[{"name":null,"email":null,"_id":"634a463662f3d3800f13132f"}],"create_date":"2022-10-06T20:44:15.295Z","desc":"This app masks a region of interest by a lesion mask. ","__v":11,"doi":"10.25663/brainlife.app.680","_canedit":true},{"_id":"62682dc8f3858674a29f9c3f","user_id":"16","projects":[],"admins":["16"],"name":"Filter Streamlines using SIFT","github":"brainlife/app-sift-sift2","github_branch":"sift-v1.0","desc":null,"tags":[],"contributors":[{"name":"Brad Caron","email":null,"_id":"634a43ff62f3d3800f130a26"}],"config":{"track":{"type":"input","file_id":"track","input_id":"track"},"response":{"type":"input","file_id":"response","input_id":"csd"},"lmax2":{"type":"input","file_id":"lmax2","input_id":"csd"},"lmax4":{"type":"input","file_id":"lmax4","input_id":"csd"},"lmax6":{"type":"input","file_id":"lmax6","input_id":"csd"},"lmax8":{"type":"input","file_id":"lmax8","input_id":"csd"},"lmax10":{"type":"input","file_id":"lmax10","input_id":"csd"},"lmax12":{"type":"input","file_id":"lmax12","input_id":"csd"},"lmax14":{"type":"input","file_id":"lmax14","input_id":"csd"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"anat":{"type":"input","file_id":"t1","input_id":"anat"},"lmax":{"id":"lmax","type":"number","placeholder":"","advanced":false,"desc":"the spherical harmonic order (lmax) to use","default":8,"_order":2,"pid":0.5805090874491159},"fd_scale_gm":{"id":"fd_scale_gm","type":"boolean","placeholder":"","advanced":true,"desc":"provide this option (in conjunction with -act) to heuristically downsize the fibre density estimates based on the presence of GM in the voxel. This can assist in reducing tissue interface effects when using a single-tissue deconvolution algorithm","default":true,"_order":3,"pid":0.14781827560335292},"no_dilate_lut":{"id":"no_dilate_lut","type":"boolean","placeholder":"","advanced":true,"desc":" do NOT dilate FOD lobe lookup tables; only map streamlines to FOD lobes if the precise tangent lies within the angular spread of that lobe","default":false,"_order":4,"pid":0.7788761633690136},"fd_thresh":{"id":"fd_thresh","type":"number","placeholder":"","advanced":true,"desc":" fibre density threshold; exclude an FOD lobe from filtering processing if its integral is less than this amount (streamlines will still be mapped to it, but it will not contribute to the cost function or the filtering)","default":0,"_order":6,"pid":0.20003750375390728},"term_number":{"id":"term_number","type":"number","placeholder":"","advanced":true,"desc":"number of streamlines - continue filtering until this number of streamlines remain","default":null,"_order":7,"pid":0.9761435522711005},"term_ratio":{"id":"term_ratio","type":"number","placeholder":"","advanced":true,"desc":"termination ratio - defined as the ratio between reduction in cost function, and reduction in density of streamlines.\nSmaller values result in more streamlines being filtered out.","default":null,"_order":8,"pid":0.5114207068129113},"term_mu":{"id":"term_mu","type":"number","placeholder":"","advanced":true,"desc":"terminate filtering once the SIFT proportionality coefficient reaches a given value","default":null,"_order":9,"pid":0.8952843536481588},"premask":{"id":"premask","type":"boolean","placeholder":"","advanced":true,"desc":"If the t1 has been masked already, set to true","default":false,"_order":10,"pid":0.4608146484517258}},"inputs":[{"id":"track","desc":"path to the input tractogram","datatype":"5907d922436ee50ffde9c549","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"62681cd2f3858674a29f554f"},{"id":"csd","desc":"paths to the individual FOD files","datatype":"5c536bf0f9109beac46adb45","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"62681cd2f3858674a29f5550"},{"id":"mask","datatype":"5a281aee2c214c9ba83ce620","datatype_tags":["5tt_masks"],"optional":true,"multi":false,"advanced":false,"_id":"62681cd2f3858674a29f5551"},{"id":"anat","desc":"Only required if no tissue-type mask datatype available","datatype":"58c33bcee13a50849b25879a","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"626b10bff3858674a2a5a2d8"}],"outputs":[{"id":"labels","desc":"label file containing the streamline indices that survived SIFT2","datatype":"606345ade4a8347b6f337de4","datatype_tags":["binary"],"datatype_tags_pass":"track","output_on_root":false,"files":null,"archive":true,"_id":"62681d36f3858674a29f5a97"},{"id":"raw","desc":"contains the derivative files generated during the sift process, including the weights and proportionality coefficient and relative statistics files","datatype":"59c3eae633fc1cf9ead71679","datatype_tags":["sift2"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"62681d36f3858674a29f5a98"},{"id":"filtered","desc":"this contains the filtered tractogram. not automatically archived to save space and avoid redundant data objects","datatype":"5907d922436ee50ffde9c549","datatype_tags":["filtered","sift"],"datatype_tags_pass":"track","output_on_root":false,"files":null,"archive":false,"_id":"62682f2bf3858674a29fa3f3"}],"stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a43ff62f3d3800f130a25"}],"examples":1,"success_rate":53.333333333333336,"users":2,"groups":2,"runtime_mean":1753199.75,"runtime_std":581686.8902920948,"requested":15},"removed":false,"__v":463,"create_date":"2022-04-26T17:37:12.434Z","doi":"10.25663/brainlife.app.616","_canedit":true},{"_id":"626c5a55f3858674a2a7d7c3","user_id":"16","projects":[],"admins":["16"],"name":"Filter WMC Datatype","github":"bacaron/app-filter-wmc","github_branch":"master","tags":[],"config":{"classification":{"type":"input","file_id":"classification","input_id":"wmc"},"tracts":{"type":"input","file_id":"tracts","input_id":"wmc"},"surfaces":{"type":"input","file_id":"surfaces","input_id":"wmc"},"index":{"type":"input","file_id":"index","input_id":"labels"},"track":{"type":"input","file_id":"track","input_id":"track"}},"inputs":[{"id":"wmc","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"626c5a55f3858674a2a7d7c4"},{"id":"labels","datatype":"606345ade4a8347b6f337de4","datatype_tags":["binary"],"optional":false,"multi":false,"advanced":false,"_id":"626c5a55f3858674a2a7d7c5"},{"id":"track","desc":"Needed to generate files for visualization purposes","datatype":"5907d922436ee50ffde9c549","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"626c5d91f3858674a2a7e009"}],"outputs":[{"id":"wmc","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags":["filtered"],"datatype_tags_pass":"wmc","output_on_root":false,"files":null,"archive":true,"_id":"626c5a55f3858674a2a7d7c6"}],"stats":{"resources":[],"success_rate":33.33333333333333,"users":1,"groups":1,"runtime_mean":17379,"runtime_std":5236,"requested":7,"examples":1},"removed":false,"contributors":[{"name":"Brad Caron","email":null,"_id":"634a442f62f3d3800f130ceb"}],"create_date":"2022-04-29T21:36:21.428Z","desc":null,"__v":294,"doi":"10.25663/brainlife.app.621","_canedit":true},{"_id":"60b895780ad40d2658ca61fb","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a40fe62f3d3800f12dea1"}],"success_rate":89.69398815975987,"users":1,"runtime_mean":13171.74,"runtime_std":3860.977911410527,"requested":14435,"examples":5,"groups":4},"projects":[],"admins":["1348"],"tags":[],"removed":false,"config":{"psd":{"type":"input","file_id":"psd","input_id":"psd01"},"fmin":{"id":"fmin","type":"number","placeholder":"","advanced":false,"desc":"Min frequency of the range (Hz)","default":7.8,"_order":2,"pid":0.40094833838642396,"min":0},"fmax":{"id":"fmax","type":"number","placeholder":"","advanced":false,"desc":"Max frequency of the range (Hz)","default":12.2,"_order":3,"pid":0.43594037833768184}},"inputs":[{"id":"psd01","datatype":"60c7669e7657d98fe5e128b1","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"60d08509cdfdb5a6b4ff56d2"}],"outputs":[{"id":"out_dir","datatype":"60c7669e7657d98fe5e128b1","datatype_tags":["peak_freq"],"datatype_tags_pass":"psd01","output_on_root":false,"files":null,"archive":true,"_id":"610aec03548c0430535c6144"},{"id":"out_figs","datatype":"59c3eae633fc1cf9ead71679","datatype_tags":["peak_freq"],"datatype_tags_pass":"psd01","output_on_root":false,"files":null,"archive":false,"_id":"60b895780ad40dae6bca61fe"}],"github_branch":"master","github":"guiomar/app-peak-frequency","name":"Find frequency peak of PSD data","user_id":"1342","contributors":[{"name":"Julia Guiomar Niso Galán","email":null,"_id":"634a40fe62f3d3800f12dea2"},{"name":null,"email":null,"_id":"634a40fe62f3d3800f12dea3"}],"create_date":"2021-06-03T08:40:24.032Z","desc":"Detect individual alpha peak in MEG signals","__v":2564,"doi":"10.25663/brainlife.app.531","desc_override":"Detects peak frequency of PSD for each channel on a given bandwith","_canedit":true},{"_id":"5b1efc8673279e0028adfc08","projects":[],"admins":["61","285","87","1"],"tags":["diffusion-mri","diffusion-reconstruction","dipy"],"removed":false,"name":"Fit CSA","desc":"Brainlife wrapper app for dipy_fit_csa workflows","citation":null,"references":[],"avatar":"https://raw.githubusercontent.com/brain-life/brainlife.github.io/master/images/app-logos/dipy_fit_csa.png","github":"dipy/bl_apps_dipy_fit_csa","github_branch":"1.1.1","config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"b0_threshold":{"type":"number","placeholder":"0","desc":"Threshold used to find b=0 directions","default":50,"id":"b0_threshold","pid":0.7153872556331251,"_order":2},"bvecs_tol":{"type":"number","placeholder":"0.01","desc":"Threshold used so that norm(bvec)=1 (default 0.01)","default":0.01,"id":"bvecs_tol","pid":0.45869334319119637,"_order":3},"sh_order":{"type":"number","placeholder":"6","desc":"Spherical harmonics order (default 6) used in the CSA fit.","default":6,"id":"sh_order","pid":0.5699821947460646,"_order":4},"odf_to_sh_order":{"type":"number","placeholder":"8","desc":"Spherical harmonics order used for peak_from_model to compress\nthe ODF to spherical harmonics coefficients (default 8","default":8,"id":"odf_to_sh_order","pid":0.4052132862841127,"_order":5}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5b1efc8673279e0028adfc09","id":"dwi","datatype":"58c33c5fe13a50849b25879b"},{"datatype_tags":["brain"],"optional":false,"multi":false,"advanced":false,"_id":"5b1efc8673279e0028adfc0a","id":"mask","datatype":"5a281aee2c214c9ba83ce620"}],"outputs":[{"datatype_tags":["csa_model_fit"],"output_on_root":false,"archive":true,"_id":"5b1efc8673279e0028adfc0b","id":"output","datatype":"59494478fa1d2e5a1ffd23b4","datatype_tags_pass":null,"files":null}],"desc_override":"Fits Constant Solid Angle (CSA) model to diffusion data (dipy_fit_csa)","user_id":"61","contributors":[{"name":"Serge Koudoro","email":null,"_id":"634a332462f3d3800f117d87"},{"name":"Javier Guaje","email":null,"_id":"634a332462f3d3800f117d88"}],"create_date":"2018-06-11T22:49:42.618Z","stats":{"stars":0,"requested":163,"users":6,"success_rate":98.14814814814815,"serviceinfo":{"_id":"5d729e1f78356a109788b2dd","counts":{"_id":"5e5c3da987cac786d7ab13bb","failed":1372,"finished":2816,"removed":5103,"requested":5301,"running":3198,"running_sync":0,"stop_requested":12},"success_rate":67.23973256924546,"users":20,"readme_status":"ok","runtime_mean":5885857.53,"runtime_std":14501545.618587041,"service":"brain-life/app-dipy-workflows","__v":0},"gitinfo":{"desc":"Brainlife wrapper app for Dipy workflows.","tags":["dipy"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Serge Koudoro","email":null},{"name":"Aman Arya","email":"aman.arya524@gmail.com"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":637961.91,"runtime_std":538398.7297441944,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a332362f3d3800f117d86"}],"examples":1,"groups":5},"doi":"10.25663/bl.app.61","__v":12792,"_canedit":true},{"_id":"5b1efd2973279e0028adfc18","projects":[],"admins":["61","285","87","1"],"tags":["diffusion-mri","diffusion-reconstruction","dipy"],"removed":false,"name":"Fit CSD","desc":"Brainlife wrapper app for dipy_fit_csd workflows.","citation":null,"references":[],"avatar":"https://raw.githubusercontent.com/brain-life/brainlife.github.io/master/images/app-logos/dipy_fit_csd.png","github":"dipy/bl_apps_dipy_fit_csd","github_branch":"1.1.1","config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"b0_threshold":{"type":"number","placeholder":"0","desc":"Threshold used to find b=0 directions","default":50,"id":"b0_threshold","pid":0.8364427844131008,"_order":2},"bvecs_tol":{"type":"number","placeholder":"0.01","desc":"Bvecs should be unit vectors. (default:0.01)","default":0.01,"id":"bvecs_tol","pid":0.11877123139801538,"_order":3},"roi_radius":{"type":"number","placeholder":"10","desc":"Radius of cubic ROI in voxels (default 10)","default":10,"id":"roi_radius","pid":0.7176210283954632,"_order":4},"fa_thr":{"type":"number","placeholder":"0.7","desc":"FA threshold for calculating the response function (default 0.7)","default":0.7,"id":"fa_thr","pid":0.2964472631909656,"_order":5},"sh_order":{"type":"number","placeholder":"6","desc":"Spherical harmonics order (default 6) used in the CSA fit.","default":6,"id":"sh_order","pid":0.2737874660004169,"_order":6},"odf_to_sh_order":{"type":"number","placeholder":"8","desc":"Spherical harmonics order used for peak_from_model to compress\nthe ODF to spherical harmonics coefficients (default 8)","default":8,"id":"odf_to_sh_order","pid":0.13994755509796164,"_order":7}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5b1efd2973279e0028adfc19","id":"dwi","datatype":"58c33c5fe13a50849b25879b"},{"datatype_tags":["brain"],"optional":false,"multi":false,"advanced":false,"_id":"5b1efd2973279e0028adfc1a","id":"mask","datatype":"5a281aee2c214c9ba83ce620"}],"outputs":[{"datatype_tags":["csd_model_fit"],"output_on_root":false,"archive":true,"_id":"5b1efd2973279e0028adfc1b","id":"output","datatype":"59494478fa1d2e5a1ffd23b4","datatype_tags_pass":null,"files":null}],"desc_override":"Fit Constrained spherical deconvolution (CSD) model to diffusion data (dipy_fit_csd)","user_id":"61","contributors":[{"name":"Serge Koudoro","email":null,"_id":"634a332d62f3d3800f117e19"},{"name":"Javier Guaje","email":null,"_id":"634a332d62f3d3800f117e1a"}],"create_date":"2018-06-11T22:52:25.572Z","stats":{"stars":0,"requested":744,"users":12,"success_rate":77.93522267206477,"serviceinfo":{"_id":"5d729e1f78356a109788b2dd","counts":{"_id":"5e5c3dab87cac7457eab13bc","failed":1372,"finished":2816,"removed":5103,"requested":5301,"running":3198,"running_sync":0,"stop_requested":12},"success_rate":67.23973256924546,"users":20,"readme_status":"ok","runtime_mean":5885857.53,"runtime_std":14501545.618587041,"service":"brain-life/app-dipy-workflows","__v":0},"gitinfo":{"desc":"Brainlife wrapper app for Dipy workflows.","tags":["dipy"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Serge Koudoro","email":null},{"name":"Aman Arya","email":"aman.arya524@gmail.com"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":2538438.05,"runtime_std":4953378.006700033,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a332c62f3d3800f117e18"}],"examples":1,"groups":16},"doi":"10.25663/bl.app.62","__v":12791,"_canedit":true},{"_id":"5db224e98aeeee0f87f25c1f","stats":{"stars":0,"serviceinfo":{"_id":"5db23fa5e9b0ce3ab491f8d2","counts":{"_id":"5e5c3e1c87cac76e04ab1435","failed":67,"finished":51,"removed":132,"requested":195,"running":133,"running_sync":0,"stop_requested":15},"users":2,"readme_status":"ok","service":"brainlife/app-mrtrix3-csd","__v":0,"runtime_mean":15726807.88235294,"runtime_std":8447886.226064393,"success_rate":43.22033898305085},"success_rate":81.29148230088495,"users":30,"runtime_mean":13268972.2,"runtime_std":21354224.0111234,"requested":17873,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a374e62f3d3800f11da43"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a374e62f3d3800f11da44"}],"examples":5,"groups":63},"projects":[],"admins":["16","19"],"tags":[],"removed":false,"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"brainmask":{"type":"input","file_id":"mask","input_id":"brainmask"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"anat":{"type":"input","file_id":"t1","input_id":"anat"},"lmax":{"id":"lmax","type":"number","placeholder":"","advanced":false,"desc":"spherical harmonic order (lmax) for csd estimation. see https://mrtrix.readthedocs.io/en/3.0_rc2/constrained_spherical_deconvolution/lmax.html for more information on which value to choose","default":8,"_order":2,"pid":0.6556955819752166},"premask":{"id":"premask","type":"boolean","placeholder":"","advanced":true,"desc":"If T1 has been skull stripped, select true","default":false,"_order":3,"pid":0.17514901935242477},"norm":{"id":"norm","type":"boolean","placeholder":"","advanced":false,"desc":"multi-tissue intensity normalization","default":false,"_order":4,"pid":0.4316123600353503},"ensemble":{"id":"ensemble","type":"boolean","placeholder":"","advanced":false,"desc":"if true, will ensemble through max lmax. else, will generate requested lmax","default":true,"_order":5,"pid":0.6737036625259214}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5db224e98aeeee238cf25c20","id":"dwi","datatype":"58c33c5fe13a50849b25879b","desc":"The path to the DWI datatype"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5db23d8c8aeeee6a49f2603f","id":"brainmask","datatype":"5a281aee2c214c9ba83ce620","desc":"The path to the mask datatype of the brainmask for the DWI"},{"datatype_tags":["5tt_masks"],"optional":true,"multi":false,"advanced":false,"_id":"5db274788aeeee1444f26f6e","id":"mask","datatype":"5a281aee2c214c9ba83ce620","desc":"The path to the mask datatype of the 5 tissue probability mask from Tissue-type Segmentation (optional). If not inputted, will be generated using MRtrix3"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e3876bdb81ce214409d26cb","id":"anat","datatype":"58c33bcee13a50849b25879a","desc":"The path to the anat/t1w datatype"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5db224e98aeeee0565f25c21","id":"csd","datatype":"5c536bf0f9109beac46adb45","datatype_tags_pass":"dwi","files":null,"desc":"The CSD FOD images"},{"datatype_tags":["5tt_masks"],"output_on_root":false,"archive":false,"_id":"5eb188f50d2117adb842ab1f","id":"5tt","datatype":"5a281aee2c214c9ba83ce620","datatype_tags_pass":null,"files":null,"desc":"The 5 tissue probability image generated using MRtrix3"},{"datatype_tags":["dwi","brain"],"output_on_root":false,"archive":false,"_id":"5eb1f9f392fca97131750e39","id":"brainmask","datatype":"5a281aee2c214c9ba83ce620","datatype_tags_pass":null,"files":null,"desc":"The brainmask of the DWI image"}],"github_branch":"csd_generation-v1.0","github":"bacaron/app-mrtrix3-act","name":"Fit Constrained Deconvolution Model for Tracking","user_id":"16","contributors":[{"name":"Brent McPherson","email":"bcmcpher@gmail.com","_id":"634a374f62f3d3800f11da45"},{"name":"Brad Caron","email":null,"_id":"634a374f62f3d3800f11da46"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a374f62f3d3800f11da47"}],"create_date":"2019-10-24T22:25:45.338Z","desc":"Runs mrtrix3 ACT (Anatomically Constrained Tractography) using either single- or multi-shell diffusion-weighted MRI data. ","doi":"10.25663/brainlife.app.238","__v":6660,"desc_override":"This will fit the constrained spherical deconvolution model to an input DWI image. The outputs from this can be used for subsequent tracking apps.","_canedit":true},{"_id":"5ae9d732f446980028b15ec2","doi":"10.25663/bl.app.9","stats":{"stars":0,"requested":511,"users":10,"success_rate":69.26713947990544,"serviceinfo":{"_id":"5d729e1f78356a109788b2dd","counts":{"_id":"5e5c3d9c87cac7dfd9ab13ac","failed":1372,"finished":2816,"removed":5103,"requested":5301,"running":3198,"running_sync":0,"stop_requested":12},"success_rate":67.23973256924546,"users":20,"readme_status":"ok","runtime_mean":5885857.53,"runtime_std":14501545.618587041,"service":"brain-life/app-dipy-workflows","__v":0},"gitinfo":{"desc":"Brainlife wrapper app for Dipy workflows.","tags":["dipy"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Serge Koudoro","email":null},{"name":"Aman Arya","email":"aman.arya524@gmail.com"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":498319.79,"runtime_std":473676.3283006085,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a32ab62f3d3800f11781e"}],"examples":1,"groups":18},"name":"Fit DKI","desc":"Brainlife wrapper app for dipy_fit_dki workflows. Fit a Diffusion Kurtosis Imaging model to multishell Diffusion-weighted data","citation":null,"avatar":"https://raw.githubusercontent.com/brain-life/brainlife.github.io/master/images/app-logos/dipy_fit_dki.png","github":"dipy/bl_apps_dipy_fit_dki","github_branch":"1.1.1","config":{"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"b0_threshold":{"id":"b0_threshold","type":"number","placeholder":"","desc":"","default":50,"_order":3,"pid":0.8030663771106812,"optional":false}},"desc_override":"Fit a Diffusion Kurtosis Imaging model to multishell Diffusion-weighted data (dipy_fit_dki)","user_id":"41","create_date":"2018-05-02T15:20:18.139Z","removed":false,"outputs":[{"datatype_tags":["dki"],"output_on_root":false,"archive":true,"_id":"5ae9d732f446980028b15ec3","id":"output","datatype":"5a79df48d071a1753f1d661b","datatype_tags_pass":null,"files":null}],"inputs":[{"datatype_tags":["!single_shell"],"optional":false,"multi":false,"advanced":false,"_id":"5ae9d732f446980028b15ec5","id":"dwi","datatype":"58c33c5fe13a50849b25879b","desc":"This App will only work with multishell datasets."},{"datatype_tags":["brain"],"optional":false,"multi":false,"advanced":false,"_id":"5ae9d732f446980028b15ec4","id":"mask","datatype":"5a281aee2c214c9ba83ce620","desc":"This is normally a white matter mask. But you could also pass the whole brain mask instead if you are interested in tensor measures in the gray matter, for example."}],"contributors":[{"name":"Serge Koudoro","email":null,"_id":"634a32ac62f3d3800f11781f"},{"name":"Javier Guaje","email":null,"_id":"634a32ac62f3d3800f117820"},{"name":"Brad Caron","email":null,"_id":"634a32ac62f3d3800f117821"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a32ac62f3d3800f117822"}],"tags":["diffusion-mri","dipy"],"references":[],"admins":["285","87","1"],"projects":[],"__v":13740,"_canedit":true},{"_id":"5b1efb6673279e0028adfc01","projects":[],"admins":["61","285","87","1"],"tags":["diffusion-mri","dipy"],"removed":false,"name":"Fit DTI","desc":"Brainlife wrapper app for dipy_fit_dti workflows.","citation":null,"references":[],"avatar":"https://raw.githubusercontent.com/brain-life/brainlife.github.io/master/images/app-logos/dipy_fit_dti.png","github":"dipy/bl_apps_dipy_fit_dti","github_branch":"1.1.1","config":{"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"b0_threshold":{"type":"number","placeholder":"0.0","desc":"Threshold used to find b=0 directions","default":50,"id":"b0_threshold","pid":0.3577029679742083,"_order":2},"bvecs_tol":{"type":"number","placeholder":"0.01","desc":"Threshold used to check that norm(bvec) = 1 +/- bvecs_tolb-vectors are unit vectors","default":0.01,"id":"bvecs_tol","pid":0.11755865932144327,"_order":3}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5b1efb6673279e0028adfc02","id":"dwi","datatype":"58c33c5fe13a50849b25879b"},{"datatype_tags":["brain"],"optional":false,"multi":false,"advanced":false,"_id":"5b1efb6673279e0028adfc03","id":"mask","datatype":"5a281aee2c214c9ba83ce620"}],"outputs":[{"datatype_tags":["dti"],"output_on_root":false,"archive":true,"_id":"5b1efb6673279e0028adfc04","id":"output","datatype":"5a79df48d071a1753f1d661b","datatype_tags_pass":null,"files":null}],"desc_override":"Tensor reconstruction and compute DTI metrics using weighted least-squares (dipy_fit_dti)","user_id":"61","contributors":[{"name":"Serge Koudoro","email":null,"_id":"634a331a62f3d3800f117d55"},{"name":"Javier Guaje","email":null,"_id":"634a331a62f3d3800f117d56"}],"create_date":"2018-06-11T22:44:54.991Z","stats":{"stars":0,"requested":2360,"users":12,"success_rate":48.7781036168133,"serviceinfo":{"_id":"5d729e1f78356a109788b2dd","counts":{"_id":"5e5c3da887cac70a9bab13ba","failed":1372,"finished":2816,"removed":5103,"requested":5301,"running":3198,"running_sync":0,"stop_requested":12},"success_rate":67.23973256924546,"users":20,"readme_status":"ok","runtime_mean":5885857.53,"runtime_std":14501545.618587041,"service":"brain-life/app-dipy-workflows","__v":0},"gitinfo":{"desc":"Brainlife wrapper app for Dipy workflows.","tags":["dipy"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Serge Koudoro","email":null},{"name":"Aman Arya","email":"aman.arya524@gmail.com"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":26786.19,"runtime_std":12287.864107073288,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a331a62f3d3800f117d54"}],"examples":2,"groups":32},"doi":"10.25663/bl.app.60","__v":12842,"_canedit":true},{"_id":"5ea7b4d2f1745d1c26f80269","stats":{"success_rate":0,"users":3,"requested":10,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a39ea62f3d3800f12350d"}],"examples":0,"groups":3},"projects":[],"admins":["285","87"],"tags":["diffusion-mri","dipy"],"removed":false,"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"DWI"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"DWI"},"bvals":{"type":"input","file_id":"bvals","input_id":"DWI"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"split_b_D":{"id":"split_b_D","type":"number","placeholder":"","advanced":false,"desc":"Value to split the bvals to estimate D for the two-stage process of fitting","default":400,"_order":2,"pid":0.774489291859566},"split_b_S0":{"id":"split_b_S0","type":"number","placeholder":"","advanced":false,"desc":"Value to split the bvals to estimate S0 for the two-stage process of fitting.","default":200,"_order":3,"pid":0.49972632745911816},"b0_threshold":{"id":"b0_threshold","type":"number","placeholder":"","advanced":false,"desc":"Threshold value for the b0 bval.","default":0,"_order":4,"pid":0.3129792651234553},"command":{"id":"command","type":"string","placeholder":"","advanced":false,"desc":"","default":"dipy_fit_ivim","_order":5,"pid":0.9815480507528807,"readonly":true}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ea7b4d2f1745d2566f8026a","id":"DWI","datatype":"58c33c5fe13a50849b25879b"},{"datatype_tags":["brain","dwi"],"optional":false,"multi":false,"advanced":false,"_id":"5ea7b4d2f1745dbbeaf8026b","id":"mask","datatype":"5a281aee2c214c9ba83ce620"}],"outputs":[{"datatype_tags":["dwi"],"output_on_root":false,"archive":true,"_id":"5ea7b4d2f1745d25f3f8026c","id":"output","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null,"desc":"- S0_predicted.nii.gz: Name of the S0 signal estimated to be saved\n- perfusion_fraction.nii.gz: Name of the estimated volume fractions to be saved\n- D_star.nii.gz: Name of the estimated pseudo-diffusion parameter to be saved\n- D.nii.gz: Name of the estimated diffusion parameter to be saved"}],"github_branch":"1.1.1","github":"dipy/bl_apps_dipy_fit_ivim","name":"Fit IVIM","desc_override":"Fit Intra-voxel Incoherent Motion (IVIM) reconstruction on diffusion data to get IVIM metrics","user_id":"87","contributors":[{"name":"Serge Koudoro","email":null,"_id":"634a39eb62f3d3800f12350e"},{"name":"Javier Guaje","email":null,"_id":"634a39eb62f3d3800f12350f"}],"create_date":"2020-04-28T04:45:06.165Z","desc":"Brainlife wrapper app for dipy_fit_ivim workflows.","doi":"10.25663/brainlife.app.322","__v":4995,"_canedit":true},{"_id":"5b217a3e16fe38002748e5ff","projects":[],"admins":["285","87","1"],"tags":["diffusion-mri","dipy"],"removed":false,"name":"Fit MAPMRI","desc":"Brainlife wrapper app for dipy_fit_mapmri workflows.","citation":null,"references":[],"avatar":"https://raw.githubusercontent.com/brain-life/brainlife.github.io/master/images/app-logos/dipy_mapmri.png","github":"dipy/bl_apps_dipy_fit_mapmri","github_branch":"1.1.1","config":{"dwi":{"type":"input","file_id":"dwi","input_id":"input"},"bvals":{"type":"input","file_id":"bvals","input_id":"input"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"input"},"command":{"type":"string","placeholder":"","desc":"","default":"dipy_fit_mapmri","readonly":true,"id":"command","pid":0.39034809020392447,"_order":2},"small_delta":{"type":"number","placeholder":"","desc":"Small delta value used in generation of gradient table of provided\nbval and bvec.","default":null,"id":"small_delta","pid":0.6243060231842996,"_order":3},"big_delta":{"type":"number","placeholder":"","desc":"Big delta value used in generation of gradient table of provided\nbval and bvec.","default":null,"id":"big_delta","pid":0.4195901860173461,"_order":4},"b0_threshold":{"type":"number","placeholder":"0","desc":"Threshold used to find b=0 directions (default 0.0)","default":50,"id":"b0_threshold","pid":0.16722212660475444,"_order":5,"optional":false},"bval_threshold":{"type":"number","placeholder":"2000","desc":"Sets the b-value threshold to be used in the scale factor\nestimation. In order for the estimated non-Gaussianity to have\nmeaning this value should set to a lower value (b<2000 s/mm^2)\nsuch that the scale factors are estimated on signal points that\nreasonably represent the spins at Gaussian diffusion","default":2000,"id":"bval_threshold","pid":0.793358628981873,"_order":6,"optional":false},"laplacian_weighting":{"type":"number","placeholder":"0.05","desc":"Weighting value used in fitting the MAPMRI model in the laplacian\nand both model types. (default: 0.05)","default":0.05,"id":"laplacian_weighting","pid":0.28742714610825093,"_order":7},"radial_order":{"type":"number","placeholder":"6","desc":"Even value used to set the order of the basis\n(default: 6)","default":6,"optional":false,"id":"radial_order","pid":0.13335044713743338,"_order":8},"laplacian":{"type":"boolean","placeholder":"","desc":"Regularize using the Laplacian of the MAP-MRI basis (default True)","default":true,"id":"laplacian","pid":0.46449841436510986,"_order":9},"positivity":{"type":"boolean","placeholder":"","desc":"Constrain the propagator to be positive. (default True)","default":true,"id":"positivity","pid":0.5421291431463027,"_order":10}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5b217a3e16fe38002748e600","id":"input","datatype":"58c33c5fe13a50849b25879b","desc":"Path to the input volume/bvals/bvecs."}],"outputs":[{"datatype_tags":["dipy_fit_mapmri"],"output_on_root":false,"archive":true,"_id":"5b217ae816fe38002748e607","id":"output","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null}],"desc_override":"Fit MAPMRI model (with optional Laplacian regularization). Generates rtop, lapnorm, msd, qiv, rtap, rtpp, non-gaussian (ng), parallel ng, perpendicular ng.  Either the laplacian or positivity or both must be set to True. (dipy_fit_mapmri)","user_id":"61","contributors":[{"name":"Serge Koudoro","email":null,"_id":"634a335a62f3d3800f117eb8"},{"name":"Javier Guaje","email":null,"_id":"634a335a62f3d3800f117eb9"}],"create_date":"2018-06-13T20:10:38.805Z","stats":{"stars":0,"requested":12,"users":2,"success_rate":36.36363636363637,"serviceinfo":{"_id":"5d729e1f78356a109788b2dd","counts":{"_id":"5e5c3db087cac7647dab13c1","failed":1372,"finished":2816,"removed":5103,"requested":5301,"running":3198,"running_sync":0,"stop_requested":12},"success_rate":67.23973256924546,"users":20,"readme_status":"ok","runtime_mean":5885857.53,"runtime_std":14501545.618587041,"service":"brain-life/app-dipy-workflows","__v":0},"gitinfo":{"desc":"Brainlife wrapper app for Dipy workflows.","tags":["dipy"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Serge Koudoro","email":null},{"name":"Aman Arya","email":"aman.arya524@gmail.com"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":16267104.75,"runtime_std":4083623.5805641646,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a335a62f3d3800f117eb7"}],"examples":1,"groups":2},"doi":"10.25663/bl.app.67","__v":12752,"_canedit":true},{"_id":"5ec2c32b41ba11f78bf40526","projects":[],"admins":["16"],"tags":["postprocessing"],"removed":false,"name":"Fit NODDI model using AMICO (dtiinit)","desc":"This app will fit the Neurite Orientation Dispersion and Density Imaging (NODDI; Zhang et al, 2012) model to multi-shell, normalized DWI data using the Accelerated Microstructure Imaging via Convex Optimization (AMICO; Daducci et al, 2015) toolbox. Requires normalized, multi-shell DWI data (including bvals and bvecs) and an optional brainmask of the DWI. Will output the four NODDI output files: neurite density index (ndi), orientation dispersion index (odi), isotropic volume fraction (isovf), and the directions (dirs).","github":"brainlife/app-noddi-amico","github_branch":"dtiinit-v1.0","config":{"dtiinit":{"type":"input","file_id":"output","input_id":"dtiinit"},"dPar":{"type":"number","placeholder":"","desc":"The parallel diffusivity value for the NODDI model fit","default":0.0017,"id":"dPar","pid":0.2854910689544974,"_order":2}},"user_id":"16","outputs":[{"datatype_tags":[],"output_on_root":true,"archive":true,"_id":"59fa056a98d5fa005dc3d555","id":"0","datatype":"5bd77a8615a8683a39440dab","files":null,"desc":"The NODDI (deprecated) datafiles"},{"datatype_tags":["noddi","brain","dwi"],"output_on_root":true,"archive":true,"_id":"5bdcab3418c7cd002708d7a7","id":"1","datatype":"5a281aee2c214c9ba83ce620","datatype_tags_pass":null,"files":null,"desc":"The brainmask of the DWI image"}],"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ec2c32b41ba112d2df40529","id":"dtiinit","datatype":"58cb234be13a50849b25882f","desc":"The path to the top directory containing the output from DTIINIT"}],"__v":4846,"contributors":[{"name":"Brad Caron","email":null,"_id":"634a3a9462f3d3800f123dea"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a3a9462f3d3800f123deb"},{"name":"Franco Pestilli","email":null,"_id":"634a3a9462f3d3800f123dec"},{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a3a9462f3d3800f123ded"}],"stats":{"requested":17488,"users":28,"success_rate":80.55006717774441,"gitinfo":{"desc":"This app will fit the Neurite Orientation Dispersion and Density Imaging (NODDI; Zhang et al, 2012) model to multi-shell, normalized DWI data using the Accelerated Microstructure Imaging via Convex Optimization (AMICO; Daducci et al, 2015) toolbox. Requires normalized, multi-shell DWI data (including bvals and bvecs), and the single shell dwi file that has been aligned to the subject's T1 (i.e. dtiinit output) as input. The app will align the multi-shell data to the single-shell data (if dtiinit was used for tracking; otherwise single shell data is not necessary) in order to assure that NODDI outputs are in the same space as the tensor outputs for later analyses. Will output the five NODDI output files: FIT_ICVF_NEW, FIT_OD_NEW, FIT_ISOVF_NEW, FIT_dir, and config.pickle.","tags":["postprocessing"],"stats":{"stars":1},"contributors":[{"name":"Brad Caron","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":926049.16,"runtime_std":1069495.2315192036,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3a9362f3d3800f123de7"},{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a3a9362f3d3800f123de8"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3a9362f3d3800f123de9"}],"examples":0,"groups":55},"desc_override":"This app will fit the Neurite Orientation Dispersion and Density Imaging (NODDI; Zhang et al, 2012) model to multi-shell, normalized DWI data using the Accelerated Microstructure Imaging via Convex Optimization (AMICO; Daducci et al, 2015) toolbox. Requires normalized, multi-shell DWI data (including bvals and bvecs), and the single shell dwi file that has been aligned to the subject's T1 (i.e. dtiinit output) as input. The app will align the multi-shell data to the single-shell data in order to assure that NODDI outputs are in the same space as the tensor outputs for later analyses. Will output the five NODDI output files: FIT_ICVF_NEW, FIT_OD_NEW, FIT_ISOVF_NEW, FIT_dir, and config.pickle.","create_date":"2020-05-18T17:17:31.299Z","doi":"10.25663/brainlife.app.343","deprecated_by":"5bc7ac1244f3980027a7aafd","_canedit":true},{"_id":"59fa056a98d5fa005dc3d553","name":"Fit NODDI model using AMICO (dtiinit) -  DEPRECATED","desc":"This app will fit the Neurite Orientation Dispersion and Density Imaging (NODDI; Zhang et al, 2012) model to multi-shell, normalized DWI data using the Accelerated Microstructure Imaging via Convex Optimization (AMICO; Daducci et al, 2015) toolbox. Requires normalized, multi-shell DWI data (including bvals and bvecs) and an optional brainmask of the DWI. Will output the four NODDI output files: neurite density index (ndi), orientation dispersion index (odi), isotropic volume fraction (isovf), and the directions (dirs).","github":"brainlife/app-noddi-amico","github_branch":"original_code","config":{"dwi":{"type":"input","file_id":"dwi","input_id":"0"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"0"},"bvals":{"type":"input","file_id":"bvals","input_id":"0"},"dtiinit":{"type":"input","file_id":"output","input_id":"1"},"dPar":{"type":"number","placeholder":"","desc":"The parallel diffusivity value for the NODDI model fit","default":0.0017,"id":"dPar","pid":0.19999327898846997,"_order":2}},"user_id":"16","create_date":"2017-11-01T17:33:30.599Z","removed":false,"_rate":0,"outputs":[{"datatype_tags":[],"output_on_root":true,"archive":true,"_id":"59fa056a98d5fa005dc3d555","id":"0","datatype":"5bd77a8615a8683a39440dab","files":null,"desc":"The NODDI (deprecated) files"},{"datatype_tags":["noddi"],"output_on_root":true,"archive":true,"_id":"5bdcab3418c7cd002708d7a7","id":"1","datatype":"5a281aee2c214c9ba83ce620","datatype_tags_pass":null,"files":null,"desc":"The brainmask of the DWI image"}],"inputs":[{"datatype_tags":["!single_shell"],"optional":false,"multi":false,"advanced":false,"_id":"59fa056a98d5fa005dc3d557","id":"0","datatype":"58c33c5fe13a50849b25879b","desc":"The path to the DWI datatype"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5aac5d0bf0b5260027e24aef","id":"1","datatype":"58cb234be13a50849b25882f","desc":"The path to the top directory containing the output from DTIINIT"}],"tags":["postprocessing"],"admins":["16"],"projects":[],"__v":14298,"contributors":[{"name":"Brad Caron","email":null,"_id":"634a316062f3d3800f1166ad"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a316062f3d3800f1166ae"},{"name":"Franco Pestilli","email":null,"_id":"634a316062f3d3800f1166af"},{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a316062f3d3800f1166b0"}],"references":[],"stats":{"stars":1,"requested":17488,"users":28,"success_rate":80.55006717774441,"serviceinfo":{"_id":"5d729e1f78356a109788b2ff","counts":{"_id":"5e5c688a87cac7ea85ab1bb2","failed":1432,"finished":3375,"removed":7983,"requested":8628,"running":4929,"running_sync":0,"stop_requested":178},"success_rate":70.21011025587684,"users":12,"readme_status":"ok","runtime_mean":7179274.96,"runtime_std":6595445.539946354,"service":"brain-life/app-noddi-amico","__v":0},"gitinfo":{"desc":"This app will fit the Neurite Orientation Dispersion and Density Imaging (NODDI; Zhang et al, 2012) model to multi-shell, normalized DWI data using the Accelerated Microstructure Imaging via Convex Optimization (AMICO; Daducci et al, 2015) toolbox. Requires normalized, multi-shell DWI data (including bvals and bvecs), and the single shell dwi file that has been aligned to the subject's T1 (i.e. dtiinit output) as input. The app will align the multi-shell data to the single-shell data (if dtiinit was used for tracking; otherwise single shell data is not necessary) in order to assure that NODDI outputs are in the same space as the tensor outputs for later analyses. Will output the five NODDI output files: FIT_ICVF_NEW, FIT_OD_NEW, FIT_ISOVF_NEW, FIT_dir, and config.pickle.","tags":["postprocessing"],"stats":{"stars":1},"contributors":[{"name":"Brad Caron","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":926049.16,"runtime_std":1069495.2315192036,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a315f62f3d3800f1166aa"},{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a315f62f3d3800f1166ab"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a315f62f3d3800f1166ac"}],"examples":0,"groups":55},"desc_override":"This app will fit the Neurite Orientation Dispersion and Density Imaging (NODDI; Zhang et al, 2012) model to multi-shell, normalized DWI data using the Accelerated Microstructure Imaging via Convex Optimization (AMICO; Daducci et al, 2015) toolbox. Requires normalized, multi-shell DWI data (including bvals and bvecs), and the single shell dwi file that has been aligned to the subject's T1 (i.e. dtiinit output) as input. The app will align the multi-shell data to the single-shell data in order to assure that NODDI outputs are in the same space as the tensor outputs for later analyses. Will output the five NODDI output files: FIT_ICVF_NEW, FIT_OD_NEW, FIT_ISOVF_NEW, FIT_dir, and config.pickle.","doi":"10.25663/bl.app.35","deprecated_by":"5bc7ac1244f3980027a7aafd","_canedit":true},{"_id":"60ad394922b42ae2f1766b79","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a40e262f3d3800f12dbf9"}],"success_rate":92.72727272727272,"users":6,"runtime_mean":252700.63,"runtime_std":466225.56352039846,"requested":228,"examples":1,"groups":8},"projects":[],"admins":["16"],"tags":[],"removed":false,"config":{"diff":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvec":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bval":{"type":"input","file_id":"bvals","input_id":"dwi"},"sbref":{"type":"input","file_id":"sbref","input_id":"dwi"},"sbref_json":{"type":"input","file_id":"sbref_json","input_id":"dwi"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"norm":{"id":"norm","type":"boolean","placeholder":"","advanced":false,"desc":"Normalize diffusion data before fit","default":false,"_order":2,"pid":0.10768439953511488},"tensor_fit":{"id":"tensor_fit","type":"number","placeholder":"","advanced":false,"desc":"If user wants to fit tensor to a specific shell, specify here. otherwise will fit on entire diffusion data","default":"","_order":3,"pid":0.009875427137392645,"optional":true}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"60ad394922b42a5f28766b7a","id":"dwi","datatype":"58c33c5fe13a50849b25879b"},{"datatype_tags":["dwi","brain"],"optional":true,"multi":false,"advanced":false,"_id":"60ad394922b42a1648766b7b","id":"mask","datatype":"5a281aee2c214c9ba83ce620"}],"outputs":[{"datatype_tags":["mrtrix3"],"output_on_root":false,"archive":true,"_id":"60ad394922b42a7649766b7c","id":"output","datatype":"5a79df48d071a1753f1d661b","datatype_tags_pass":null,"files":null}],"github_branch":"v1.0","github":"brainlife/app-mrtrix3-tensor-fit","name":"Fit Tensor Model using MRTrix3","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a40e262f3d3800f12dbfa"}],"create_date":"2021-05-25T17:52:09.513Z","desc":null,"__v":2618,"desc_override":"This app will fit the diffusion tensor model (DTI) to a dMRI input using MRTrix3. The app can run on multi-shell or single shell data, and the user can specify which shell to use. This app can also normalize the diffusion data before model fitting based on user input. This app will output the neuro/tensor output on brainlife, including individual nifti files for FA, MD, AD, and RD, the tensors nifti, westin-shape niftis, and a kurtosis nifti if multi-shell data. This app takes a neuro/dwi datatype as input, and an optional neuro/mask dwi brain datatype input. If mask not inputted, will generate mask. Note: this code was originally written by Brent McPherson (bcmcpher@iu.edu) for the Anatomically-constrained white matter tractography applications. This code was taken directly from brainlife/app-mrtrix3-act. All credit should go to Brent McPherson.","doi":"10.25663/brainlife.app.528","_canedit":true},{"_id":"6036ca8c3a001153f254ebf4","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3f3362f3d3800f12c938"}],"examples":0},"projects":[],"admins":["16"],"tags":[],"removed":false,"config":{"spgr":{"type":"input","file_id":"output","input_id":"spgr"},"seir":{"type":"input","file_id":"output","input_id":"seir"},"refImage":{"type":"input","file_id":"t1","input_id":"refImage"},"spgr_name":{"id":"spgr_name","type":"string","placeholder":"","advanced":false,"desc":"","default":"","_order":2,"pid":0.3404843437049183},"seir_name":{"id":"seir_name","type":"string","placeholder":"","advanced":false,"desc":"","default":"","_order":3,"pid":0.4023694556049944},"antsThrs":{"id":"antsThrs","type":"number","placeholder":"","advanced":true,"desc":"","default":0.8,"_order":4,"pid":0.16183317884436188},"autoacpc":{"id":"autoacpc","type":"number","placeholder":"","advanced":true,"desc":"","default":0,"_order":5,"pid":0.5231343263300221},"shiftB1":{"id":"shiftB1","type":"number","placeholder":"","advanced":true,"desc":"","default":0,"_order":6,"pid":0.1999092845595738},"spgr_tr":{"id":"spgr_tr","type":"string","placeholder":"","advanced":false,"desc":"","default":"","_order":7,"pid":0.33539186563034207},"seir_tr":{"id":"seir_tr","type":"string","placeholder":"","advanced":false,"desc":"","default":"","_order":8,"pid":0.6353690400394649},"spgr_te":{"id":"spgr_te","type":"string","placeholder":"","advanced":false,"desc":"","default":"","_order":9,"pid":0.16256736333716426},"seir_te":{"id":"seir_te","type":"string","placeholder":"","advanced":false,"desc":"","default":"","_order":10,"pid":0.6956491736634527},"spgr_flipangle":{"id":"spgr_flipangle","type":"string","placeholder":"","advanced":false,"desc":"","default":"","_order":11,"pid":0.912984543569143},"spgr_fieldstrength":{"id":"spgr_fieldstrength","type":"string","placeholder":"","advanced":false,"desc":"","default":"","_order":12,"pid":0.7142417344583452},"seir_it":{"id":"seir_it","type":"string","placeholder":"","advanced":false,"desc":"","default":"","_order":13,"pid":0.7734746455163415}},"inputs":[{"datatype_tags":["spgr"],"optional":false,"multi":false,"advanced":false,"_id":"6036ca8c3a001140a854ebf5","id":"spgr","datatype":"59c3eae633fc1cf9ead71679"},{"datatype_tags":["seir"],"optional":false,"multi":false,"advanced":false,"_id":"6036ca8c3a0011221054ebf6","id":"seir","datatype":"59c3eae633fc1cf9ead71679"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"6036ca8c3a0011a71a54ebf7","id":"refImage","datatype":"58c33bcee13a50849b25879a"}],"outputs":[{"datatype_tags":["mrq","qt1"],"output_on_root":false,"archive":true,"_id":"6036caa33a0011a9c054ec56","id":"results","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null}],"github_branch":"main","github":"brainlife/app-qt1-mrq","name":"Fit qT1 models using mrQ","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3f3362f3d3800f12c939"}],"create_date":"2021-02-24T21:52:12.157Z","desc":null,"__v":3203,"doi":"10.25663/brainlife.app.481","_canedit":true},{"_id":"5f8824eff5848e2f8a392e29","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3ddf62f3d3800f12b86b"}],"success_rate":66.66666666666666,"users":4,"runtime_mean":76441.33333333333,"runtime_std":44698.00595726341,"requested":10,"examples":0,"groups":4},"projects":[],"admins":["146"],"tags":[],"removed":false,"config":{"masks":{"type":"input","file_id":"masks","input_id":"0"},"box_size_max":{"id":"box_size_max","type":"number","placeholder":"","advanced":false,"desc":"Maximum size of the box used by the box-counting method","default":7.5,"_order":2,"pid":0.9937403766756987,"min":1,"max":100}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5f8824eff5848e1125392e2a","id":"0","datatype":"592dded1436ee50ffd88f5d0","desc":"Collection of bundle masks of which to compute the Fractal Dimension"}],"outputs":[{"datatype_tags":["FD"],"output_on_root":false,"archive":true,"_id":"5f8824eff5848eca83392e2b","id":"csv","datatype":"599f305ad1f46fec1759f363","datatype_tags_pass":null,"files":null,"desc":"csv file with the Fractal Dimension of each bundle mask of the collection"}],"github_branch":"brainlife-app","github":"FBK-NILab/fractal_dimension","name":"Fractal Dimension (FD) of bundle masks","user_id":"146","contributors":[{"name":"Emanuele Olivetti","email":null,"_id":"634a3de062f3d3800f12b86c"}],"create_date":"2020-10-15T10:31:11.861Z","desc":"Investigation on the fractal dimension of segmented white matter bundles.","doi":"10.25663/brainlife.app.442","__v":4134,"avatar":"https://github.com/FBK-NILab/fractal_dimension/blob/brainlife-app/fractal.jpg?raw=true","_canedit":true},{"_id":"5fa45626e138ec86474ea032","stats":{"resources":[],"success_rate":60,"users":4,"runtime_mean":69566,"runtime_std":41820.37049891675,"requested":5,"examples":0,"groups":4},"projects":[],"admins":["41"],"tags":[],"removed":false,"config":{"t1":{"type":"input","file_id":"t1","input_id":"anat001"},"outres":{"id":"outres","type":"string","placeholder":"","advanced":false,"desc":"x, y and z resolution in mm for the voxels of the output nifti file","default":"1 1 1","_order":2,"pid":0.6086541914757033}},"inputs":[{"datatype_tags":["acpc_aligned"],"optional":false,"multi":false,"advanced":false,"_id":"5fa45626e138eca02e4ea033","id":"anat001","datatype":"58c33bcee13a50849b25879a"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5fa45626e138ec800f4ea034","id":"out_dir","datatype":"58c33bcee13a50849b25879a","datatype_tags_pass":null,"files":null,"desc":"The directory used to save the output file, this should be created by the Ap script"}],"github_branch":"master","github":"brainlife/app-template-python","name":"Franco Python Template","desc_override":"This is the first example of registration of the python App Template found here: https://github.com/brainlife/app-template-python","user_id":"41","contributors":[{"name":"Franco Pestilli","email":null,"_id":"634a3df362f3d3800f12b9b1"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a3df362f3d3800f12b9b2"}],"create_date":"2020-11-05T19:44:38.791Z","desc":"This is a template for a python-based brainlife.io/app","doi":"10.25663/brainlife.app.444","__v":3961,"_canedit":true},{"_id":"58c56d92e13a50849b258801","user_id":"1","create_date":"2017-02-18T01:05:51.509Z","name":"Freesurfer","desc":"Freesurfer segments the t1w anatomical data into functionally different parts of the brain. Segmentation/parcellation can then be fed to many other subsequent analysis. ","github":"brainlife/app-freesurfer","admins":["16","41","146","1"],"config":{"t1":{"type":"input","file_id":"t1","input_id":"t1"},"t2":{"type":"input","file_id":"t2","input_id":"t2"},"version":{"id":"version","type":"enum","placeholder":"","advanced":false,"desc":"Freesurfer version to use. https://surfer.nmr.mgh.harvard.edu/fswiki/ReleaseNotes","default":"7.1.0","_order":2,"pid":0.621075438339314,"options":[{"desc":"","label":"6.0.0","value":"6.0.0"},{"desc":"","label":"6.0.1","value":"6.0.1"},{"desc":"","label":"7.1.0","value":"7.1.0"}]},"hires":{"id":"hires","type":"boolean","placeholder":"","desc":"Check this flag if your input t1 has voxel sizes less than 1mm3 (submillimeter resolution) like HCP 7T. (HCP 3T is 1.25mm). The processing will take a significantly longer time. See https://surfer.nmr.mgh.harvard.edu/fswiki/SubmillimeterRecon","default":false,"_order":3,"pid":0.31383279926375174},"notalcheck":{"id":"notalcheck","type":"boolean","placeholder":"","advanced":false,"desc":"If you are seeing \"ERROR: Talairach failed\", you might be able to work around this by setting this option so that freesurfer will skip this process. If you set this option, you will need to make sure that your image is well aligned to the 3 primary axis.","default":false,"_order":4,"pid":0.45576843340824036},"cw256":{"id":"cw256","type":"boolean","placeholder":"","advanced":false,"desc":"If a scan has a field-of-view (FOV) greater than 256, check this to force the FOV to 256. You often need to do this for an image with sub 1mm voxel size (like HCP 7T)","default":false,"_order":5,"pid":0.514973599083937},"debug":{"id":"debug","type":"boolean","placeholder":"","advanced":true,"desc":"Turn on copious amount of freesurfer log","default":false,"_order":6,"pid":0.34106822319193153},"expert":{"id":"expert","type":"string","placeholder":"","advanced":true,"desc":"You can specify extra command line options for various freesurfer commands executed by recon-all. Please leave it blank unless necessary. https://surfer.nmr.mgh.harvard.edu/fswiki/recon-all#ExpertOptionsFile","default":"","_order":7,"pid":0.17204320084078728,"multiline":true,"optional":true},"hippocampal":{"id":"hippocampal","type":"boolean","placeholder":"","desc":"Generate an automated segmentation of the hippocampal subfields based on a statistical atlas built primarily upon ultra-high resolution (~0.1 mm isotropic) ex vivo MRI data. This new method can take advantage high-resolution, dedicated images when available (typically, but not necessarily, T2 weighted), and solves a number of limitations of the in vivo atlas that was distributed with FreeSurfer 5.1-5.3, namely","default":false,"_order":8,"pid":0.9426543163332042},"thalamicnuclei":{"id":"thalamicnuclei","type":"boolean","placeholder":"","advanced":false,"desc":"(For freesurfer >7) Generate a parcellation of the thalamus into 25 different nuclei, using a probabilistic atlas built with histological data. The parcellation is based on structural MRI, either the main T1 scan processed through recon-all, or an additional scan of a different modality, which potentially shows better contrast between the nuclei. [http://freesurfer.net/fswiki/ThalamicNuclei]","default":false,"_order":9,"pid":0.009416088090288932}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"58fa8210af44920021b9e0d0","id":"t1","datatype":"58c33bcee13a50849b25879a","desc":"ACPC aligned anatomy input to segment"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5ba128f901381a0028908880","id":"t2","datatype":"594c0325fa1d2e5a1f0beda5","desc":"Using T2 to improve pial surfaces"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"58fa8210af44920021b9e0d1","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e","files":null,"datatype_tags_pass":"t1"},{"datatype_tags":["aparc"],"output_on_root":false,"archive":false,"_id":"5fc662c01828bc0be551fb72","id":"parc","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags_pass":null,"files":null},{"datatype_tags":["aparc.a2009s"],"output_on_root":false,"archive":false,"_id":"5fc662c01828bc37e851fb73","id":"parc2009","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags_pass":null,"files":null},{"datatype_tags":["aparc.DKTAtlas"],"output_on_root":false,"archive":false,"_id":"5fc662c01828bc050351fb74","id":"parcDKT","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags_pass":null,"files":null}],"__v":14376,"tags":["analysis","anatomy-preprocessing"],"removed":false,"_rate":5,"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a305462f3d3800f115eed"},{"name":"Giulia Bertò","email":null,"_id":"634a305462f3d3800f115eee"},{"name":"Franco Pestilli","email":null,"_id":"634a305462f3d3800f115eef"},{"name":"Brad Caron","email":null,"_id":"634a305462f3d3800f115ef0"},{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a305462f3d3800f115ef1"}],"projects":[],"avatar":"https://raw.githubusercontent.com/brain-life/app-freesurfer/master/docs/fscortex.png","github_branch":"1.12","references":[],"stats":{"stars":1,"serviceinfo":{"_id":"5d729e1e78356a109788b237","counts":{"_id":"5e5c687087cac710c7ab1b93","failed":2373,"finished":7602,"removed":15314,"requested":17864,"running":10020,"running_sync":0,"stop_requested":967},"success_rate":76.21052631578948,"users":86,"readme_status":"ok","runtime_mean":33554577.82,"runtime_std":31101394.54702112,"service":"brainlife/app-freesurfer","__v":0},"gitinfo":{"desc":"Freesurfer segments the t1w anatomical data into functionally different parts of the brain. Segmentation/parcellation can then be fed to many other subsequent analysis. Please consider using OSG version of Freesurfer (https://brainlife.io/app/5931c0b8ff090a00210eff09) to process a large number of subjects. ","tags":["analysis","anatomy-preprocessing"],"stats":{"stars":1},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null},{"name":"Lindsey Kitchell","email":null}]},"success_rate":57.46525157050129,"users":370,"runtime_mean":17880985.44,"runtime_std":8742266.217776744,"requested":309564,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a305362f3d3800f115ee7"},{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a305362f3d3800f115ee8"},{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"634a305362f3d3800f115ee9"},{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"634a305362f3d3800f115eea"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a305362f3d3800f115eeb"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"634a305362f3d3800f115eec"}],"examples":5,"groups":892},"doi":"10.25663/bl.app.0","deprecated_by":"5fe1056057aacd480f2f8e48","_canedit":true},{"_id":"5fe1056057aacd480f2f8e48","projects":[],"admins":["1"],"tags":["analysis","anatomy-preprocessing"],"removed":false,"user_id":"1","name":"Freesurfer 7.1.1","desc":"Freesurfer segments the t1w anatomical data into functionally different parts of the brain. Segmentation/parcellation can then be fed to many other subsequent analysis. ","github":"brainlife/app-freesurfer","config":{"t1":{"type":"input","file_id":"t1","input_id":"t1"},"t2":{"type":"input","file_id":"t2","input_id":"t2"},"hires":{"id":"hires","type":"boolean","placeholder":"","desc":"Check this flag if your input t1 has voxel sizes less than 1mm3 (submillimeter resolution) like HCP 7T. (HCP 3T is 1.25mm). The processing will take a significantly longer time. See https://surfer.nmr.mgh.harvard.edu/fswiki/SubmillimeterRecon","default":false,"_order":3,"pid":0.9089035024355487},"notalcheck":{"id":"notalcheck","type":"boolean","placeholder":"","advanced":false,"desc":"If you are seeing \"ERROR: Talairach failed\", you might be able to work around this by setting this option so that freesurfer will skip this process. If you set this option, you will need to make sure that your image is well aligned to the 3 primary axis.","default":false,"_order":4,"pid":0.5293136409413339},"cw256":{"id":"cw256","type":"boolean","placeholder":"","advanced":false,"desc":"If a scan has a field-of-view (FOV) greater than 256, check this to force the FOV to 256. You often need to do this for an image with sub 1mm voxel size (like HCP 7T)","default":false,"_order":5,"pid":0.45628632413700143},"debug":{"id":"debug","type":"boolean","placeholder":"","advanced":true,"desc":"Turn on copious amount of freesurfer log","default":false,"_order":6,"pid":0.10750995985935008},"expert":{"id":"expert","type":"string","placeholder":"","advanced":true,"desc":"You can specify extra command line options for various freesurfer commands executed by recon-all. Please leave it blank unless necessary. https://surfer.nmr.mgh.harvard.edu/fswiki/recon-all#ExpertOptionsFile","default":"","_order":7,"pid":0.4544921047404702,"multiline":true,"optional":true},"hippocampal":{"id":"hippocampal","type":"boolean","placeholder":"","desc":"Generate an automated segmentation of the hippocampal subfields based on a statistical atlas built primarily upon ultra-high resolution (~0.1 mm isotropic) ex vivo MRI data. This new method can take advantage high-resolution, dedicated images when available (typically, but not necessarily, T2 weighted), and solves a number of limitations of the in vivo atlas that was distributed with FreeSurfer 5.1-5.3, namely","default":false,"_order":8,"pid":0.7807933875564661},"thalamicnuclei":{"id":"thalamicnuclei","type":"boolean","placeholder":"","advanced":false,"desc":"(For freesurfer >7) Generate a parcellation of the thalamus into 25 different nuclei, using a probabilistic atlas built with histological data. The parcellation is based on structural MRI, either the main T1 scan processed through recon-all, or an additional scan of a different modality, which potentially shows better contrast between the nuclei. [http://freesurfer.net/fswiki/ThalamicNuclei]","default":false,"_order":9,"pid":0.0679482980028594},"localGI":{"id":"localGI","type":"boolean","placeholder":"","advanced":true,"desc":"local Gyrification Index (lGI) This will produce files named lh.pial_lgi and rh.pial_lgi in the subjects surf directory. These files can be loaded as overlays in tksurfer. See https://surfer.nmr.mgh.harvard.edu/fswiki/LGI","default":false,"_order":10,"pid":0.5398735239620145}},"inputs":[{"id":"t1","desc":"ACPC aligned anatomy input to segment","datatype":"58c33bcee13a50849b25879a","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"58fa8210af44920021b9e0d0"},{"id":"t2","desc":"Using T2 to improve pial surfaces","datatype":"594c0325fa1d2e5a1f0beda5","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5ba128f901381a0028908880"}],"outputs":[{"id":"freesurfer","datatype":"58cb22c8e13a50849b25882e","datatype_tags":[],"datatype_tags_pass":"t1","output_on_root":false,"files":null,"archive":true,"_id":"58fa8210af44920021b9e0d1"},{"id":"parc","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags":["aparc"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":false,"_id":"5fc662c01828bc0be551fb72"},{"id":"parc2009","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags":["aparc.a2009s"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":false,"_id":"5fc662c01828bc37e851fb73"},{"id":"parcDKT","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags":["aparc.DKTAtlas"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":false,"_id":"5fc662c01828bc050351fb74"}],"__v":3700,"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a3e8762f3d3800f12be73"},{"name":"Giulia Bertò","email":null,"_id":"634a3e8762f3d3800f12be74"},{"name":"Franco Pestilli","email":null,"_id":"634a3e8762f3d3800f12be75"},{"name":"Brad Caron","email":null,"_id":"634a3e8762f3d3800f12be76"},{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a3e8762f3d3800f12be77"}],"avatar":"https://raw.githubusercontent.com/brain-life/app-freesurfer/master/docs/fscortex.png","github_branch":"7.1.1-1","stats":{"gitinfo":{"desc":"Freesurfer segments the t1w anatomical data into functionally different parts of the brain. Segmentation/parcellation can then be fed to many other subsequent analysis. Please consider using OSG version of Freesurfer (https://brainlife.io/app/5931c0b8ff090a00210eff09) to process a large number of subjects. ","tags":["analysis","anatomy-preprocessing"],"stats":{"stars":1},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null},{"name":"Lindsey Kitchell","email":null}]},"success_rate":57.46525157050129,"users":370,"runtime_mean":17880985.44,"runtime_std":8742266.217776744,"requested":309564,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3e8662f3d3800f12be6d"},{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a3e8662f3d3800f12be6e"},{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"634a3e8662f3d3800f12be6f"},{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"634a3e8662f3d3800f12be70"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3e8662f3d3800f12be71"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"634a3e8662f3d3800f12be72"}],"examples":5,"groups":892},"create_date":"2020-12-21T20:28:16.298Z","doi":"10.25663/brainlife.app.462","_canedit":true},{"_id":"621abcaa5d8ab5d5f015c555","user_id":"16","projects":[],"admins":["16"],"name":"Freesurfer 7.1.1 - Multiple T1w Inputs","github":"bacaron/app-freesurfer","github_branch":"7.1.1-multiple-t1-reference","desc_override":"Freesurfer segments the t1w anatomical data into functionally different parts of the brain. Segmentation/parcellation can then be fed to many other subsequent analysis. This is a copy of https://doi.org/10.25663/brainlife.app.462, but updated to allow for multiple T1w inputs","tags":[],"config":{"t1_ref":{"type":"input","file_id":"t1","input_id":"t1_ref"},"t1":{"type":"input","file_id":"t1","input_id":"t1"},"t2":{"type":"input","file_id":"t2","input_id":"t2"},"hires":{"id":"hires","type":"boolean","placeholder":"","advanced":false,"desc":"Check this flag if your input t1 has voxel sizes less than 1mm3 (submillimeter resolution) like HCP 7T. (HCP 3T is 1.25mm). The processing will take a significantly longer time. See https://surfer.nmr.mgh.harvard.edu/fswiki/SubmillimeterRecon","default":false,"_order":2,"pid":0.4792546917778867},"notalcheck":{"id":"notalcheck","type":"boolean","placeholder":"","advanced":false,"desc":"If you are seeing \"ERROR: Talairach failed\", you might be able to work around this by setting this option so that freesurfer will skip this process. If you set this option, you will need to make sure that your image is well aligned to the 3 primary axis.","default":false,"_order":3,"pid":0.7171128730630341},"cw256":{"id":"cw256","type":"boolean","placeholder":"","advanced":false,"desc":"If a scan has a field-of-view (FOV) greater than 256, check this to force the FOV to 256. You often need to do this for an image with sub 1mm voxel size (like HCP 7T)","default":false,"_order":4,"pid":0.00738217233969396},"debug":{"id":"debug","type":"boolean","placeholder":"","advanced":true,"desc":"Turn on copious amount of freesurfer log","default":false,"_order":5,"pid":0.5206988322093052},"expert?":{"id":"expert?","type":"string","placeholder":"","advanced":true,"desc":"You can specify extra command line options for various freesurfer commands executed by recon-all. Please leave it blank unless necessary. https://surfer.nmr.mgh.harvard.edu/fswiki/recon-all#ExpertOptionsFile","default":"","_order":6,"pid":0.4012504347890503,"optional":true},"hippocampal":{"id":"hippocampal","type":"boolean","placeholder":"","advanced":false,"desc":"Generate an automated segmentation of the hippocampal subfields based on a statistical atlas built primarily upon ultra-high resolution (~0.1 mm isotropic) ex vivo MRI data. This new method can take advantage high-resolution, dedicated images when available (typically, but not necessarily, T2 weighted), and solves a number of limitations of the in vivo atlas that was distributed with FreeSurfer 5.1-5.3, namely","default":false,"_order":7,"pid":0.26235395293008934},"thalamicnuclei":{"id":"thalamicnuclei","type":"boolean","placeholder":"","advanced":false,"desc":"(For freesurfer >7) Generate a parcellation of the thalamus into 25 different nuclei, using a probabilistic atlas built with histological data. The parcellation is based on structural MRI, either the main T1 scan processed through recon-all, or an additional scan of a different modality, which potentially shows better contrast between the nuclei. [http://freesurfer.net/fswiki/ThalamicNuclei]","default":false,"_order":8,"pid":0.7912048443349061},"localGI":{"id":"localGI","type":"boolean","placeholder":"","advanced":true,"desc":"local Gyrification Index (lGI) This will produce files named lh.pial_lgi and rh.pial_lgi in the subjects surf directory. These files can be loaded as overlays in tksurfer. See https://surfer.nmr.mgh.harvard.edu/fswiki/LGI","default":false,"_order":9,"pid":0.9950879772732623}},"inputs":[{"id":"t1_ref","desc":"Intended to be used to provide a reference T1 for Freesurfer. T1-weighted magnetic resonance data (MRI), saved in NIfTI-1 format.","datatype":"58c33bcee13a50849b25879a","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"6226b82d5d8ab5d5f029466d"},{"id":"t1","desc":"T1-weighted magnetic resonance data (MRI), saved in NIfTI-1 format.","datatype":"58c33bcee13a50849b25879a","datatype_tags":[],"optional":false,"multi":true,"advanced":false,"_id":"621abcaa5d8ab5d5f015c556"},{"id":"t2","desc":"Using T2 to improve pial surfaces","datatype":"594c0325fa1d2e5a1f0beda5","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"621abcaa5d8ab5d5f015c557"}],"outputs":[{"id":"freesurfer","desc":"Folder structure generated by FreeSurfer recon-all process.","datatype":"58cb22c8e13a50849b25882e","datatype_tags":[],"datatype_tags_pass":"t1_ref","output_on_root":false,"files":null,"archive":true,"_id":"621abcaa5d8ab5d5f015c558"},{"id":"parc","desc":"(aka \"segmentation\") parc.nii.gz containing volumetric parcellation / atlas, along with a key.txt file indicating the coorespondance between parc.nii.gz labels and human readable region names.","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags":["aparc"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"621abcaa5d8ab5d5f015c559"},{"id":"parc2009","desc":"(aka \"segmentation\") parc.nii.gz containing volumetric parcellation / atlas, along with a key.txt file indicating the coorespondance between parc.nii.gz labels and human readable region names.","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags":["aparc.a2009s"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"621abcaa5d8ab5d5f015c55a"},{"id":"parcDKT","desc":"(aka \"segmentation\") parc.nii.gz containing volumetric parcellation / atlas, along with a key.txt file indicating the coorespondance between parc.nii.gz labels and human readable region names.","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags":["aparc.DKTAtlas"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"621abcaa5d8ab5d5f015c55b"}],"stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a439e62f3d3800f13052f"}],"success_rate":55.26315789473685,"users":5,"runtime_mean":22507547.73,"runtime_std":6051231.848881931,"requested":691,"examples":1,"groups":5},"removed":false,"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a439f62f3d3800f130530"},{"name":"Brad Caron","email":null,"_id":"634a439f62f3d3800f130531"},{"name":"Franco Pestilli","email":null,"_id":"634a439f62f3d3800f130532"},{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a439f62f3d3800f130533"}],"create_date":"2022-02-26T23:50:02.652Z","desc":"Freesurfer segments the t1w anatomical data into functionally different parts of the brain. Segmentation/parcellation can then be fed to many other subsequent analysis. ","__v":780,"doi":"10.25663/brainlife.app.605","_canedit":true},{"_id":"61e1a03433cb3deb499043ba","user_id":"1","projects":[],"admins":["1"],"avatar":"https://surfer.nmr.mgh.harvard.edu/wiki/fswiki_htdocs/common/fslogosmall.png","name":"Freesurfer 7.1.1 Longitudinal (Step 2/2)","github":"brainlife/app-freesurfer-longitudinal","github_branch":"main","desc":"This App allows brainlife.io to perform freesurfer longitudinal processing","desc_override":"This is step 2 of Freesurfer longitudinal processing.  This App uses the longitudinal base template created by \"Longitudinal Template\" App and a freesurfer output and run longitudinal data products. https://surfer.nmr.mgh.harvard.edu/fswiki/FsTutorial/LongitudinalTutorial","tags":[],"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a438c62f3d3800f130467"}],"config":{"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"template":{"type":"input","file_id":"template","input_id":"template"},"timepoints":{"type":"input","file_id":"timepoints","input_id":"template"},"mode":{"id":"mode","type":"string","placeholder":"","advanced":true,"desc":"","default":"long","_order":2,"pid":0.9134375459259987,"readonly":true}},"inputs":[{"id":"freesurfer","datatype":"58cb22c8e13a50849b25882e","datatype_tags":["!longitudinal-template","!longitudinal"],"optional":false,"multi":false,"advanced":false,"_id":"61e195b233cb3deb499027b5"},{"id":"template","desc":"Longitudinal base template geneerated by \"Longitudinal Template\" App. ","datatype":"59bbfadd6b956e1c2ae89ef3","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"61e1a08433cb3deb49904eec"}],"outputs":[{"id":"output","datatype":"58cb22c8e13a50849b25882e","datatype_tags":["longitudinal"],"datatype_tags_pass":"freesurfer","output_on_root":false,"files":null,"archive":true,"_id":"61e195b233cb3deb499027b6"}],"stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a438b62f3d3800f130465"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a438b62f3d3800f130466"}],"examples":2,"success_rate":54.803583735354934,"users":4,"runtime_mean":7234278.02,"runtime_std":749569.9601947503,"requested":11215,"groups":8},"removed":false,"__v":1020,"create_date":"2022-01-14T16:09:24.274Z","doi":"10.25663/brainlife.app.603","_canedit":true},{"_id":"61e195b233cb3deb499027b4","user_id":"1","projects":[],"admins":["1"],"avatar":"https://surfer.nmr.mgh.harvard.edu/wiki/fswiki_htdocs/common/fslogosmall.png","name":"Freesurfer 7.1.1 Longitudinal (Step1/2)","github":"brainlife/app-freesurfer-longitudinal","github_branch":"main","desc_override":"This is step 1 of Freesurfer longitudinal processing.  This App produces base template from multiple preprocessed freesurfer output (from the same subjects at different timepoints) https://surfer.nmr.mgh.harvard.edu/fswiki/FsTutorial/LongitudinalTutorial","tags":[],"config":{"freesurfers":{"type":"input","file_id":"output","input_id":"freesurfer"},"mode":{"id":"mode","type":"string","placeholder":"","advanced":true,"desc":"","default":"base","_order":2,"pid":0.7659357319247719,"readonly":true}},"inputs":[{"id":"freesurfer","datatype":"58cb22c8e13a50849b25882e","datatype_tags":[],"optional":false,"multi":true,"advanced":false,"_id":"61e195b233cb3deb499027b5"}],"outputs":[{"id":"output","datatype":"59bbfadd6b956e1c2ae89ef3","datatype_tags":[],"datatype_tags_pass":"freesurfer","output_on_root":false,"files":null,"archive":true,"_id":"61e195b233cb3deb499027b6"}],"stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a438162f3d3800f1302c9"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a438162f3d3800f1302ca"}],"examples":2,"success_rate":54.803583735354934,"users":4,"runtime_mean":7234278.02,"runtime_std":749569.9601947503,"requested":11215,"groups":8},"removed":false,"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a438162f3d3800f1302cb"}],"create_date":"2022-01-14T15:24:34.972Z","desc":"This App allows brainlife.io to perform freesurfer longitudinal processing","__v":1020,"doi":"10.25663/brainlife.app.602","_canedit":true},{"_id":"62fa925519b13f0a0edd5c7c","user_id":"146","projects":[],"admins":["146","16","1","41"],"avatar":"https://raw.githubusercontent.com/brain-life/app-freesurfer/master/docs/fscortex.png","name":"Freesurfer 7.3.2","github":"brainlife/app-freesurfer","github_branch":"7.3.2","desc_override":"","tags":["analysis","anatomy-preprocessing"],"config":{"t1":{"type":"input","file_id":"t1","input_id":"t1"},"t2":{"type":"input","file_id":"t2","input_id":"t2"},"hires":{"id":"hires","type":"boolean","placeholder":"","advanced":false,"desc":"Check this flag if your input t1 has voxel sizes less than 1mm3 (submillimeter resolution) like HCP 7T. (HCP 3T is 1.25mm). The processing will take a significantly longer time. See https://surfer.nmr.mgh.harvard.edu/fswiki/SubmillimeterRecon","default":false,"_order":2,"pid":0.7287357965991992},"notalcheck":{"id":"notalcheck","type":"boolean","placeholder":"","advanced":false,"desc":"If you are seeing \"ERROR: Talairach failed\", you might be able to work around this by setting this option so that freesurfer will skip this process. If you set this option, you will need to make sure that your image is well aligned to the 3 primary axis.","default":false,"_order":3,"pid":0.2083868330723695},"cw256":{"id":"cw256","type":"boolean","placeholder":"","advanced":false,"desc":"If a scan has a field-of-view (FOV) greater than 256, check this to force the FOV to 256. You often need to do this for an image with sub 1mm voxel size (like HCP 7T)","default":false,"_order":4,"pid":0.9440285556432155},"debug":{"id":"debug","type":"boolean","placeholder":"","advanced":true,"desc":"Turn on copious amount of freesurfer log","default":false,"_order":5,"pid":0.2953658771847876},"expert":{"id":"expert","type":"string","placeholder":"","advanced":true,"desc":"You can specify extra command line options for various freesurfer commands executed by recon-all. Please leave it blank unless necessary. https://surfer.nmr.mgh.harvard.edu/fswiki/recon-all#ExpertOptionsFile","default":"","_order":6,"pid":0.6238111432258551,"optional":true,"multiline":true},"hippocampal":{"id":"hippocampal","type":"boolean","placeholder":"","advanced":false,"desc":"Generate an automated segmentation of the hippocampal subfields based on a statistical atlas built primarily upon ultra-high resolution (~0.1 mm isotropic) ex vivo MRI data. This new method can take advantage high-resolution, dedicated images when available (typically, but not necessarily, T2 weighted), and solves a number of limitations of the in vivo atlas that was distributed with FreeSurfer 5.1-5.3, namely","default":false,"_order":7,"pid":0.26913840360274044},"thalamicnuclei":{"id":"thalamicnuclei","type":"boolean","placeholder":"","advanced":false,"desc":"(For freesurfer >7) Generate a parcellation of the thalamus into 25 different nuclei, using a probabilistic atlas built with histological data. The parcellation is based on structural MRI, either the main T1 scan processed through recon-all, or an additional scan of a different modality, which potentially shows better contrast between the nuclei. [http://freesurfer.net/fswiki/ThalamicNuclei]","default":false,"_order":8,"pid":0.8912645874039573}," localGI":{"id":" localGI","type":"boolean","placeholder":"","advanced":false,"desc":"local Gyrification Index (lGI) This will produce files named lh.pial_lgi and rh.pial_lgi in the subjects surf directory. These files can be loaded as overlays in tksurfer. See https://surfer.nmr.mgh.harvard.edu/fswiki/LGI","default":false,"_order":9,"pid":0.7559196209986805}},"inputs":[{"id":"t1","datatype":"58c33bcee13a50849b25879a","datatype_tags":[],"optional":false,"includes":"ACPC aligned anatomy input to segment","multi":false,"advanced":false,"_id":"62fa925519b13f0a0edd5c7d"},{"id":"t2","datatype":"594c0325fa1d2e5a1f0beda5","datatype_tags":[],"optional":true,"includes":"Using T2 to improve pial surfaces","multi":false,"advanced":false,"_id":"62fa925519b13f0a0edd5c7e"}],"outputs":[{"id":"freesurfer","desc":"","datatype":"58cb22c8e13a50849b25882e","datatype_tags":[],"datatype_tags_pass":"t1","output_on_root":false,"files":null,"archive":true,"_id":"62fa925519b13f0a0edd5c7f"},{"id":"parc","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags":["aparc"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":false,"_id":"62fa925519b13f0a0edd5c80"},{"id":"parc2009","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags":["aparc.a2009s"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":false,"_id":"62fa925519b13f0a0edd5c81"},{"id":"parcDKT","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags":["aparc.DKTAtlas"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":false,"_id":"62fa925519b13f0a0edd5c82"}],"stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a45ad62f3d3800f13117c"},{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a45ad62f3d3800f13117d"},{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"634a45ad62f3d3800f13117e"},{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"634a45ad62f3d3800f13117f"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a45ad62f3d3800f131180"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"634a45ad62f3d3800f131181"}],"success_rate":57.46525157050129,"users":370,"groups":892,"runtime_mean":17880985.44,"runtime_std":8742266.217776744,"requested":309564,"examples":1},"removed":false,"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a45ae62f3d3800f131182"},{"name":"Giulia Bertò","email":null,"_id":"634a45ae62f3d3800f131183"},{"name":"Franco Pestilli","email":null,"_id":"634a45ae62f3d3800f131184"},{"name":"Brad Caron","email":null,"_id":"634a45ae62f3d3800f131185"},{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a45ae62f3d3800f131186"}],"create_date":"2022-08-15T18:37:09.298Z","desc":"Freesurfer segments the t1w anatomical data into functionally different parts of the brain. Segmentation/parcellation can then be fed to many other subsequent analysis. ","__v":20,"doi":"10.25663/brainlife.app.664","_canedit":true},{"_id":"59714d376c3b7e0029153f53","name":"Freesurfer Deface","desc":"Runs freesurfer/mri_deface with talairach_mixed_with_skull.gca and face.gca","github":"brainlife/app-deface","github_branch":"7.1.1","config":{"t1":{"file_id":"t1","input_id":"t1","type":"input"}},"user_id":"1","create_date":"2017-07-21T00:39:19.596Z","removed":false,"_rate":5,"outputs":[{"datatype_tags":["defaced"],"output_on_root":false,"archive":true,"_id":"59714d376c3b7e0029153f54","id":"out","datatype":"58c33bcee13a50849b25879a","files":null,"datatype_tags_pass":"t1"}],"inputs":[{"datatype_tags":["!defaced"],"optional":false,"multi":false,"advanced":false,"_id":"59714d376c3b7e0029153f55","id":"t1","datatype":"58c33bcee13a50849b25879a"}],"tags":["anatomy-preprocessing"],"admins":["16","41","146","1"],"__v":14291,"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a30f362f3d3800f116552"}],"projects":[],"references":[],"stats":{"stars":0,"requested":2264,"users":20,"success_rate":40.456989247311824,"serviceinfo":{"_id":"5d729e1f78356a109788b2ad","counts":{"_id":"5e5c688187cac703e0ab1ba6","failed":859,"finished":2196,"removed":6528,"requested":6993,"running":2969,"running_sync":0,"stop_requested":59},"success_rate":71.88216039279868,"users":24,"readme_status":"too short","runtime_mean":1513684.8,"runtime_std":1709238.5304946993,"service":"brain-life/app-deface","__v":0},"gitinfo":{"desc":"Runs freesurfer/mri_deface with talairach_mixed_with_skull.gca and face.gca","tags":["anatomy-preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":1006699.69,"runtime_std":1407053.529012473,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a30f362f3d3800f116551"}],"examples":1,"groups":25},"doi":"10.25663/brainlife.app.146","_canedit":true},{"_id":"5b7f0f89b3e3800027ce9b6c","projects":[],"admins":["16","41","146","1"],"tags":[],"removed":false,"config":{"outputs":{"type":"input","file_id":"output","input_id":"freesurfer"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":true,"advanced":false,"_id":"5b7f0f89b3e3800027ce9b6d","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e"}],"outputs":[],"name":"Freesurfer Group Analysis","github":"brainlife/app-freesurfer-agg","user_id":"1","references":[],"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a33b362f3d3800f118014"}],"create_date":"2018-08-23T19:48:25.197Z","desc":"Do some basic group analysis on freesurfer outputs","stats":{"stars":0,"requested":24,"users":9,"success_rate":57.89473684210527,"serviceinfo":{"_id":"5d729e1f78356a109788b29d","counts":{"_id":"5e5c3db887cac78b76ab13cc","failed":1,"finished":11,"removed":15,"requested":15,"running":11,"running_sync":0,"stop_requested":0},"success_rate":91.66666666666666,"users":6,"readme_status":"too short","runtime_mean":193613,"runtime_std":167896.7124925863,"service":"brainlife/app-freesurfer-agg","__v":0},"gitinfo":{"desc":"Do some basic group analysis on freesurfer outputs","tags":[],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":193613,"runtime_std":167896.7124925863,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a33b362f3d3800f118012"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a33b362f3d3800f118013"}],"examples":0,"groups":7},"doi":"10.25663/bl.app.94","__v":11131,"_canedit":true},{"_id":"5aa826baf315ba00317fe086","name":"Freesurfer Labels to 3D Surfaces","desc":"This application will create a 3D surface for 87 freesurfer labels from the aparc+aseg.mgz file. ","citation":null,"avatar":"https://raw.githubusercontent.com/kitchell/app-3Dfreesurfs/master/3dfreesurfs.png","github":"kitchell/app-3Dfreesurfs","github_branch":"v1.0","config":{"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"filetype":{"type":"enum","placeholder":"","desc":"choose output filetype","default":"vtk","options":[{"desc":"use .vtk filetype","label":".vtk","value":"vtk"},{"desc":"use .ply filetype","label":".ply","value":"ply"},{"desc":"use .stl filetype","label":".stl","value":"stl"}],"id":"filetype","pid":0.007203535789236382,"_order":2,"readonly":false}},"user_id":"43","create_date":"2018-03-13T19:30:02.173Z","removed":false,"_rate":0,"outputs":[{"datatype_tags":["freesurfer"],"output_on_root":true,"archive":true,"_id":"5aa826baf315ba00317fe087","id":"surfaces","datatype":"59307a08436ee50ffd973278","files":null}],"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5aa826baf315ba00317fe088","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e"}],"contributors":[{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a323262f3d3800f116fe3"},{"name":"Steven O'Riley","email":null,"_id":"634a323262f3d3800f116fe4"},{"name":null,"email":null,"_id":"634a323262f3d3800f116fe5"}],"tags":["postprocessing"],"references":[],"admins":["43"],"projects":[],"__v":14244,"stats":{"stars":0,"requested":1829,"users":19,"success_rate":84.76896748431261,"serviceinfo":{"_id":"5d729e1f78356a109788b383","counts":{"_id":"5e5c68a187cac70fe5ab1bcd","failed":253,"finished":1480,"removed":1721,"requested":1807,"running":1519,"running_sync":0,"stop_requested":2},"success_rate":85.40103866128102,"users":14,"readme_status":"ok","runtime_mean":23835989.59,"runtime_std":25927493.88505046,"service":"kitchell/app-3Dfreesurfs","__v":0},"gitinfo":{"desc":"This application will create a 3D surface for 87 freesurfer labels from the aparc+aseg.mgz file. ","tags":["postprocessing"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Steven O'Riley","email":null}]},"runtime_mean":20676283.97,"runtime_std":25373756.702320904,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a323262f3d3800f116fe2"}],"examples":0,"groups":13},"doi":"10.25663/bl.app.98","_canedit":true},{"_id":"622bd8be5d8ab5d5f034854a","user_id":"16","projects":[],"admins":["16"],"name":"Freesurfer Longitudinal Statistics","github":"brainlife/app-freesurfer-longitudinal-statistics","github_branch":"v1.0-free_7_1_1-wb_1_5_0","desc_override":"This app will compute longitudinal statistics using the Freesurfer Longitudinal pipeline","tags":[],"config":{"freesurfers":{"type":"input","file_id":"output","input_id":"freesurfers"},"freesurfer_template_base":{"type":"input","file_id":"template","input_id":"freesurfer_template_base"},"timepoints":{"type":"input","file_id":"timepoints","input_id":"freesurfer_template_base"},"fsaverage":{"id":"fsaverage","type":"enum","placeholder":"","advanced":false,"desc":"fsaverage space for statistic computation","default":"fsaverage6","_order":3,"pid":0.9444729245754709,"options":[{"desc":"fsaverage","label":"fsaverage","value":"fsaverage"},{"desc":"fsaverage4","label":"fsaverage4","value":"fsaverage4"},{"desc":"fsaverage5","label":"fsaverage5","value":"fsaverage5"},{"desc":"fsaverage6","label":"fsaverage6","value":"fsaverage6"},{"desc":"fsaverage3","label":"fsaverage3","value":"fsaverage3"}]},"validator_csv":{"id":"validator_csv","type":"enum","placeholder":"","advanced":false,"desc":"this is the csv to be used by the validator","default":"longitudinal_stats_aparc.a2009s","_order":4,"pid":0.9703494306555916,"options":[{"desc":"longitudinal_stats_aparc","label":"longitudinal_stats_aparc","value":"longitudinal_stats_aparc"},{"desc":"longitudinal_stats_aparc.a2009s","label":"longitudinal_stats_aparc.a2009s","value":"longitudinal_stats_aparc.a2009s"},{"desc":"longitudinal_stats_aparc.DKTatlas","label":"longitudinal_stats_aparc.DTKatlas","value":"longitudinal_stats_aparc.DKTatlas"}]},"timeframe":{"id":"timeframe","type":"string","placeholder":"","advanced":false,"desc":"this is a space separated list of timepoint sampling to compute the rate of change","default":"","_order":5,"pid":0.8817756158033835}},"inputs":[{"id":"freesurfers","datatype":"58cb22c8e13a50849b25882e","datatype_tags":["longitudinal"],"optional":false,"multi":true,"advanced":false,"_id":"622bd8be5d8ab5d5f034854b"},{"id":"freesurfer_template_base","datatype":"59bbfadd6b956e1c2ae89ef3","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"622bd8be5d8ab5d5f034854c"}],"outputs":[{"id":"parc_stats","desc":"this will contain stats from all three freesurfer parcellations","datatype":"5edd3b77c5972b8c47b3a2c3","datatype_tags":["aparc","aparc_a2009s","aparc_DKTatlas","freesurfer_longitudinal"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"622bd8be5d8ab5d5f034854d"},{"id":"cortexmap","desc":"this will contain surface versions of computed stats for visualizations and group analyses on the surface","datatype":"5c58aa5ef9109beac4b52f61","datatype_tags":["freesurfer_longitudinal"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"622bd8be5d8ab5d5f034854e"}],"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a43c662f3d3800f1307e9"}],"examples":1,"success_rate":52.63157894736842,"users":1,"runtime_mean":1020193.6666666666,"runtime_std":92726.57671898721,"requested":62,"groups":1},"removed":false,"contributors":[{"name":"Brad Caron","email":null,"_id":"634a43c662f3d3800f1307ea"}],"create_date":"2022-03-11T23:18:22.535Z","desc":null,"__v":711,"doi":"10.25663/brainlife.app.609","_canedit":true},{"_id":"5e31bea8b81ce26c2f9c9a88","stats":{"stars":0,"serviceinfo":{"_id":"5e3221e029fabd6848ed6d1e","counts":{"_id":"5e5c3e3787cac708caab144f","failed":17,"finished":139,"removed":6,"requested":164,"running":154,"running_sync":0,"stop_requested":2},"success_rate":89.1025641025641,"users":13,"readme_status":"too short","runtime_mean":70411.26,"runtime_std":231629.3800326557,"service":"brainlife/app-freesurfer-stats","__v":0},"success_rate":80.6976418279337,"users":84,"runtime_mean":566450.48,"runtime_std":1502852.264375946,"requested":118550,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a382862f3d3800f11ec67"}],"examples":5,"groups":168},"projects":[],"admins":["16"],"tags":[],"removed":false,"config":{"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"parcellation":{"id":"parcellation","type":"enum","placeholder":"","advanced":false,"desc":"","default":"","_order":2,"pid":0.7291449733089987,"options":[{"desc":"Desikan-Killiany Atlas","label":"aparc","value":"aparc"},{"desc":"Destrieux Atlas","label":"aparc.a2009s","value":"aparc.a2009s"},{"desc":"DKT Atlas","label":"aparc.DKTatlas","value":"aparc.DKTatlas"}]}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e31bea8b81ce20e409c9a89","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e","includes":"output/stats\noutput/mri/aparc*"}],"outputs":[{"datatype_tags":["freesurfer"],"output_on_root":false,"archive":true,"_id":"5edff6acc5972b7f97b41356","id":"output","datatype":"5edd3b77c5972b8c47b3a2c3","datatype_tags_pass":"freesurfer","files":null}],"github_branch":"v1.3","github":"brainlife/app-freesurfer-stats","name":"Freesurfer Statistics","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a382862f3d3800f11ec68"}],"create_date":"2020-01-29T17:19:36.866Z","desc":null,"doi":"10.25663/brainlife.app.272","__v":5719,"desc_override":"This app will convert important parcellation statistics, including volume, thickness, and curvature, to a .csv file for each hemisphere. These can be used for group analyses.","_canedit":true},{"_id":"5e03c7c332bff0800ae2a47b","stats":{"stars":0,"serviceinfo":{"_id":"5e03fcebc25c3d6b98eaf9ef","counts":{"_id":"5e5c3e3487cac73103ab144b","failed":2,"finished":0,"removed":1,"requested":2,"running":2,"running_sync":0,"stop_requested":0},"success_rate":0,"users":1,"readme_status":"ok","service":"brainlife/app-freesurfer-osg","__v":0},"success_rate":15,"users":6,"runtime_mean":59877015.666666664,"runtime_std":35020234.91876788,"requested":89,"resources":[{"resource_id":"5931bee335530000253833d2","name":"osgconnect","_id":"634a381f62f3d3800f11e864"}],"examples":1,"groups":7},"projects":[],"admins":["16","41","146","1"],"tags":[],"removed":false,"config":{"t1":{"type":"input","file_id":"t1","input_id":"t1"},"t2":{"type":"input","file_id":"t2","input_id":"t2"},"version":{"id":"version","type":"enum","placeholder":"","advanced":false,"desc":"Freesurfer version to use","default":"6.0.1","_order":2,"pid":0.1942312927606935,"options":[{"desc":"","label":"6.0.0","value":"6.0.0"},{"desc":"","label":"6.0.1","value":"6.0.1"}],"readonly":false},"hires":{"id":"hires","type":"boolean","placeholder":"","advanced":false,"desc":"Check this flag if your input t1 has voxel sizes less than 1mm3 (submillimeter resolution) like HCP 7T. (HCP 3T is 1.25mm). The processing will take a significantly longer time. See https://surfer.nmr.mgh.harvard.edu/fswiki/SubmillimeterRecon","default":false,"_order":3,"pid":0.9678324817633728},"notalcheck":{"id":"notalcheck","type":"boolean","placeholder":"","advanced":false,"desc":"If you are seeing \"ERROR: Talairach failed\", you might be able to work around this by setting this option so that freesurfer will skip this process. If you set this option, you will need to make sure that your image is well aligned to the 3 primary axis.","default":false,"_order":4,"pid":0.9422444362652957},"cw256":{"id":"cw256","type":"boolean","placeholder":"","advanced":false,"desc":"If a scan has a field-of-view (FOV) greater than 256, check this to force the FOV to 256. You often need to do this for image with sub 1mm voxel size (like HCP 7T)","default":false,"_order":5,"pid":0.7023986229420902},"hippocampal":{"id":"hippocampal","type":"boolean","placeholder":"","advanced":false,"desc":"(only for >7) Generate an automated segmentation of the hippocampal subfields based on a statistical atlas built primarily upon ultra-high resolution (~0.1 mm isotropic) ex vivo MRI data. This new method can take advantage high-resolution, dedicated images when available (typically, but not necessarily, T2 weighted), and solves a number of limitations of the in vivo atlas that was distributed with FreeSurfer 5.1-5.3, namely","default":false,"_order":6,"pid":0.9244089938014994,"readonly":false},"debug":{"id":"debug","type":"boolean","placeholder":"","advanced":true,"desc":"Turn on copious amount of freesurfer log","default":false,"_order":7,"pid":0.6494766442088054}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e03c7c332bff08cbae2a47d","id":"t1","datatype":"58c33bcee13a50849b25879a"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5e03c7c332bff0c0c7e2a47c","id":"t2","datatype":"594c0325fa1d2e5a1f0beda5"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5e03c7c332bff0f5e0e2a47e","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e","datatype_tags_pass":null,"files":null}],"github_branch":"master","github":"brainlife/app-freesurfer-osg","name":"Freesurfer on OSG","user_id":"1","contributors":[{"name":"Mats Rynge","email":"mats@rynge.net","_id":"634a382062f3d3800f11e865"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a382062f3d3800f11e866"}],"create_date":"2019-12-25T20:34:11.450Z","desc":"A Pegasus workflow for running FreeSurfer on the Open Science Grid","doi":"10.25663/brainlife.app.268","__v":6446,"desc_override":"Submit Freesurfer workflow on Open Science Grid (A national, distributed computing partnership for data-intensive research)","avatar":"https://raw.githubusercontent.com/soichih/app-fsurf/master/docs/logo.png","_canedit":true},{"_id":"5931c0b8ff090a00210eff09","name":"Freesurfer on OSG (fsurf)","desc":"A Pegasus workflow for running FreeSurfer on the Open Science Grid","avatar":"https://raw.githubusercontent.com/soichih/app-fsurf/master/docs/logo.png","github":"brainlife/app-freesurfer-osg","github_branch":"master","config":{"t1":{"type":"input","file_id":"t1","input_id":"t1"},"t2":{"type":"input","file_id":"t2","input_id":"t2"},"hippocampal":{"id":"hippocampal","type":"boolean","placeholder":"","advanced":false,"desc":"Generate an automated segmentation of the hippocampal subfields based on a statistical atlas built primarily upon ultra-high resolution (~0.1 mm isotropic) ex vivo MRI data. This new method can take advantage high-resolution, dedicated images when available (typically, but not necessarily, T2 weighted), and solves a number of limitations of the in vivo atlas that was distributed with FreeSurfer 5.1-5.3, namely","default":false,"_order":2,"pid":0.9371939850430882},"hires":{"id":"hires","type":"boolean","placeholder":"","advanced":false,"desc":"Check this flag if your input t1 has voxel sizes less than 1mm3 (submillimeter resolution) like HCP 7T. (HCP 3T is 1.25mm). The processing will take a significantly longer time. See https://surfer.nmr.mgh.harvard.edu/fswiki/SubmillimeterRecon","default":false,"_order":3,"pid":0.8664396732553938},"notalcheck":{"id":"notalcheck","type":"boolean","placeholder":"","advanced":false,"desc":"If you are seeing \"ERROR: Talairach failed\", you might be able to work around this by setting this option so that freesurfer will skip this process. If you set this option, you will need to make sure that your image is well aligned to the 3 primary axis.","default":false,"_order":4,"pid":0.05410054325441549},"cw256":{"id":"cw256","type":"boolean","placeholder":"","advanced":false,"desc":"If a scan has a field-of-view (FOV) greater than 256, check this to force the FOV to 256. You often need to do this for image with sub 1mm voxel size (like HCP 7T)","default":false,"_order":5,"pid":0.8622407972230652},"debug":{"id":"debug","type":"boolean","placeholder":"","advanced":true,"desc":"Turn on copious amount of freesurfer log","default":false,"_order":6,"pid":0.8660641968387137}},"user_id":"1","removed":false,"create_date":"2017-06-02T19:47:04.671Z","outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5931c0b8ff090a00210eff07","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e","files":null}],"inputs":[{"datatype_tags":["defaced"],"optional":false,"multi":false,"advanced":false,"_id":"5931c0b8ff090a00210eff08","id":"t1","datatype":"58c33bcee13a50849b25879a"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ea9b990f1745d0e38f84424","id":"t2","datatype":"594c0325fa1d2e5a1f0beda5","desc":"Using T2 to improve pial surfaces"}],"admins":["16","41","146","1"],"__v":14318,"tags":[],"_rate":4,"contributors":[{"name":"Mats Rynge","email":"mats@rynge.net","_id":"634a30b462f3d3800f116514"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a30b462f3d3800f116515"}],"projects":[],"references":[],"stats":{"stars":0,"requested":89,"users":6,"success_rate":15,"serviceinfo":{"_id":"5d729e1e78356a109788b20b","counts":{"_id":"5e5c687a87cac7566aab1b9d","failed":158,"finished":470,"removed":1848,"requested":2017,"running":929,"running_sync":0,"stop_requested":334},"success_rate":74.84076433121018,"users":11,"readme_status":"ok","runtime_mean":129984753.41,"runtime_std":58332240.99430344,"service":"brainlife/app-fsurf","__v":0},"gitinfo":{"desc":"Run freesurfer (v6) on Open Science Grid using fsurf command.","tags":["anatomy-preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":59877015.666666664,"runtime_std":35020234.91876788,"resources":[{"resource_id":"5931bee335530000253833d2","name":"osgconnect","_id":"634a30b462f3d3800f116513"}],"examples":0,"groups":7},"doi":"10.25663/bl.app.49","desc_override":"OSG no longer supports fsurf. We are currently working on the new pegasus based workflow. Until it becomes available, please use the other Freesurfer App https://brainlife.io/app/58c56d92e13a50849b258801","deprecated_by":"5e03c7c332bff0800ae2a47b","_canedit":true},{"_id":"5f6d182b6bbee393d99a6b2c","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3d8562f3d3800f12a59f"}],"success_rate":45.45454545454545,"users":5,"runtime_mean":10363832.8,"runtime_std":5921550.37251561,"requested":15,"examples":0,"groups":7},"projects":[],"admins":["283"],"tags":[],"removed":false,"config":{"bold":{"type":"input","file_id":"bold","input_id":"fmri"},"events":{"type":"input","file_id":"events","input_id":"fmri"},"events_json":{"type":"input","file_id":"events_json","input_id":"fmri"},"sbref":{"type":"input","file_id":"sbref","input_id":"fmri"},"sbref_json":{"type":"input","file_id":"sbref_json","input_id":"fmri"},"physio":{"type":"input","file_id":"physio","input_id":"fmri"},"physio_json":{"type":"input","file_id":"physio_json","input_id":"fmri"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":true,"advanced":false,"_id":"5f6d182b6bbee364139a6b2d","id":"fmri","datatype":"59b685a08e5d38b0b331ddc5","desc":"fMRI runs must have conditions repeated across runs. Must have an events.tsv associated with each run specifying onset times and durations of stimuli"}],"outputs":[{"datatype_tags":["denoised"],"output_on_root":false,"archive":true,"_id":"5f6d182b6bbee3b59d9a6b2e","id":"denoised_bold/run1","datatype":"59b685a08e5d38b0b331ddc5","datatype_tags_pass":"fmri","files":null}],"github_branch":"master","github":"davhunt/app-GLMdenoise","name":"GLMdenoise","user_id":"283","contributors":[{"name":"David Hunt","email":"davhunt@iu.edu","_id":"634a3d8562f3d3800f12a5a0"}],"create_date":"2020-09-24T22:05:31.550Z","desc":null,"__v":4152,"doi":"10.25663/brainlife.app.451","_canedit":true},{"_id":"5f5a7b200c8f95f36765fee9","stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3d0d62f3d3800f12a059"},{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a3d0d62f3d3800f12a05a"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3d0d62f3d3800f12a05b"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"634a3d0d62f3d3800f12a05c"}],"success_rate":83.41739577972209,"users":25,"runtime_mean":799849.04,"runtime_std":1408516.1455727932,"requested":12365,"examples":3,"groups":53},"projects":[],"admins":["16"],"tags":[],"removed":false,"config":{"rois":{"type":"input","file_id":"rois","input_id":"rois"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"min_degree":{"id":"min_degree","type":"string","placeholder":"","advanced":false,"desc":"Minimum eccentricity degree for parcellation. Can only be one value","default":"0","_order":2,"pid":0.5454012650366888},"max_degree":{"id":"max_degree","type":"string","placeholder":"","advanced":false,"desc":"Maximum eccentricity degree for parcellation. Can only be one value","default":"5","_order":3,"pid":0.46231418034547733},"inputparc":{"id":"inputparc","type":"enum","placeholder":"","advanced":false,"desc":"","default":"","_order":4,"pid":0.6175550687425626,"options":[{"desc":"","label":"aparc","value":"aparc"},{"desc":"","label":"aparc.a2009s","value":"aparc.a2009s"},{"desc":"","label":"aparc.DKTatlas","value":"aparc.DKTatlas"}]},"include_lgn":{"id":"include_lgn","type":"boolean","placeholder":"","advanced":false,"desc":"","default":false,"_order":5,"pid":0.2532834599650562},"include_oc":{"id":"include_oc","type":"boolean","placeholder":"","advanced":false,"desc":"","default":false,"_order":6,"pid":0.7680208805583306}},"inputs":[{"datatype_tags":["eccentricity"],"optional":false,"multi":false,"advanced":false,"_id":"5f5a7b200c8f95a32e65feea","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5f5a7b200c8f9507ab65feeb","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e"}],"outputs":[{"datatype_tags":["eccentricity"],"output_on_root":false,"archive":true,"_id":"5f5a7b200c8f95226465feed","id":"parc","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags_pass":null,"files":null}],"github_branch":"eccentricity-parcellation-v1.2","github":"brainlife/app-roiGenerator","name":"Generate Eccentricity Parcellations from Visual ROIs","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3d0e62f3d3800f12a05d"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a3d0e62f3d3800f12a05e"},{"name":"Franco Pestilli","email":null,"_id":"634a3d0e62f3d3800f12a05f"}],"create_date":"2020-09-10T19:14:40.887Z","desc":"Generate a parcellation volume (and roi nifti files split into each label) for specific ROIs, or every ROI, for a parcellation from freesurfer output and/or input parcellation volume. This App can also inflate input parcellation volume toward non-white matter voxels.","doi":"10.25663/brainlife.app.417","__v":4140,"_canedit":true},{"_id":"5beefe7b910945002799f6d8","stats":{"stars":1,"requested":89,"users":3,"success_rate":33.76623376623377,"serviceinfo":{"_id":"5d729e1f78356a109788b26f","counts":{"_id":"5e5c3dc987cac76e25ab13df","failed":49,"finished":26,"removed":82,"requested":86,"running":76,"running_sync":0,"stop_requested":1},"success_rate":34.66666666666667,"users":3,"readme_status":"ok","runtime_mean":198971,"runtime_std":212886.16087097963,"service":"davhunt/surface_tools","__v":0},"gitinfo":{"desc":"Computes n equally spaced offset surfaces between the white and pial surfaces with equal ratios between areas of successive surfaces, which samples the same layers in gyri and sulci.","tags":[],"stats":{"stars":1},"contributors":[{"name":"David Hunt","email":"davhunt@indiana.edu"},{"name":null,"email":null},{"name":"Richard","email":null}]},"runtime_mean":198971,"runtime_std":212886.16087097963,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a346162f3d3800f118ac0"}],"examples":0,"groups":5},"projects":[],"admins":["283"],"tags":[],"removed":false,"config":{"output":{"type":"input","file_id":"output","input_id":"freesurfer"},"smoothing":{"id":"smoothing","type":"number","placeholder":"","desc":"fwhm value for smoothing","default":0,"_order":3,"pid":0.31429162676434075,"optional":true},"n_surfs":{"id":"n_surfs","type":"number","placeholder":"","desc":"","default":5,"_order":4,"pid":0.8560894828338206,"min":""}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5beefe7b910945002799f6d9","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e"}],"outputs":[{"datatype_tags":["vol_surface"],"output_on_root":false,"archive":true,"_id":"5c0965f4f9b4a2002efc15d3","id":"output_surfaces","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null}],"name":"Generate Equivolumetric Surfaces","github":"davhunt/surface_tools","user_id":"283","references":[],"contributors":[{"name":"David Hunt","email":"davhunt@iu.edu","_id":"634a346262f3d3800f118ac1"},{"name":null,"email":null,"_id":"634a346262f3d3800f118ac2"},{"name":"Richard","email":null,"_id":"634a346262f3d3800f118ac3"}],"create_date":"2018-11-16T17:29:31.877Z","doi":"10.25663/brainlife.app.126","__v":9482,"desc_override":"Computes n equally spaced offset surfaces between the white and pial surfaces with equal ratios between areas of successive surfaces, which samples the same layers in gyri and sulci.","desc":"Computes n equally spaced offset surfaces between the white and pial surfaces with equal ratios between areas of successive surfaces, which samples the same layers in gyri and sulci.","_canedit":true},{"_id":"5fc953b61828bc065252abf2","stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3e3b62f3d3800f12babe"},{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a3e3b62f3d3800f12babf"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3e3b62f3d3800f12bac0"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"634a3e3b62f3d3800f12bac1"}],"success_rate":83.41739577972209,"users":25,"runtime_mean":799849.04,"runtime_std":1408516.1455727932,"requested":12365,"examples":1,"groups":53},"projects":[],"admins":["16"],"tags":[],"removed":false,"config":{"rois":{"type":"input","file_id":"rois","input_id":"rois"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5fc953b61828bc4dc052abf3","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5fc953b61828bc85ec52abf4","id":"parc","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags_pass":"rois","files":null}],"github_branch":"parcellation-generation-v1.0","github":"brainlife/app-roiGenerator","name":"Generate Parcellation (Volume) from ROIs","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3e3b62f3d3800f12bac2"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a3e3b62f3d3800f12bac3"},{"name":"Franco Pestilli","email":null,"_id":"634a3e3b62f3d3800f12bac4"}],"create_date":"2020-12-03T21:08:06.682Z","desc":"Generate a parcellation volume (and roi nifti files split into each label) for specific ROIs, or every ROI, for a parcellation from freesurfer output and/or input parcellation volume. This App can also inflate input parcellation volume toward non-white matter voxels.","__v":3832,"doi":"10.25663/brainlife.app.453","_canedit":true},{"_id":"5e76b21ade643b2ad12a8e31","stats":{"success_rate":97.87234042553192,"users":1,"runtime_mean":809545.4130434783,"runtime_std":269084.6723375842,"requested":76,"resources":[],"examples":0,"groups":1},"projects":["5e58aea8fa8db57f2e9c4f71"],"admins":["16","83"],"tags":[],"removed":false,"config":{"anat":{"type":"input","file_id":"t1","input_id":"anat"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"postfreesurfer":{"type":"input","file_id":"output","input_id":"postfreesurfer"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e76b21ade643b7a472a8e32","id":"anat","datatype":"58c33bcee13a50849b25879a","desc":"The path to the anat/t1w datatype"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e76b21ade643bb3a82a8e33","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e","desc":"The path to the top directory containing the output from freesurfer"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e76b21ade643b55ae2a8e34","id":"postfreesurfer","datatype":"5e767ddcde643b260e2a8a52","desc":"The path to the top directory containing the output from the HCP PostFreesurfer pipeline"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5e76b21ade643b3d5a2a8e35","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9","datatype_tags_pass":null,"files":null,"desc":"The prostriate and LGN ROIs"},{"datatype_tags":["pros_lgn_roi_derivatives"],"output_on_root":false,"archive":true,"_id":"5e76b21ade643b57872a8e36","id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null,"desc":"The directory containing the derivatives generated during the app. Useful for debugging and QA"}],"github_branch":"master","github":"brainlife/app-prostriata-lgn-roi-generation","name":"Generate Prostriata and LGN ROIs","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a38a162f3d3800f11f6c2"},{"name":"Jan Kurzawski","email":null,"_id":"634a38a162f3d3800f11f6c3"}],"create_date":"2020-03-22T00:32:26.812Z","desc":null,"doi":"10.25663/brainlife.app.288","__v":5299,"_canedit":true},{"_id":"5f86894be6432df0c492cd28","projects":[],"admins":["16"],"tags":[],"removed":false,"stats":{"success_rate":83.41739577972209,"users":25,"runtime_mean":799849.04,"runtime_std":1408516.1455727932,"requested":12365,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3dcc62f3d3800f12b74b"},{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a3dcc62f3d3800f12b74c"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3dcc62f3d3800f12b74d"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"634a3dcc62f3d3800f12b74e"}],"examples":1,"groups":53},"config":{"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"prfDir":{"type":"input","file_id":"varea","input_id":"prf"},"thalamusInflate":{"id":"thalamusInflate","type":"number","placeholder":"","advanced":false,"desc":"if ROI inflation into WM for thalamus segmentation is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":null,"_order":11,"pid":0.49622253599308896,"optional":true},"visInflate":{"id":"visInflate","type":"number","placeholder":"","advanced":false,"desc":"if ROI inflation into WM for visual area segmentation is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":null,"_order":12,"pid":0.038915566959053516,"optional":true},"freesurferInflate":{"id":"freesurferInflate","type":"number","placeholder":"","advanced":false,"desc":"if ROI inflation into WM for freesurfer segmentation is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":null,"_order":13,"pid":0.08638112288286792,"optional":true},"inputparc":{"id":"inputparc","type":"enum","placeholder":"","advanced":false,"desc":"","default":"aparc.a2009s","_order":14,"pid":0.5833492925105686,"options":[{"desc":"Desikan-Killiany Atlas","label":"aparc","value":"aparc"},{"desc":"Destrieux Atlas","label":"aparc.a2009s","value":"aparc.a2009s"},{"desc":"DKT Atlas","label":"aparc.DKTatlas","value":"aparc.DKTatlas"}]}},"inputs":[{"datatype_tags":["thalamic_nuclei"],"optional":false,"multi":false,"advanced":false,"_id":"5dbb497c8aeeee77fef34e79","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e","desc":"Path to the freesurfer datatype. This NEEDS to have been run through segment thalamic nuclei app, or have the thalamic nuclei generated in the original freesurfer generation, for this to work. This is used to generate the LGN ROIs."},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5dbb497c8aeeee7339f34e76","id":"prf","datatype":"5d9d18d8e30ae43bb0612715","desc":"This is the path to the prf datatype. This NEEDS to have a visual area segmentation (varea.nii.gz) for this to work. This is used to generate V1. The Benson anatomical atlas can be used to generate this segmentation."}],"outputs":[{"datatype_tags":["optic_radiation","visual_white_matter","visual_areas","benson"],"output_on_root":false,"archive":true,"_id":"5dbb497c8aeeeef269f34e7d","id":"parc","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags_pass":null,"files":null},{"datatype_tags":["optic_radiation","visual_white_matter","benson"],"output_on_root":false,"archive":true,"_id":"5dbb497c8aeeeeb60bf34e7c","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9","datatype_tags_pass":null,"files":null}],"github_branch":"visual-white-matter-t1space-v1.1","github":"brainlife/app-roiGenerator","name":"Generate ROIs for Visual White Matter Analysis in Freesurfer Space (Benson pRF)","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3dcd62f3d3800f12b74f"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a3dcd62f3d3800f12b750"},{"name":"Franco Pestilli","email":null,"_id":"634a3dcd62f3d3800f12b751"}],"desc":"Generate a parcellation volume (and roi nifti files split into each label) for specific ROIs, or every ROI, for a parcellation from freesurfer output and/or input parcellation volume. This App can also inflate input parcellation volume toward non-white matter voxels.","__v":4138,"desc_override":"This app will generate ROIs that can be used for visual white matter analysis. This includes V1 from a pRF visual area segmentation, the left and right LGNs from a thalamic nuclei segmentation, and exclusion ROIs from freesurfer. ","create_date":"2020-10-14T05:14:51.293Z","doi":"10.25663/brainlife.app.440","_canedit":true},{"_id":"5ec69cdd1f4464c1e69e3a21","projects":[],"admins":["16"],"tags":[],"removed":false,"stats":{"success_rate":83.41739577972209,"users":25,"runtime_mean":799849.04,"runtime_std":1408516.1455727932,"requested":12365,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3ad162f3d3800f1246fe"},{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a3ad162f3d3800f1246ff"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3ad162f3d3800f124700"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"634a3ad162f3d3800f124701"}],"examples":2,"groups":53},"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"prfDir":{"type":"input","file_id":"varea","input_id":"prf"},"thalamusInflate":{"id":"thalamusInflate","type":"number","placeholder":"","advanced":false,"desc":"if ROI inflation into WM for thalamus segmentation is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":null,"_order":11,"pid":0.42415415265570844,"optional":true},"visInflate":{"id":"visInflate","type":"number","placeholder":"","advanced":false,"desc":"if ROI inflation into WM for visual area segmentation is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":null,"_order":12,"pid":0.49045651096619447,"optional":true},"freesurferInflate":{"id":"freesurferInflate","type":"number","placeholder":"","advanced":false,"desc":"if ROI inflation into WM for freesurfer segmentation is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":null,"_order":13,"pid":0.34598890391021797,"optional":true},"inputparc":{"id":"inputparc","type":"enum","placeholder":"","advanced":false,"desc":"The freesurfer parcellation to use","default":"aparc.a2009s","_order":14,"pid":0.6209376733347913,"options":[{"desc":"Desikan-Killiany Atlas","label":"aparc","value":"aparc"},{"desc":"Destrieux Atlas","label":"aparc.a2009s","value":"aparc.a2009s"},{"desc":"DKT Atlas","label":"aparc.DKTatlas","value":"aparc.DKTatlas"}]}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5dbb497c8aeeeef799f34e7b","id":"dwi","datatype":"58c33c5fe13a50849b25879b","desc":"The path to the DWI datatype"},{"datatype_tags":["thalamic_nuclei"],"optional":false,"multi":false,"advanced":false,"_id":"5dbb497c8aeeee77fef34e79","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e","desc":"Path to the freesurfer datatype. This NEEDS to have been run through segment thalamic nuclei app, or have the thalamic nuclei generated in the original freesurfer generation, for this to work. This is used to generate the LGN ROIs."},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5dbb497c8aeeeef56df34e77","id":"mask","datatype":"5a281aee2c214c9ba83ce620","desc":"Specify this if you want to use your custom brainmask. If neither dtiinit nor brainmask is specified, this App will create brainmask from your dwi input using FSL bet."},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5dbb497c8aeeee7339f34e76","id":"prf","datatype":"5d9d18d8e30ae43bb0612715","desc":"This is the path to the prf datatype. This NEEDS to have a visual area segmentation (varea.nii.gz) for this to work. This is used to generate V1. The Benson anatomical atlas can be used to generate this segmentation."}],"outputs":[{"datatype_tags":["optic_radiation","visual_white_matter","visual_areas","benson14_retinotopy"],"output_on_root":false,"archive":true,"_id":"5dbb497c8aeeeef269f34e7d","id":"parc","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags_pass":null,"files":null,"desc":"The parcellation of the freesurfer and exclusion ROIs"},{"datatype_tags":["optic_radiation","visual_white_matter","benson"],"output_on_root":false,"archive":true,"_id":"5dbb497c8aeeeeb60bf34e7c","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9","datatype_tags_pass":null,"files":null,"desc":"The directory containing all of the ROIs to use for visual white matter tracking"}],"github_branch":"visual-white-matter-dwi-v1.1","github":"brainlife/app-roiGenerator","name":"Generate ROIs for Visual White Matter Tracking in dMRI Space (Benson pRF)","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3ad262f3d3800f124702"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a3ad262f3d3800f124703"},{"name":"Franco Pestilli","email":null,"_id":"634a3ad262f3d3800f124704"}],"desc":"Generate a parcellation volume (and roi nifti files split into each label) for specific ROIs, or every ROI, for a parcellation from freesurfer output and/or input parcellation volume. This App can also inflate input parcellation volume toward non-white matter voxels.","__v":4842,"desc_override":"This app will generate ROIs that can be used for visual white matter tracking, including optic radiation tracking. This includes V1 from a pRF visual area segmentation, the left and right LGNs from a thalamic nuclei segmentation, and exclusion ROIs from freesurfer. The ROIs will be resliced into diffusion space in of this.","create_date":"2020-05-21T15:23:09.019Z","doi":"10.25663/brainlife.app.349","_canedit":true},{"_id":"5f5277bf42c17215e36504d8","projects":[],"admins":["16"],"tags":[],"removed":false,"stats":{"success_rate":83.41739577972209,"users":25,"runtime_mean":799849.04,"runtime_std":1408516.1455727932,"requested":12365,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3cdd62f3d3800f129bdd"},{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a3cdd62f3d3800f129bde"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3cdd62f3d3800f129bdf"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"634a3cdd62f3d3800f129be0"}],"examples":5,"groups":53},"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"parc":{"type":"input","file_id":"parc","input_id":"parc"},"thalamusInflate":{"id":"thalamusInflate","type":"number","placeholder":"","advanced":false,"desc":"if ROI inflation into WM for thalamus segmentation is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":null,"_order":11,"pid":0.9278522310001072,"optional":true},"visInflate":{"id":"visInflate","type":"number","placeholder":"","advanced":false,"desc":"if ROI inflation into WM for visual area segmentation is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":null,"_order":12,"pid":0.9037006677858608,"optional":true},"freesurferInflate":{"id":"freesurferInflate","type":"number","placeholder":"","advanced":false,"desc":"if ROI inflation into WM for freesurfer segmentation is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":null,"_order":13,"pid":0.471761995042852,"optional":true},"inputparc":{"id":"inputparc","type":"enum","placeholder":"","advanced":false,"desc":"","default":"aparc.a2009s","_order":14,"pid":0.27038572480200984,"options":[{"desc":"Desikan-Killiany Atlas","label":"aparc","value":"aparc"},{"desc":"Destrieux Atlas","label":"aparc.a2009s","value":"aparc.a2009s"},{"desc":"DKT Atlas","label":"aparc.DKTatlas","value":"aparc.DKTatlas"}]},"include_lgn":{"id":"include_lgn","type":"boolean","placeholder":"","advanced":false,"desc":"","default":false,"_order":15,"pid":0.04635765691021598},"include_oc":{"id":"include_oc","type":"boolean","placeholder":"","advanced":false,"desc":"","default":false,"_order":16,"pid":0.43923261696236304}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5dbb497c8aeeeef799f34e7b","id":"dwi","datatype":"58c33c5fe13a50849b25879b"},{"datatype_tags":["thalamic_nuclei"],"optional":false,"multi":false,"advanced":false,"_id":"5dbb497c8aeeee77fef34e79","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e","desc":"Path to the freesurfer datatype. This NEEDS to have been run through segment thalamic nuclei app, or have the thalamic nuclei generated in the original freesurfer generation, for this to work. This is used to generate the LGN ROIs."},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5dbb497c8aeeeef56df34e77","id":"mask","datatype":"5a281aee2c214c9ba83ce620","desc":"Specify this if you want to use your custom brainmask. If neither dtiinit nor brainmask is specified, this App will create brainmask from your dwi input using FSL bet."},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5dbb497c8aeeee7339f34e76","id":"parc","datatype":"5c1a7489f9109beac4a88a1f","desc":"This is the path to the parcellation/volume datatype. This NEEDS to contain the glasser parcellation mapped to the subject. This is used to generate visual rois."}],"outputs":[{"datatype_tags":["optic_radiation","hcp-mmp","visual_white_matter","visual_areas"],"output_on_root":false,"archive":true,"_id":"5dbb497c8aeeeef269f34e7d","id":"parc","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags_pass":null,"files":null},{"datatype_tags":["optic_radiation","hcp-mmp","visual_white_matter"],"output_on_root":false,"archive":true,"_id":"5dbb497c8aeeeeb60bf34e7c","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9","datatype_tags_pass":null,"files":null}],"github_branch":"visual-white-matter-glasser-dwi-v1.0","github":"brainlife/app-roiGenerator","name":"Generate ROIs for Visual White Matter Tracking in dMRI Space (Glasser Parcellation)","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3cde62f3d3800f129be1"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a3cde62f3d3800f129be2"},{"name":"Franco Pestilli","email":null,"_id":"634a3cde62f3d3800f129be3"}],"desc":"Generate a parcellation volume (and roi nifti files split into each label) for specific ROIs, or every ROI, for a parcellation from freesurfer output and/or input parcellation volume. This App can also inflate input parcellation volume toward non-white matter voxels.","__v":4162,"desc_override":"This app will generate ROIs that can be used for visual white matter tracking, including optic radiation tracking. This includes visual areas from the Glasser parcellation, the left and right LGNs from a thalamic nuclei segmentation, and exclusion ROIs from freesurfer. The ROIs will be resliced into diffusion space in of this.","create_date":"2020-09-04T17:22:07.793Z","doi":"10.25663/brainlife.app.411","_canedit":true},{"_id":"603b05a578e65d7545d1b80c","projects":[],"admins":["16"],"tags":[],"removed":false,"stats":{"success_rate":83.41739577972209,"users":25,"runtime_mean":799849.04,"runtime_std":1408516.1455727932,"requested":12365,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3f5a62f3d3800f12cd40"},{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a3f5a62f3d3800f12cd41"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3f5a62f3d3800f12cd42"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"634a3f5a62f3d3800f12cd43"}],"examples":1,"groups":53},"config":{"input_nifti":{"type":"input","file_id":"dwi","input_id":"input_nifti"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"input_nifti"},"bvals":{"type":"input","file_id":"bvals","input_id":"input_nifti"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"lh_annot":{"type":"input","file_id":"left","input_id":"parcellation"},"rh_annot":{"type":"input","file_id":"right","input_id":"parcellation"},"label":{"type":"input","file_id":"label","input_id":"parcellation"},"prfSurfacesDir":{"type":"input","file_id":"prf_surfaces","input_id":"prfSurfacesDir"},"thalamusInflate":{"id":"thalamusInflate","type":"number","placeholder":"","advanced":false,"desc":"if ROI inflation into WM for thalamus segmentation is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":null,"_order":11,"pid":0.35129100125899937,"optional":true},"freesurferInflate":{"id":"freesurferInflate","type":"number","placeholder":"","advanced":false,"desc":"if ROI inflation into WM for freesurfer segmentation is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":null,"_order":13,"pid":0.16259550083320096,"optional":true},"inputparc":{"id":"inputparc","type":"enum","placeholder":"","advanced":false,"desc":"","default":"aparc.a2009s","_order":14,"pid":0.3232714099289966,"options":[{"desc":"Desikan-Killiany Atlas","label":"aparc","value":"aparc"},{"desc":"Destrieux Atlas","label":"aparc.a2009s","value":"aparc.a2009s"},{"desc":"DKT Atlas","label":"aparc.DKTatlas","value":"aparc.DKTatlas"}]},"min_degree":{"id":"min_degree","type":"string","placeholder":"","advanced":false,"desc":"Mininum eccentricity degrees for ROIs","default":"0 15 30","_order":15,"pid":0.2390414804392451},"max_degree":{"id":"max_degree","type":"string","placeholder":"","advanced":false,"desc":"Maximum eccentricity degrees for ROIs","default":"3 30 90","_order":16,"pid":0.018861343684135834}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5dbb497c8aeeeef799f34e7b","id":"input_nifti","datatype":"58c33c5fe13a50849b25879b"},{"datatype_tags":["thalamic_nuclei"],"optional":false,"multi":false,"advanced":false,"_id":"5dbb497c8aeeee77fef34e79","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e","desc":"Path to the freesurfer datatype. This NEEDS to have been run through segment thalamic nuclei app, or have the thalamic nuclei generated in the original freesurfer generation, for this to work. This is used to generate the LGN ROIs."},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5dbb497c8aeeeef56df34e77","id":"mask","datatype":"5a281aee2c214c9ba83ce620","desc":"Specify this if you want to use your custom brainmask. If neither dtiinit nor brainmask is specified, this App will create brainmask from your dwi input using FSL bet."},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"603b05a578e65da2aed1b813","id":"parcellation","datatype":"5f78b377268f76598c29b27a"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5f52cc1242c17268b6651a91","id":"prfSurfacesDir","datatype":"5d9d18d8e30ae43bb0612715"}],"outputs":[{"datatype_tags":["optic_radiation","hcp-mmp","visual_white_matter","visual_areas"],"output_on_root":false,"archive":true,"_id":"5dbb497c8aeeeef269f34e7d","id":"parc","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags_pass":null,"files":null},{"datatype_tags":["optic_radiation","hcp-mmp","eccentricity","visual_white_matter"],"output_on_root":false,"archive":true,"_id":"5dbb497c8aeeeeb60bf34e7c","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9","datatype_tags_pass":null,"files":null}],"github_branch":"visual-white-matter-eccentricity-glasser-updated-surf-v1.0","github":"brainlife/app-roiGenerator","name":"Generate ROIs for Visual White Matter Tracking in dMRI Space (Glasser Parcellation) Binned by prf Eccentricity Estimates","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3f5b62f3d3800f12cd44"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a3f5b62f3d3800f12cd45"},{"name":"Franco Pestilli","email":null,"_id":"634a3f5b62f3d3800f12cd46"}],"desc":"Generate a parcellation volume (and roi nifti files split into each label) for specific ROIs, or every ROI, for a parcellation from freesurfer output and/or input parcellation volume. This App can also inflate input parcellation volume toward non-white matter voxels.","__v":3180,"desc_override":"This app will generate ROIs that can be used for visual white matter tracking, including optic radiation tracking. This includes visual areas from the Glasser parcellation, the left and right LGNs from a thalamic nuclei segmentation, and exclusion ROIs from freesurfer. The ROIs will be resliced into diffusion space in of this. The Glasser ROIs will be binned by Eccentricity based on pRF mapping","create_date":"2021-02-28T02:53:25.737Z","doi":"10.25663/brainlife.app.485","_canedit":true},{"_id":"5f52cc1242c172b908651a8a","projects":[],"admins":["16"],"tags":[],"removed":false,"stats":{"success_rate":83.41739577972209,"users":25,"runtime_mean":799849.04,"runtime_std":1408516.1455727932,"requested":12365,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3ce662f3d3800f129c0e"},{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a3ce662f3d3800f129c0f"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3ce662f3d3800f129c10"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"634a3ce662f3d3800f129c11"}],"examples":1,"groups":53},"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"input_nifti"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"input_nifti"},"bvals":{"type":"input","file_id":"bvals","input_id":"input_nifti"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"lh_annot":{"type":"input","file_id":"lh_annot","input_id":"parc"},"rh_annot":{"type":"input","file_id":"rh_annot","input_id":"parc"},"prfSurfacesDir":{"type":"input","file_id":"prf_surfaces","input_id":"prfSurfacesDir"},"thalamusInflate":{"id":"thalamusInflate","type":"number","placeholder":"","advanced":false,"desc":"if ROI inflation into WM for thalamus segmentation is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":null,"_order":11,"pid":0.2962164358082364,"optional":true},"freesurferInflate":{"id":"freesurferInflate","type":"number","placeholder":"","advanced":false,"desc":"if ROI inflation into WM for freesurfer segmentation is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":null,"_order":13,"pid":0.16150254683497423,"optional":true},"inputparc":{"id":"inputparc","type":"enum","placeholder":"","advanced":false,"desc":"","default":"aparc.a2009s","_order":14,"pid":0.7621113814337135,"options":[{"desc":"Desikan-Killiany Atlas","label":"aparc","value":"aparc"},{"desc":"Destrieux Atlas","label":"aparc.a2009s","value":"aparc.a2009s"},{"desc":"DKT Atlas","label":"aparc.DKTatlas","value":"aparc.DKTatlas"}]},"min_degree":{"id":"min_degree","type":"string","placeholder":"","advanced":false,"desc":"Mininum eccentricity degrees for ROIs","default":"0 15 30","_order":15,"pid":0.6114011363920158},"max_degree":{"id":"max_degree","type":"string","placeholder":"","advanced":false,"desc":"Maximum eccentricity degrees for ROIs","default":"3 30 90","_order":16,"pid":0.8741921784063837}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5dbb497c8aeeeef799f34e7b","id":"input_nifti","datatype":"58c33c5fe13a50849b25879b"},{"datatype_tags":["thalamic_nuclei"],"optional":false,"multi":false,"advanced":false,"_id":"5dbb497c8aeeee77fef34e79","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e","desc":"Path to the freesurfer datatype. This NEEDS to have been run through segment thalamic nuclei app, or have the thalamic nuclei generated in the original freesurfer generation, for this to work. This is used to generate the LGN ROIs."},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5dbb497c8aeeeef56df34e77","id":"mask","datatype":"5a281aee2c214c9ba83ce620","desc":"Specify this if you want to use your custom brainmask. If neither dtiinit nor brainmask is specified, this App will create brainmask from your dwi input using FSL bet."},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5dbb497c8aeeee7339f34e76","id":"parc","datatype":"5c478b7bf9109beac4520be6","desc":"This is the path to the parcellation/volume datatype. This NEEDS to contain the glasser parcellation mapped to the subject. This is used to generate visual rois."},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5f52cc1242c17268b6651a91","id":"prfSurfacesDir","datatype":"5d9d18d8e30ae43bb0612715"}],"outputs":[{"datatype_tags":["optic_radiation","hcp-mmp","visual_white_matter","visual_areas"],"output_on_root":false,"archive":true,"_id":"5dbb497c8aeeeef269f34e7d","id":"parc","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags_pass":null,"files":null},{"datatype_tags":["optic_radiation","hcp-mmp","eccentricity","visual_white_matter"],"output_on_root":false,"archive":true,"_id":"5dbb497c8aeeeeb60bf34e7c","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9","datatype_tags_pass":null,"files":null}],"github_branch":"visual-white-matter-eccentricity-glasser-v1.0","github":"brainlife/app-roiGenerator","name":"Generate ROIs for Visual White Matter Tracking in dMRI Space (Glasser Parcellation) Binned by prf Eccentricity Estimates - Deprecated Surface","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3ce762f3d3800f129c12"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a3ce762f3d3800f129c13"},{"name":"Franco Pestilli","email":null,"_id":"634a3ce762f3d3800f129c14"}],"desc":"Generate a parcellation volume (and roi nifti files split into each label) for specific ROIs, or every ROI, for a parcellation from freesurfer output and/or input parcellation volume. This App can also inflate input parcellation volume toward non-white matter voxels.","__v":4160,"desc_override":"This app will generate ROIs that can be used for visual white matter tracking, including optic radiation tracking. This includes visual areas from the Glasser parcellation, the left and right LGNs from a thalamic nuclei segmentation, and exclusion ROIs from freesurfer. The ROIs will be resliced into diffusion space in of this. The Glasser ROIs will be binned by Eccentricity based on pRF mapping","create_date":"2020-09-04T23:21:54.054Z","doi":"10.25663/brainlife.app.413","deprecated_by":"603b05a578e65d7545d1b80c","_canedit":true},{"_id":"5c364d71836af601cc85864d","projects":[],"admins":["41","56"],"tags":[],"removed":false,"stats":{"stars":0,"requested":894,"users":13,"success_rate":88.02308802308802,"serviceinfo":{"_id":"5d729e1f78356a109788b253","counts":{"_id":"5e5c3dd587cac75d3eab13ea","failed":44,"finished":45,"removed":85,"requested":98,"running":93,"running_sync":0,"stop_requested":4},"success_rate":50.56179775280899,"users":6,"readme_status":"no README.md","runtime_mean":16224554.8,"runtime_std":32069300.72016451,"service":"brainlife/app-ROIsfromAtlas","__v":0},"gitinfo":{"desc":null,"tags":[],"stats":{"stars":0},"contributors":[{"name":"Daniel Bullock","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":567417.45,"runtime_std":2004141.731529691,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a34c862f3d3800f118e0f"}],"examples":3,"groups":23},"config":{"atlas":{"type":"input","file_id":"parc","input_id":"atlas"},"key":{"type":"input","file_id":"key","input_id":"atlas"},"roiPairs":{"id":"roiPairs","type":"string","placeholder":"","desc":"This is where you enter in the indexes for the parcellation regions you would like to convert into ROIs (disregard the \"pairs\" implication).\nMust be in appropriate format, for example:\n23 95 2 8\n1 2 12 34 8 3 5\n4 5 236 86 \n72 12 55 \nline breaks separate ROIs","default":"","_order":3,"pid":0.6975328977809252,"multiline":true},"smoothKernel":{"id":"smoothKernel","type":"number","placeholder":"1","desc":"Smoothing Kernel for ROI.  Odd, whole number values only.  Values larger than 1 result in ROI inflation.  0 performs no inflation.\nhttps://www.mathworks.com/help/matlab/ref/smooth3.html","default":1,"_order":4,"pid":0.7710216104275667,"min":1}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c0865fff9b4a2002efc1583","id":"atlas","datatype":"5c1a7489f9109beac4a88a1f"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5c364d71836af601cc85864f","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9","datatype_tags_pass":null,"files":{"rois":"rois"}}],"name":"Generate ROIs from an atlas","github":"brainlife/app-ROIsfromAtlas","user_id":"56","references":[],"contributors":[{"name":"Daniel Bullock","email":"iisdanbul@gmail.com","_id":"634a34c962f3d3800f118e10"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a34c962f3d3800f118e11"}],"__v":8853,"desc":null,"create_date":"2019-01-09T19:37:21.715Z","doi":"10.25663/brainlife.app.140","desc_override":"Generates specified ROIS (in nifti format) from an input atlas.","github_branch":"1.0","_canedit":true},{"_id":"60f83f2db991118b34b56b02","projects":[],"admins":["16"],"tags":[],"removed":false,"stats":{"success_rate":83.41739577972209,"users":25,"runtime_mean":799849.04,"runtime_std":1408516.1455727932,"requested":12365,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a419f62f3d3800f12e3fd"},{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a419f62f3d3800f12e3fe"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a419f62f3d3800f12e3ff"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"634a419f62f3d3800f12e400"}],"examples":1,"groups":53},"config":{"t1":{"type":"input","file_id":"t1","input_id":"anat"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"parc":{"type":"input","file_id":"parc","input_id":"parcellation"},"key":{"type":"input","file_id":"key","input_id":"parcellation"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"prfDir":{"type":"input","file_id":"varea","input_id":"prf"},"parcellationROIs":{"id":"parcellationROIs","type":"string","placeholder":"","advanced":false,"desc":"If a non-freesurfer parcellation is used, enter ROI numbers from key.txt (parcellation) ROIs wanted.\n\nExample: 45,54\n\nROIs will be outputted with following name format to avoid complications with other parcellations and similar ROI numbers: ROIparc-#.nii.gz, with # being the number of the ROI","default":"","_order":2,"pid":0.12190060737781405,"optional":true},"subcorticalROIs":{"id":"subcorticalROIs","type":"string","placeholder":"","advanced":false,"desc":"Enter the number of the subcortical ROI (if wanted).\n\nROIs will be outputted with following name format to avoid complications with other parcellations and similar ROI numbers: ROIsubcortical#.nii.gz, with # being the number of the ROI. ","default":"","_order":3,"pid":0.8313670581346646,"optional":true},"thalamicROIs":{"id":"thalamicROIs","type":"string","placeholder":"","advanced":false,"desc":"If thalamic nuclei segmentation from freesurfer is used, enter the number of the thalamic ROI (if wanted).\n\nPlease refer to this color lut (https://github.com/freesurfer/freesurfer/blob/dev/ThalamicNuclei/compressionLookupTable.txt) and your thalamic segmentation for specific ROI numbers\n\nROIs will be outputted with following name format to avoid complications with other parcellations and similar ROI numbers: ROIthalamus-#.nii.gz, with # being the number of the ROI. ","default":"","_order":4,"pid":0.12873086419159874,"optional":true},"hippocampalROIs":{"id":"hippocampalROIs","type":"string","placeholder":"","advanced":false,"desc":"If hippocampal segmentation from freesurfer is used, enter the number of the hippocampusROI (if wanted).\n\nPlease refer to this color lut (https://github.com/freesurfer/freesurfer/blob/dev/ThalamicNuclei/compressionLookupTable.txt) and your hippocampal segmentation for specific ROI numbers\n\nROIs will be outputted with following name format to avoid complications with other parcellations and similar ROI numbers: ROIhippocampus-#.nii.gz, with # being the number of the ROI. ","default":"","_order":5,"pid":0.6926671672255972,"optional":true},"amygdalaROIs":{"id":"amygdalaROIs","type":"string","placeholder":"","advanced":false,"desc":"If amygdala segmentation from freesurfer is used, enter the number of the amygdala ROI (if wanted).\n\nPlease refer to this color lut (https://github.com/freesurfer/freesurfer/blob/dev/ThalamicNuclei/compressionLookupTable.txt) and your amygdala segmentation for specific ROI numbers\n\nROIs will be outputted with following name format to avoid complications with other parcellations and similar ROI numbers: ROIamygdala-#.nii.gz, with # being the number of the ROI. ","default":"","_order":6,"pid":0.4305236500341376,"optional":true},"prfROIs":{"id":"prfROIs","type":"string","placeholder":"","advanced":false,"desc":"If a visual area segmentation from a PRF mapping app is used, enter the number of the visual field ROI (if wanted).\n\nPlease refer to visual area segmentation from the PRF to determine ROI numbers.\n\nROIs will be outputted with following name format to avoid complications with other parcellations and similar ROI numbers: ROIvarea-#.nii.gz, with # being the number of the ROI. ","default":"","_order":7,"pid":0.5922247323629094,"optional":true},"freesurferROIs":{"id":"freesurferROIs","type":"string","placeholder":"","advanced":false,"desc":"If ROIs from the freesurfer segmentation is desired, enter the number of the ROI from the freesurfer colorLUT.\n\nROIs will be outputted with following name format to avoid complications with other parcellations and similar ROI numbers: ROIfreesurfer-#.nii.gz, with # being the number of the ROI. ","default":"","_order":8,"pid":0.03381933971377038,"optional":true},"mergeROIsL":{"id":"mergeROIsL","type":"string","placeholder":"","advanced":false,"desc":"Left hemisphere ROI numbers and source parcellation you would like to merge into a single ROI\n\nDue to the possibility of different parcellations including the same set of labels, you must specify the source location using the following list of prefixes, followed by the roi number:\n\nfreesurfer: freesurfer-#\nparcellation: parc-#\nsubcortical: subcortical-#\nprf visual areas: varea-#\namygdala: amygdala-#\nhippocampus: hippocampus-#\nthalamus: thalamus-#\n\nif the user wants to merge multiple ROIs made from subset of all ROIs, enter each set of ROIs on a new line. the mergename field will need to correspond to these pairings (i.e. same number of pairings per left and right hemisphere, same order)\n\nex. freesurfer-11111 freesurfer-111112\nfreesurfer-11113 freesurfer-11114 freesurfer-11115","default":"","_order":9,"pid":0.3250501913078526,"optional":true,"multiline":true},"mergeROIsR":{"id":"mergeROIsR","type":"string","placeholder":"","advanced":false,"desc":"Right hemisphere ROI numbers and source parcellation you would like to merge into a single ROI.\n\nDue to the possibility of different parcellations including the same set of labels, you must specify the source location using the following list of prefixes, followed by the roi number:\n\nfreesurfer: freesurfer-#\nparcellation: parc-#\nsubcortical: subcortical-#\nprf visual areas: varea-#\namygdala: amygdala-#\nhippocampus: hippocampus-#\nthalamus: thalamus-#\n\nif the user wants to merge multiple ROIs made from subset of all ROIs, enter each set of ROIs on a new line. the mergename field will need to correspond to these pairings (i.e. same number of pairings per left and right hemisphere, same order)\n\nex. freesurfer-12111 freesurfer-121112\nfreesurfer-12113 freesurfer-12114 freesurfer-12115","default":"","_order":10,"pid":0.10752332710379708,"optional":true,"multiline":true},"mergename":{"id":"mergename","type":"string","placeholder":"","advanced":false,"desc":"Name for the ROI that you would like merged. The output will be in the following format: ROI${mergename}.nii.gz\n\nif the user wants to merge multiple ROIs made from subset of all ROIs, enter each name on a line. this field will need to correspond to these pairings (i.e. same number of pairings per left and right hemisphere, same order)\n\nex. test1\ntest2","default":"","_order":11,"pid":0.362248318190299,"optional":true,"multiline":true},"parcInflate":{"id":"parcInflate","type":"number","placeholder":"","advanced":false,"desc":"if parcellation ROI inflation into WM is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":null,"_order":12,"pid":0.18297207506778712,"optional":true},"thalamusInflate":{"id":"thalamusInflate","type":"number","placeholder":"","advanced":false,"desc":"if ROI inflation into WM for thalamus segmentation is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":null,"_order":13,"pid":0.7692322061148633,"optional":true},"hippocampusInflate":{"id":"hippocampusInflate","type":"string","placeholder":"","advanced":false,"desc":"if ROI inflation into WM for hippocampal subfield segmentation is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":"","_order":14,"pid":0.48597825625886415,"optional":true},"amygdalaInflate":{"id":"amygdalaInflate","type":"string","placeholder":"","advanced":false,"desc":"if ROI inflation into WM for amygdala segmentation is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":"","_order":15,"pid":0.2862777794638637,"optional":true},"visInflate":{"id":"visInflate","type":"number","placeholder":"","advanced":false,"desc":"if ROI inflation into WM for visual area segmentation is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":null,"_order":16,"pid":0.8399898524320751,"optional":true},"freesurferInflate":{"id":"freesurferInflate","type":"number","placeholder":"","advanced":false,"desc":"if ROI inflation into WM for freesurfer segmentation is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":null,"_order":17,"pid":0.49411335398855927,"optional":true},"inputparc":{"id":"inputparc","type":"enum","placeholder":"","advanced":false,"desc":"The input freesurfer parcellation","default":"aparc","_order":18,"pid":0.05720839727588545,"options":[{"desc":"Desikan-Killiany Atlas","label":"aparc","value":"aparc"},{"desc":"Destrieux Atlas","label":"aparc.a2009s","value":"aparc.a2009s"},{"desc":"DKT Atlas","label":"aparc.DKTatlas","value":"aparc.DKTatlas"}]},"whitematter":{"id":"whitematter","type":"boolean","placeholder":"","advanced":false,"desc":"If you want to include the white matter in the inflation, which will limit the amount of inflation into the white matter, select 'true'.  However, selecting 'false' will trim the white matter, which may eliminate some potential ROIs.","default":true,"_order":19,"pid":0.6996043553701595}},"inputs":[{"id":"anat","datatype":"58c33bcee13a50849b25879a","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"60f83f2db9911166bfb56b06"},{"id":"freesurfer","desc":"The path to the top directory containing the output from freesurfer. If you want thalamic ROIs, make sure to use the output from app-segment-thalamic-nuclei","datatype":"58cb22c8e13a50849b25882e","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5dbb497c8aeeee77fef34e79"},{"id":"parcellation","desc":"The non-freesurfer parcellation to make ROIs from (optional). ","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5dbb497c8aeeee5680f34e78"},{"id":"mask","desc":"Specify this if you want to use your custom brainmask. If brainmask is not specified, this App will create brainmask from your frmi input using FSL bet.","datatype":"5a281aee2c214c9ba83ce620","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5dbb497c8aeeeef56df34e77"},{"id":"prf","desc":"Specify prf input if you want to generate ROIs from the PRF/varea parcellation. ","datatype":"5d9d18d8e30ae43bb0612715","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5dbb497c8aeeee7339f34e76"}],"outputs":[{"id":"parc","desc":"The parcellation containing all of the ROIs in a single nifti","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5dbb497c8aeeeef269f34e7d"},{"id":"rois","desc":"The directory containing all of the ROIs","datatype":"5be9ea0315a8683a39a1ebd9","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5dbb497c8aeeeeb60bf34e7c"}],"github_branch":"merge-t1-v1.0","github":"brainlife/app-roiGenerator","name":"Generate ROIs in Anatomical Space","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a41a062f3d3800f12e401"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a41a062f3d3800f12e402"},{"name":"Franco Pestilli","email":null,"_id":"634a41a062f3d3800f12e403"}],"desc":"Generate a parcellation volume (and roi nifti files split into each label) for specific ROIs, or every ROI, for a parcellation from freesurfer output and/or input parcellation volume. This App can also inflate input parcellation volume toward non-white matter voxels.","__v":2250,"desc_override":"This app will generate ROIs from a parcellation, subcortical structures found in the Freesurfer aseg, cortical structures found in the Freesurfer parcellations, and population receptive field visual area segmentations. The ROIs will be resliced into anatomical space. Merging of rois is allowed.","create_date":"2021-07-21T15:37:17.317Z","doi":"10.25663/brainlife.app.549","_canedit":true},{"_id":"5dbb497c8aeeee769af34e75","stats":{"stars":0,"serviceinfo":{"_id":"5d729e1f78356a109788b2b7","counts":{"_id":"5e5c3e1e87cac7842bab1438","failed":788,"finished":6048,"removed":7078,"requested":7656,"running":6617,"running_sync":0,"stop_requested":49},"success_rate":88.47279110590989,"users":12,"readme_status":"ok","runtime_mean":5580586.29,"runtime_std":23419021.556393724,"service":"brain-life/app-roiGenerator","__v":0},"success_rate":83.41739577972209,"users":25,"runtime_mean":799849.04,"runtime_std":1408516.1455727932,"requested":12365,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a376262f3d3800f11e074"},{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a376262f3d3800f11e075"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a376262f3d3800f11e076"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"634a376262f3d3800f11e077"}],"examples":5,"groups":53},"projects":[],"admins":["16"],"tags":[],"removed":false,"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"parc":{"type":"input","file_id":"parc","input_id":"parcellation"},"key":{"type":"input","file_id":"key","input_id":"parcellation"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"prfDir":{"type":"input","file_id":"varea","input_id":"prf"},"parcellationROIs":{"id":"parcellationROIs","type":"string","placeholder":"","advanced":false,"desc":"If a non-freesurfer parcellation is used, enter ROI numbers from key.txt (parcellation) ROIs wanted.\n\nExample: 45,54\n\nROIs will be outputted with following name format to avoid complications with other parcellations and similar ROI numbers: ROIparc-#.nii.gz, with # being the number of the ROI","default":"","_order":2,"pid":0.13647383930050672,"optional":true},"subcorticalROIs":{"id":"subcorticalROIs","type":"string","placeholder":"","advanced":false,"desc":"Enter the number of the subcortical ROI (if wanted).\n\nROIs will be outputted with following name format to avoid complications with other parcellations and similar ROI numbers: ROIsubcortical#.nii.gz, with # being the number of the ROI. ","default":"","_order":3,"pid":0.9787462836870496,"optional":true},"thalamicROIs":{"id":"thalamicROIs","type":"string","placeholder":"","advanced":false,"desc":"If thalamic nuclei segmentation from freesurfer is used, enter the number of the thalamic ROI (if wanted).\n\nPlease refer to this color lut (https://github.com/freesurfer/freesurfer/blob/dev/ThalamicNuclei/compressionLookupTable.txt) and your thalamic segmentation for specific ROI numbers\n\nROIs will be outputted with following name format to avoid complications with other parcellations and similar ROI numbers: ROIthalamus-#.nii.gz, with # being the number of the ROI. ","default":"","_order":4,"pid":0.3750638628404386,"optional":true},"hippocampalROIs":{"id":"hippocampalROIs","type":"string","placeholder":"","advanced":false,"desc":"If hippocampal segmentation from freesurfer is used, enter the number of the hippocampusROI (if wanted).\n\nPlease refer to this color lut (https://github.com/freesurfer/freesurfer/blob/dev/ThalamicNuclei/compressionLookupTable.txt) and your hippocampal segmentation for specific ROI numbers\n\nROIs will be outputted with following name format to avoid complications with other parcellations and similar ROI numbers: ROIhippocampus-#.nii.gz, with # being the number of the ROI. ","default":"","_order":5,"pid":0.7480401452493456,"optional":true},"amygdalaROIs":{"id":"amygdalaROIs","type":"string","placeholder":"","advanced":false,"desc":"If amygdala segmentation from freesurfer is used, enter the number of the amygdala ROI (if wanted).\n\nPlease refer to this color lut (https://github.com/freesurfer/freesurfer/blob/dev/ThalamicNuclei/compressionLookupTable.txt) and your amygdala segmentation for specific ROI numbers\n\nROIs will be outputted with following name format to avoid complications with other parcellations and similar ROI numbers: ROIamygdala-#.nii.gz, with # being the number of the ROI. ","default":"","_order":6,"pid":0.6531017938123255,"optional":true},"prfROIs":{"id":"prfROIs","type":"string","placeholder":"","advanced":false,"desc":"If a visual area segmentation from a PRF mapping app is used, enter the number of the visual field ROI (if wanted).\n\nPlease refer to visual area segmentation from the PRF to determine ROI numbers.\n\nROIs will be outputted with following name format to avoid complications with other parcellations and similar ROI numbers: ROIvarea-#.nii.gz, with # being the number of the ROI. ","default":"","_order":7,"pid":0.4794047576449456,"optional":true},"freesurferROIs":{"id":"freesurferROIs","type":"string","placeholder":"","advanced":false,"desc":"If ROIs from the freesurfer segmentation is desired, enter the number of the ROI from the freesurfer colorLUT.\n\nROIs will be outputted with following name format to avoid complications with other parcellations and similar ROI numbers: ROIfreesurfer-#.nii.gz, with # being the number of the ROI. ","default":"","_order":8,"pid":0.8969311448995576,"optional":true},"mergeROIsL":{"id":"mergeROIsL","type":"string","placeholder":"","advanced":false,"desc":"Left hemisphere ROI numbers and source parcellation you would like to merge into a single ROI\n\nDue to the possibility of different parcellations including the same set of labels, you must specify the source location using the following list of prefixes, followed by the roi number:\n\nfreesurfer: freesurfer-#\nparcellation: parc-#\nsubcortical: subcortical-#\nprf visual areas: varea-#\namygdala: amygdala-#\nhippocampus: hippocampus-#\nthalamus: thalamus-#\n\nif the user wants to merge multiple ROIs made from subset of all ROIs, enter each set of ROIs on a new line. the mergename field will need to correspond to these pairings (i.e. same number of pairings per left and right hemisphere, same order)\n\nex. freesurfer-11111 freesurfer-111112\nfreesurfer-11113 freesurfer-11114 freesurfer-11115","default":"","_order":9,"pid":0.8718718934247682,"optional":true,"multiline":true},"mergeROIsR":{"id":"mergeROIsR","type":"string","placeholder":"","advanced":false,"desc":"Right hemisphere ROI numbers and source parcellation you would like to merge into a single ROI.\n\nDue to the possibility of different parcellations including the same set of labels, you must specify the source location using the following list of prefixes, followed by the roi number:\n\nfreesurfer: freesurfer-#\nparcellation: parc-#\nsubcortical: subcortical-#\nprf visual areas: varea-#\namygdala: amygdala-#\nhippocampus: hippocampus-#\nthalamus: thalamus-#\n\nif the user wants to merge multiple ROIs made from subset of all ROIs, enter each set of ROIs on a new line. the mergename field will need to correspond to these pairings (i.e. same number of pairings per left and right hemisphere, same order)\n\nex. freesurfer-12111 freesurfer-121112\nfreesurfer-12113 freesurfer-12114 freesurfer-12115","default":"","_order":10,"pid":0.7366885865821597,"optional":true,"multiline":true},"mergename":{"id":"mergename","type":"string","placeholder":"","advanced":false,"desc":"Name for the ROI that you would like merged. The output will be in the following format: ROI${mergename}.nii.gz\n\nif the user wants to merge multiple ROIs made from subset of all ROIs, enter each name on a line. this field will need to correspond to these pairings (i.e. same number of pairings per left and right hemisphere, same order)\n\nex. test1\ntest2","default":"","_order":11,"pid":0.4101843629352667,"optional":true,"multiline":true},"parcInflate":{"id":"parcInflate","type":"number","placeholder":"","advanced":false,"desc":"if parcellation ROI inflation into WM is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":null,"_order":12,"pid":0.9731001830772391,"optional":true},"thalamusInflate":{"id":"thalamusInflate","type":"number","placeholder":"","advanced":false,"desc":"if ROI inflation into WM for thalamus segmentation is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":null,"_order":13,"pid":0.4110203779915149,"optional":true},"hippocampusInflate":{"id":"hippocampusInflate","type":"string","placeholder":"","advanced":false,"desc":"if ROI inflation into WM for hippocampal subfield segmentation is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":"","_order":14,"pid":0.42791502109889645,"optional":true},"amygdalaInflate":{"id":"amygdalaInflate","type":"string","placeholder":"","advanced":false,"desc":"if ROI inflation into WM for amygdala segmentation is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":"","_order":15,"pid":0.18010180324313296,"optional":true},"visInflate":{"id":"visInflate","type":"number","placeholder":"","advanced":false,"desc":"if ROI inflation into WM for visual area segmentation is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":null,"_order":16,"pid":0.877434185958586,"optional":true},"freesurferInflate":{"id":"freesurferInflate","type":"number","placeholder":"","advanced":false,"desc":"if ROI inflation into WM for freesurfer segmentation is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":null,"_order":17,"pid":0.49489002835068674,"optional":true},"inputparc":{"id":"inputparc","type":"enum","placeholder":"","advanced":false,"desc":"The input freesurfer parcellation","default":"aparc","_order":18,"pid":0.1786032118896025,"options":[{"desc":"Desikan-Killiany Atlas","label":"aparc","value":"aparc"},{"desc":"Destrieux Atlas","label":"aparc.a2009s","value":"aparc.a2009s"},{"desc":"DKT Atlas","label":"aparc.DKTatlas","value":"aparc.DKTatlas"}]},"whitematter":{"id":"whitematter","type":"boolean","placeholder":"","advanced":false,"desc":"If you want to include the white matter in the inflation, which will limit the amount of inflation into the white matter, select 'true'.  However, selecting 'false' will trim the white matter, which may eliminate some potential ROIs.","default":true,"_order":19,"pid":0.8736196974306818}},"inputs":[{"id":"dwi","desc":"The path to the DWI datatype","datatype":"58c33c5fe13a50849b25879b","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5dbb497c8aeeeef799f34e7b"},{"id":"freesurfer","desc":"The path to the top directory containing the output from freesurfer. If you want thalamic ROIs, make sure to use the output from app-segment-thalamic-nuclei","datatype":"58cb22c8e13a50849b25882e","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5dbb497c8aeeee77fef34e79"},{"id":"parcellation","desc":"The non-freesurfer parcellation to make ROIs from (optional). ","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5dbb497c8aeeee5680f34e78"},{"id":"mask","desc":"Specify this if you want to use your custom brainmask. If neither dtiinit nor brainmask is specified, this App will create brainmask from your dwi input using FSL bet.","datatype":"5a281aee2c214c9ba83ce620","datatype_tags":["brain","dwi"],"optional":true,"multi":false,"advanced":false,"_id":"5dbb497c8aeeeef56df34e77"},{"id":"prf","desc":"Specify prf input if you want to generate ROIs from the PRF/varea parcellation. ","datatype":"5d9d18d8e30ae43bb0612715","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5dbb497c8aeeee7339f34e76"}],"outputs":[{"id":"parc","desc":"The parcellation containing all of the ROIs in a single nifti","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5dbb497c8aeeeef269f34e7d"},{"id":"rois","desc":"The directory containing all of the ROIs","datatype":"5be9ea0315a8683a39a1ebd9","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5dbb497c8aeeeeb60bf34e7c"}],"github_branch":"merge-dwi-v1.3","github":"brainlife/app-roiGenerator","name":"Generate ROIs in DMRI Space","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a376362f3d3800f11e078"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a376362f3d3800f11e079"},{"name":"Franco Pestilli","email":null,"_id":"634a376362f3d3800f11e07a"}],"create_date":"2019-10-31T20:52:12.219Z","desc":"Generate a parcellation volume (and roi nifti files split into each label) for specific ROIs, or every ROI, for a parcellation from freesurfer output and/or input parcellation volume. This App can also inflate input parcellation volume toward non-white matter voxels.","doi":"10.25663/brainlife.app.242","__v":6598,"desc_override":"This app will generate ROIs from a parcellation, subcortical structures found in the Freesurfer aseg, cortical structures found in the Freesurfer parcellations, and population receptive field visual area segmentations. The ROIs will be resliced into diffusion space in of this, merging ROIs is allowed.","deprecated_by":"6192d0a4983d5bb13f958870","_canedit":true},{"_id":"5ec29d1641ba11e054f3edc1","projects":[],"admins":["16"],"tags":[],"removed":false,"stats":{"success_rate":83.41739577972209,"users":25,"runtime_mean":799849.04,"runtime_std":1408516.1455727932,"requested":12365,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3a8a62f3d3800f123ddf"},{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a3a8a62f3d3800f123de0"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3a8a62f3d3800f123de1"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"634a3a8a62f3d3800f123de2"}],"examples":0,"groups":53},"config":{"dtiinit":{"type":"input","file_id":"output","input_id":"dtiinit"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"parc":{"type":"input","file_id":"parc","input_id":"parcellation"},"key":{"type":"input","file_id":"key","input_id":"parcellation"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"prfDir":{"type":"input","file_id":"varea","input_id":"prf"},"parcellationROIs":{"id":"parcellationROIs","type":"string","placeholder":"","advanced":false,"desc":"If a non-freesurfer parcellation is used, enter ROI numbers from key.txt (parcellation) ROIs wanted.\n\nExample: 45,54\n\nROIs will be outputted with following name format to avoid complications with other parcellations and similar ROI numbers: ROI#.nii.gz, with # being the number of the ROI","default":"","_order":2,"pid":0.3205721052634747,"optional":true},"subcorticalROIs":{"id":"subcorticalROIs","type":"string","placeholder":"","advanced":false,"desc":"Enter the number of the subcortical ROI (if wanted).\n\nROIs will be outputted with following name format to avoid complications with other parcellations and similar ROI numbers: ROI0#.nii.gz, with # being the number of the ROI. Please note the leading 0.","default":"","_order":3,"pid":0.6766979847729337,"optional":true},"thalamicROIs":{"id":"thalamicROIs","type":"string","placeholder":"","advanced":false,"desc":"If thalamic nuclei segmentation from freesurfer is used, enter the number of the thalamic ROI (if wanted).\n\nPlease refer to this color lut (https://github.com/freesurfer/freesurfer/blob/dev/ThalamicNuclei/compressionLookupTable.txt) and your thalamic segmentation for specific ROI numbers\n\nROIs will be outputted with following name format to avoid complications with other parcellations and similar ROI numbers: ROI00#.nii.gz, with # being the number of the ROI. Please note the leading 00.","default":"","_order":4,"pid":0.00909948231355484,"optional":true},"prfROIs":{"id":"prfROIs","type":"string","placeholder":"","advanced":false,"desc":"If a visual area segmentation from a PRF mapping app is used, enter the number of the visual field ROI (if wanted).\n\nPlease refer to visual area segmentation from the PRF to determine ROI numbers.\n\nROIs will be outputted with following name format to avoid complications with other parcellations and similar ROI numbers: ROI000#.nii.gz, with # being the number of the ROI. Please note the leading 000.","default":"","_order":5,"pid":0.7648747473263087,"optional":true},"freesurferROIs":{"id":"freesurferROIs","type":"string","placeholder":"","advanced":false,"desc":"If ROIs from the freesurfer segmentation is desired, enter the number of the ROI from the freesurfer colorLUT.\n\nROIs will be outputted with following name format to avoid complications with other parcellations and similar ROI numbers: ROI0000#.nii.gz, with # being the number of the ROI. Please note the leading 0000.","default":"","_order":6,"pid":0.4638434309246313,"optional":true},"mergeROIsL":{"id":"mergeROIsL","type":"string","placeholder":"","advanced":false,"desc":"Left hemisphere ROI numbers you would like to merge into a single ROI","default":"","_order":7,"pid":0.2624077752076983,"optional":true},"mergeROIsR":{"id":"mergeROIsR","type":"string","placeholder":"","advanced":false,"desc":"Right hemisphere ROI numbers you would like to merge into a single ROI","default":"","_order":8,"pid":0.1968529261498042,"optional":true},"mergename":{"id":"mergename","type":"string","placeholder":"","advanced":false,"desc":"Name for the ROI that you would like merged. The output will be in the following format: ROI${mergename}.nii.gz","default":"","_order":9,"pid":0.6491665651086356,"optional":true},"parcInflate":{"id":"parcInflate","type":"number","placeholder":"","advanced":false,"desc":"if parcellation ROI inflation into WM is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":null,"_order":10,"pid":0.7594947023995289,"optional":true},"thalamusInflate":{"id":"thalamusInflate","type":"number","placeholder":"","advanced":false,"desc":"if ROI inflation into WM for thalamus segmentation is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":null,"_order":11,"pid":0.666845537241276,"optional":true},"visInflate":{"id":"visInflate","type":"number","placeholder":"","advanced":false,"desc":"if ROI inflation into WM for visual area segmentation is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":null,"_order":12,"pid":0.7896093889062157,"optional":true},"freesurferInflate":{"id":"freesurferInflate","type":"number","placeholder":"","advanced":false,"desc":"if ROI inflation into WM for freesurfer segmentation is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":null,"_order":13,"pid":0.0639114905079925,"optional":true},"inputparc":{"id":"inputparc","type":"enum","placeholder":"","advanced":false,"desc":"The input freesurfer parcellation","default":"aparc","_order":14,"pid":0.3748697664274059,"options":[{"desc":"Desikan-Killiany Atlas","label":"aparc","value":"aparc"},{"desc":"Destrieux Atlas","label":"aparc.a2009s","value":"aparc.a2009s"},{"desc":"DKT Atlas","label":"aparc.DKTatlas","value":"aparc.DKTatlas"}]},"whitematter":{"id":"whitematter","type":"boolean","placeholder":"","advanced":false,"desc":"If you want to include the white matter in the inflation, which will limit the amount of inflation into the white matter, select 'true'.  However, selecting 'false' will trim the white matter, which may eliminate some potential ROIs.","default":true,"_order":15,"pid":0.8247946037707625}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ec29d1641ba1151d7f3edc2","id":"dtiinit","datatype":"58cb234be13a50849b25882f","desc":"This is the path to the dtiinit output directory"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5dbb497c8aeeee77fef34e79","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e","desc":"If you want thalamic ROIs, make sure to use the output from app-segment-thalamic-nuclei"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5dbb497c8aeeee5680f34e78","id":"parcellation","datatype":"5c1a7489f9109beac4a88a1f"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5dbb497c8aeeeef56df34e77","id":"mask","datatype":"5a281aee2c214c9ba83ce620","desc":"Specify this if you want to use your custom brainmask. If neither dtiinit nor brainmask is specified, this App will create brainmask from your dwi input using FSL bet."},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5dbb497c8aeeee7339f34e76","id":"prf","datatype":"5d9d18d8e30ae43bb0612715","desc":"Specify prf input if you want to generate ROIs from the PRF/varea parcellation. "}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5dbb497c8aeeeef269f34e7d","id":"parc","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags_pass":null,"files":null,"desc":"The parcellation containing all of the ROIs in a single nifti"},{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5dbb497c8aeeeeb60bf34e7c","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9","datatype_tags_pass":null,"files":null,"desc":"The directory containing all of the ROIs"}],"github_branch":"merge-dwi","github":"brainlife/app-roiGenerator","name":"Generate ROIs in DMRI Space (dtiinit)","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3a8b62f3d3800f123de3"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a3a8b62f3d3800f123de4"},{"name":"Franco Pestilli","email":null,"_id":"634a3a8b62f3d3800f123de5"}],"desc":"Generate a parcellation volume (and roi nifti files split into each label) for specific ROIs, or every ROI, for a parcellation from freesurfer output and/or input parcellation volume. This App can also inflate input parcellation volume toward non-white matter voxels.","__v":4846,"desc_override":"This app will generate ROIs from a parcellation, subcortical structures found in the Freesurfer aseg, cortical structures found in the Freesurfer parcellations, and population receptive field visual area segmentations. The ROIs will be resliced into diffusion space in of this, merging ROIs is allowed.","create_date":"2020-05-18T14:35:02.421Z","doi":"10.25663/brainlife.app.342","deprecated_by":"5dbb497c8aeeee769af34e75","_canedit":true},{"_id":"6192cd0d983d5bb13f951b61","user_id":"16","projects":[],"admins":["16"],"name":"Generate ROIs in DMRI Space with FA Skeleton mask","github":"brainlife/app-roiGenerator","github_branch":"merge-dwi-v1.4-fa","desc":"Generate a parcellation volume (and roi nifti files split into each label) for specific ROIs, or every ROI, for a parcellation from freesurfer output and/or input parcellation volume. This App can also inflate input parcellation volume toward non-white matter voxels.","desc_override":"This app will generate ROIs from a parcellation, subcortical structures found in the Freesurfer aseg, cortical structures found in the Freesurfer parcellations, and population receptive field visual area segmentations. The ROIs will be resliced into diffusion space in of this, merging ROIs is allowed.","tags":[],"contributors":[{"name":"Brad Caron","email":null,"_id":"634a431b62f3d3800f12fe3c"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a431b62f3d3800f12fe3d"},{"name":"Franco Pestilli","email":null,"_id":"634a431b62f3d3800f12fe3e"}],"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"parc":{"type":"input","file_id":"parc","input_id":"parcellation"},"key":{"type":"input","file_id":"key","input_id":"parcellation"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"prfDir":{"type":"input","file_id":"varea","input_id":"prf"},"fa":{"type":"input","file_id":"fa","input_id":"fa"},"parcellationROIs":{"id":"parcellationROIs","type":"string","placeholder":"","advanced":false,"desc":"If a non-freesurfer parcellation is used, enter ROI numbers from key.txt (parcellation) ROIs wanted.\n\nExample: 45,54\n\nROIs will be outputted with following name format to avoid complications with other parcellations and similar ROI numbers: ROIparc-#.nii.gz, with # being the number of the ROI","default":"","_order":2,"pid":0.008999801684528519,"optional":true},"subcorticalROIs":{"id":"subcorticalROIs","type":"string","placeholder":"","advanced":false,"desc":"Enter the number of the subcortical ROI (if wanted).\n\nROIs will be outputted with following name format to avoid complications with other parcellations and similar ROI numbers: ROIsubcortical#.nii.gz, with # being the number of the ROI. ","default":"","_order":3,"pid":0.629154564532995,"optional":true},"thalamicROIs":{"id":"thalamicROIs","type":"string","placeholder":"","advanced":false,"desc":"If thalamic nuclei segmentation from freesurfer is used, enter the number of the thalamic ROI (if wanted).\n\nPlease refer to this color lut (https://github.com/freesurfer/freesurfer/blob/dev/ThalamicNuclei/compressionLookupTable.txt) and your thalamic segmentation for specific ROI numbers\n\nROIs will be outputted with following name format to avoid complications with other parcellations and similar ROI numbers: ROIthalamus-#.nii.gz, with # being the number of the ROI. ","default":"","_order":4,"pid":0.3164717394065517,"optional":true},"hippocampalROIs":{"id":"hippocampalROIs","type":"string","placeholder":"","advanced":false,"desc":"If hippocampal segmentation from freesurfer is used, enter the number of the hippocampusROI (if wanted).\n\nPlease refer to this color lut (https://github.com/freesurfer/freesurfer/blob/dev/ThalamicNuclei/compressionLookupTable.txt) and your hippocampal segmentation for specific ROI numbers\n\nROIs will be outputted with following name format to avoid complications with other parcellations and similar ROI numbers: ROIhippocampus-#.nii.gz, with # being the number of the ROI. ","default":"","_order":5,"pid":0.6728072883657902,"optional":true},"amygdalaROIs":{"id":"amygdalaROIs","type":"string","placeholder":"","advanced":false,"desc":"If amygdala segmentation from freesurfer is used, enter the number of the amygdala ROI (if wanted).\n\nPlease refer to this color lut (https://github.com/freesurfer/freesurfer/blob/dev/ThalamicNuclei/compressionLookupTable.txt) and your amygdala segmentation for specific ROI numbers\n\nROIs will be outputted with following name format to avoid complications with other parcellations and similar ROI numbers: ROIamygdala-#.nii.gz, with # being the number of the ROI. ","default":"","_order":6,"pid":0.5316886852572743,"optional":true},"prfROIs":{"id":"prfROIs","type":"string","placeholder":"","advanced":false,"desc":"If a visual area segmentation from a PRF mapping app is used, enter the number of the visual field ROI (if wanted).\n\nPlease refer to visual area segmentation from the PRF to determine ROI numbers.\n\nROIs will be outputted with following name format to avoid complications with other parcellations and similar ROI numbers: ROIvarea-#.nii.gz, with # being the number of the ROI. ","default":"","_order":7,"pid":0.19701096306897126,"optional":true},"freesurferROIs":{"id":"freesurferROIs","type":"string","placeholder":"","advanced":false,"desc":"If ROIs from the freesurfer segmentation is desired, enter the number of the ROI from the freesurfer colorLUT.\n\nROIs will be outputted with following name format to avoid complications with other parcellations and similar ROI numbers: ROIfreesurfer-#.nii.gz, with # being the number of the ROI. ","default":"","_order":8,"pid":0.6870575649734736,"optional":true},"mergeROIsL":{"id":"mergeROIsL","type":"string","placeholder":"","advanced":false,"desc":"Left hemisphere ROI numbers and source parcellation you would like to merge into a single ROI\n\nDue to the possibility of different parcellations including the same set of labels, you must specify the source location using the following list of prefixes, followed by the roi number:\n\nfreesurfer: freesurfer-#\nparcellation: parc-#\nsubcortical: subcortical-#\nprf visual areas: varea-#\namygdala: amygdala-#\nhippocampus: hippocampus-#\nthalamus: thalamus-#\n\nif the user wants to merge multiple ROIs made from subset of all ROIs, enter each set of ROIs on a new line. the mergename field will need to correspond to these pairings (i.e. same number of pairings per left and right hemisphere, same order)\n\nex. freesurfer-11111 freesurfer-111112\nfreesurfer-11113 freesurfer-11114 freesurfer-11115","default":"","_order":9,"pid":0.2516790179365216,"optional":true,"multiline":true},"mergeROIsR":{"id":"mergeROIsR","type":"string","placeholder":"","advanced":false,"desc":"Right hemisphere ROI numbers and source parcellation you would like to merge into a single ROI.\n\nDue to the possibility of different parcellations including the same set of labels, you must specify the source location using the following list of prefixes, followed by the roi number:\n\nfreesurfer: freesurfer-#\nparcellation: parc-#\nsubcortical: subcortical-#\nprf visual areas: varea-#\namygdala: amygdala-#\nhippocampus: hippocampus-#\nthalamus: thalamus-#\n\nif the user wants to merge multiple ROIs made from subset of all ROIs, enter each set of ROIs on a new line. the mergename field will need to correspond to these pairings (i.e. same number of pairings per left and right hemisphere, same order)\n\nex. freesurfer-12111 freesurfer-121112\nfreesurfer-12113 freesurfer-12114 freesurfer-12115","default":"","_order":10,"pid":0.9790792899378832,"optional":true,"multiline":true},"mergename":{"id":"mergename","type":"string","placeholder":"","advanced":false,"desc":"Name for the ROI that you would like merged. The output will be in the following format: ROI${mergename}.nii.gz\n\nif the user wants to merge multiple ROIs made from subset of all ROIs, enter each name on a line. this field will need to correspond to these pairings (i.e. same number of pairings per left and right hemisphere, same order)\n\nex. test1\ntest2","default":"","_order":11,"pid":0.11266591981957064,"optional":true,"multiline":true},"parcInflate":{"id":"parcInflate","type":"number","placeholder":"","advanced":false,"desc":"if parcellation ROI inflation into WM is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":null,"_order":12,"pid":0.5067520204614283,"optional":true},"thalamusInflate":{"id":"thalamusInflate","type":"number","placeholder":"","advanced":false,"desc":"if ROI inflation into WM for thalamus segmentation is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":null,"_order":13,"pid":0.1491145982069867,"optional":true},"hippocampusInflate":{"id":"hippocampusInflate","type":"string","placeholder":"","advanced":false,"desc":"if ROI inflation into WM for hippocampal subfield segmentation is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":"","_order":14,"pid":0.5787034280293825,"optional":true},"amygdalaInflate":{"id":"amygdalaInflate","type":"string","placeholder":"","advanced":false,"desc":"if ROI inflation into WM for amygdala segmentation is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":"","_order":15,"pid":0.8392210156863161,"optional":true},"visInflate":{"id":"visInflate","type":"number","placeholder":"","advanced":false,"desc":"if ROI inflation into WM for visual area segmentation is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":null,"_order":16,"pid":0.43379960407922946,"optional":true},"freesurferInflate":{"id":"freesurferInflate","type":"number","placeholder":"","advanced":false,"desc":"if ROI inflation into WM for freesurfer segmentation is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":null,"_order":17,"pid":0.4700802636908854,"optional":true},"inputparc":{"id":"inputparc","type":"enum","placeholder":"","advanced":false,"desc":"The input freesurfer parcellation","default":"aparc","_order":18,"pid":0.2663989302022962,"options":[{"desc":"Desikan-Killiany Atlas","label":"aparc","value":"aparc"},{"desc":"Destrieux Atlas","label":"aparc.a2009s","value":"aparc.a2009s"},{"desc":"DKT Atlas","label":"aparc.DKTatlas","value":"aparc.DKTatlas"}]},"skel_stop":{"id":"skel_stop","type":"enum","placeholder":"","advanced":true,"desc":"Determine how little inflation into white matter is performed","default":"skel_stop","_order":19,"pid":0.730604413832112,"options":[{"desc":"skel_stop (allows 1 layer of inflation into wm)","label":"skel_stop","value":"skel_stop"},{"desc":"skel_stop_strict (doesn't allow inflation)","label":"skel_stop_strict","value":"skel_stop_strict"},{"desc":"no_stop","label":"no_stop","value":"no_stop"}]},"skel_thr":{"id":"skel_thr","type":"number","placeholder":"","advanced":true,"desc":"Threshold for FA white matter skeleton","default":0.2,"_order":20,"pid":0.9093563774639898},"neigh_def":{"id":"neigh_def","type":"enum","placeholder":"","advanced":true,"desc":"Determines how neighbor voxels are defined","default":"neigh_face_only","_order":21,"pid":0.20386212936341552,"options":[{"desc":"neigh_face_only","label":"neigh_face_only","value":"neigh_face_only"},{"desc":"neigh_face_edge","label":"neigh_face_edge","value":"neigh_face_edge"},{"desc":"neigh_upto_vert","label":"neigh_upto_vert","value":"neigh_upto_vert"}]}},"inputs":[{"id":"dwi","desc":"The path to the DWI datatype","datatype":"58c33c5fe13a50849b25879b","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5dbb497c8aeeeef799f34e7b"},{"id":"freesurfer","desc":"The path to the top directory containing the output from freesurfer. If you want thalamic ROIs, make sure to use the output from app-segment-thalamic-nuclei","datatype":"58cb22c8e13a50849b25882e","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5dbb497c8aeeee77fef34e79"},{"id":"parcellation","desc":"The non-freesurfer parcellation to make ROIs from (optional). ","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5dbb497c8aeeee5680f34e78"},{"id":"mask","desc":"Specify this if you want to use your custom brainmask. If neither dtiinit nor brainmask is specified, this App will create brainmask from your dwi input using FSL bet.","datatype":"5a281aee2c214c9ba83ce620","datatype_tags":["brain","dwi"],"optional":true,"multi":false,"advanced":false,"_id":"5dbb497c8aeeeef56df34e77"},{"id":"prf","desc":"Specify prf input if you want to generate ROIs from the PRF/varea parcellation. ","datatype":"5d9d18d8e30ae43bb0612715","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5dbb497c8aeeee7339f34e76"},{"id":"fa","datatype":"5a79df48d071a1753f1d661b","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"6192cd0d983d5bb13f951b6a"}],"outputs":[{"id":"parc","desc":"The parcellation containing all of the ROIs in a single nifti","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5dbb497c8aeeeef269f34e7d"},{"id":"rois","desc":"The directory containing all of the ROIs","datatype":"5be9ea0315a8683a39a1ebd9","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5dbb497c8aeeeeb60bf34e7c"}],"stats":{"success_rate":83.41739577972209,"users":25,"runtime_mean":799849.04,"runtime_std":1408516.1455727932,"requested":12365,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a431a62f3d3800f12fe38"},{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a431a62f3d3800f12fe39"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a431a62f3d3800f12fe3a"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"634a431a62f3d3800f12fe3b"}],"examples":1,"groups":53},"removed":false,"__v":1344,"create_date":"2021-11-15T21:11:41.382Z","doi":"10.25663/brainlife.app.591","_canedit":true},{"_id":"6192d0a4983d5bb13f958870","user_id":"16","projects":[],"admins":["16"],"name":"Generate ROIs in DMRI Space with WM Skeleton mask","github":"brainlife/app-roiGenerator","github_branch":"merge-dwi-v1.4-wm","desc":"Generate a parcellation volume (and roi nifti files split into each label) for specific ROIs, or every ROI, for a parcellation from freesurfer output and/or input parcellation volume. This App can also inflate input parcellation volume toward non-white matter voxels.","desc_override":"This app will generate ROIs from a parcellation, subcortical structures found in the Freesurfer aseg, cortical structures found in the Freesurfer parcellations, and population receptive field visual area segmentations. The ROIs will be resliced into diffusion space in of this, merging ROIs is allowed.","tags":[],"contributors":[{"name":"Brad Caron","email":null,"_id":"634a432462f3d3800f12ff16"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a432462f3d3800f12ff17"},{"name":"Franco Pestilli","email":null,"_id":"634a432462f3d3800f12ff18"}],"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"parc":{"type":"input","file_id":"parc","input_id":"parcellation"},"key":{"type":"input","file_id":"key","input_id":"parcellation"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"prfDir":{"type":"input","file_id":"varea","input_id":"prf"},"parcellationROIs":{"id":"parcellationROIs","type":"string","placeholder":"","advanced":false,"desc":"If a non-freesurfer parcellation is used, enter ROI numbers from key.txt (parcellation) ROIs wanted.\n\nExample: 45,54\n\nROIs will be outputted with following name format to avoid complications with other parcellations and similar ROI numbers: ROIparc-#.nii.gz, with # being the number of the ROI","default":"","_order":2,"pid":0.869685479794909,"optional":true},"subcorticalROIs":{"id":"subcorticalROIs","type":"string","placeholder":"","advanced":false,"desc":"Enter the number of the subcortical ROI (if wanted).\n\nROIs will be outputted with following name format to avoid complications with other parcellations and similar ROI numbers: ROIsubcortical#.nii.gz, with # being the number of the ROI. ","default":"","_order":3,"pid":0.8647268573267682,"optional":true},"thalamicROIs":{"id":"thalamicROIs","type":"string","placeholder":"","advanced":false,"desc":"If thalamic nuclei segmentation from freesurfer is used, enter the number of the thalamic ROI (if wanted).\n\nPlease refer to this color lut (https://github.com/freesurfer/freesurfer/blob/dev/ThalamicNuclei/compressionLookupTable.txt) and your thalamic segmentation for specific ROI numbers\n\nROIs will be outputted with following name format to avoid complications with other parcellations and similar ROI numbers: ROIthalamus-#.nii.gz, with # being the number of the ROI. ","default":"","_order":4,"pid":0.7961408139477409,"optional":true},"hippocampalROIs":{"id":"hippocampalROIs","type":"string","placeholder":"","advanced":false,"desc":"If hippocampal segmentation from freesurfer is used, enter the number of the hippocampusROI (if wanted).\n\nPlease refer to this color lut (https://github.com/freesurfer/freesurfer/blob/dev/ThalamicNuclei/compressionLookupTable.txt) and your hippocampal segmentation for specific ROI numbers\n\nROIs will be outputted with following name format to avoid complications with other parcellations and similar ROI numbers: ROIhippocampus-#.nii.gz, with # being the number of the ROI. ","default":"","_order":5,"pid":0.8087084952053175,"optional":true},"amygdalaROIs":{"id":"amygdalaROIs","type":"string","placeholder":"","advanced":false,"desc":"If amygdala segmentation from freesurfer is used, enter the number of the amygdala ROI (if wanted).\n\nPlease refer to this color lut (https://github.com/freesurfer/freesurfer/blob/dev/ThalamicNuclei/compressionLookupTable.txt) and your amygdala segmentation for specific ROI numbers\n\nROIs will be outputted with following name format to avoid complications with other parcellations and similar ROI numbers: ROIamygdala-#.nii.gz, with # being the number of the ROI. ","default":"","_order":6,"pid":0.3172076565513444,"optional":true},"prfROIs":{"id":"prfROIs","type":"string","placeholder":"","advanced":false,"desc":"If a visual area segmentation from a PRF mapping app is used, enter the number of the visual field ROI (if wanted).\n\nPlease refer to visual area segmentation from the PRF to determine ROI numbers.\n\nROIs will be outputted with following name format to avoid complications with other parcellations and similar ROI numbers: ROIvarea-#.nii.gz, with # being the number of the ROI. ","default":"","_order":7,"pid":0.07145065370815129,"optional":true},"freesurferROIs":{"id":"freesurferROIs","type":"string","placeholder":"","advanced":false,"desc":"If ROIs from the freesurfer segmentation is desired, enter the number of the ROI from the freesurfer colorLUT.\n\nROIs will be outputted with following name format to avoid complications with other parcellations and similar ROI numbers: ROIfreesurfer-#.nii.gz, with # being the number of the ROI. ","default":"","_order":8,"pid":0.9462224720736042,"optional":true},"mergeROIsL":{"id":"mergeROIsL","type":"string","placeholder":"","advanced":false,"desc":"Left hemisphere ROI numbers and source parcellation you would like to merge into a single ROI\n\nDue to the possibility of different parcellations including the same set of labels, you must specify the source location using the following list of prefixes, followed by the roi number:\n\nfreesurfer: freesurfer-#\nparcellation: parc-#\nsubcortical: subcortical-#\nprf visual areas: varea-#\namygdala: amygdala-#\nhippocampus: hippocampus-#\nthalamus: thalamus-#\n\nif the user wants to merge multiple ROIs made from subset of all ROIs, enter each set of ROIs on a new line. the mergename field will need to correspond to these pairings (i.e. same number of pairings per left and right hemisphere, same order)\n\nex. freesurfer-11111 freesurfer-111112\nfreesurfer-11113 freesurfer-11114 freesurfer-11115","default":"","_order":9,"pid":0.2291965392622144,"optional":true,"multiline":true},"mergeROIsR":{"id":"mergeROIsR","type":"string","placeholder":"","advanced":false,"desc":"Right hemisphere ROI numbers and source parcellation you would like to merge into a single ROI.\n\nDue to the possibility of different parcellations including the same set of labels, you must specify the source location using the following list of prefixes, followed by the roi number:\n\nfreesurfer: freesurfer-#\nparcellation: parc-#\nsubcortical: subcortical-#\nprf visual areas: varea-#\namygdala: amygdala-#\nhippocampus: hippocampus-#\nthalamus: thalamus-#\n\nif the user wants to merge multiple ROIs made from subset of all ROIs, enter each set of ROIs on a new line. the mergename field will need to correspond to these pairings (i.e. same number of pairings per left and right hemisphere, same order)\n\nex. freesurfer-12111 freesurfer-121112\nfreesurfer-12113 freesurfer-12114 freesurfer-12115","default":"","_order":10,"pid":0.6852017225767385,"optional":true,"multiline":true},"mergename":{"id":"mergename","type":"string","placeholder":"","advanced":false,"desc":"Name for the ROI that you would like merged. The output will be in the following format: ROI${mergename}.nii.gz\n\nif the user wants to merge multiple ROIs made from subset of all ROIs, enter each name on a line. this field will need to correspond to these pairings (i.e. same number of pairings per left and right hemisphere, same order)\n\nex. test1\ntest2","default":"","_order":11,"pid":0.41675108732426247,"optional":true,"multiline":true},"parcInflate":{"id":"parcInflate","type":"number","placeholder":"","advanced":false,"desc":"if parcellation ROI inflation into WM is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":null,"_order":12,"pid":0.13532354875727393,"optional":true},"thalamusInflate":{"id":"thalamusInflate","type":"number","placeholder":"","advanced":false,"desc":"if ROI inflation into WM for thalamus segmentation is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":null,"_order":13,"pid":0.2008958682932026,"optional":true},"hippocampusInflate":{"id":"hippocampusInflate","type":"string","placeholder":"","advanced":false,"desc":"if ROI inflation into WM for hippocampal subfield segmentation is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":"","_order":14,"pid":0.7885267970350359,"optional":true},"amygdalaInflate":{"id":"amygdalaInflate","type":"string","placeholder":"","advanced":false,"desc":"if ROI inflation into WM for amygdala segmentation is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":"","_order":15,"pid":0.35131783380574333,"optional":true},"visInflate":{"id":"visInflate","type":"number","placeholder":"","advanced":false,"desc":"if ROI inflation into WM for visual area segmentation is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":null,"_order":16,"pid":0.31597556165861596,"optional":true},"freesurferInflate":{"id":"freesurferInflate","type":"number","placeholder":"","advanced":false,"desc":"if ROI inflation into WM for freesurfer segmentation is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":null,"_order":17,"pid":0.05584733621998317,"optional":true},"inputparc":{"id":"inputparc","type":"enum","placeholder":"","advanced":false,"desc":"The input freesurfer parcellation","default":"aparc","_order":18,"pid":0.8536983729031714,"options":[{"desc":"Desikan-Killiany Atlas","label":"aparc","value":"aparc"},{"desc":"Destrieux Atlas","label":"aparc.a2009s","value":"aparc.a2009s"},{"desc":"DKT Atlas","label":"aparc.DKTatlas","value":"aparc.DKTatlas"}]},"skel_stop":{"id":"skel_stop","type":"enum","placeholder":"","advanced":true,"desc":"Determine how much inflation into white matter is performed","default":"skel_stop","_order":19,"pid":0.20219027567846737,"options":[{"desc":"skel_stop (allows 1 layer of inflation into wm)","label":"skel_stop","value":"skel_stop"},{"desc":"skel_stop_strict (doesn't allow inflation)","label":"skel_stop_strict","value":"skel_stop_strict"},{"desc":"no_stop","label":"no_stop","value":"no_stop"}]},"neigh_def":{"id":"neigh_def","type":"enum","placeholder":"","advanced":true,"desc":"Determines how neighbor voxels are defined","default":"neigh_face_only","_order":21,"pid":0.34937578521765955,"options":[{"desc":"neigh_face_only","label":"neigh_face_only","value":"neigh_face_only"},{"desc":"neigh_face_edge","label":"neigh_face_edge","value":"neigh_face_edge"},{"desc":"neigh_upto_vert","label":"neigh_upto_vert","value":"neigh_upto_vert"}]},"whitematter":{"id":"whitematter","type":"boolean","placeholder":"","advanced":true,"desc":"determine whether white matter is kept before inflation. True = white matter included, false = trim off white matter","default":true,"_order":22,"pid":0.1157255111939609}},"inputs":[{"id":"dwi","desc":"The path to the DWI datatype","datatype":"58c33c5fe13a50849b25879b","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5dbb497c8aeeeef799f34e7b"},{"id":"freesurfer","desc":"The path to the top directory containing the output from freesurfer. If you want thalamic ROIs, make sure to use the output from app-segment-thalamic-nuclei","datatype":"58cb22c8e13a50849b25882e","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5dbb497c8aeeee77fef34e79"},{"id":"parcellation","desc":"The non-freesurfer parcellation to make ROIs from (optional). ","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5dbb497c8aeeee5680f34e78"},{"id":"mask","desc":"Specify this if you want to use your custom brainmask. If neither dtiinit nor brainmask is specified, this App will create brainmask from your dwi input using FSL bet.","datatype":"5a281aee2c214c9ba83ce620","datatype_tags":["brain","dwi"],"optional":true,"multi":false,"advanced":false,"_id":"5dbb497c8aeeeef56df34e77"},{"id":"prf","desc":"Specify prf input if you want to generate ROIs from the PRF/varea parcellation. ","datatype":"5d9d18d8e30ae43bb0612715","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5dbb497c8aeeee7339f34e76"}],"outputs":[{"id":"parc","desc":"The parcellation containing all of the ROIs in a single nifti","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5dbb497c8aeeeef269f34e7d"},{"id":"rois","desc":"The directory containing all of the ROIs","datatype":"5be9ea0315a8683a39a1ebd9","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5dbb497c8aeeeeb60bf34e7c"}],"stats":{"success_rate":83.41739577972209,"users":25,"runtime_mean":799849.04,"runtime_std":1408516.1455727932,"requested":12365,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a432462f3d3800f12ff12"},{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a432462f3d3800f12ff13"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a432462f3d3800f12ff14"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"634a432462f3d3800f12ff15"}],"examples":0,"groups":53},"removed":false,"__v":1341,"create_date":"2021-11-15T21:27:00.058Z","doi":"10.25663/brainlife.app.592","_canedit":true},{"_id":"60f5a0bab99111586bb464ae","projects":[],"admins":["16"],"tags":[],"removed":false,"stats":{"success_rate":83.41739577972209,"users":25,"runtime_mean":799849.04,"runtime_std":1408516.1455727932,"requested":12365,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a418362f3d3800f12e319"},{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a418362f3d3800f12e31a"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a418362f3d3800f12e31b"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"634a418362f3d3800f12e31c"}],"examples":0,"groups":53},"config":{"fmri":{"type":"input","file_id":"bold","input_id":"fmri"},"events":{"type":"input","file_id":"events","input_id":"fmri"},"events_json":{"type":"input","file_id":"events_json","input_id":"fmri"},"sbref":{"type":"input","file_id":"sbref","input_id":"fmri"},"sbref_json":{"type":"input","file_id":"sbref_json","input_id":"fmri"},"physio":{"type":"input","file_id":"physio","input_id":"fmri"},"physio_json":{"type":"input","file_id":"physio_json","input_id":"fmri"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"parc":{"type":"input","file_id":"parc","input_id":"parcellation"},"key":{"type":"input","file_id":"key","input_id":"parcellation"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"prfDir":{"type":"input","file_id":"varea","input_id":"prf"},"parcellationROIs":{"id":"parcellationROIs","type":"string","placeholder":"","advanced":false,"desc":"If a non-freesurfer parcellation is used, enter ROI numbers from key.txt (parcellation) ROIs wanted.\n\nExample: 45,54\n\nROIs will be outputted with following name format to avoid complications with other parcellations and similar ROI numbers: ROIparc-#.nii.gz, with # being the number of the ROI","default":"","_order":2,"pid":0.7437564099168568,"optional":true},"subcorticalROIs":{"id":"subcorticalROIs","type":"string","placeholder":"","advanced":false,"desc":"Enter the number of the subcortical ROI (if wanted).\n\nROIs will be outputted with following name format to avoid complications with other parcellations and similar ROI numbers: ROIsubcortical#.nii.gz, with # being the number of the ROI. ","default":"","_order":3,"pid":0.5721140602473056,"optional":true},"thalamicROIs":{"id":"thalamicROIs","type":"string","placeholder":"","advanced":false,"desc":"If thalamic nuclei segmentation from freesurfer is used, enter the number of the thalamic ROI (if wanted).\n\nPlease refer to this color lut (https://github.com/freesurfer/freesurfer/blob/dev/ThalamicNuclei/compressionLookupTable.txt) and your thalamic segmentation for specific ROI numbers\n\nROIs will be outputted with following name format to avoid complications with other parcellations and similar ROI numbers: ROIthalamus-#.nii.gz, with # being the number of the ROI. ","default":"","_order":4,"pid":0.8635532554677803,"optional":true},"hippocampalROIs":{"id":"hippocampalROIs","type":"string","placeholder":"","advanced":false,"desc":"If hippocampal segmentation from freesurfer is used, enter the number of the hippocampusROI (if wanted).\n\nPlease refer to this color lut (https://github.com/freesurfer/freesurfer/blob/dev/ThalamicNuclei/compressionLookupTable.txt) and your hippocampal segmentation for specific ROI numbers\n\nROIs will be outputted with following name format to avoid complications with other parcellations and similar ROI numbers: ROIhippocampus-#.nii.gz, with # being the number of the ROI. ","default":"","_order":5,"pid":0.94673450127063,"optional":true},"amygdalaROIs":{"id":"amygdalaROIs","type":"string","placeholder":"","advanced":false,"desc":"If amygdala segmentation from freesurfer is used, enter the number of the amygdala ROI (if wanted).\n\nPlease refer to this color lut (https://github.com/freesurfer/freesurfer/blob/dev/ThalamicNuclei/compressionLookupTable.txt) and your amygdala segmentation for specific ROI numbers\n\nROIs will be outputted with following name format to avoid complications with other parcellations and similar ROI numbers: ROIamygdala-#.nii.gz, with # being the number of the ROI. ","default":"","_order":6,"pid":0.3437365894767127,"optional":true},"prfROIs":{"id":"prfROIs","type":"string","placeholder":"","advanced":false,"desc":"If a visual area segmentation from a PRF mapping app is used, enter the number of the visual field ROI (if wanted).\n\nPlease refer to visual area segmentation from the PRF to determine ROI numbers.\n\nROIs will be outputted with following name format to avoid complications with other parcellations and similar ROI numbers: ROIvarea-#.nii.gz, with # being the number of the ROI. ","default":"","_order":7,"pid":0.977962431952435,"optional":true},"freesurferROIs":{"id":"freesurferROIs","type":"string","placeholder":"","advanced":false,"desc":"If ROIs from the freesurfer segmentation is desired, enter the number of the ROI from the freesurfer colorLUT.\n\nROIs will be outputted with following name format to avoid complications with other parcellations and similar ROI numbers: ROIfreesurfer-#.nii.gz, with # being the number of the ROI. ","default":"","_order":8,"pid":0.12314534639336538,"optional":true},"mergeROIsL":{"id":"mergeROIsL","type":"string","placeholder":"","advanced":false,"desc":"Left hemisphere ROI numbers and source parcellation you would like to merge into a single ROI\n\nDue to the possibility of different parcellations including the same set of labels, you must specify the source location using the following list of prefixes, followed by the roi number:\n\nfreesurfer: freesurfer-#\nparcellation: parc-#\nsubcortical: subcortical-#\nprf visual areas: varea-#\namygdala: amygdala-#\nhippocampus: hippocampus-#\nthalamus: thalamus-#\n\nif the user wants to merge multiple ROIs made from subset of all ROIs, enter each set of ROIs on a new line. the mergename field will need to correspond to these pairings (i.e. same number of pairings per left and right hemisphere, same order)\n\nex. freesurfer-11111 freesurfer-111112\nfreesurfer-11113 freesurfer-11114 freesurfer-11115","default":"","_order":9,"pid":0.6856146762631162,"optional":true,"multiline":true},"mergeROIsR":{"id":"mergeROIsR","type":"string","placeholder":"","advanced":false,"desc":"Right hemisphere ROI numbers and source parcellation you would like to merge into a single ROI.\n\nDue to the possibility of different parcellations including the same set of labels, you must specify the source location using the following list of prefixes, followed by the roi number:\n\nfreesurfer: freesurfer-#\nparcellation: parc-#\nsubcortical: subcortical-#\nprf visual areas: varea-#\namygdala: amygdala-#\nhippocampus: hippocampus-#\nthalamus: thalamus-#\n\nif the user wants to merge multiple ROIs made from subset of all ROIs, enter each set of ROIs on a new line. the mergename field will need to correspond to these pairings (i.e. same number of pairings per left and right hemisphere, same order)\n\nex. freesurfer-12111 freesurfer-121112\nfreesurfer-12113 freesurfer-12114 freesurfer-12115","default":"","_order":10,"pid":0.6618758675753674,"optional":true,"multiline":true},"mergename":{"id":"mergename","type":"string","placeholder":"","advanced":false,"desc":"Name for the ROI that you would like merged. The output will be in the following format: ROI${mergename}.nii.gz\n\nif the user wants to merge multiple ROIs made from subset of all ROIs, enter each name on a line. this field will need to correspond to these pairings (i.e. same number of pairings per left and right hemisphere, same order)\n\nex. test1\ntest2","default":"","_order":11,"pid":0.2125039231926431,"optional":true,"multiline":true},"parcInflate":{"id":"parcInflate","type":"number","placeholder":"","advanced":false,"desc":"if parcellation ROI inflation into WM is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":null,"_order":12,"pid":0.9969814748544198,"optional":true},"thalamusInflate":{"id":"thalamusInflate","type":"number","placeholder":"","advanced":false,"desc":"if ROI inflation into WM for thalamus segmentation is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":null,"_order":13,"pid":0.6804903710581273,"optional":true},"hippocampusInflate":{"id":"hippocampusInflate","type":"string","placeholder":"","advanced":false,"desc":"if ROI inflation into WM for hippocampal subfield segmentation is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":"","_order":14,"pid":0.9635835597656504,"optional":true},"amygdalaInflate":{"id":"amygdalaInflate","type":"string","placeholder":"","advanced":false,"desc":"if ROI inflation into WM for amygdala segmentation is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":"","_order":15,"pid":0.19535688872197676,"optional":true},"visInflate":{"id":"visInflate","type":"number","placeholder":"","advanced":false,"desc":"if ROI inflation into WM for visual area segmentation is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":null,"_order":16,"pid":0.48810437988821753,"optional":true},"freesurferInflate":{"id":"freesurferInflate","type":"number","placeholder":"","advanced":false,"desc":"if ROI inflation into WM for freesurfer segmentation is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":null,"_order":17,"pid":0.9688569569827068,"optional":true},"inputparc":{"id":"inputparc","type":"enum","placeholder":"","advanced":false,"desc":"The input freesurfer parcellation","default":"aparc","_order":18,"pid":0.2999038543053193,"options":[{"desc":"Desikan-Killiany Atlas","label":"aparc","value":"aparc"},{"desc":"Destrieux Atlas","label":"aparc.a2009s","value":"aparc.a2009s"},{"desc":"DKT Atlas","label":"aparc.DKTatlas","value":"aparc.DKTatlas"}]},"whitematter":{"id":"whitematter","type":"boolean","placeholder":"","advanced":false,"desc":"If you want to include the white matter in the inflation, which will limit the amount of inflation into the white matter, select 'true'.  However, selecting 'false' will trim the white matter, which may eliminate some potential ROIs.","default":true,"_order":19,"pid":0.17246888474748512}},"inputs":[{"id":"fmri","desc":"The path to the fmri datatype","datatype":"59b685a08e5d38b0b331ddc5","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5dbb497c8aeeeef799f34e7b"},{"id":"freesurfer","desc":"The path to the top directory containing the output from freesurfer. If you want thalamic ROIs, make sure to use the output from app-segment-thalamic-nuclei","datatype":"58cb22c8e13a50849b25882e","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5dbb497c8aeeee77fef34e79"},{"id":"parcellation","desc":"The non-freesurfer parcellation to make ROIs from (optional). ","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5dbb497c8aeeee5680f34e78"},{"id":"mask","desc":"Specify this if you want to use your custom brainmask. If brainmask is not specified, this App will create brainmask from your frmi input using FSL bet.","datatype":"5a281aee2c214c9ba83ce620","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5dbb497c8aeeeef56df34e77"},{"id":"prf","desc":"Specify prf input if you want to generate ROIs from the PRF/varea parcellation. ","datatype":"5d9d18d8e30ae43bb0612715","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5dbb497c8aeeee7339f34e76"}],"outputs":[{"id":"parc","desc":"The parcellation containing all of the ROIs in a single nifti","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5dbb497c8aeeeef269f34e7d"},{"id":"rois","desc":"The directory containing all of the ROIs","datatype":"5be9ea0315a8683a39a1ebd9","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5dbb497c8aeeeeb60bf34e7c"}],"github_branch":"merge-fmri-v1.0","github":"brainlife/app-roiGenerator","name":"Generate ROIs in FMRI Space","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a418462f3d3800f12e31d"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a418462f3d3800f12e31e"},{"name":"Franco Pestilli","email":null,"_id":"634a418462f3d3800f12e31f"}],"desc":"Generate a parcellation volume (and roi nifti files split into each label) for specific ROIs, or every ROI, for a parcellation from freesurfer output and/or input parcellation volume. This App can also inflate input parcellation volume toward non-white matter voxels.","__v":2266,"desc_override":"This app will generate ROIs from a parcellation, subcortical structures found in the Freesurfer aseg, cortical structures found in the Freesurfer parcellations, and population receptive field visual area segmentations. The ROIs will be resliced into functional space. Merging of rois is allowed.","create_date":"2021-07-19T15:56:42.355Z","doi":"10.25663/brainlife.app.546","_canedit":true},{"_id":"5f35afa64615e04b1abf9a43","stats":{"resources":[],"success_rate":0,"users":2,"requested":6,"examples":0,"groups":2},"projects":["5e2b98fbe51f7a9aeb88c43c"],"admins":["16"],"tags":[],"removed":false,"config":{"anat":{"type":"input","file_id":"t1","input_id":"anat"},"classification":{"type":"input","file_id":"classification","input_id":"classification"},"tracts":{"type":"input","file_id":"tracts","input_id":"classification"},"surfaces":{"type":"input","file_id":"surfaces","input_id":"classification"},"track":{"type":"input","file_id":"track","input_id":"track"},"colors":{"id":"colors","type":"string","placeholder":"","advanced":false,"desc":"color array for each track. should correspond to the number of tracks in 'tract_indices' configuration.\n\nexample for 1 tract:\n0 1 0\n\nexample for multiple tracts:\n0 1 0\n1 0 0","default":"","_order":2,"pid":0.405969671186285,"multiline":true,"optional":null},"tractIndices":{"id":"tractIndices","type":"string","placeholder":"","advanced":false,"desc":"tract indices wanted to plot. should correspond to the index number found in the classification structure\n\nexample:\n40 41","default":"","_order":3,"pid":0.8488568699589591},"slices":{"id":"slices","type":"string","placeholder":"","advanced":false,"desc":"sagittal: -1 0 0 (one slice to the left of midsagittal; change accordingly for different slices\n\naxial: 0 0 -1\n\ncoronal: 0 -1 0","default":"","_order":4,"pid":0.06886681123081861},"figView":{"id":"figView","type":"string","placeholder":"","advanced":false,"desc":"name of figview (axial, sagittal, coronal)","default":"sagittal","_order":5,"pid":0.9771241186158779},"subsample":{"id":"subsample","type":"number","placeholder":"","advanced":false,"desc":"number of tracts to plot. to plot all, leave empty","default":"","_order":6,"pid":0.2671551331327293,"optional":true}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5f35afa64615e07806bf9a44","id":"anat","datatype":"58c33bcee13a50849b25879a"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5f35afa64615e06ae1bf9a45","id":"classification","datatype":"5cc1d64c44947d8aea6b2d8b"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5f35afa64615e03e8ebf9a46","id":"track","datatype":"5907d922436ee50ffde9c549"}],"outputs":[{"datatype_tags":["tract_overlays"],"output_on_root":false,"archive":true,"_id":"5f35afa64615e03315bf9a47","id":"output","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null}],"github_branch":"master","github":"brainlife/app-plot-classified-streamlines","name":"Generate Tract Overlays on Anatomical Image","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3c9b62f3d3800f1298cb"}],"create_date":"2020-08-13T21:24:54.575Z","desc":null,"doi":"10.25663/brainlife.app.401","__v":4163,"_canedit":true},{"_id":"5f52cc4b42c17250a7651b63","projects":[],"admins":["16"],"tags":[],"removed":false,"stats":{"success_rate":83.41739577972209,"users":25,"runtime_mean":799849.04,"runtime_std":1408516.1455727932,"requested":12365,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3cf162f3d3800f129e0c"},{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a3cf162f3d3800f129e0d"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3cf162f3d3800f129e0e"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"634a3cf162f3d3800f129e0f"}],"examples":3,"groups":53},"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"prfSurfacesDir":{"type":"input","file_id":"prf_surfaces","input_id":"prfSurfacesDir"},"thalamusInflate":{"id":"thalamusInflate","type":"number","placeholder":"","advanced":false,"desc":"if ROI inflation into WM for thalamus segmentation is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":null,"_order":11,"pid":0.8428257490805177,"optional":true},"freesurferInflate":{"id":"freesurferInflate","type":"number","placeholder":"","advanced":false,"desc":"if ROI inflation into WM for freesurfer segmentation is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":null,"_order":13,"pid":0.17540818586601414,"optional":true},"inputparc":{"id":"inputparc","type":"enum","placeholder":"","advanced":false,"desc":"","default":"aparc.a2009s","_order":14,"pid":0.3908371349024342,"options":[{"desc":"Desikan-Killiany Atlas","label":"aparc","value":"aparc"},{"desc":"Destrieux Atlas","label":"aparc.a2009s","value":"aparc.a2009s"},{"desc":"DKT Atlas","label":"aparc.DKTatlas","value":"aparc.DKTatlas"}]},"min_degree":{"id":"min_degree","type":"string","placeholder":"","advanced":false,"desc":"Mininum eccentricity degrees for ROIs","default":"0 15 30","_order":15,"pid":0.709092366644104},"max_degree":{"id":"max_degree","type":"string","placeholder":"","advanced":false,"desc":"Maximum eccentricity degrees for ROIs","default":"3 30 90","_order":16,"pid":0.8040372279449567}},"inputs":[{"id":"dwi","datatype":"58c33c5fe13a50849b25879b","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5dbb497c8aeeeef799f34e7b"},{"id":"freesurfer","desc":"Path to the freesurfer datatype. This NEEDS to have been run through segment thalamic nuclei app, or have the thalamic nuclei generated in the original freesurfer generation, for this to work. This is used to generate the LGN ROIs.","datatype":"58cb22c8e13a50849b25882e","datatype_tags":["thalamic_nuclei"],"optional":false,"multi":false,"advanced":false,"_id":"5dbb497c8aeeee77fef34e79"},{"id":"mask","desc":"Specify this if you want to use your custom brainmask. If neither dtiinit nor brainmask is specified, this App will create brainmask from your dwi input using FSL bet.","datatype":"5a281aee2c214c9ba83ce620","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5dbb497c8aeeeef56df34e77"},{"id":"prfSurfacesDir","datatype":"5d9d18d8e30ae43bb0612715","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5f52cc1242c17268b6651a91"}],"outputs":[{"id":"parc","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags":["optic_radiation","benson","visual_white_matter","visual_areas"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5dbb497c8aeeeef269f34e7d"},{"id":"rois","datatype":"5be9ea0315a8683a39a1ebd9","datatype_tags":["optic_radiation","eccentricity","benson","visual_white_matter"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5dbb497c8aeeeeb60bf34e7c"},{"id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags":["visual_areas","visual_white_matter","eccentricity","benson","derivatives"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5f6ad088cfa36520b9c9f482"}],"github_branch":"visual-white-matter-eccentricity-dwi-v1.1","github":"brainlife/app-roiGenerator","name":"Generate Visual Regions of Interest Binned by Eccentricity Estimates (Benson Atlas) - Diffusion Space","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3cf262f3d3800f129e10"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a3cf262f3d3800f129e11"},{"name":"Franco Pestilli","email":null,"_id":"634a3cf262f3d3800f129e12"}],"desc":"Generate a parcellation volume (and roi nifti files split into each label) for specific ROIs, or every ROI, for a parcellation from freesurfer output and/or input parcellation volume. This App can also inflate input parcellation volume toward non-white matter voxels.","__v":4165,"desc_override":"This app will generate ROIs that can be used for visual white matter eccentricity tracking, including the optic radiation tracking. This includes visual areas from the Benson visual areas, the left and right LGNs from a thalamic nuclei segmentation, and exclusion ROIs from freesurfer. The ROIs will be resliced into diffusion space in of this. The Glasser ROIs will be binned by Eccentricity based on pRF mapping","create_date":"2020-09-04T23:22:51.536Z","doi":"10.25663/brainlife.app.414","_canedit":true},{"_id":"5f873282e6432d41a892e131","projects":[],"admins":["16"],"tags":[],"removed":false,"stats":{"success_rate":83.41739577972209,"users":25,"runtime_mean":799849.04,"runtime_std":1408516.1455727932,"requested":12365,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3dd662f3d3800f12b85a"},{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a3dd662f3d3800f12b85b"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3dd662f3d3800f12b85c"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"634a3dd662f3d3800f12b85d"}],"examples":5,"groups":53},"config":{"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"prfSurfacesDir":{"type":"input","file_id":"prf_surfaces","input_id":"prfSurfacesDir"},"thalamusInflate":{"id":"thalamusInflate","type":"number","placeholder":"","advanced":false,"desc":"if ROI inflation into WM for thalamus segmentation is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":null,"_order":11,"pid":0.16625917885942576,"optional":true},"freesurferInflate":{"id":"freesurferInflate","type":"number","placeholder":"","advanced":false,"desc":"if ROI inflation into WM for freesurfer segmentation is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":null,"_order":13,"pid":0.37741064721461826,"optional":true},"inputparc":{"id":"inputparc","type":"enum","placeholder":"","advanced":false,"desc":"","default":"aparc.a2009s","_order":14,"pid":0.4178897755567722,"options":[{"desc":"Desikan-Killiany Atlas","label":"aparc","value":"aparc"},{"desc":"Destrieux Atlas","label":"aparc.a2009s","value":"aparc.a2009s"},{"desc":"DKT Atlas","label":"aparc.DKTatlas","value":"aparc.DKTatlas"}]},"min_degree":{"id":"min_degree","type":"string","placeholder":"","advanced":false,"desc":"Mininum eccentricity degrees for ROIs","default":"0 15 30","_order":15,"pid":0.01677625375540026},"max_degree":{"id":"max_degree","type":"string","placeholder":"","advanced":false,"desc":"Maximum eccentricity degrees for ROIs","default":"3 30 90","_order":16,"pid":0.10644892603285872}},"inputs":[{"id":"freesurfer","desc":"Path to the freesurfer datatype. This NEEDS to have been run through segment thalamic nuclei app, or have the thalamic nuclei generated in the original freesurfer generation, for this to work. This is used to generate the LGN ROIs.","datatype":"58cb22c8e13a50849b25882e","datatype_tags":["thalamic_nuclei"],"optional":false,"multi":false,"advanced":false,"_id":"5dbb497c8aeeee77fef34e79"},{"id":"prfSurfacesDir","datatype":"5d9d18d8e30ae43bb0612715","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5f52cc1242c17268b6651a91"}],"outputs":[{"id":"parc","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags":["optic_radiation","benson","eccentricity","visual_white_matter","visual_areas"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5dbb497c8aeeeef269f34e7d"},{"id":"rois","datatype":"5be9ea0315a8683a39a1ebd9","datatype_tags":["optic_radiation","eccentricity","benson","visual_white_matter"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5dbb497c8aeeeeb60bf34e7c"},{"id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags":["visual_areas","visual_white_matter","eccentricity","benson","derivatives"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5f6ad088cfa36520b9c9f482"}],"github_branch":"visual-white-matter-eccentricity-t1-v1.2","github":"brainlife/app-roiGenerator","name":"Generate Visual Regions of Interest Binned by Eccentricity Estimates (Benson Atlas) - Freesurfer Space","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3dd762f3d3800f12b85e"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a3dd762f3d3800f12b85f"},{"name":"Franco Pestilli","email":null,"_id":"634a3dd762f3d3800f12b860"}],"desc":"Generate a parcellation volume (and roi nifti files split into each label) for specific ROIs, or every ROI, for a parcellation from freesurfer output and/or input parcellation volume. This App can also inflate input parcellation volume toward non-white matter voxels.","__v":4121,"desc_override":"This app will generate ROIs that can be used for visual white matter eccentricity tracking, including the optic radiation tracking. This includes visual areas from the Benson visual areas, the left and right LGNs from a thalamic nuclei segmentation, and exclusion ROIs from freesurfer. The ROIs will be resliced into diffusion space in of this. The Glasser ROIs will be binned by Eccentricity based on pRF mapping","create_date":"2020-10-14T17:16:50.559Z","doi":"10.25663/brainlife.app.441","_canedit":true},{"_id":"62757902cbc76827b7240da9","user_id":"16","projects":[],"admins":["16"],"name":"Generate Visual Regions of Interest Binned by Eccentricity Estimates (Benson Atlas) - fMRI Space","github":"brainlife/app-roiGenerator","github_branch":"visual-white-matter-eccentricity-fmri-v1.1","desc":"Generate a parcellation volume (and roi nifti files split into each label) for specific ROIs, or every ROI, for a parcellation from freesurfer output and/or input parcellation volume. This App can also inflate input parcellation volume toward non-white matter voxels.","desc_override":"This app will generate ROIs that can be used for visual white matter eccentricity tracking, including the optic radiation tracking. This includes visual areas from the Benson visual areas, the left and right LGNs from a thalamic nuclei segmentation, and exclusion ROIs from freesurfer. The ROIs will be resliced into functional mri space. The Glasser ROIs will be binned by Eccentricity based on pRF mapping","tags":[],"contributors":[{"name":"Brad Caron","email":null,"_id":"634a444b62f3d3800f130de7"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a444b62f3d3800f130de8"},{"name":"Franco Pestilli","email":null,"_id":"634a444b62f3d3800f130de9"}],"config":{"bold":{"type":"input","file_id":"bold","input_id":"fmri"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"prfSurfacesDir":{"type":"input","file_id":"prf_surfaces","input_id":"prfSurfacesDir"},"thalamusInflate":{"id":"thalamusInflate","type":"number","placeholder":"","advanced":false,"desc":"if ROI inflation into WM for thalamus segmentation is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":null,"_order":11,"pid":0.13923723749003203,"optional":true},"freesurferInflate":{"id":"freesurferInflate","type":"number","placeholder":"","advanced":false,"desc":"if ROI inflation into WM for freesurfer segmentation is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":null,"_order":13,"pid":0.34333290989468823,"optional":true},"inputparc":{"id":"inputparc","type":"enum","placeholder":"","advanced":false,"desc":"","default":"aparc.a2009s","_order":14,"pid":0.8501149124873759,"options":[{"desc":"Desikan-Killiany Atlas","label":"aparc","value":"aparc"},{"desc":"Destrieux Atlas","label":"aparc.a2009s","value":"aparc.a2009s"},{"desc":"DKT Atlas","label":"aparc.DKTatlas","value":"aparc.DKTatlas"}]},"min_degree":{"id":"min_degree","type":"string","placeholder":"","advanced":false,"desc":"Mininum eccentricity degrees for ROIs","default":"0 15 30","_order":15,"pid":0.8133032175790829},"max_degree":{"id":"max_degree","type":"string","placeholder":"","advanced":false,"desc":"Maximum eccentricity degrees for ROIs","default":"3 30 90","_order":16,"pid":0.7204644176269784}},"inputs":[{"id":"fmri","datatype":"59b685a08e5d38b0b331ddc5","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"62757902cbc76827b7240dad"},{"id":"freesurfer","desc":"Path to the freesurfer datatype. This NEEDS to have been run through segment thalamic nuclei app, or have the thalamic nuclei generated in the original freesurfer generation, for this to work. This is used to generate the LGN ROIs.","datatype":"58cb22c8e13a50849b25882e","datatype_tags":["thalamic_nuclei"],"optional":false,"multi":false,"advanced":false,"_id":"5dbb497c8aeeee77fef34e79"},{"id":"mask","desc":"Specify this if you want to use your custom brainmask. If this is not specified, this App will create brainmask from your func/task input using FSL bet.","datatype":"5a281aee2c214c9ba83ce620","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5dbb497c8aeeeef56df34e77"},{"id":"prfSurfacesDir","datatype":"5d9d18d8e30ae43bb0612715","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5f52cc1242c17268b6651a91"}],"outputs":[{"id":"parc","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags":["optic_radiation","benson","visual_white_matter","visual_areas"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5dbb497c8aeeeef269f34e7d"},{"id":"rois","datatype":"5be9ea0315a8683a39a1ebd9","datatype_tags":["optic_radiation","eccentricity","benson","visual_white_matter"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5dbb497c8aeeeeb60bf34e7c"},{"id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags":["visual_areas","visual_white_matter","eccentricity","benson","derivatives"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5f6ad088cfa36520b9c9f482"}],"stats":{"success_rate":83.41739577972209,"groups":53,"users":25,"runtime_mean":799849.04,"runtime_std":1408516.1455727932,"requested":12365,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a444b62f3d3800f130de3"},{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a444b62f3d3800f130de4"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a444b62f3d3800f130de5"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"634a444b62f3d3800f130de6"}],"examples":0},"removed":false,"__v":405,"create_date":"2022-05-06T19:37:38.699Z","doi":"10.25663/brainlife.app.624","_canedit":true},{"_id":"6220e63e5d8ab5d5f01fb8c1","user_id":"16","projects":[],"admins":["16","43","386","146"],"name":"Generate figures of white matter tracts overlaid on anatomical image","github":"brainlife/app-wmc_figures","github_branch":"1.1","desc":"This service creates 6 figures of each specified white matter tract (any wmc structure): axial, axial_flipped, sagittal_left, sagittal_right, coronal, and coronal_flipped. Please choose the t1 image slices you would like displayed. The default slices work well for the HCP t1 images if they have not been re-ACPC aligned. If you have ACPC aligned your t1 images using the ACPC alignment app on brainlife, the following values are a good starting point: coronal = 105, sagittal = 89, axial = 65. The img_min and img_max values refer to the value range displayed for the t1 image. The value range is calculated as follow (mean + img_min * std, mean + img_max * std). The default values are a good starting place, adjust them if your t1 is too dark or too light.","tags":["quality-check"],"contributors":[{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a43b362f3d3800f13070d"},{"name":"Giulia Bertò","email":null,"_id":"634a43b362f3d3800f13070e"},{"name":"Brad Caron","email":null,"_id":"634a43b362f3d3800f13070f"},{"name":"Anibal Sólon","email":"anibalsolon@gmail.com","_id":"634a43b362f3d3800f130710"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a43b362f3d3800f130711"}],"config":{"classification":{"type":"input","file_id":"classification","input_id":"wmc"},"wmc":{"type":"input","file_id":"tracts","input_id":"wmc"},"surfaces":{"type":"input","file_id":"surfaces","input_id":"wmc"},"anat":{"type":"input","file_id":"t1","input_id":"t1"},"coronal":{"default":"","type":"integer","id":"coronal","pid":0.11362450585341621,"_order":2,"optional":true,"desc":"If you want to specify which slice to use in the coronal plane, set that value here (ex. 128). Otherwise, the app will identify the mid-coronal slice."},"sagittal":{"default":"","type":"integer","id":"sagittal","pid":0.2886667459290797,"_order":3,"optional":true,"desc":"If you want to specify which slice to use in the sagittal plane, set that value here (ex. 128). Otherwise, the app will identify the mid-sagittal slice."},"axial":{"default":"","type":"integer","id":"axial","pid":0.9314541493140753,"_order":4,"optional":true,"desc":"If you want to specify which slice to use in the axial plane, set that value here (ex. 128). Otherwise, the app will identify the mid-axial slice."},"img_max":{"default":"","desc":"This field will set the maximum intensity brightness of the anatomical slice. The higher the value, the brighter the image.  Warning: default value is img_max=3 for branch 1.0 and original T1 max value for branch 1.1.","placeholder":"","type":"integer","id":"img_max","pid":0.8953845811236671,"_order":5,"optional":true},"img_min":{"default":"","desc":"This field will set the minimum intensity brightness of the anatomical slice. The higher the value, the more saturated (i.e. less dynamic range) the image.  Warning: default value is img_min=0.5 for branch 1.0 and original T1 min value for branch 1.1.","placeholder":"","type":"integer","id":"img_min","pid":0.41714684737607866,"_order":6,"optional":true},"tracts":{"id":"tracts","type":"string","placeholder":"","advanced":false,"desc":"Only output images of specified set of tracts. Tract codes must be listed with a white space separating them, e.g. 'leftArcuate rightArcuate'. It is important that the codes listed here match EXACTLY with the names listed in the classification structure. If left blank, all the tracts will be considered (default). For tract codes derived from common segmentations available on brainlife, please refer to the README.","default":"","_order":7,"pid":0.30907449167358525,"optional":true}},"inputs":[{"id":"wmc","desc":"White Matter Classification structure","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5967b45e81d7ef0021538e8b"},{"id":"t1","desc":"T1 image","datatype":"58c33bcee13a50849b25879a","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"596e25aa62986e00270caca4"}],"outputs":[{"id":"images","desc":"Images of the specified tracts, 6 figures each","datatype":"5967b799b09297d8d831709e","datatype_tags":["white_matter_tract_overlays"],"datatype_tags_pass":"wmc","output_on_root":false,"files":null,"archive":true,"_id":"5967b45e81d7ef0021538e8a"}],"stats":{"success_rate":82.22222222222221,"users":2,"runtime_mean":1260651.5,"runtime_std":548565.7530242386,"requested":253,"gitinfo":{"desc":"This service creates 4 figures of each AFQ tract: axial, left sagittal, right sagittal, coronal. Please choose the t1 image slices you would like displayed. The default slices work well for the HCP t1 images if they have not been re-ACPC aligned. If you have ACPC aligned your t1 images using the ACPC alignment app on Brain Life the following values are a good starting point: coronal = 105, sagittal = 89, axial = 65. The img_min and img_max values refer to the value range displayed for the t1 image. The value range is calulated as follow (mean + img_min * std, mean + img_max * std). The default values are a good starting place, adjust them if your t1 is too dark or too light.","tags":["quality-check"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a43b262f3d3800f13070c"}],"examples":2,"groups":4},"removed":false,"__v":758,"create_date":"2022-03-03T16:01:02.906Z","doi":"10.25663/brainlife.app.607","_canedit":true},{"_id":"5e90d0b1952fef2bba7bc991","projects":[],"admins":["16","43"],"tags":["quality-check"],"removed":false,"name":"Generate figures of whole-brain tractogram (tck)","desc":"This service creates 4 figures of each AFQ tract: axial, left sagittal, right sagittal, coronal. Please choose the t1 image slices you would like displayed. The default slices work well for the HCP t1 images if they have not been re-ACPC aligned. If you have ACPC aligned your t1 images using the ACPC alignment app on Brain Life the following values are a good starting point: coronal = 105, sagittal = 89, axial = 65. The img_min and img_max values refer to the value range displayed for the t1 image. The value range is calulated as follow (mean + img_min * std, mean + img_max * std). The default values are a good starting place, adjust them if your t1 is too dark or too light.","github":"kitchell/app-AFQ_figures","github_branch":"tractogram-v1.0","config":{"track":{"type":"input","file_id":"track","input_id":"track"}},"user_id":"16","outputs":[{"datatype_tags":["wb_tractogram"],"output_on_root":true,"archive":true,"_id":"5967b45e81d7ef0021538e8a","id":"images","datatype":"5967b799b09297d8d831709e","files":null,"desc":"The directory containing multiple images of the whole brain tractogram"}],"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5967b45e81d7ef0021538e8b","id":"track","datatype":"5907d922436ee50ffde9c549","desc":"The path to the tractogram (tck)"}],"__v":5145,"contributors":[{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a397c62f3d3800f12250a"},{"name":"Brad Caron","email":null,"_id":"634a397c62f3d3800f12250b"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a397c62f3d3800f12250c"}],"stats":{"requested":2027,"users":38,"success_rate":80.15963511972633,"gitinfo":{"desc":"This service creates 4 figures of each AFQ tract: axial, left sagittal, right sagittal, coronal. Please choose the t1 image slices you would like displayed. The default slices work well for the HCP t1 images if they have not been re-ACPC aligned. If you have ACPC aligned your t1 images using the ACPC alignment app on Brain Life the following values are a good starting point: coronal = 105, sagittal = 89, axial = 65. The img_min and img_max values refer to the value range displayed for the t1 image. The value range is calulated as follow (mean + img_min * std, mean + img_max * std). The default values are a good starting place, adjust them if your t1 is too dark or too light.","tags":["quality-check"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":512506.64,"runtime_std":484617.70921336574,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a397b62f3d3800f122509"}],"examples":3,"groups":33},"create_date":"2020-04-10T20:01:53.595Z","doi":"10.25663/brainlife.app.310","desc_override":"This app will generate png images of the whole brain tractrogram from four different views/orientations: coronal, axial, sagittal_left, sagittal_right. Intended for general QA","_canedit":true},{"_id":"5e9d30c6f1745d6b05f681b7","stats":{"success_rate":2.8532608695652173,"users":8,"runtime_mean":161075.92857142858,"runtime_std":182852.0241826307,"requested":1511,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a39c062f3d3800f122c68"}],"examples":1,"groups":11},"projects":[],"admins":["16"],"tags":["qa"],"removed":false,"config":{"lmax2":{"type":"input","file_id":"lmax2","input_id":"csd"},"lmax4":{"type":"input","file_id":"lmax4","input_id":"csd"},"lmax6":{"type":"input","file_id":"lmax6","input_id":"csd"},"lmax8":{"type":"input","file_id":"lmax8","input_id":"csd"},"lmax10":{"type":"input","file_id":"lmax10","input_id":"csd"},"lmax12":{"type":"input","file_id":"lmax12","input_id":"csd"},"lmax14":{"type":"input","file_id":"lmax14","input_id":"csd"},"lmax":{"id":"lmax","type":"number","placeholder":"","advanced":false,"desc":"","default":8,"_order":2,"pid":0.09502499369119688},"odf_scale":{"id":"odf_scale","type":"string","placeholder":"","advanced":false,"desc":"","default":"2","_order":3,"pid":0.44257781729483403},"x_slice":{"id":"x_slice","type":"string","placeholder":"","advanced":false,"desc":"","default":"121 174","_order":4,"pid":0.00842845315896179},"y_slice":{"id":"y_slice","type":"string","placeholder":"","advanced":false,"desc":"","default":"140 193","_order":5,"pid":0.9115780445523063},"z_slice":{"id":"z_slice","type":"string","placeholder":"","advanced":false,"desc":"","default":"77 78","_order":6,"pid":0.6136016204872825}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e9d30c6f1745d9ef7f681b8","id":"csd","datatype":"5c536bf0f9109beac46adb45"}],"outputs":[{"datatype_tags":["odf"],"output_on_root":false,"archive":true,"_id":"5e9d30c6f1745d864cf681b9","id":"images","datatype":"5967b799b09297d8d831709e","datatype_tags_pass":null,"files":null}],"github_branch":"master","github":"brainlife/app-plot-odf","name":"Generate image of ODF","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a39c162f3d3800f122c69"}],"create_date":"2020-04-20T05:19:02.677Z","desc":null,"doi":"10.25663/brainlife.app.317","__v":5064,"_canedit":true},{"_id":"5e88c6f0952fef0a3d7abf59","stats":{"success_rate":81.79611650485437,"users":103,"runtime_mean":58754.91,"runtime_std":300878.7313808703,"requested":22105,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a38fc62f3d3800f120777"}],"examples":5,"groups":153},"projects":[],"admins":["16"],"tags":["qa"],"removed":false,"config":{"input":{"type":"input","file_id":"dwi","input_id":"input"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"input"},"bvals":{"type":"input","file_id":"bvals","input_id":"input"},"volume":{"id":"volume","type":"string","placeholder":"","advanced":false,"desc":"if you don't want to generate an image of the first volume, input a volume here","default":"","_order":2,"pid":0.716522734937602,"optional":true}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e88c6f0952fef0d207abf5a","id":"input","datatype":"58c33c5fe13a50849b25879b"}],"outputs":[{"datatype_tags":["qa_image","dwi"],"output_on_root":false,"archive":true,"_id":"5e88c6f0952fef7e037abf5b","id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null}],"github_branch":"master-app-v1.0.0","github":"brainlife/app-slicer-fsl","name":"Generate images of DWI","desc_override":"Create mid-axial, sagittal, and coronal slice png of DWI image","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a38fc62f3d3800f120778"}],"create_date":"2020-04-04T17:42:08.836Z","desc":null,"doi":"10.25663/brainlife.app.298","__v":5198,"_canedit":true},{"_id":"5e8e162f952fef6d527b6d09","projects":[],"admins":["16"],"tags":["qa"],"removed":false,"stats":{"success_rate":81.79611650485437,"users":103,"runtime_mean":58754.91,"runtime_std":300878.7313808703,"requested":22105,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a396f62f3d3800f1221c2"}],"examples":4,"groups":153},"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"anat":{"type":"input","file_id":"t1","input_id":"anat"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e88c6f0952fef0d207abf5a","id":"dwi","datatype":"58c33c5fe13a50849b25879b","desc":"The path to the DWI datatype"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e8e162f952fef52407b6d0b","id":"anat","datatype":"58c33bcee13a50849b25879a","desc":"The path to the anat/t1w datatype"}],"outputs":[{"datatype_tags":["qa_image","dwi-t1"],"output_on_root":false,"archive":true,"_id":"5e88c6f0952fef7e037abf5b","id":"raw","datatype":"5967b799b09297d8d831709e","datatype_tags_pass":null,"files":null,"desc":"Directory containing png images of the dwi overlayed on the t1 using FSL"}],"github_branch":"dwi-t1-v1.0.0","github":"brainlife/app-slicer-fsl","name":"Generate images of DWI overlaid on T1","desc_override":"Create mid-axial, sagittal, and coronal slice png of T1 image with DWI outline overlayed","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a396f62f3d3800f1221c3"}],"desc":null,"__v":5149,"create_date":"2020-04-08T18:21:35.188Z","doi":"10.25663/brainlife.app.309","_canedit":true},{"_id":"5ed02d3c0a8ed86d37483300","projects":[],"admins":["16"],"tags":["qa"],"removed":false,"stats":{"success_rate":81.79611650485437,"users":103,"runtime_mean":58754.91,"runtime_std":300878.7313808703,"requested":22105,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3b7f62f3d3800f12626d"}],"examples":4,"groups":153},"config":{"dir":{"type":"input","file_id":"dir","input_id":"input"},"ndi":{"type":"input","file_id":"ndi","input_id":"input"},"isovf":{"type":"input","file_id":"isovf","input_id":"input"},"odi":{"type":"input","file_id":"odi","input_id":"input"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e88c6f0952fef0d207abf5a","id":"input","datatype":"5ed02a620a8ed8e39c482a61","desc":"The path to the NODDI datatype files"}],"outputs":[{"datatype_tags":["qa_image","noddi"],"output_on_root":false,"archive":true,"_id":"5e88c6f0952fef7e037abf5b","id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null,"desc":"Directory containing pngs of the NODDI measures using FSL"}],"github_branch":"noddi-v1.0.1","github":"brainlife/app-slicer-fsl","name":"Generate images of NODDI","desc_override":"Create mid-axial, sagittal, and coronal slice pngs of the NODDI","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3b7f62f3d3800f12626e"}],"desc":null,"__v":4763,"create_date":"2020-05-28T21:29:32.757Z","doi":"10.25663/brainlife.app.367","_canedit":true},{"_id":"5e88c77c952fef4cce7ac043","projects":[],"admins":["16"],"tags":["qa"],"removed":false,"stats":{"success_rate":81.79611650485437,"users":103,"runtime_mean":58754.91,"runtime_std":300878.7313808703,"requested":22105,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a392a62f3d3800f120ec1"}],"examples":0,"groups":153},"config":{"icvf":{"type":"input","file_id":"icvf","input_id":"input"},"isovf":{"type":"input","file_id":"isovf","input_id":"input"},"od":{"type":"input","file_id":"od","input_id":"input"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e88c6f0952fef0d207abf5a","id":"input","datatype":"5bd77a8615a8683a39440dab","desc":"The path to the NODDi (deprecated) datatype files"}],"outputs":[{"datatype_tags":["qa_image","noddi"],"output_on_root":false,"archive":true,"_id":"5e88c6f0952fef7e037abf5b","id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null,"desc":"Directory containing pngs of the NODDI (deprecated) measures using FSL"}],"github_branch":"noddi-v1.0.0","github":"brainlife/app-slicer-fsl","name":"Generate images of NODDI - Deprecated","desc_override":"Create mid-axial, sagittal, and coronal slice pngs of the NODDI","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a392b62f3d3800f120ec2"}],"desc":null,"__v":5198,"create_date":"2020-04-04T17:44:28.855Z","doi":"10.25663/brainlife.app.303","deprecated_by":"5ed02d3c0a8ed86d37483300","_canedit":true},{"_id":"5e88c72d952fefe0a07abfb6","projects":[],"admins":["16"],"tags":["qa"],"removed":false,"stats":{"success_rate":81.79611650485437,"users":103,"runtime_mean":58754.91,"runtime_std":300878.7313808703,"requested":22105,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a390d62f3d3800f120a8d"}],"examples":4,"groups":153},"config":{"input":{"type":"input","file_id":"t1","input_id":"input"},"volume":{"id":"volume","type":"string","placeholder":"","advanced":false,"desc":"if you don't want to generate an image of the first volume, input a volume here","default":"","_order":2,"pid":0.6767743023278934,"optional":true}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e88c6f0952fef0d207abf5a","id":"input","datatype":"58c33bcee13a50849b25879a","desc":"The path to the anat/t1w datatype"}],"outputs":[{"datatype_tags":["qa_image","t1"],"output_on_root":false,"archive":true,"_id":"5e88c6f0952fef7e037abf5b","id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null,"desc":"Directory containing a png of the T1 image using FSL"}],"github_branch":"master-app-v1.0.0","github":"brainlife/app-slicer-fsl","name":"Generate images of T1","desc_override":"Create mid-axial, sagittal, and coronal slice png of T1 image","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a390d62f3d3800f120a8e"}],"desc":null,"__v":5201,"create_date":"2020-04-04T17:43:09.187Z","doi":"10.25663/brainlife.app.300","_canedit":true},{"_id":"5e88c743952fef67fc7abfe5","projects":[],"admins":["16"],"tags":["qa"],"removed":false,"stats":{"success_rate":81.79611650485437,"users":103,"runtime_mean":58754.91,"runtime_std":300878.7313808703,"requested":22105,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a391662f3d3800f120b70"}],"examples":3,"groups":153},"config":{"input":{"type":"input","file_id":"t2","input_id":"input"},"volume":{"id":"volume","type":"string","placeholder":"","advanced":false,"desc":"if you don't want to generate an image of the first volume, input a volume here","default":"","_order":2,"pid":0.19793250128620565,"optional":true}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e88c6f0952fef0d207abf5a","id":"input","datatype":"594c0325fa1d2e5a1f0beda5","desc":"The path to the anat/t2w datatype"}],"outputs":[{"datatype_tags":["qa_image","t2"],"output_on_root":false,"archive":true,"_id":"5e88c6f0952fef7e037abf5b","id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null,"desc":"Directory containing png of the T2  image using FSL"}],"github_branch":"master-app-v1.0.0","github":"brainlife/app-slicer-fsl","name":"Generate images of T2","desc_override":"Create mid-axial, sagittal, and coronal slice png of T2 image","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a391662f3d3800f120b71"}],"desc":null,"__v":5200,"create_date":"2020-04-04T17:43:31.028Z","doi":"10.25663/brainlife.app.301","_canedit":true},{"_id":"617061bffc8eb9a0ee00a911","projects":[],"admins":["16"],"tags":["qa"],"removed":false,"stats":{"success_rate":81.79611650485437,"users":103,"runtime_mean":58754.91,"runtime_std":300878.7313808703,"requested":22105,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a430862f3d3800f12fe0f"}],"examples":1,"groups":153},"config":{"input":{"type":"input","file_id":"dwi","input_id":"input"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"input"},"bvals":{"type":"input","file_id":"bvals","input_id":"input"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e88c6f0952fef0d207abf5a","id":"input","datatype":"58c33c5fe13a50849b25879b"}],"outputs":[{"datatype_tags":["qa_image","dwi","gif"],"output_on_root":false,"archive":true,"_id":"5e88c6f0952fef7e037abf5b","id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":"input","files":null}],"github_branch":"montage-v1.0","github":"brainlife/app-slicer-fsl","name":"Generate images of all DWI volumes and create gif","desc_override":"Create mid-axial, sagittal, and coronal slice png of DWI image volumes and create gif for easy QA","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a430862f3d3800f12fe10"}],"desc":null,"__v":1541,"create_date":"2021-10-20T18:36:47.939Z","doi":"10.25663/brainlife.app.588","_canedit":true},{"_id":"5fe00ea457aacde3b62f7704","stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3e7f62f3d3800f12bc18"}],"success_rate":82.88659793814433,"users":6,"runtime_mean":291778.52,"runtime_std":256482.0561467597,"requested":549,"examples":1,"groups":6},"projects":[],"admins":["16"],"tags":[],"removed":false,"config":{"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"cortexmap":{"type":"input","file_id":"cortexmap","input_id":"cortexmap"},"surface":{"id":"surface","type":"enum","placeholder":"","advanced":false,"desc":"Surface to use in the image. Pial, white, and inflated come from freesurfer's standard segmentation. Midthickness comes from Cortex Mapping datatype","default":"midthickness","_order":2,"pid":0.5023777869223611,"options":[{"desc":"midthickness","label":"midthickness","value":"midthickness"},{"desc":"pial","label":"pial","value":"pial"},{"desc":"white","label":"white","value":"white"},{"desc":"inflated","label":"inflated","value":"inflated"}]},"min_percentile":{"id":"min_percentile","type":"number","placeholder":"","advanced":true,"desc":"Minimum percentile to map to colorbar","default":4,"_order":3,"pid":0.14484038619158213},"max_percentile":{"id":"max_percentile","type":"number","placeholder":"","advanced":true,"desc":"Maximum percentile to map to colorbar","default":96,"_order":4,"pid":0.031237911987542333},"threshold":{"id":"threshold","type":"number","placeholder":"","advanced":true,"desc":"Threshold value to use for computing minimum,  median, and maximum values to map colormap to.\n\nWill update to plot only data above threshold once functionality is available.","default":1e-9,"_order":5,"pid":0.8356367307845847},"colormap":{"id":"colormap","type":"enum","placeholder":"","advanced":true,"desc":"Matplotlib colormap to use for representing data mapped to cortical surface. 'Videen_style' is based on Connectome Workbench's and nilearn's colormap scheme.\n\nDefault: videen_style","default":"videen_style","_order":6,"pid":0.7338242333464808,"options":[{"desc":"videen_style","label":"videen_style","value":"videen_style"},{"desc":"viridis","label":"viridis","value":"viridis"},{"desc":"plasma","label":"plasma","value":"plasma"},{"desc":"inferno","label":"inferno","value":"inferno"},{"desc":"magma","label":"magma","value":"magma"},{"desc":"cividis","label":"cividis","value":"cividis"},{"desc":"Greys","label":"Greys","value":"Greys"},{"desc":"Purples","label":"Purples","value":"Purples"},{"desc":"Blues","label":"Blues","value":"Blues"},{"desc":"Greens","label":"Greens","value":"Greens"},{"desc":"Reds","label":"Reds","value":"Reds"},{"desc":"YlOrBr","label":"YlOrBr","value":"YlOrBr"},{"desc":"YlOrRd","label":"YlOrRd","value":"YlOrRd"},{"desc":"OrRd","label":"OrRd","value":"OrRd"},{"desc":"PuRd","label":"PuRd","value":"PuRd"},{"desc":"RdPu","label":"RdPu","value":"RdPu"},{"desc":"BuPu","label":"BuPu","value":"BuPu"},{"desc":"GnBu","label":"GnBu","value":"GnBu"},{"desc":"PuBu","label":"PuBu","value":"PuBu"},{"desc":"YlGnBu","label":"YlGnBu","value":"YlGnBu"},{"desc":"PuBuGn","label":"PuBuGn","value":"PuBuGn"},{"desc":"BuGn","label":"BuGn","value":"BuGn"},{"desc":"YlGn","label":"YlGn","value":"YlGn"},{"desc":"binary","label":"binary","value":"binary"},{"desc":"gist_yarg","label":"gist_yarg","value":"gist_yarg"},{"desc":"gist_gray","label":"gist_gray","value":"gist_gray"},{"desc":"gray","label":"gray","value":"gray"},{"desc":"bone","label":"bone","value":"bone"},{"desc":"pink","label":"pink","value":"pink"},{"desc":"spring","label":"spring","value":"spring"},{"desc":"summer","label":"summer","value":"summer"},{"desc":"autumn","label":"autumn","value":"autumn"},{"desc":"winter","label":"winter","value":"winter"},{"desc":"cool","label":"cool","value":"cool"},{"desc":"Wistia","label":"Wistia","value":"Wistia"},{"desc":"hot","label":"hot","value":"hot"},{"desc":"afmhot","label":"afmhot","value":"afmhot"},{"desc":"gist_heat","label":"gist_heat","value":"gist_heat"},{"desc":"copper","label":"copper","value":"copper"},{"desc":"PiYG","label":"PiYG","value":"PiYG"},{"desc":"PRGn","label":"PRGn","value":"PRGn"},{"desc":"BrBG","label":"BrBG","value":"BrBG"},{"desc":"PuOr","label":"PuOr","value":"PuOr"},{"desc":"RdGy","label":"RdGy","value":"RdGy"},{"desc":"RdBu","label":"RdBu","value":"RdBu"},{"desc":"RdYlBu","label":"RdYlBu","value":"RdYlBu"},{"desc":"RdYlGn","label":"RdYlGn","value":"RdYlGn"},{"desc":"Spectral","label":"Spectral","value":"Spectral"},{"desc":"coolwarm","label":"coolwarm","value":"coolwarm"},{"desc":"bwr","label":"bwr","value":"bwr"},{"desc":"seismic","label":"seismic","value":"seismic"},{"desc":"twilight","label":"twilight","value":"twilight"},{"desc":"twilight_shifted","label":"twilight_shifted","value":"twilight_shifted"},{"desc":"hsv","label":"hsv","value":"hsv"},{"desc":"flag","label":"flag","value":"flag"},{"desc":"prism","label":"prism","value":"prism"},{"desc":"ocean","label":"ocean","value":"ocean"},{"desc":"gist_earth","label":"gist_earth","value":"gist_earth"},{"desc":"terrain","label":"terrain","value":"terrain"},{"desc":"gist_stern","label":"gist_stern","value":"gist_stern"},{"desc":"gnuplot","label":"gnuplot","value":"gnuplot"},{"desc":"gnuplot2","label":"gnuplot2","value":"gnuplot2"},{"desc":"CMRmap","label":"CMRmap","value":"CMRmap"},{"desc":"cubehelix","label":"cubehelix","value":"cubehelix"},{"desc":"brg","label":"brg","value":"brg"},{"desc":"gist_rainbow","label":"gist_rainbow","value":"gist_rainbow"},{"desc":"rainbow","label":"rainbow","value":"rainbow"},{"desc":"jet","label":"jet","value":"jet"},{"desc":"turbo","label":"turbo","value":"turbo"},{"desc":"nipy_spectral","label":"nipy_spectral","value":"nipy_spectral"},{"desc":"gist_ncar","label":"gist_ncar","value":"gist_ncar"}]}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5fe00ea457aacdeb3b2f7705","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e","desc":"Path to the freesurfer dataset. Needed for image generation, even when surface = midthickness"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5fe00ea457aacd2b012f7706","id":"cortexmap","datatype":"5c58aa5ef9109beac4b52f61","desc":"Path to cortexmap data"}],"outputs":[{"datatype_tags":["cortex_mapping","qa_image"],"output_on_root":false,"archive":true,"_id":"5fe00ea457aacd0def2f7707","id":"images","datatype":"5967b799b09297d8d831709e","datatype_tags_pass":null,"files":null,"desc":"File containing multiple images of medial and lateral views of the cortex mapped data on the chosen surface"}],"github_branch":"v1.0","github":"brainlife/app-cortex-mapping-images","name":"Generate images of data mapped to cortical surface","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3e7f62f3d3800f12bc19"}],"create_date":"2020-12-21T02:55:32.999Z","desc":null,"__v":3711,"doi":"10.25663/brainlife.app.461","desc_override":"This app will generate images (jpgs) of data mapped to the cortical surface using MNE-python's (https://mne.tools/stable/index.html) build of pysurfer (https://pysurfer.github.io/index.html).","_canedit":true},{"_id":"5e88c717952fef602e7abf87","projects":[],"admins":["16"],"tags":["qa"],"removed":false,"stats":{"success_rate":81.79611650485437,"users":103,"runtime_mean":58754.91,"runtime_std":300878.7313808703,"requested":22105,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a390462f3d3800f120822"}],"examples":2,"groups":153},"config":{"input":{"type":"input","file_id":"bold","input_id":"input"},"volume":{"id":"volume","type":"string","placeholder":"","advanced":false,"desc":"choose the volume to generate the image of. if empty, will use the first volume","default":"","_order":2,"pid":0.9240433897309297,"optional":true}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e88c6f0952fef0d207abf5a","id":"input","datatype":"59b685a08e5d38b0b331ddc5","desc":"The path to the func/task datatype"}],"outputs":[{"datatype_tags":["qa_image","fmri"],"output_on_root":false,"archive":true,"_id":"5e88c6f0952fef7e037abf5b","id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null,"desc":"Directory containing png of the FMRI image using FSL"}],"github_branch":"master-app-v1.0.0","github":"brainlife/app-slicer-fsl","name":"Generate images of fMRI","desc_override":"Create mid-axial, sagittal, and coronal slice png of fMRI image","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a390462f3d3800f120823"}],"desc":null,"__v":5198,"create_date":"2020-04-04T17:42:47.311Z","doi":"10.25663/brainlife.app.299","_canedit":true},{"_id":"604b9bbf38fe120d9bef80f2","projects":[],"admins":["16"],"tags":["qa"],"removed":false,"stats":{"success_rate":81.79611650485437,"users":103,"runtime_mean":58754.91,"runtime_std":300878.7313808703,"requested":22105,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3f8862f3d3800f12cfb9"}],"examples":1,"groups":153},"config":{"bold":{"type":"input","file_id":"bold","input_id":"bold"},"anat":{"type":"input","file_id":"t1","input_id":"anat"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e88c6f0952fef0d207abf5a","id":"bold","datatype":"59b685a08e5d38b0b331ddc5","desc":"The path to the DWI datatype"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e8e162f952fef52407b6d0b","id":"anat","datatype":"58c33bcee13a50849b25879a","desc":"The path to the anat/t1w datatype"}],"outputs":[{"datatype_tags":["qa_image"],"output_on_root":false,"archive":true,"_id":"5e88c6f0952fef7e037abf5b","id":"raw","datatype":"5967b799b09297d8d831709e","datatype_tags_pass":null,"files":null,"desc":"Directory containing png images of the fmri overlayed on the t1 using FSL"}],"github_branch":"fmri-t1-v1.0.0","github":"brainlife/app-slicer-fsl","name":"Generate images of fMRI overlaid on T1","desc_override":"Create mid-axial, sagittal, and coronal slice png of T1 image with fMRI outline overlayed","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3f8962f3d3800f12cfba"}],"desc":null,"__v":3082,"create_date":"2021-03-12T16:50:07.506Z","doi":"10.25663/brainlife.app.490","_canedit":true},{"_id":"5e8ccf72952fef2eb67b4252","projects":[],"admins":["16"],"tags":["qa"],"removed":false,"stats":{"success_rate":81.79611650485437,"users":103,"runtime_mean":58754.91,"runtime_std":300878.7313808703,"requested":22105,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a396462f3d3800f121d6a"}],"examples":1,"groups":153},"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"mask":{"type":"input","file_id":"mask","input_id":"mask"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e8ccf72952fefe6cf7b4253","id":"dwi","datatype":"58c33c5fe13a50849b25879b","desc":"The path to the DWI datatype"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e88c6f0952fef0d207abf5a","id":"mask","datatype":"5a281aee2c214c9ba83ce620","desc":"The path to the mask datatype containing the brainmask of the DWI"}],"outputs":[{"datatype_tags":["qa_image","mask"],"output_on_root":false,"archive":true,"_id":"5e88c6f0952fef7e037abf5b","id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null,"desc":"Directory containing png of the brainmask overlayed on the DWI using FSL"}],"github_branch":"dwi-mask-overlay-v1.0.0","github":"brainlife/app-slicer-fsl","name":"Generate images of mask overlaid on DWI","desc_override":"Create mid-axial, sagittal, and coronal slice png of the brainmask overlaid on the DWI image","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a396462f3d3800f121d6b"}],"desc":null,"__v":5156,"create_date":"2020-04-07T19:07:30.909Z","doi":"10.25663/brainlife.app.308","_canedit":true},{"_id":"5e8ccdb3952fef30b27b41e3","projects":[],"admins":["16"],"tags":["qa"],"removed":false,"stats":{"success_rate":81.79611650485437,"users":103,"runtime_mean":58754.91,"runtime_std":300878.7313808703,"requested":22105,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a395b62f3d3800f121d5e"}],"examples":1,"groups":153},"config":{"input":{"type":"input","file_id":"mask","input_id":"input"},"volume":{"id":"volume","type":"string","placeholder":"","advanced":false,"desc":"if you don't want to generate an image of the first volume, input a volume here","default":"","_order":2,"pid":0.2053970208435698,"optional":true}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e88c6f0952fef0d207abf5a","id":"input","datatype":"5a281aee2c214c9ba83ce620","desc":"The path to the mask datatype"}],"outputs":[{"datatype_tags":["qa_image","mask"],"output_on_root":false,"archive":true,"_id":"5e88c6f0952fef7e037abf5b","id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null,"desc":"Directory containing png of the mask image using FSL"}],"github_branch":"master-app-v1.0.0","github":"brainlife/app-slicer-fsl","name":"Generate images of masks","desc_override":"Create mid-axial, sagittal, and coronal slice png of the mask","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a395b62f3d3800f121d5f"}],"desc":null,"__v":5158,"create_date":"2020-04-07T19:00:03.379Z","doi":"10.25663/brainlife.app.307","_canedit":true},{"_id":"5e88c763952fefb8487ac014","projects":[],"admins":["16"],"tags":["qa"],"removed":false,"stats":{"success_rate":81.79611650485437,"users":103,"runtime_mean":58754.91,"runtime_std":300878.7313808703,"requested":22105,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a392162f3d3800f120ebe"}],"examples":5,"groups":153},"config":{"fa":{"type":"input","file_id":"fa","input_id":"input"},"md":{"type":"input","file_id":"md","input_id":"input"},"rd":{"type":"input","file_id":"rd","input_id":"input"},"ad":{"type":"input","file_id":"ad","input_id":"input"},"ga":{"type":"input","file_id":"ga","input_id":"input"},"ak":{"type":"input","file_id":"ak","input_id":"input"},"mk":{"type":"input","file_id":"mk","input_id":"input"},"rk":{"type":"input","file_id":"rk","input_id":"input"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e88c6f0952fef0d207abf5a","id":"input","datatype":"5a79df48d071a1753f1d661b","desc":"The path to the tensor datatype files"}],"outputs":[{"datatype_tags":["qa_image","tensor"],"output_on_root":false,"archive":true,"_id":"5e88c6f0952fef7e037abf5b","id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null,"desc":"Directory containing pngs of the DTI/DKI measures using FSL"}],"github_branch":"tensor-v1.0.0","github":"brainlife/app-slicer-fsl","name":"Generate images of tensor","desc_override":"Create mid-axial, sagittal, and coronal slice pngs of tensor outputs","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a392262f3d3800f120ebf"}],"desc":null,"__v":5198,"create_date":"2020-04-04T17:44:03.199Z","doi":"10.25663/brainlife.app.302","_canedit":true},{"_id":"5e9272ed3f18bacda81d973e","projects":[],"admins":["16"],"tags":["qa"],"removed":false,"stats":{"success_rate":81.79611650485437,"users":103,"runtime_mean":58754.91,"runtime_std":300878.7313808703,"requested":22105,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a399062f3d3800f1228df"}],"examples":2,"groups":153},"config":{"input":{"type":"input","file_id":"mask","input_id":"input"},"anat":{"type":"input","file_id":"t1","input_id":"anat"}},"inputs":[{"datatype_tags":["5tt"],"optional":false,"multi":false,"advanced":false,"_id":"5e88c6f0952fef0d207abf5a","id":"input","datatype":"5a281aee2c214c9ba83ce620","desc":"The path to the mask datatype containing the 5 tissue probability image from Tissue-type segmentation"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5e9272ed3f18ba99e31d9740","id":"anat","datatype":"58c33bcee13a50849b25879a","desc":"If you include a T1, the output pngs will include an outline of the different tissue type masks overlayed on the T1 image"}],"outputs":[{"datatype_tags":["qa_image","tissue_types"],"output_on_root":false,"archive":true,"_id":"5e88c6f0952fef7e037abf5b","id":"raw","datatype":"5967b799b09297d8d831709e","datatype_tags_pass":null,"files":null,"desc":"Directory containing png of the 5 tissue type probability mask using FSL"}],"github_branch":"5tt-v1.0.0","github":"brainlife/app-slicer-fsl","name":"Generate images of tissue type masks","desc_override":"Create mid-axial, sagittal, and coronal slice png of tissue type masks. If you include a T1, the pngs will display an outline of the different masks on the T1. Else, the pngs will be of binary masks of the different tissue types: gray matter, white matter, CSF, and gray matter white matter interface.","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a399162f3d3800f1228e0"}],"desc":null,"__v":5137,"create_date":"2020-04-12T01:46:21.788Z","doi":"10.25663/brainlife.app.312","_canedit":true},{"_id":"6109ecd3b991116939bee534","projects":[],"admins":["16"],"tags":[],"removed":false,"stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a41e062f3d3800f12efe3"}],"success_rate":82.88659793814433,"users":6,"runtime_mean":291778.52,"runtime_std":256482.0561467597,"requested":549,"examples":1,"groups":6},"config":{"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"rois":{"type":"input","file_id":"rois","input_id":"rois"},"label":{"type":"input","file_id":"label","input_id":"rois"},"surface":{"id":"surface","type":"enum","placeholder":"","advanced":false,"desc":"Surface to use in the image. Pial, white, and inflated come from freesurfer's standard segmentation. Midthickness comes from Cortex Mapping datatype","default":"inflated","_order":2,"pid":0.11677207917455823,"options":[{"desc":"pial","label":"pial","value":"pial"},{"desc":"white","label":"white","value":"white"},{"desc":"inflated","label":"inflated","value":"inflated"}]},"min_percentile":{"id":"min_percentile","type":"number","placeholder":"","advanced":true,"desc":"Minimum percentile to map to colorbar","default":4,"_order":3,"pid":0.8097218102099738},"max_percentile":{"id":"max_percentile","type":"number","placeholder":"","advanced":true,"desc":"Maximum percentile to map to colorbar","default":96,"_order":4,"pid":0.390311746849784},"threshold":{"id":"threshold","type":"number","placeholder":"","advanced":true,"desc":"Threshold value to use for computing minimum,  median, and maximum values to map colormap to.\n\nWill update to plot only data above threshold once functionality is available.","default":1e-9,"_order":5,"pid":0.4228250600446004},"colormap":{"id":"colormap","type":"enum","placeholder":"","advanced":true,"desc":"Matplotlib colormap to use for representing data mapped to cortical surface. 'Videen_style' is based on Connectome Workbench's and nilearn's colormap scheme.\n\nDefault: videen_style","default":"hot","_order":6,"pid":0.7599330585670228,"options":[{"desc":"videen_style","label":"videen_style","value":"videen_style"},{"desc":"viridis","label":"viridis","value":"viridis"},{"desc":"plasma","label":"plasma","value":"plasma"},{"desc":"inferno","label":"inferno","value":"inferno"},{"desc":"magma","label":"magma","value":"magma"},{"desc":"cividis","label":"cividis","value":"cividis"},{"desc":"Greys","label":"Greys","value":"Greys"},{"desc":"Purples","label":"Purples","value":"Purples"},{"desc":"Blues","label":"Blues","value":"Blues"},{"desc":"Greens","label":"Greens","value":"Greens"},{"desc":"Reds","label":"Reds","value":"Reds"},{"desc":"YlOrBr","label":"YlOrBr","value":"YlOrBr"},{"desc":"YlOrRd","label":"YlOrRd","value":"YlOrRd"},{"desc":"OrRd","label":"OrRd","value":"OrRd"},{"desc":"PuRd","label":"PuRd","value":"PuRd"},{"desc":"RdPu","label":"RdPu","value":"RdPu"},{"desc":"BuPu","label":"BuPu","value":"BuPu"},{"desc":"GnBu","label":"GnBu","value":"GnBu"},{"desc":"PuBu","label":"PuBu","value":"PuBu"},{"desc":"YlGnBu","label":"YlGnBu","value":"YlGnBu"},{"desc":"PuBuGn","label":"PuBuGn","value":"PuBuGn"},{"desc":"BuGn","label":"BuGn","value":"BuGn"},{"desc":"YlGn","label":"YlGn","value":"YlGn"},{"desc":"binary","label":"binary","value":"binary"},{"desc":"gist_yarg","label":"gist_yarg","value":"gist_yarg"},{"desc":"gist_gray","label":"gist_gray","value":"gist_gray"},{"desc":"gray","label":"gray","value":"gray"},{"desc":"bone","label":"bone","value":"bone"},{"desc":"pink","label":"pink","value":"pink"},{"desc":"spring","label":"spring","value":"spring"},{"desc":"summer","label":"summer","value":"summer"},{"desc":"autumn","label":"autumn","value":"autumn"},{"desc":"winter","label":"winter","value":"winter"},{"desc":"cool","label":"cool","value":"cool"},{"desc":"Wistia","label":"Wistia","value":"Wistia"},{"desc":"hot","label":"hot","value":"hot"},{"desc":"afmhot","label":"afmhot","value":"afmhot"},{"desc":"gist_heat","label":"gist_heat","value":"gist_heat"},{"desc":"copper","label":"copper","value":"copper"},{"desc":"PiYG","label":"PiYG","value":"PiYG"},{"desc":"PRGn","label":"PRGn","value":"PRGn"},{"desc":"BrBG","label":"BrBG","value":"BrBG"},{"desc":"PuOr","label":"PuOr","value":"PuOr"},{"desc":"RdGy","label":"RdGy","value":"RdGy"},{"desc":"RdBu","label":"RdBu","value":"RdBu"},{"desc":"RdYlBu","label":"RdYlBu","value":"RdYlBu"},{"desc":"RdYlGn","label":"RdYlGn","value":"RdYlGn"},{"desc":"Spectral","label":"Spectral","value":"Spectral"},{"desc":"coolwarm","label":"coolwarm","value":"coolwarm"},{"desc":"bwr","label":"bwr","value":"bwr"},{"desc":"seismic","label":"seismic","value":"seismic"},{"desc":"twilight","label":"twilight","value":"twilight"},{"desc":"twilight_shifted","label":"twilight_shifted","value":"twilight_shifted"},{"desc":"hsv","label":"hsv","value":"hsv"},{"desc":"flag","label":"flag","value":"flag"},{"desc":"prism","label":"prism","value":"prism"},{"desc":"ocean","label":"ocean","value":"ocean"},{"desc":"gist_earth","label":"gist_earth","value":"gist_earth"},{"desc":"terrain","label":"terrain","value":"terrain"},{"desc":"gist_stern","label":"gist_stern","value":"gist_stern"},{"desc":"gnuplot","label":"gnuplot","value":"gnuplot"},{"desc":"gnuplot2","label":"gnuplot2","value":"gnuplot2"},{"desc":"CMRmap","label":"CMRmap","value":"CMRmap"},{"desc":"cubehelix","label":"cubehelix","value":"cubehelix"},{"desc":"brg","label":"brg","value":"brg"},{"desc":"gist_rainbow","label":"gist_rainbow","value":"gist_rainbow"},{"desc":"rainbow","label":"rainbow","value":"rainbow"},{"desc":"jet","label":"jet","value":"jet"},{"desc":"turbo","label":"turbo","value":"turbo"},{"desc":"nipy_spectral","label":"nipy_spectral","value":"nipy_spectral"},{"desc":"gist_ncar","label":"gist_ncar","value":"gist_ncar"}]}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5fe00ea457aacdeb3b2f7705","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e","desc":"Path to the freesurfer dataset. Needed for image generation, even when surface = midthickness"},{"datatype_tags":["tractEndpointDensity"],"optional":false,"multi":false,"advanced":false,"_id":"6109ecd3b991110ef5bee537","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9"}],"outputs":[{"datatype_tags":["qa_image","tract_endpoints"],"output_on_root":false,"archive":true,"_id":"5fe00ea457aacd0def2f7707","id":"images","datatype":"5967b799b09297d8d831709e","datatype_tags_pass":"rois","files":null,"desc":"File containing multiple images of different views of each tract endpoint"}],"github_branch":"tract-endpoints-v1.0","github":"brainlife/app-cortex-mapping-images","name":"Generate images of tract endpoints on cortical surface","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a41e062f3d3800f12efe4"}],"desc":null,"__v":2146,"desc_override":"This app will generate images (jpgs) of tract endpoint rois mapped to the cortical surface using MNE-python's (https://mne.tools/stable/index.html) build of pysurfer (https://pysurfer.github.io/index.html).","create_date":"2021-08-04T01:26:43.064Z","doi":"10.25663/brainlife.app.555","_canedit":true},{"_id":"60fecf3eb9911170e6b89722","stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a41a962f3d3800f12e4a7"}],"success_rate":44.38652766639935,"users":14,"runtime_mean":9394121.4,"runtime_std":8236894.053758132,"requested":3594,"examples":0,"groups":24},"projects":[],"admins":["16"],"tags":["diffusion-mri","mri","tracking","tractography","vision"],"removed":false,"config":{"classification":{"type":"input","file_id":"classification","input_id":"wmc"},"tracts":{"type":"input","file_id":"tracts","input_id":"wmc"},"surfaces":{"type":"input","file_id":"surfaces","input_id":"wmc"},"rois":{"type":"input","file_id":"rois","input_id":"rois"},"label":{"type":"input","file_id":"label","input_id":"rois"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"60fecf3eb991111ca7b89723","id":"wmc","datatype":"5cc1d64c44947d8aea6b2d8b"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"60fecf3eb99111491cb89724","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9"}],"outputs":[{"datatype_tags":["surface_rois"],"output_on_root":false,"archive":true,"_id":"60fecf3eb99111a214b89725","id":"wmc","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags_pass":"wmc","files":null}],"github_branch":"tmp-add-rois","github":"brainlife/app-trekker-roi-tracking","name":"Generate surface visualizations of ROIs for WMC Datatype Viewer","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a41a962f3d3800f12e4a8"},{"name":"Franco Pestilli","email":null,"_id":"634a41a962f3d3800f12e4a9"}],"create_date":"2021-07-26T15:05:34.772Z","desc":"Brainlife App (wrapper) for dMRI based fiber tracking between ROIs using parallel transport tractography","__v":2211,"desc_override":"This app will generate surface visualizations of ROIs for the WMC datatype viewer. This is intended to be used with ROI tracking apps.","doi":"10.25663/brainlife.app.550","_canedit":true},{"_id":"5cb64c22454d3c00353fa27f","stats":{"stars":0,"requested":13211,"users":7,"success_rate":84.2468709538196,"serviceinfo":{"_id":"5d729e1e78356a109788b223","counts":{"_id":"5e5c3df087cac70df9ab1405","failed":1153,"finished":6909,"removed":8575,"requested":9022,"running":7857,"running_sync":0,"stop_requested":43},"success_rate":85.69833788141901,"users":5,"readme_status":"ok","runtime_mean":232893653.1,"runtime_std":1128125841.5110195,"service":"brainlife/app-endpointMapGeneration","__v":0},"gitinfo":{"desc":null,"tags":[],"stats":{"stars":0},"contributors":[{"name":"Daniel Bullock","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":1296803.13,"runtime_std":1834645.5911389024,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a35aa62f3d3800f11a212"}],"examples":0,"groups":12},"projects":[],"admins":["56"],"tags":[],"removed":false,"config":{"track":{"type":"input","file_id":"track","input_id":"track"},"output":{"type":"input","file_id":"output","input_id":"classification"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"decayFunc":{"id":"decayFunc","type":"enum","placeholder":"","desc":"","default":"","_order":2,"pid":0.25418249336421206,"options":[{"desc":"Make endpoint maps using only and exactly tracts' streamline endpoints","label":"Exact endpoints","value":"exact"},{"desc":"For each streamline endpoint in a tract, each adjacent mm voxel within the threshold distance is treated as though it has an endpoint in it.","label":"No decay","value":"box"},{"desc":"An gaussian smoothing kernel is applied to each of a tract's streamline endpoints such that the density computed for each endpoint is spread in a gaussian fashion, with the kernel corresponding to the input threshold distance.","label":"Gaussian decay","value":"gaussian"}]},"decayRadiusThresh":{"id":"decayRadiusThresh","type":"number","placeholder":"1","desc":"Odd integer values only, larger than 0.  Defines the kernel to be used if either no decay or gaussian decay is selected.  Defines *diameter* (not radius, hence odd) of smoothing kernel Ignored in the case of exact endpoints.","default":1,"_order":3,"pid":0.34109294793636313,"readonly":false,"min":1}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5cb64c22454d3c00353fa282","id":"track","datatype":"5907d922436ee50ffde9c549"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5cb64c22454d3c00353fa281","id":"classification","datatype":"58f10a90436ee50ffd9063c5"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5cb64c22454d3c00353fa280","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e"}],"outputs":[{"datatype_tags":["tractEndpointDensity"],"output_on_root":false,"archive":true,"_id":"5cb64c22454d3c00353fa283","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9","datatype_tags_pass":null,"files":null}],"github_branch":"master","github":"brainlife/app-endpointMapGeneration","name":"Generate tract endpoint maps","user_id":"56","contributors":[{"name":"Daniel Bullock","email":"iisdanbul@gmail.com","_id":"634a35aa62f3d3800f11a213"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a35aa62f3d3800f11a214"}],"create_date":"2019-04-16T21:41:54.126Z","desc":"This app will generate endpoint maps for all tracts in an input classification structure.  User can specify what sort of decay/smoothing algorithm can be used (or none) and whether the output is to be normalized (e.g. max density voxel in tract endpoint mask = 1).","doi":"10.25663/brainlife.app.182","__v":8233,"deprecated_by":"5cc9ea944b5e4502275edb99","_canedit":true},{"_id":"5cc9ea944b5e4502275edb99","projects":[],"admins":["56"],"tags":[],"removed":false,"stats":{"stars":0,"requested":13211,"users":7,"success_rate":84.2468709538196,"serviceinfo":{"_id":"5d729e1e78356a109788b223","counts":{"_id":"5e5c3dfd87cac7676fab1411","failed":1153,"finished":6909,"removed":8575,"requested":9022,"running":7857,"running_sync":0,"stop_requested":43},"success_rate":85.69833788141901,"users":5,"readme_status":"ok","runtime_mean":232893653.1,"runtime_std":1128125841.5110195,"service":"brainlife/app-endpointMapGeneration","__v":0},"gitinfo":{"desc":null,"tags":[],"stats":{"stars":0},"contributors":[{"name":"Daniel Bullock","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":1296803.13,"runtime_std":1834645.5911389024,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a362d62f3d3800f11c17b"}],"examples":2,"groups":12},"config":{"track":{"type":"input","file_id":"track","input_id":"track"},"classification":{"type":"input","file_id":"classification","input_id":"classification"},"tracts":{"type":"input","file_id":"tracts","input_id":"classification"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"decayFunc":{"id":"decayFunc","type":"enum","placeholder":"","desc":"","default":"","_order":2,"pid":0.15526574570988694,"options":[{"desc":"Make endpoint maps using only and exactly tracts' streamline endpoints","label":"Exact endpoints","value":"exact"},{"desc":"For each streamline endpoint in a tract, each adjacent mm voxel within the threshold distance is treated as though it has an endpoint in it.","label":"No decay","value":"box"},{"desc":"An gaussian smoothing kernel is applied to each of a tract's streamline endpoints such that the density computed for each endpoint is spread in a gaussian fashion, with the kernel corresponding to the input threshold distance.","label":"Gaussian decay","value":"gaussian"}]},"decayRadiusThresh":{"id":"decayRadiusThresh","type":"number","placeholder":"1","desc":"Odd integer values only, larger than 0.  Defines the kernel to be used if either no decay or gaussian decay is selected.  Defines *diameter* (not radius, hence odd) of smoothing kernel Ignored in the case of exact endpoints.","default":1,"_order":3,"pid":0.05836110040370901,"readonly":false,"min":1}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5cb64c22454d3c00353fa282","id":"track","datatype":"5907d922436ee50ffde9c549"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5cb64c22454d3c00353fa281","id":"classification","datatype":"5cc1d64c44947d8aea6b2d8b"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5cb64c22454d3c00353fa280","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e"}],"outputs":[{"datatype_tags":["tractEndpointDensity"],"output_on_root":false,"archive":true,"_id":"5cb64c22454d3c00353fa283","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9","datatype_tags_pass":null,"files":null}],"github_branch":"1.0","github":"brainlife/app-endpointMapGeneration","name":"Generate tract endpoint maps","user_id":"56","contributors":[{"name":"Daniel Bullock","email":"iisdanbul@gmail.com","_id":"634a362d62f3d3800f11c17c"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a362d62f3d3800f11c17d"}],"desc":"This app will generate endpoint maps for all tracts in an input classification structure.  User can specify what sort of decay/smoothing algorithm can be used (or none) and whether the output is to be normalized (e.g. max density voxel in tract endpoint mask = 1).","__v":8123,"create_date":"2019-05-01T18:51:00.197Z","doi":"10.25663/brainlife.app.194","desc_override":"This app will generate endpoint maps for all tracts in an input classification structure.  User can specify what sort of decay/smoothing algorithm can be used (or none).","_canedit":true},{"_id":"628ceb91d0697cf1eaed4a14","user_id":"56","projects":[],"admins":["56"],"name":"Generate tract figures (wma_pyTools)","github":"DanNBullock/app-wma_pyTools-TractFigs","desc_override":"Generate the following kinds of figures:\n> General streamline anatomy plot (color-coded in accordance with morphological characteristics)\n> Density GIFs\n> Multi-tile density plots\n> \"Fingerprint\" plots (radial bar-plots indicating streamline termination locations)","tags":[],"config":{"tractogram":{"type":"input","file_id":"track","input_id":"tractogram"},"wmc":{"type":"input","file_id":"classification","input_id":"wmc"},"tracts":{"type":"input","file_id":"tracts","input_id":"wmc"},"surfaces":{"type":"input","file_id":"surfaces","input_id":"wmc"},"anat":{"type":"input","file_id":"t1","input_id":"anat"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"parc":{"type":"input","file_id":"parc","input_id":"parc"},"key":{"type":"input","file_id":"key","input_id":"parc"},"label":{"type":"input","file_id":"label","input_id":"parc"},"spagettiFlag":{"id":"spagettiFlag","type":"boolean","placeholder":"","advanced":false,"desc":"Produce general streamline anatomy plot (color-coded in accordance with morphological characteristics).","default":true,"_order":2,"pid":0.9610867173313113},"gifFlag":{"id":"gifFlag","type":"boolean","placeholder":"","advanced":false,"desc":"Produce ensity GIFs","default":true,"_order":3,"pid":0.5345761140504897},"tileFlag":{"id":"tileFlag","type":"boolean","placeholder":"","advanced":false,"desc":"Produce multi-tile density plots","default":true,"_order":4,"pid":0.8360592377560192},"fingerprintFlag":{"id":"fingerprintFlag","type":"boolean","placeholder":"","advanced":false,"desc":"Produce \"fingerprint\" plots (radial bar-plots indicating streamline termination locations).","default":true,"_order":5,"pid":0.7082795573262123},"inflateParam":{"id":"inflateParam","type":"number","placeholder":"2","advanced":true,"desc":"Whether or not to inflate the passed parcellation and, if so, by how many voxel iterations.","default":2,"_order":6,"pid":0.8326874462602707,"min":0,"max":20}},"inputs":[{"id":"tractogram","datatype":"5907d922436ee50ffde9c549","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"628ceb91d0697cf1eaed4a17"},{"id":"wmc","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"628ceb91d0697cf1eaed4a18"},{"id":"anat","datatype":"58c33bcee13a50849b25879a","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"628ceb91d0697cf1eaed4a15"},{"id":"freesurfer","desc":"The 2009 freesurfer parcellation will be used for determining endpoint locations / identities for the purposes of the \"fingerprint\" plot (also, alternatively, as the color scheme selector for the streamline plot).","datatype":"58cb22c8e13a50849b25882e","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"628ceb91d0697cf1eaed4a16"},{"id":"parc","desc":"The desired parcellation to be used for labeled regions in the \"fingerprint\" plot (also, alternatively, as the color scheme selector for the streamline plot).  WILL OVERRIDE FREESURFER INPUT.","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"629faf947f60950a54d5bed7"}],"outputs":[{"id":"output","datatype":"5967b799b09297d8d831709e","datatype_tags":[],"datatype_tags_pass":"wmc","output_on_root":false,"files":null,"archive":true,"_id":"628ceba6d0697cf1eaed4d5e"}],"stats":{"resources":[],"examples":0,"success_rate":25.40983606557377,"users":2,"groups":3,"runtime_mean":6991695.677419355,"runtime_std":3642247.983751814,"requested":170},"removed":false,"contributors":[{"name":"Daniel Bullock","email":"iisdanbul@gmail.com","_id":"634a44c162f3d3800f130e95"}],"create_date":"2022-05-24T14:28:33.443Z","desc":"An app for generating multiple different kinds of figures from an input set of tracts (e.g as represented by a WMC object)","__v":317,"doi":"10.25663/brainlife.app.638","github_branch":"parcOverride","_canedit":true},{"_id":"594c649629ff5f002175469b","name":"HCP Pipeline","desc":"Run HCP Pipeline powered by BIDS app","avatar":null,"github":"soichih/app-bids-hcppipeline","github_branch":null,"config":{"t1":{"file_id":"t1","input_id":"t1","type":"input"},"t2":{"file_id":"t2","input_id":"t2","type":"input"}},"user_id":"1","removed":false,"_rate":0,"create_date":"2017-06-23T00:45:10.046Z","outputs":[{"datatype_tags":["hcp-pipeline"],"output_on_root":true,"_id":"594c694c29ff5f002175469c","id":"output","datatype":"59c3eae633fc1cf9ead71679","files":null,"archive":true}],"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"_id":"594c649629ff5f002175469a","id":"t1","datatype":"58c33bcee13a50849b25879a"},{"datatype_tags":[],"optional":false,"multi":false,"_id":"594c649629ff5f0021754699","id":"t2","datatype":"594c0325fa1d2e5a1f0beda5"}],"admins":["1"],"__v":14300,"tags":["pipeline"],"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a30c662f3d3800f11651c"}],"projects":["5a74ccd66ed91402ce400cc6"],"references":[],"stats":{"stars":0,"requested":26,"users":3,"success_rate":27.77777777777778,"serviceinfo":{"_id":"5d729e1f78356a109788b33f","counts":{"_id":"5e5c687c87cac773c0ab1ba0","failed":13,"finished":5,"removed":12,"requested":26,"running":21,"running_sync":0,"stop_requested":3},"success_rate":27.77777777777778,"users":3,"readme_status":"too short","runtime_mean":32793107.6,"runtime_std":43886625.308774926,"service":"soichih/app-bids-hcppipeline","__v":0},"gitinfo":{"desc":"Run HCP Pipeline powered by BIDS app","tags":["pipeline"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":32793107.6,"runtime_std":43886625.308774926,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a30c662f3d3800f11651b"}],"examples":0,"groups":1},"doi":"10.25663/bl.app.82","_canedit":true},{"_id":"5aabcf10f0b5260027e24ac8","name":"HCP Pipeline (FreeSurfer)","desc":"BIDS app for HCP FreeSurfer for BrainLife. Requires T1w_acpc_dc_restore.nii.gz, T1w_acpc_dc_restore_brain.nii.gz, and T2w_acpc_dc_restore.nii.gz from PreFS pipeline. (Please see https://github.com/Washington-University/HCPpipelines/wiki/v3.4.0-Release-Notes,-Installation,-and-Usage#structural-preprocessing for more information on HCP structural pipelines.)","citation":null,"github":"brainlife/app-hcp-freesurfer","github_branch":"master","config":{"hcp_freesurferpre":{"type":"input","file_id":"hcp_freesurferpre","input_id":"hcp_freesurferpre"}},"user_id":"121","create_date":"2018-03-16T14:05:04.737Z","removed":false,"_rate":0,"outputs":[{"datatype_tags":["v5"],"output_on_root":true,"archive":true,"_id":"5aabcf10f0b5260027e24ac9","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e","files":null}],"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5aabcf10f0b5260027e24aca","id":"hcp_freesurferpre","datatype":"5b3abb88d7b3f1e24e431321","desc":"Directory generated by BIDS HCP PreFreeSurfer app"}],"contributors":[{"name":null,"email":null,"_id":"634a324462f3d3800f116fe9"}],"tags":["pipeline"],"references":[],"admins":["16","41","146","121"],"projects":[],"__v":14243,"stats":{"stars":0,"requested":2,"users":2,"success_rate":0,"serviceinfo":{"_id":"5d729e1f78356a109788b357","counts":{"_id":"5e5c68a487cac75565ab1bcf","failed":11,"finished":14,"removed":22,"requested":31,"running":24,"running_sync":0,"stop_requested":1},"success_rate":56.00000000000001,"users":5,"readme_status":"no README.md","runtime_mean":33284964.57142857,"runtime_std":9051124.883766728,"service":"kathrynalpert/app-hcp-freesurfer","__v":0},"gitinfo":{"desc":"BIDS app for HCP FreeSurfer for BrainLife. Requires T1w_acpc_dc_restore.nii.gz, T1w_acpc_dc_restore_brain.nii.gz, and T2w_acpc_dc_restore.nii.gz from PreFS pipeline. (Please see https://github.com/Washington-University/HCPpipelines/wiki/v3.4.0-Release-Notes,-Installation,-and-Usage#structural-preprocessing for more information on HCP structural pipelines.)","tags":["pipeline"],"stats":{"stars":0},"contributors":[{"name":null,"email":null}]},"resources":[],"examples":0,"groups":2},"doi":"10.25663/bl.app.79","deprecated_by":"5ffee3dfaacf9e53e7a67093","_canedit":true},{"_id":"5aabd373f0b5260027e24acc","name":"HCP Pipeline (PostFreeSurfer)","desc":"BIDS app for HCP post-FreeSurfer for BrainLife. Outputs include surface topologies and features resampled onto the high (164k) dimensional atlas space as well as myelin mappings. (Please see https://github.com/Washington-University/HCPpipelines/wiki/v3.4.0-Release-Notes,-Installation,-and-Usage#structural-preprocessing for more information on HCP structural pipelines.)","citation":null,"github":"soichih/app-hcp-postfreesurfer","github_branch":"master","config":{"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"hcp_freesurferpre":{"type":"input","file_id":"hcp_freesurferpre","input_id":"hcp_freesurferpre"}},"user_id":"121","create_date":"2018-03-16T14:23:47.707Z","removed":false,"_rate":0,"outputs":[{"datatype_tags":["hcp-pipeline"],"output_on_root":true,"archive":true,"_id":"5aabd373f0b5260027e24acd","id":"HCP_postFS","datatype":"59c3eae633fc1cf9ead71679","files":null}],"inputs":[{"datatype_tags":["v5"],"optional":false,"multi":false,"advanced":false,"_id":"5aabd373f0b5260027e24ace","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e","desc":"FreeSurfer directories"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5aae7486d6cc2e088d83b91f","id":"hcp_freesurferpre","datatype":"5b3abb88d7b3f1e24e431321","desc":"Output from HCP PreFreeSurfer"}],"contributors":[{"name":null,"email":null,"_id":"634a324d62f3d3800f116feb"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a324d62f3d3800f116fec"}],"tags":[],"references":[],"admins":["16","41","146","121","1"],"projects":[],"__v":14245,"stats":{"stars":0,"requested":4,"users":2,"success_rate":25,"serviceinfo":{"_id":"5d729e1f78356a109788b381","counts":{"_id":"5e5c68a487cac7485cab1bd0","failed":16,"finished":18,"removed":31,"requested":49,"running":32,"running_sync":0,"stop_requested":0},"success_rate":52.94117647058824,"users":5,"readme_status":"no README.md","runtime_mean":2233282,"runtime_std":5226413.059791804,"service":"kathrynalpert/app-hcp-postfreesurfer","__v":0},"gitinfo":{"desc":"BIDS app for HCP post-FreeSurfer for BrainLife. Outputs include surface topologies and features resampled onto the high (164k) dimensional atlas space as well as myelin mappings. (Please see https://github.com/Washington-University/HCPpipelines/wiki/v3.4.0-Release-Notes,-Installation,-and-Usage#structural-preprocessing for more information on HCP structural pipelines.)","tags":["pipeline"],"stats":{"stars":0},"contributors":[{"name":null,"email":null}]},"runtime_mean":1402873,"runtime_std":0,"resources":[],"examples":0,"groups":3},"doi":"10.25663/bl.app.80","deprecated_by":"5ffee3dfaacf9e53e7a67093","_canedit":true},{"_id":"5aaae79df0b5260027e24abe","name":"HCP Pipeline (PreFreeSurfer)","desc":"BIDS app for HCP pre-FreeSurfer for BrainLife. Performs ACPC alignment, FNIRT-based brain extraction, and bias field correction. (Please see https://github.com/Washington-University/HCPpipelines/wiki/v3.4.0-Release-Notes,-Installation,-and-Usage#structural-preprocessing for more information on HCP structural pipelines.)","citation":null,"github":"brainlife/app-hcp-prefreesurfer","github_branch":"master","config":{"t1":{"type":"input","file_id":"t1","input_id":"t1"},"t2":{"type":"input","file_id":"t2","input_id":"t2"}},"user_id":"121","create_date":"2018-03-15T21:37:33.295Z","removed":false,"_rate":0,"outputs":[{"datatype_tags":[],"output_on_root":true,"archive":true,"_id":"5aaae79df0b5260027e24abf","id":"HCP_preFS","datatype":"5b3abb88d7b3f1e24e431321","files":null}],"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5aaae79df0b5260027e24ac1","id":"t1","datatype":"58c33bcee13a50849b25879a","desc":"T1 scan"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5aaae79df0b5260027e24ac0","id":"t2","datatype":"594c0325fa1d2e5a1f0beda5","desc":"T2 scan"}],"contributors":[{"name":null,"email":null,"_id":"634a323b62f3d3800f116fe7"}],"tags":["pipeline"],"references":[],"admins":["16","41","146","121","1"],"projects":[],"__v":14247,"stats":{"stars":0,"requested":45,"users":5,"success_rate":0,"serviceinfo":{"_id":"5d729e1f78356a109788b345","counts":{"_id":"5e5c68a387cac70d92ab1bce","failed":16,"finished":21,"removed":33,"requested":47,"running":31,"running_sync":0,"stop_requested":0},"success_rate":56.75675675675676,"users":7,"readme_status":"no README.md","runtime_mean":2623391.1428571427,"runtime_std":1104606.8054193282,"service":"kathrynalpert/app-hcp-prefreesurfer","__v":0},"gitinfo":{"desc":"BIDS app for HCP pre-FreeSurfer for BrainLife. Performs ACPC alignment, FNIRT-based brain extraction, and bias field correction. (Please see https://github.com/Washington-University/HCPpipelines/wiki/v3.4.0-Release-Notes,-Installation,-and-Usage#structural-preprocessing for more information on HCP structural pipelines.)","tags":["pipeline"],"stats":{"stars":0},"contributors":[{"name":null,"email":null}]},"resources":[],"examples":0,"groups":5},"doi":"10.25663/bl.app.78","deprecated_by":"5ffee3dfaacf9e53e7a67093","_canedit":true},{"_id":"6195b7a070ab03658d4c2af1","user_id":"283","projects":["5c645a8ef2362b00318046d4"],"admins":["283"],"name":"HCP Pipeline test app","github":"brainlife/app-hcp-pipeline","github_branch":"v4.1.3","desc_override":"testing volume and surface fMRI pipelines with fmaps","tags":["pipeline","preprocessing"],"config":{"t1":{"type":"input","file_id":"t1","input_id":"t1"},"t2":{"type":"input","file_id":"t2","input_id":"t2"},"fsin":{"type":"input","file_id":"output","input_id":"fsin"},"bold":{"type":"input","file_id":"bold","input_id":"fmri"},"events":{"type":"input","file_id":"events","input_id":"fmri"},"events_json":{"type":"input","file_id":"events_json","input_id":"fmri"},"sbref":{"type":"input","file_id":"sbref","input_id":"fmri"},"sbref_json":{"type":"input","file_id":"sbref_json","input_id":"fmri"},"physio":{"type":"input","file_id":"physio","input_id":"fmri"},"physio_json":{"type":"input","file_id":"physio_json","input_id":"fmri"},"phasediff":{"type":"input","file_id":"phasediff","input_id":"fmap"},"phasediff_json":{"type":"input","file_id":"phasediff_json","input_id":"fmap"},"magnitude":{"type":"input","file_id":"magnitude","input_id":"fmap"},"magnitude_json":{"type":"input","file_id":"magnitude_json","input_id":"fmap"},"magnitude1":{"type":"input","file_id":"magnitude1","input_id":"fmap"},"magnitude1_json":{"type":"input","file_id":"magnitude1_json","input_id":"fmap"},"magnitude2":{"type":"input","file_id":"magnitude2","input_id":"fmap"},"magnitude2_json":{"type":"input","file_id":"magnitude2_json","input_id":"fmap"},"fieldmap":{"type":"input","file_id":"fieldmap","input_id":"fmap"},"fieldmap_json":{"type":"input","file_id":"fieldmap_json","input_id":"fmap"},"phase1":{"type":"input","file_id":"phase1","input_id":"fmap"},"phase1_json":{"type":"input","file_id":"phase1_json","input_id":"fmap"},"phase2":{"type":"input","file_id":"phase2","input_id":"fmap"},"phase2_json":{"type":"input","file_id":"phase2_json","input_id":"fmap"},"epi1":{"type":"input","file_id":"epi1","input_id":"fmap"},"epi1_json":{"type":"input","file_id":"epi1_json","input_id":"fmap"},"epi2":{"type":"input","file_id":"epi2","input_id":"fmap"},"epi2_json":{"type":"input","file_id":"epi2_json","input_id":"fmap"},"stage":{"id":"stage","type":"string","placeholder":"","advanced":false,"desc":"","default":"PreFreeSurfer FreeSurfer PostFreeSurfer ","_order":2,"pid":0.21449848475057776},"processing_mode":{"id":"processing_mode","type":"enum","placeholder":"","advanced":false,"desc":"","default":"legacy","_order":3,"pid":0.9303832059326904,"options":[{"desc":"","label":"hcp","value":"hcp"},{"desc":"","label":"legacy","value":"legacy"},{"desc":"","label":"auto","value":"auto"}]},"notalcheck":{"id":"notalcheck","type":"boolean","placeholder":"","advanced":false,"desc":"","default":false,"_order":4,"pid":0.020288451555107168},"skipbidsvalidation":{"id":"skipbidsvalidation","type":"boolean","placeholder":"","advanced":false,"desc":"","default":true,"_order":5,"pid":0.9813342169596386},"gdcoeffs":{"id":"gdcoeffs","type":"string","placeholder":"copy paste text here","advanced":true,"desc":"the coeff.grad text file copy-pasted into this box","default":"","_order":6,"pid":0.3561034971512662,"optional":true,"multiline":true}},"inputs":[{"id":"t1","datatype":"58c33bcee13a50849b25879a","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"6195b7a070ab03658d4c2af2"},{"id":"t2","datatype":"594c0325fa1d2e5a1f0beda5","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"6195b7a070ab03658d4c2af3"},{"id":"fsin","datatype":"58cb22c8e13a50849b25882e","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"6195b7a070ab03658d4c2af4"},{"id":"fmri","datatype":"59b685a08e5d38b0b331ddc5","datatype_tags":[],"optional":false,"multi":true,"advanced":false,"_id":"6195b7a070ab03658d4c2af5"},{"id":"fmap","datatype":"5c390505f9109beac42b00df","datatype_tags":[],"optional":true,"multi":true,"advanced":false,"_id":"6195bdca70ab03658d4c89cd"}],"outputs":[{"id":"output","datatype":"5e767ddcde643b260e2a8a52","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"6195b7a070ab03658d4c2af6"}],"stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a432d62f3d3800f12ff2b"}],"success_rate":26.168224299065418,"users":10,"runtime_mean":29772992.39285714,"runtime_std":15462883.03244422,"requested":134,"examples":1,"groups":9},"removed":false,"contributors":[{"name":"Giulia Bertò","email":null,"_id":"634a432e62f3d3800f12ff2c"}],"create_date":"2021-11-18T02:17:04.870Z","desc":"brainlife wrapper for HCP Pipelines","__v":1331,"doi":"10.25663/brainlife.app.593","_canedit":true},{"_id":"5ffee3dfaacf9e53e7a67093","projects":[],"admins":["146"],"tags":["pipeline","preprocessing"],"removed":false,"stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3ea262f3d3800f12c22f"}],"success_rate":26.168224299065418,"users":10,"runtime_mean":29772992.39285714,"runtime_std":15462883.03244422,"requested":134,"examples":1,"groups":9},"config":{"t1":{"type":"input","file_id":"t1","input_id":"0"},"t2":{"type":"input","file_id":"t2","input_id":"1"},"fsin":{"type":"input","file_id":"output","input_id":"2"},"stage":{"id":"stage","type":"string","placeholder":"","advanced":false,"desc":"Which stages to run. Space separated list. (at the moment only the default [PreFreeSurfer FreeSurfer PostFreeSurfer] can be run). If you input a freesurfer folder, the FreeSurfer step will be skipped.","default":"PreFreeSurfer FreeSurfer PostFreeSurfer","_order":3,"pid":0.8801594474904992,"readonly":true},"processing_mode":{"id":"processing_mode","type":"enum","placeholder":"","advanced":false,"desc":"Control HCP-Pipeline mode. 'hcp' (HCPStyleData): require T2w and fieldmap modalities. 'legacy' (LegacyStyleData): always ignore T2w and fieldmaps. 'auto': use T2w and/or fieldmaps if available. (at the moment only 'legacy' can be run).","default":"legacy","_order":4,"pid":0.5237232075352651,"options":[{"desc":"(HCPStyleData): require T2w and fieldmap modalities","label":"hcp","value":"hcp"},{"desc":"(LegacyStyleData): always ignore T2w and fieldmaps","label":"legacy","value":"legacy"},{"desc":"use T2w and/or fieldmaps if available","label":"auto","value":"auto"}],"readonly":false},"notalcheck":{"id":"notalcheck","type":"boolean","placeholder":"","advanced":false,"desc":"If you are seeing \"ERROR: Talairach failed\", you might be able to work around this by setting this option so that freesurfer will skip this process. If you set this option, you will need to make sure that your image is well aligned to the 3 primary axis.","default":false,"_order":5,"pid":0.7739411151881834},"skipbidsvalidation":{"id":"skipbidsvalidation","type":"boolean","placeholder":"","advanced":false,"desc":"Skip the BIDS validation of input data. Try this option if your data is not BIDS compatible but you'd like to go ahead and process it through this App anyway.","default":false,"_order":6,"pid":0.8805468833745442}},"inputs":[{"id":"0","desc":"T1 image","datatype":"58c33bcee13a50849b25879a","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5fc668231828bc8d0d51fdb2"},{"id":"1","desc":"T2 image","datatype":"594c0325fa1d2e5a1f0beda5","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5fca0e3e1828bc31a052cea9"},{"id":"2","desc":"Freesurfer output. With this input, the FreeSurfer step will be skipped. WARNING: FreeSurfer 7.X is not currently supported due to poor quality surface reconstructions. Please provide a FreeSurfer 6.0 output. (NOTE: do not provide this input when using ABCD data)","datatype":"58cb22c8e13a50849b25882e","datatype_tags":["!v7"],"optional":true,"multi":false,"advanced":false,"_id":"603d2d9278e65d8487d2115f"}],"outputs":[{"id":"output","datatype":"5e767ddcde643b260e2a8a52","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5fc668231828bc23f151fdb3"}],"github_branch":"v4.1.3","github":"brainlife/app-hcp-pipeline","name":"HCP Pipelines - Structural preprocessing","user_id":"146","contributors":[{"name":"Giulia Bertò","email":null,"_id":"634a3ea262f3d3800f12c230"}],"desc":"brainlife wrapper for HCP Pipelines","__v":3541,"create_date":"2021-01-13T12:13:19.942Z","doi":"10.25663/brainlife.app.465","_canedit":true},{"_id":"5f592ced0c8f9597ac65ae41","stats":{"resources":[{"resource_id":"5ffc99da0df8ff7fc740c95a","name":"Bridges2 @ PSC (GPU-Shared)","_id":"634a3d0362f3d3800f129e8f"}],"success_rate":98.61594102100432,"users":14,"runtime_mean":292645.25,"runtime_std":1223669.2760744332,"requested":22557,"examples":2,"groups":20},"projects":[],"admins":["386"],"tags":["brainlifeio"],"removed":false,"config":{"t1":{"type":"input","file_id":"t1","input_id":"t1"},"tta":{"id":"tta","type":"boolean","placeholder":"","advanced":true,"desc":"Testing-time augmentation: mirror the input image on the three axes and infer the brain mask on the original & the three new images, taking the majority decision for each voxel for the final output.","default":false,"_order":2,"pid":0.5094717236928106},"mode":{"id":"mode","type":"enum","placeholder":"","advanced":true,"desc":"Inference mode","default":"fast","_order":3,"pid":0.1452274004630787,"options":[{"desc":"Uses five models to infer the brain mask, taking the majority decision for each voxel for the final output","label":"Accurate","value":"accurate"},{"desc":"Uses one model to infer the brain mask.","label":"Fast","value":"fast"}]}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5f592ced0c8f954ca565ae42","id":"t1","datatype":"58c33bcee13a50849b25879a"}],"outputs":[{"datatype_tags":["brain_extracted"],"output_on_root":false,"archive":true,"_id":"5f592ced0c8f95e7ec65ae43","id":"output","datatype":"58c33bcee13a50849b25879a","datatype_tags_pass":"t1","files":null},{"datatype_tags":["brain_mask"],"output_on_root":false,"archive":true,"_id":"60c282196e2f88020b84672c","id":"mask","datatype":"5a281aee2c214c9ba83ce620","datatype_tags_pass":null,"files":null}],"github_branch":"main","github":"anibalsolon/HD-BET_app","name":"HD-BET","user_id":"386","contributors":[{"name":"Anibal Sólon","email":"anibalsolon@gmail.com","_id":"634a3d0462f3d3800f129e90"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a3d0462f3d3800f129e91"}],"create_date":"2020-09-09T19:28:45.061Z","desc":"HD-BET is an automated brain extraction method for MRI using neural networks.","doi":"10.25663/brainlife.app.416","__v":4156,"_canedit":true},{"_id":"6117984ca5a04c6800fa6973","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a422c62f3d3800f12f404"}],"success_rate":0,"users":1,"requested":1,"examples":0,"groups":1},"projects":[],"admins":["1697"],"tags":[],"removed":false,"config":{"input":{"type":"input","file_id":"tsv","input_id":"input_timeseries"},"input_type":{"id":"input_type","type":"string","placeholder":"tsv or mat","advanced":false,"desc":"Type of input data (can be tsv or mat)","default":"tsv","_order":2,"pid":0.8455864347441377},"input_path":{"id":"input_path","type":"string","placeholder":"data/timeseries.tsv.gz","advanced":false,"desc":"Path to input data","default":"data/timeseries.tsv.gz","_order":3,"pid":0.004656367761597391},"metric":{"id":"metric","type":"string","placeholder":"Oinfo or dOinfo","advanced":false,"desc":"The metric you want to compute. Can be either Oinfo or dOinfo","default":"Oinfo","_order":4,"pid":0.04531199940871222},"higher_order":{"id":"higher_order","type":"boolean","placeholder":"","advanced":false,"desc":"Decides whether to adapt to code to enable higher orders without running out of memory. If set to true, generates combinations iteratively and can be retrieved using the combinatorial numbering system else it will precompute all of the combinations.","default":true,"_order":5,"pid":0.8925120715595704},"estimator":{"id":"estimator","type":"string","placeholder":"gcmi or lin_est","advanced":false,"desc":"Decides which estimator to use for the backend - gcmi or lin_est","default":"gcmi","_order":6,"pid":0.49839620738669554,"optional":true},"modelorder":{"id":"modelorder","type":"number","placeholder":"3","advanced":false,"desc":"model order, only required in dOinfo computation not Oinfo","default":3,"_order":7,"pid":0.5110414278011971,"optional":true},"maxsize":{"id":"maxsize","type":"number","placeholder":"4","advanced":false,"desc":"Max n-plet size to sweep till.","default":4,"_order":8,"pid":0.6074606400620639,"optional":true},"n_best":{"id":"n_best","type":"number","placeholder":"10","advanced":false,"desc":"Decides how many of the best redundancy and synergy combination outputs to save","default":10,"_order":9,"pid":0.43190050380564304,"optional":true},"nboot":{"id":"nboot","type":"number","placeholder":"100","advanced":false,"desc":"Number of bootstrap samples to be used, default 100","default":100,"_order":10,"pid":0.5097730591829407,"optional":true}},"inputs":[{"datatype_tags":["time series"],"optional":false,"multi":false,"advanced":false,"_id":"6117984ca5a04c711afa6974","id":"input_timeseries","datatype":"604a4553ebfe4559de3af944","desc":"The code takes data/timeseries.tsv.gz or data/ts.mat as input and outputs the pickle with redundancy and synergy metrics"}],"outputs":[{"datatype_tags":["raw"],"output_on_root":false,"archive":true,"_id":"6117984ca5a04cd62efa6975","id":"output","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null,"desc":"Output is a dict pickled and stored in the output directory. For more on how to read outputs please refer to read_outputs.py"}],"github_branch":"v1.0","github":"PranavMahajan25/HOI_toolbox","name":"HOI_toolbox","user_id":"1697","contributors":[{"name":"Pranav Mahajan","email":null,"_id":"634a422d62f3d3800f12f405"},{"name":"Daniele Marinazzo","email":"daniele.marinazzo@gmail.com","_id":"634a422d62f3d3800f12f406"}],"create_date":"2021-08-14T10:17:48.449Z","desc":"Higher-order interactions toolbox","__v":2063,"doi":"10.25663/brainlife.app.563","_canedit":true},{"_id":"60f206cfddc2dfbfa56726d1","projects":[],"admins":["16"],"tags":[],"removed":false,"stats":{"success_rate":90.91310101455669,"users":5,"runtime_mean":3144216.95,"runtime_std":7326976.712590997,"requested":3443,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a417a62f3d3800f12e2ff"}],"examples":0,"groups":7},"config":{"track":{"type":"input","file_id":"track","input_id":"track"},"wmc":{"type":"input","file_id":"classification","input_id":"wmc"},"rois":{"type":"input","file_id":"rois","input_id":"rois"},"roi_name":{"id":"roi_name","type":"string","placeholder":"","advanced":false,"desc":"name of the roi","default":"","_order":2,"pid":0.10044238333471012},"intersect_type":{"id":"intersect_type","type":"enum","placeholder":"","advanced":false,"desc":"Type of logic for keeping or removing streamlines","default":"","_order":3,"pid":0.907218410320076,"options":[{"desc":"Keep those that intersect with ROI","label":"and","value":"and"},{"desc":"Remove those that intersect with ROI","label":"not","value":"not"}]},"minimum_distance":{"id":"minimum_distance","type":"number","placeholder":"","advanced":false,"desc":"Minimum distance","default":0.87,"_order":4,"pid":0.7468768724844126}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e54514f5b9d90739a72d5fd","id":"track","datatype":"5907d922436ee50ffde9c549","desc":"The path to the track/tck datatype"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e54514f5b9d90841a72d5fe","id":"wmc","datatype":"5cc1d64c44947d8aea6b2d8b","desc":"The path to the classification.mat structure from the wmc datatype"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e54514f5b9d90643572d5ff","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9","desc":"The path to the rois datatype"}],"outputs":[{"datatype_tags":["intersected"],"output_on_root":false,"archive":true,"_id":"5e54514f5b9d903fe772d600","id":"wmc","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags_pass":"wmc","files":null,"desc":"The classification structure including a classification.mat structure that contains the streamline indices in the whole-brain tractogram."}],"github_branch":"master","github":"brainlife/app-intersect-tract-roi","name":"Intersect Tracts with ROI - deprecated","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a417b62f3d3800f12e300"},{"name":"Jan Kurzawski","email":null,"_id":"634a417b62f3d3800f12e301"},{"name":"Franco Pestilli","email":null,"_id":"634a417b62f3d3800f12e302"}],"desc":null,"__v":2286,"create_date":"2021-07-16T22:23:11.490Z","deprecated_by":"5e54514f5b9d90668672d5fc","doi":"10.25663/brainlife.app.545","_canedit":true},{"_id":"5fa48155e138ec0c3e4ea742","stats":{"resources":[],"examples":0},"projects":[],"admins":["1114"],"tags":[],"removed":false,"config":{"t1":{"type":"input","file_id":"t1","input_id":"t1"},"outres":{"id":"outres","type":"string","placeholder":"1 1 1","advanced":false,"desc":"","default":"1 1 1","_order":2,"pid":0.7403744170588455}},"inputs":[{"datatype_tags":["acpc_aligned"],"optional":false,"multi":false,"advanced":false,"_id":"5fa48155e138ec70ca4ea743","id":"t1","datatype":"58c33bcee13a50849b25879a"}],"outputs":[{"datatype_tags":["resliced"],"output_on_root":false,"archive":true,"_id":"5fa48155e138ec13214ea744","id":"out_dir","datatype":"58c33bcee13a50849b25879a","datatype_tags_pass":null,"files":null}],"github_branch":null,"github":"jkilmarx/app-template-python","name":"Justin Reslice T1w App","user_id":"1114","contributors":[{"name":"Franco Pestilli","email":null,"_id":"634a3e0e62f3d3800f12b9c6"}],"create_date":"2020-11-05T22:48:53.296Z","desc":"This is a template for a python-based brainlife.io/app","doi":"10.25663/brainlife.app.447","__v":3959,"_canedit":true},{"_id":"5a53b2be56e507002d1a9628","name":"Laplace Beltrami Spectrum: Eigenvalues Only","desc":"Application to calculate the Laplace Beltrami Spectrum and Eigenvectors using Matlab. ","citation":null,"avatar":null,"github":"kitchell/app-LBspectrum_matlab","github_branch":"singularity","config":{"surfaces":{"type":"input","file_id":"surfaces","input_id":"surfaces"},"save_eigenvectors":{"type":"boolean","placeholder":"","desc":"this app does not save the eigenvectors","default":false,"readonly":true,"id":"save_eigenvectors","pid":0.7345985087181655,"_order":2},"spectrum_size":{"default":50,"desc":"","placeholder":"","type":"number","id":"spectrum_size","pid":0.3342396995842589,"_order":3}},"user_id":"43","create_date":"2018-01-08T18:04:46.964Z","removed":false,"_rate":0,"outputs":[{"datatype_tags":[],"output_on_root":true,"_id":"5a53b2be56e507002d1a9629","id":"0","datatype":"59399b95436ee50ffdc08381","files":null,"datatype_tags_pass":"surfaces","archive":true}],"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"_id":"5a53b2be56e507002d1a962a","id":"surfaces","datatype":"59307a08436ee50ffd973278"}],"contributors":[{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a31d562f3d3800f11693f"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a31d562f3d3800f116940"},{"name":null,"email":null,"_id":"634a31d562f3d3800f116941"}],"tags":["analysis"],"references":[],"admins":["43"],"projects":[],"__v":14257,"desc_override":"Application to calculate the Laplace Beltrami Spectrum using matlab","stats":{"stars":1,"requested":17837,"users":5,"success_rate":85.35309503051438,"serviceinfo":{"_id":"5d729e1f78356a109788b36d","counts":{"_id":"5e5c689787cac75002ab1bc1","failed":2016,"finished":11747,"removed":16362,"requested":17836,"running":13648,"running_sync":0,"stop_requested":96},"success_rate":85.35203080723679,"users":4,"readme_status":"ok","runtime_mean":44779865.46,"runtime_std":43296674.825561434,"service":"kitchell/app-LBspectrum_matlab","__v":0},"gitinfo":{"desc":"Application to calculate the Laplace Beltrami Spectrum and Eigenvectors using Matlab. ","tags":["analysis"],"stats":{"stars":1},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":44726378.73,"runtime_std":43347998.284694776,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a31d462f3d3800f11693e"}],"examples":0,"groups":4},"doi":"10.25663/bl.app.97","_canedit":true},{"_id":"5a64d43c3a1b10004544482a","name":"Laplace Beltrami Spectrum: Eigenvalues and Eigenvectors","desc":"Application to calculate the Laplace Beltrami Spectrum and Eigenvectors using Matlab. ","citation":null,"avatar":null,"github":"kitchell/app-LBspectrum_matlab","github_branch":"singularity_evecs","config":{"surfaces":{"type":"input","file_id":"surfaces","input_id":"0"},"save_eigenvectors":{"readonly":true,"default":true,"desc":"this app saves the eigenvectors","placeholder":"","type":"boolean","id":"save_eigenvectors","pid":0.43272384973668876,"_order":2},"spectrum_size":{"default":50,"desc":"number of eigenvalues","placeholder":"","type":"number","id":"spectrum_size","pid":0.1181990295355535,"_order":3}},"user_id":"43","create_date":"2018-01-21T17:56:12.460Z","removed":false,"_rate":0,"outputs":[{"datatype_tags":[],"_id":"5a64d43c3a1b10004544482b","id":"0","datatype":"59399b95436ee50ffdc08381","files":null,"output_on_root":true,"archive":true},{"datatype_tags":["eigenvectors"],"_id":"5a6bea1c276f7400275bfbe6","id":"1","datatype":"59c3eae633fc1cf9ead71679","files":{"evecs":"eigenvectors.mat"},"output_on_root":true,"archive":true}],"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"_id":"5a64d43c3a1b10004544482c","id":"0","datatype":"59307a08436ee50ffd973278"}],"contributors":[{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a320262f3d3800f116aa6"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a320262f3d3800f116aa7"},{"name":null,"email":null,"_id":"634a320262f3d3800f116aa8"}],"tags":["analysis"],"references":[],"admins":["43"],"projects":[],"__v":14249,"stats":{"stars":1,"requested":17837,"users":5,"success_rate":85.35309503051438,"serviceinfo":{"_id":"5d729e1f78356a109788b36d","counts":{"_id":"5e5c689b87cac73326ab1bc6","failed":2016,"finished":11747,"removed":16362,"requested":17836,"running":13648,"running_sync":0,"stop_requested":96},"success_rate":85.35203080723679,"users":4,"readme_status":"ok","runtime_mean":44779865.46,"runtime_std":43296674.825561434,"service":"kitchell/app-LBspectrum_matlab","__v":0},"gitinfo":{"desc":"Application to calculate the Laplace Beltrami Spectrum and Eigenvectors using Matlab. ","tags":["analysis"],"stats":{"stars":1},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":44726378.73,"runtime_std":43347998.284694776,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a320262f3d3800f116aa5"}],"examples":0,"groups":4},"doi":"10.25663/bl.app.96","_canedit":true},{"_id":"5baa44b1d0be8b002776b8f7","projects":[],"admins":["16","41","146","1"],"tags":["analysis"],"removed":false,"config":{"track":{"type":"input","file_id":"track","input_id":"track"},"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"life_discretization":{"id":"life_discretization","type":"number","placeholder":"","desc":"","default":360,"_order":2,"pid":0.8780703050260601,"readonly":false},"num_iterations":{"id":"num_iterations","type":"number","placeholder":"","desc":"","default":100,"_order":3,"pid":0.8927958067588646}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5baa44b1d0be8b002776b8f9","id":"track","datatype":"5907d922436ee50ffde9c549"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5baa44b1d0be8b002776b8f8","id":"dwi","datatype":"58c33c5fe13a50849b25879b","desc":"you should feed preprocessed dwi. we will add preprocessed datatype tag once we have most preprocessed dwi tagged with \"preprocessed\"\n"}],"outputs":[{"datatype_tags":[],"output_on_root":true,"archive":true,"_id":"5baa44b1d0be8b002776b8fa","id":"fe","datatype":"58d15eaee13a50849b258844","datatype_tags_pass":"track","files":null}],"name":"LiFE (dwi)","avatar":"https://brainlife.io/images/app-logos/app-life.png","github":"brainlife/app-life","user_id":"1","references":[],"contributors":[{"name":"Franco Pestilli","email":null,"_id":"634a33e162f3d3800f118461"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a33e162f3d3800f118462"},{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a33e162f3d3800f118463"},{"name":"Ariel Rokem","email":"arokem@gmail.com","_id":"634a33e162f3d3800f118464"},{"name":"Steven O'Riley","email":null,"_id":"634a33e162f3d3800f118465"},{"name":"Brent McPherson","email":"bcmcpher@gmail.com","_id":"634a33e162f3d3800f118466"},{"name":"Brian Wandell","email":null,"_id":"634a33e162f3d3800f118467"}],"create_date":"2018-09-25T14:22:41.720Z","desc":"LiFE (Linear Fasicle Evaluation) predicts the measured diffusion signal using the orientation of the fascicles present in a connectome. LiFE uses the difference between the measured and predicted diffusion signals to measure prediction error. The connectome model prediction error is used to compute two metrics to evaluate the evidence supporting properties of the connectome.","stats":{"stars":1,"requested":11904,"users":36,"success_rate":87.22677595628416,"serviceinfo":{"_id":"5d729e1e78356a109788b1ff","counts":{"_id":"5e5c3dbc87cac7c863ab13d1","failed":126,"finished":188,"removed":197,"requested":340,"running":304,"running_sync":0,"stop_requested":8},"success_rate":59.87261146496815,"users":20,"readme_status":"ok","runtime_mean":4337540.8,"runtime_std":5967128.320774562,"service":"brainlife/app-life","__v":0},"gitinfo":{"desc":"LiFE (Linear Fasicle Evaluation) predicts the measured diffusion signal using the orientation of the fascicles present in a connectome. LiFE uses the difference between the measured and predicted diffusion signals to measure prediction error. The connectome model prediction error is used to compute two metrics to evaluate the evidence supporting properties of the connectome.","tags":["analysis"],"stats":{"stars":1},"contributors":[{"name":"Franco Pestilli","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Lindsey Kitchell","email":null},{"name":"Ariel Rokem","email":"arokem@gmail.com"},{"name":"Steven O'Riley","email":null},{"name":"Brent McPherson","email":null},{"name":"Brian Wandell","email":null}]},"runtime_mean":2739061.47,"runtime_std":3226896.4477694123,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a33e062f3d3800f118460"}],"examples":3,"groups":50},"doi":"10.25663/bl.app.104","__v":10404,"github_branch":"1.10","_canedit":true},{"_id":"604bbf6d38fe12172eef88b8","stats":{"resources":[],"success_rate":88.94952251023193,"users":1,"runtime_mean":33781361.54,"runtime_std":8658796.84671172,"requested":1341,"examples":4,"groups":3},"projects":["5fb1ccf37e8ecb8242aaca75","5a28e449e78f7477c8b8d9aa"],"admins":["19"],"tags":[],"removed":false,"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"sbref":{"type":"input","file_id":"sbref","input_id":"dwi"},"sbref_json":{"type":"input","file_id":"sbref_json","input_id":"dwi"},"anat":{"type":"input","file_id":"t1","input_id":"anat"},"track":{"type":"input","file_id":"track","input_id":"track"},"life_discretization":{"id":"life_discretization","type":"number","placeholder":"","advanced":false,"desc":"The dictionary size","default":360,"_order":2,"pid":0.6616409642200273,"min":360,"max":1080},"num_iterations":{"id":"num_iterations","type":"number","placeholder":"","advanced":false,"desc":"The number of iterations of LiFE to run.","default":100,"_order":3,"pid":0.5123307441353276,"min":50,"max":1500}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"604bbf6d38fe1259d1ef88b9","id":"dwi","datatype":"58c33c5fe13a50849b25879b","desc":"The preprocessed DWI used to generate the tractography."},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"604bbf6d38fe1281c9ef88ba","id":"anat","datatype":"58c33bcee13a50849b25879a","desc":"The anatomical scan the DWI was aligned to during preprocessing."},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"604bbf6d38fe12592fef88bb","id":"track","datatype":"5907d922436ee50ffde9c549","desc":"The tractography on which to perform LiFE evaluation."}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"604bbf6d38fe123b3cef88bc","id":"life","datatype":"58d15eaee13a50849b258844","datatype_tags_pass":null,"files":null,"desc":"The LiFE output for future analysis and plotting initial results."}],"github_branch":"master","github":"bcmcpher/app-life-dev","name":"LiFE - Multishell","desc_override":"This is a branch to the LiFE app that builds from my development fork","user_id":"19","contributors":[{"name":"Franco Pestilli","email":null,"_id":"634a3f9362f3d3800f12d0d2"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a3f9362f3d3800f12d0d3"},{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a3f9362f3d3800f12d0d4"},{"name":"Brent McPherson","email":"bcmcpher@gmail.com","_id":"634a3f9362f3d3800f12d0d5"},{"name":"Ariel Rokem","email":"arokem@gmail.com","_id":"634a3f9362f3d3800f12d0d6"},{"name":"Steven O'Riley","email":null,"_id":"634a3f9362f3d3800f12d0d7"},{"name":"Brian Wandell","email":null,"_id":"634a3f9362f3d3800f12d0d8"}],"create_date":"2021-03-12T19:22:21.564Z","desc":"dev version of life app for testing my fork","__v":3093,"doi":"10.25663/brainlife.app.491","_canedit":true},{"_id":"58d15dece13a50849b258842","user_id":"1","create_date":"2017-02-18T01:05:51.509Z","name":"LiFE with dtiInit","desc":"LiFE (Linear Fasicle Evaluation) predicts the measured diffusion signal using the orientation of the fascicles present in a connectome. LiFE uses the difference between the measured and predicted diffusion signals to measure prediction error. The connectome model prediction error is used to compute two metrics to evaluate the evidence supporting properties of the connectome.","github":"brainlife/app-life","admins":["16","41","146","43","45","1"],"config":{"track":{"type":"input","file_id":"track","input_id":"track"},"dtiinit":{"type":"input","file_id":"output","input_id":"dtiinit"},"life_discretization":{"default":360,"type":"integer","id":"life_discretization","pid":0.2975718321469645,"_order":2},"num_iterations":{"default":100,"type":"integer","id":"num_iterations","pid":0.00512521422343748,"_order":3}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"58fa822aaf44920021b9e0d5","id":"track","datatype":"5907d922436ee50ffde9c549"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5953b36ad9f0e20021415cac","id":"dtiinit","datatype":"58cb234be13a50849b25882f"}],"outputs":[{"datatype_tags":[],"output_on_root":true,"archive":true,"_id":"58fa822aaf44920021b9e0d8","id":"fe","datatype":"58d15eaee13a50849b258844","files":null,"datatype_tags_pass":"track"}],"__v":14340,"_rate":5,"tags":["analysis"],"removed":false,"github_branch":"1.10","avatar":"https://brainlife.io/images/app-logos/app-life.png","contributors":[{"name":"Franco Pestilli","email":null,"_id":"634a307362f3d3800f1161d8"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a307362f3d3800f1161d9"},{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a307362f3d3800f1161da"},{"name":"Ariel Rokem","email":"arokem@gmail.com","_id":"634a307362f3d3800f1161db"},{"name":"Steven O'Riley","email":null,"_id":"634a307362f3d3800f1161dc"},{"name":"Brent McPherson","email":"bcmcpher@gmail.com","_id":"634a307362f3d3800f1161dd"},{"name":"Brian Wandell","email":null,"_id":"634a307362f3d3800f1161de"}],"projects":[],"references":[],"stats":{"stars":1,"requested":11904,"users":36,"success_rate":87.22677595628416,"serviceinfo":{"_id":"5d729e1e78356a109788b1ff","counts":{"_id":"5e5c687387cac736e7ab1b96","failed":135,"finished":194,"removed":198,"requested":652,"running":362,"running_sync":0,"stop_requested":8},"success_rate":58.96656534954408,"users":20,"readme_status":"ok","runtime_mean":3978616.38,"runtime_std":5754398.031555204,"service":"brainlife/app-life","__v":0},"gitinfo":{"desc":"LiFE (Linear Fasicle Evaluation) predicts the measured diffusion signal using the orientation of the fascicles present in a connectome. LiFE uses the difference between the measured and predicted diffusion signals to measure prediction error. The connectome model prediction error is used to compute two metrics to evaluate the evidence supporting properties of the connectome.","tags":["analysis"],"stats":{"stars":1},"contributors":[{"name":"Franco Pestilli","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Lindsey Kitchell","email":null},{"name":"Ariel Rokem","email":"arokem@gmail.com"},{"name":"Steven O'Riley","email":null},{"name":"Brent McPherson","email":null},{"name":"Brian Wandell","email":null}]},"runtime_mean":2739061.47,"runtime_std":3226896.4477694123,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a307162f3d3800f1161d7"}],"examples":2,"groups":50},"doi":"10.25663/bl.app.1","_canedit":true},{"_id":"5fd0f921678a9161d04a61cc","stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3e5f62f3d3800f12baef"}],"success_rate":44.44444444444444,"users":2,"runtime_mean":10504277.5,"runtime_std":5887499.354512173,"requested":10,"examples":1,"groups":1},"projects":[],"admins":["16"],"tags":[],"removed":false,"config":{"movingImg":{"type":"input","file_id":"dwi","input_id":"moving"},"movingBvecs":{"type":"input","file_id":"bvecs","input_id":"moving"},"movingBvals":{"type":"input","file_id":"bvals","input_id":"moving"},"referenceImg":{"type":"input","file_id":"dwi","input_id":"reference"},"referenceBvecs":{"type":"input","file_id":"bvecs","input_id":"reference"},"referenceBvals":{"type":"input","file_id":"bvals","input_id":"reference"}},"inputs":[{"id":"moving","datatype":"58c33c5fe13a50849b25879b","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5fd0f921678a91537f4a61cd"},{"id":"reference","datatype":"58c33c5fe13a50849b25879b","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5fd0f921678a91bce94a61ce"}],"outputs":[{"id":"dwi","datatype":"58c33c5fe13a50849b25879b","datatype_tags":["aligned_dwi"],"datatype_tags_pass":"moving","output_on_root":false,"files":null,"archive":true,"_id":"5fd0f921678a9141324a61cf"}],"github_branch":"dwi-v1.0","github":"brainlife/app-fsl-flirt","name":"Linearly align DWI to another DWI with FSL Flirt","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3e6062f3d3800f12baf0"}],"create_date":"2020-12-09T16:19:45.475Z","desc":null,"__v":3795,"doi":"10.25663/brainlife.app.458","_canedit":true},{"_id":"5fa47f87e138ec5bfa4ea73d","stats":{"resources":[],"examples":0},"projects":[],"admins":["1116"],"tags":[],"removed":false,"config":{"t1":{"type":"input","file_id":"t1","input_id":"in001"},"outres":{"id":"outres","type":"string","placeholder":"1 1 1","advanced":false,"desc":"Desired out resolution of the t1w data. 3 integers/flow point numbers in millimeters. ","default":"1 1 1","_order":2,"pid":0.43015618216153184}},"inputs":[{"datatype_tags":["acpc_aligned"],"optional":false,"multi":false,"advanced":false,"_id":"5fa47f87e138ec4ac24ea73e","id":"in001","datatype":"58c33bcee13a50849b25879a","desc":"This t1w data will be resampled with the input \"outres\" resolution."}],"outputs":[{"datatype_tags":["acpc_aligned"],"output_on_root":false,"archive":true,"_id":"5fa47f87e138ec197a4ea73f","id":"out_dir","datatype":"58c33bcee13a50849b25879a","datatype_tags_pass":null,"files":null,"desc":"The resampled t1w file. "}],"github_branch":"master","github":"sunaguo/brainlife-app-test","name":"Little Test","desc_override":"This is a little test of registering an app on Brainlife as part of the brain imaging course. This app takes an ACPC aligned anat/t1w data and resamples it to the desired resolution. ","user_id":"1116","contributors":[{"name":"Franco Pestilli","email":null,"_id":"634a3e0562f3d3800f12b9c3"},{"name":null,"email":null,"_id":"634a3e0562f3d3800f12b9c4"}],"create_date":"2020-11-05T22:41:11.742Z","desc":"This is a template for a python-based brainlife.io/app","doi":"10.25663/brainlife.app.446","__v":3960,"_canedit":true},{"_id":"628b6054d0697cf1eaeb1972","user_id":"1348","projects":[],"admins":["1348"],"name":"MEG CTF to mne/raw ","github":"guiomar/app_ctf2mne","github_branch":"main","desc":null,"desc_override":"Converts MEG CTF data to MNE Raw (fif)","tags":[],"contributors":[{"name":"Julia Guiomar Niso Galán","email":null,"_id":"634a449362f3d3800f130e48"}],"config":{"ds":{"type":"input","file_id":"ds","input_id":"ctf1"},"headshape":{"type":"input","file_id":"headshape","input_id":"ctf1"},"channels":{"type":"input","file_id":"channels","input_id":"ctf1"},"coordsystem":{"type":"input","file_id":"coordsystem","input_id":"ctf1"},"events":{"type":"input","file_id":"events","input_id":"ctf1"},"events_json":{"type":"input","file_id":"events_json","input_id":"ctf1"}},"inputs":[{"id":"ctf1","datatype":"6000714baacf9e22a6a691c8","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"628b5c89d0697cf1eaeaffae"}],"outputs":[{"id":"out_dir","desc":"MNE Raw data in FIF format","datatype":"61893398e8be76b34cb9826e","datatype_tags":["meg"],"datatype_tags_pass":"ctf1","output_on_root":false,"files":null,"archive":true,"_id":"628b5c89d0697cf1eaeaffaf"}],"stats":{"resources":[],"examples":1,"success_rate":20,"users":1,"groups":1,"runtime_mean":11312,"runtime_std":0,"requested":5},"removed":false,"__v":314,"create_date":"2022-05-23T10:22:12.629Z","doi":"10.25663/brainlife.app.634","_canedit":true},{"_id":"628b5c89d0697cf1eaeaffad","user_id":"1348","projects":[],"admins":["1348"],"name":"MEG FIF to mne/raw","github":"guiomar/app_fif2mne","github_branch":"main","tags":[],"config":{"fif":{"type":"input","file_id":"fif","input_id":"fif1"},"channels":{"type":"input","file_id":"channels","input_id":"fif1"},"headshape":{"type":"input","file_id":"headshape","input_id":"fif1"},"coordsystem":{"type":"input","file_id":"coordsystem","input_id":"fif1"},"calibration":{"type":"input","file_id":"calibration","input_id":"fif1"},"crosstalk":{"type":"input","file_id":"crosstalk","input_id":"fif1"},"destination":{"type":"input","file_id":"destination","input_id":"fif1"},"events":{"type":"input","file_id":"events","input_id":"fif1"},"events_json":{"type":"input","file_id":"events_json","input_id":"fif1"}},"inputs":[{"id":"fif1","datatype":"6000737faacf9ee51fa691cb","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"628b5c89d0697cf1eaeaffae"}],"outputs":[{"id":"out_dir","desc":"MNE Raw data in FIF format","datatype":"61893398e8be76b34cb9826e","datatype_tags":["meg"],"datatype_tags_pass":"fif1","output_on_root":false,"files":null,"archive":true,"_id":"628b5c89d0697cf1eaeaffaf"}],"stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a448a62f3d3800f130e40"},{"resource_id":"5e309300e017b06c99948e0a","name":"stampede2(knl) @ TACC/UT","_id":"634a448a62f3d3800f130e41"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a448a62f3d3800f130e42"}],"examples":1,"success_rate":100,"users":2,"groups":2,"runtime_mean":28476.666666666668,"runtime_std":25018.42251000028,"requested":4},"removed":false,"contributors":[{"name":"Julia Guiomar Niso Galán","email":null,"_id":"634a448a62f3d3800f130e43"}],"create_date":"2022-05-23T10:06:01.751Z","desc":null,"__v":316,"desc_override":"Converts MEG FIF data to MNE Raw (fif)","doi":"10.25663/brainlife.app.632","_canedit":true},{"_id":"60da1330cdfdb5366b00d4f7","stats":{"resources":[],"success_rate":0,"users":1,"requested":1,"examples":0,"groups":1},"projects":["5d64733db29ac960ca2e797f","60d9d99dcdfdb51f4d00beca"],"admins":["1348"],"tags":[],"removed":false,"config":{"ds":{"type":"input","file_id":"ds","input_id":"meg"},"headshape":{"type":"input","file_id":"headshape","input_id":"meg"},"channels":{"type":"input","file_id":"channels","input_id":"meg"},"coordsystem":{"type":"input","file_id":"coordsystem","input_id":"meg"},"events":{"type":"input","file_id":"events","input_id":"meg"},"events_json":{"type":"input","file_id":"events_json","input_id":"meg"},"l_freq":{"id":"l_freq","type":"number","placeholder":"","advanced":false,"desc":"For FIR filters, the lower pass-band edge; for IIR filters, the lower cutoff frequency. If None the data are only low-passed.","default":null,"_order":2,"pid":0.7207224815042735,"optional":true},"h_freq":{"id":"h_freq","type":"number","placeholder":"","advanced":false,"desc":"","default":null,"_order":3,"pid":0.5313272904352931,"optional":true}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"60da1330cdfdb5430f00d4f8","id":"meg","datatype":"6000714baacf9e22a6a691c8"}],"outputs":[{"datatype_tags":["filtered"],"output_on_root":false,"archive":true,"_id":"60da1330cdfdb5ec9c00d4f9","id":"out_dir","datatype":"6000737faacf9ee51fa691cb","datatype_tags_pass":null,"files":null}],"github_branch":"main","github":"guiomar/app-meg-filter","name":"MEG filter [ctf]","user_id":"1348","contributors":[{"name":"Julia Guiomar Niso Galán","email":null,"_id":"634a413262f3d3800f12e1ce"}],"create_date":"2021-06-28T18:21:36.123Z","desc":null,"__v":2406,"doi":"10.25663/brainlife.app.537","_canedit":true},{"_id":"616e8787fc8eb9ab81ff9105","projects":[],"admins":["1348"],"tags":[],"removed":false,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a42ed62f3d3800f12fca3"}],"success_rate":100,"users":2,"runtime_mean":69827.83333333333,"runtime_std":130934.32642263833,"requested":36,"examples":1,"groups":4},"config":{"epo":{"type":"input","file_id":"epo","input_id":"raw01"},"decim":{"id":"decim","type":"number","placeholder":"","advanced":false,"desc":"The decimation factor: Increment for selecting every nth time slice.\n\nTIP: We can use the `decim` parameter to only take every nth time slice.\nThis speeds up the computation time. Note however that for low sampling rates and high decimation parameters, you might not detect \"peaky artifacts\" (with a fast timecourse) in your data. A low amount of decimation however is almost always beneficial at no decrease of accuracy.","default":1,"_order":2,"pid":0.46312600448027563,"optional":true,"min":1,"max":100,"readonly":null},"clean_epochs":{"id":"clean_epochs","type":"boolean","placeholder":"","advanced":false,"desc":"Return clean epochs (.fif file) in addition to the rejection dictionary","default":true,"_order":3,"pid":0.18277642516424952},"method":{"id":"method","type":"enum","placeholder":"","advanced":false,"desc":"","default":"autoreject","_order":4,"pid":0.2132965535985467,"options":[{"desc":"ar","label":"AutoReject","value":"autoreject"},{"desc":"rsc","label":"Ransac","value":"ransac"}]}},"inputs":[{"id":"raw01","datatype":"61797fc39538685e5db952b0","datatype_tags":["epochs"],"optional":false,"multi":false,"advanced":false,"_id":"616e7fd8fc8eb9dccfff8eab"}],"outputs":[{"id":"out_dir","desc":"Epoched data (equal length)","datatype":"61797fc39538685e5db952b0","datatype_tags":["clean_epochs"],"datatype_tags_pass":"raw01","output_on_root":false,"files":null,"archive":false,"_id":"616e7fd8fc8eb9b2b3ff8eac"},{"id":"our_dir","datatype":"59c3eae633fc1cf9ead71679","datatype_tags":["rejection_dict"],"datatype_tags_pass":"raw01","output_on_root":false,"files":null,"archive":true,"_id":"616e8787fc8eb96a29ff9108"},{"id":"out_figs","datatype":"59666a40b09297d8d8271dfc","datatype_tags":["rejection_log"],"datatype_tags_pass":"raw01","output_on_root":false,"files":null,"archive":false,"_id":"616e8970fc8eb96da5ff9208"}],"github_branch":"main","github":"guiomar/app-artifact-rejection","name":"MNE - Autoreject","desc_override":"MNE Artifact Rejection based on Autoreject\nhttps://autoreject.github.io\n\n[1] Mainak Jas, Denis Engemann, Federico Raimondo, Yousra Bekhti, and Alexandre Gramfort, \"Automated rejection and repair of bad trials in MEG/EEG.\" In 6th International Workshop on Pattern Recognition in Neuroimaging (PRNI), 2016.\n[2] Mainak Jas, Denis Engemann, Yousra Bekhti, Federico Raimondo, and Alexandre Gramfort. 2017. \"Autoreject: Automated artifact rejection for MEG and EEG data\". NeuroImage, 159, 417-429.","user_id":"1348","contributors":[{"name":"Julia Guiomar Niso Galán","email":null,"_id":"634a42ed62f3d3800f12fca4"}],"desc":null,"__v":1561,"create_date":"2021-10-19T08:53:27.821Z","doi":"10.25663/brainlife.app.585","_canedit":true},{"_id":"601456f6e7e1b76d05aa40fa","stats":{"resources":[],"success_rate":66.66666666666666,"users":2,"runtime_mean":1965100.034883721,"runtime_std":12293734.014614021,"requested":157,"examples":2,"groups":9},"projects":["5d64733db29ac960ca2e797f","6047933aebfe4578313a8fbe"],"admins":["1348"],"tags":[],"removed":false,"config":{"output":{"type":"input","file_id":"output","input_id":"raw"},"find_flat_channels_meg":{"id":"find_flat_channels_meg","type":"boolean","placeholder":"","advanced":true,"desc":"Auto-detect \"flat\" channels (i.e. those with unusually low variability) and mark them as bad.","default":false,"_order":2,"pid":0.3904052658861328},"find_noisy_channels_meg":{"id":"find_noisy_channels_meg","type":"boolean","placeholder":"","advanced":true,"desc":"Auto-detect \"noisy\" channels and mark them as bad.","default":false,"_order":3,"pid":0.7058195165961163},"use_maxwell_filter":{"id":"use_maxwell_filter","type":"boolean","placeholder":"","advanced":false,"desc":"Whether or not to use Maxwell filtering to preprocess the data.\n\nwarning:\n    If the data were recorded with internal active compensation (MaxShield),\n    they need to be run through Maxwell filter to avoid distortions.\n    Bad channels need to be set through BIDS channels.tsv and / or via the\n    ``find_flat_channels_meg`` and ``find_noisy_channels_meg`` options above\n    before applying Maxwell filter.","default":false,"_order":4,"pid":0.4877964551161601},"mf_st_duration":{"id":"mf_st_duration","type":"number","placeholder":"None","advanced":true,"desc":"There are two kinds of maxfiltering: SSS (signal space separation) and tSSS\n(temporal signal space separation)\n(see [Taulu et al., 2004](http://cds.cern.ch/record/709081/files/0401166.pdf)).\nIf not None, apply spatiotemporal SSS (tSSS) with specified buffer\nduration (in seconds). MaxFilter™'s default is 10.0 seconds in v2.2.\nSpatiotemporal SSS acts as implicitly as a high-pass filter where the\ncut-off frequency is 1/st_dur Hz. For this (and other) reasons, longer\nbuffers are generally better as long as your system can handle the\nhigher memory usage. To ensure that each window is processed\nidentically, choose a buffer length that divides evenly into your data.\nAny data at the trailing edge that doesn't fit evenly into a whole\nbuffer window will be lumped into the previous buffer.\n???+ info \"Good Practice / Advice\"\n    If you are interested in low frequency activity (<0.1Hz), avoid using\n    tSSS and set ``mf_st_duration`` to ``None``.\n    If you are interested in low frequency above 0.1 Hz, you can use the\n    default ``mf_st_duration`` to 10 s, meaning it acts like a 0.1 Hz\n    high-pass filter.\n???+ example \"Example\"\n    ```python\n    mf_st_duration = None\n    mf_st_duration = 10.  # to apply tSSS with 0.1Hz highpass filter.\n    ```","default":"","_order":5,"pid":0.5265374920824506,"optional":true},"mf_head_origin":{"id":"mf_head_origin","type":"string","placeholder":"auto","advanced":true,"desc":"``mf_head_origin`` : array-like, shape (3,) | 'auto'\nOrigin of internal and external multipolar moment space in meters.\nIf 'auto', it will be estimated from headshape points.\nIf automatic fitting fails (e.g., due to having too few digitization\npoints), consider separately calling the fitting function with different\noptions or specifying the origin manually.\n???+ example \"Example\"\n    ```python\n    mf_head_origin = 'auto'\n    ```","default":"","_order":6,"pid":0.29387836306713744,"optional":true},"mf_reference_run":{"id":"mf_reference_run","type":"string","placeholder":"None","advanced":true,"desc":"Despite all possible care to avoid movements in the MEG, the participant\nwill likely slowly drift down from the Dewar or slightly shift the head\naround in the course of the recording session. Hence, to take this into\naccount, we are realigning all data to a single position. For this, you need\nto define a reference run (typically the one in the middle of\nthe recording session).\nWhich run to take as the reference for adjusting the head position of all\nruns. If ``None``, pick the first run.\n???+ example \"Example\"\n    ```python\n    mf_reference_run = '01'  # Use run \"01\"\n    ```","default":"","_order":7,"pid":0.8951646863803813,"optional":true},"mf_cal_fname":{"id":"mf_cal_fname","type":"string","placeholder":"None","advanced":true,"desc":"warning:\n     This parameter should only be used for BIDS datasets that don't store\n     the fine-calibration file\n     [according to BIDS](https://bids-specification.readthedocs.io/en/stable/99-appendices/06-meg-file-formats.html#cross-talk-and-fine-calibration-files).\nPath to the Maxwell Filter calibration file. If None the recommended\nlocation is used.\n???+ example \"Example\"\n    ```python\n    mf_cal_fname = '/path/to/your/file/calibration_cal.dat'\n    ```","default":"","_order":8,"pid":0.8574912117513602,"optional":true},"mf_ctc_fname":{"id":"mf_ctc_fname","type":"string","placeholder":"None","advanced":true,"desc":"Path to the Maxwell Filter cross-talk file. If None the recommended\nlocation is used.\nwarning:\n     This parameter should only be used for BIDS datasets that don't store\n     the cross-talk file\n     [according to BIDS](https://bids-specification.readthedocs.io/en/stable/99-appendices/06-meg-file-formats.html#cross-talk-and-fine-calibration-files).\n???+ example \"Example\"\n    ```python\n    mf_ctc_fname = '/path/to/your/file/crosstalk_ct.fif'\n    ```","default":"","_order":9,"pid":0.04540116351576662,"optional":true},"fix_stim_artifact":{"id":"fix_stim_artifact","type":"boolean","placeholder":"","advanced":true,"desc":"Apply interpolation to fix stimulation artifact.\n???+ example \"Example\"\n    ```python\n    fix_stim_artifact = False","default":false,"_order":10,"pid":0.8110470882604063},"stim_artifact_tmin":{"id":"stim_artifact_tmin","type":"number","placeholder":"0","advanced":true,"desc":"Start time of the interpolation window in seconds.\n???+ example \"Example\"\n    ```python\n    stim_artifact_tmin = 0.  # on stim onset\n    ```","default":"","_order":11,"pid":0.8280926869369352,"optional":true},"stim_artifact_tmax":{"id":"stim_artifact_tmax","type":"number","placeholder":"0.01","advanced":true,"desc":"End time of the interpolation window in seconds.\n???+ example \"Example\"\n    ```python\n    stim_artifact_tmax = 0.01  # up to 10ms post-stimulation\n    ```","default":"","_order":12,"pid":0.6817910388311883,"optional":true},"l_freq":{"id":"l_freq","type":"number","placeholder":"","advanced":false,"desc":"The low-frequency cut-off in the highpass filtering step.\nKeep it None if no highpass filtering should be applied.\n","default":null,"_order":13,"pid":0.6536167695532672,"optional":true},"h_freq":{"id":"h_freq","type":"number","placeholder":"","advanced":false,"desc":"The high-frequency cut-off in the lowpass filtering step.\nKeep it None if no lowpass filtering should be applied.","default":"","_order":14,"pid":0.7794652513726246,"optional":true},"resample_sfreq":{"id":"resample_sfreq","type":"number","placeholder":"None","advanced":true,"desc":"Specifies at which sampling frequency the data should be resampled.\nIf None then no resampling will be done.\n???+ example \"Example\"\n    ```python\n    resample_sfreq = None  # no resampling\n    resample_sfreq = 500  # resample to 500Hz\n    ```","default":null,"_order":15,"pid":0.7692846841900088,"optional":true},"decim":{"id":"decim","type":"number","placeholder":"","advanced":false,"desc":"Says how much to decimate data at the epochs level.\nIt is typically an alternative to the `resample_sfreq` parameter that\ncan be used for resampling raw data. ``1`` means no decimation.\n???+ info \"Good Practice / Advice\"\n    Decimation requires to lowpass filtered the data to avoid aliasing.\n    Note that using decimation is much faster than resampling.\n???+ example \"Example\"\n    ```python\n    decim = 1  # no decimation\n    decim = 4  # decimate by 4 ie devide sampling frequency by 4\n    ```","default":1,"_order":16,"pid":0.05140089273360904,"optional":true},"reject":{"id":"reject","type":"string","placeholder":"","advanced":true,"desc":"The rejection limits to mark epochs as bads.\nThis allows to remove strong transient artifacts.\nIf you want to reject and retrieve blinks or ECG artifacts later, e.g.\nwith ICA, don't specify a value for the EOG and ECG channels, respectively\n(see examples below).\n\nPass ``None`` to avoid automated epoch rejection based on amplitude.\n\n???+ note \"Note\"\n    These numbers tend to vary between subjects.. You might want to consider\n    using the autoreject method by Jas et al. 2018.\n    See https://autoreject.github.io\n\n\n???+ example \"Example\"\n    ```python\n    reject = {'grad': 4000e-13, 'mag': 4e-12, 'eog': 150e-6}\n    reject = {'grad': 4000e-13, 'mag': 4e-12, 'eeg': 200e-6}\n    reject = None\n    ```","default":"","_order":17,"pid":0.9488563426420838,"optional":true},"reject_tmin":{"id":"reject_tmin","type":"number","placeholder":"","advanced":true,"desc":"Start of the time window used to reject epochs. If ``None``, the window will\nstart with the first time point.\n???+ example \"Example\"\n    ```python\n    reject_tmin = -0.1  # 100 ms before event onset.\n    ```","default":null,"_order":18,"pid":0.8302292461579134,"optional":true},"reject_tmax":{"id":"reject_tmax","type":"number","placeholder":"","advanced":true,"desc":"End of the time window used to reject epochs. If ``None``, the window will end\nwith the last time point.\n???+ example \"Example\"\n    ```python\n    reject_tmax = 0.3  # 300 ms after event onset.\n    ```","default":null,"_order":19,"pid":0.789797442777846,"optional":true},"rename_events":{"id":"rename_events","type":"string","placeholder":"","advanced":false,"desc":"A dictionary specifying which events in the BIDS dataset to rename upon\nloading, and before processing begins.\n\nPass an empty dictionary to not perform any renaming.\n\n???+ example \"Example\"\n    Rename ``audio_left`` in the BIDS dataset to ``audio/left`` in the\n    pipeline:\n    ```python\n    rename_events = {'audio_left': 'audio/left'}\n    ```","default":"","_order":20,"pid":0.7332952471156985,"optional":true},"on_rename_missing_events":{"id":"on_rename_missing_events","type":"enum","placeholder":"","advanced":true,"desc":"How to handle the situation where you specified an event to be renamed via\n``rename_events``, but this particular event is not present in the data. By\ndefault, we will raise an exception to avoid accidental mistakes due to typos;\nhowever, if you're sure what you're doing, you may change this to ``'warn'``\nto only get a warning instead.","default":"raise","_order":21,"pid":0.2691883245343034,"options":[{"desc":"","label":"warnL","value":"warn"},{"desc":"","label":"raiseL","value":"raise"}],"optional":true},"event_repeated":{"id":"event_repeated","type":"enum","placeholder":"","advanced":true,"desc":"How to handle repeated events. We call events \"repeated\" if more than one event\noccurred at the exact same time point. Currently, MNE-Python cannot handle\nthis situation gracefully when trying to create epochs, and will throw an\nerror. To only keep the event of that time point (\"first\" here referring to\nthe order that events appear in `*_events.tsv`), pass `'drop'`. You can also\nrequest to create a new type of event by merging repeated events by setting\nthis to `'merge'`.\n\nwarning:\n    The `'merge'` option is entirely untested in the MNE BIDS Pipeline as of\n    April 1st, 2021.\n\"\"\"","default":"error","_order":22,"pid":0.15030888262738806,"options":[{"desc":"error: xx","label":"errorL","value":"error"},{"desc":"drop: xx","label":"dropL","value":"drop"},{"desc":"merge: xx","label":"mergeL","value":"merge"}],"optional":true},"epochs_metadata_tmin":{"id":"epochs_metadata_tmin","type":"number","placeholder":"","advanced":true,"desc":"The beginning of the time window for metadata generation, in seconds, relative to the time-locked event of the respective epoch. This may be less than or larger than the epoch's first time point. If ``None``, use the first\ntime point of the epoch.","default":null,"_order":23,"pid":0.3493721974026913,"readonly":false,"optional":true},"epochs_metadata_tmax":{"id":"epochs_metadata_tmax","type":"number","placeholder":"","advanced":true,"desc":"Same as ``epochs_metadata_tmin``, but specifying the **end** of the time\nwindow for metadata generation.","default":null,"_order":24,"pid":0.7394506449852262,"optional":true},"epochs_metadata_keep_first":{"id":"epochs_metadata_keep_first","type":"string","placeholder":"","advanced":true,"desc":"Event groupings using hierarchical event descriptors (HEDs) for which to store\nthe time of the **first** occurrence of any event of this group in a new column\nwith the group name, and the **type** of that event in a column named after the\ngroup, but with a ``first_`` prefix. If ``None`` (default), no event\naggregation will take place and no new columns will be created.\n\n???+ example \"Example\"\n    Assume you have two response events types, ``response/left`` and\n    ``response/right``; in some trials, both responses occur, because the\n    participant pressed both buttons. Now, you want to keep the first response\n    only. To achieve this, set\n    ```python\n    epochs_metadata_keep_first = ['response']\n    ```\n    This will add two new columns to the metadata: ``response``, indicating\n    the **time** relative to the time-locked event; and ``first_response``,\n    depicting the **type** of event (``'left'`` or ``'right'``).\n\n    You may also specify a grouping for multiple event types:\n    ```python\n    epochs_metadata_keep_first=['response', 'stimulus'].\n    ```\n    This will add the columns ``response``, ``first_response``, ``stimulus``,\n    and ``first_stimulus``.","default":"","_order":25,"pid":0.985110060730897,"optional":true},"epochs_metadata_keep_last":{"id":"epochs_metadata_keep_last","type":"string","placeholder":"","advanced":true,"desc":"Same as ``epochs_metadata_keep_first``, but for keeping the **last**\noccurrence of matching event types. The columns indicating the event types\nwill be named with a ``last_`` instead of a ``first_`` prefix.","default":"","_order":26,"pid":0.6435013445420249,"optional":true},"conditions":{"id":"conditions","type":"string","placeholder":"","advanced":false,"desc":"The time-locked events based on which to create evoked responses.\nThis can either be name of the experimental condition as specified in the\nBIDS ``*_events.tsv`` file; or the name of condition *groups*, if the condition\nnames contain the (MNE-specific) group separator, ``/``. See the [Subselecting\nepochs tutorial](https://mne.tools/stable/auto_tutorials/epochs/plot_10_epochs_overview.html#subselecting-epochs)\nfor more information.\n\nPassing a dictionary allows to assign a name to map a complex condition name\n(value) to a more legible one (value).\n\n???+ example \"Example\"\n    Specifying conditions as lists of strings:\n    ```python\n    conditions = ['auditory/left', 'visual/left']\n    conditions = ['auditory/left', 'auditory/right']\n    conditions = ['auditory']  # All \"auditory\" conditions (left AND right)\n    conditions = ['auditory', 'visual']\n    conditions = ['left', 'right']\n    ```\n    Pass a dictionary to define a mapping:\n    ```python\n    conditions = {'simple_name': 'complex/condition/with_subconditions'}\n    conditions = {'correct': 'response/correct',\n                  'incorrect': 'response/incorrect'}","default":"","_order":27,"pid":0.6740091723250299,"optional":true,"multiline":false},"epochs_tmin":{"id":"epochs_tmin","type":"number","placeholder":"0.2","advanced":true,"desc":"The beginning of an epoch, relative to the respective event, in seconds.\n\n???+ example \"Example\"\n    ```python\n    epochs_tmin = -0.2  # 200 ms before event onset\n    ```","default":"","_order":28,"pid":0.6331940018866328,"optional":true},"epochs_tmax":{"id":"epochs_tmax","type":"number","placeholder":"0.5","advanced":true,"desc":"The end of an epoch, relative to the respective event, in seconds.\n???+ example \"Example\"\n    ```python\n    epochs_tmax = 0.5  # 500 ms after event onset\n    ```","default":"","_order":29,"pid":0.2229618888365733,"optional":true},"baseline":{"id":"baseline","type":"string","placeholder":"(None, 0)","advanced":true,"desc":"Specifies which time interval to use for baseline correction of epochs;\nif ``None``, no baseline correction is applied.\n\n???+ example \"Example\"\n    ```python\n    baseline = (None, 0)  # beginning of epoch until time point zero\n    ```","default":"","_order":30,"pid":0.33586316952197626,"optional":true},"contrasts":{"id":"contrasts","type":"string","placeholder":"","advanced":false,"desc":"The conditions to contrast via a subtraction of ERPs / ERFs. Each tuple\nin the list corresponds to one contrast. The condition names must be\nspecified in ``conditions`` above. Pass an empty list to avoid calculation\nof contrasts.\n\n???+ example \"Example\"\n    Contrast the \"left\" and the \"right\" conditions by calculating\n    ``left - right`` at every time point of the evoked responses:\n    ```python\n    conditions = ['left', 'right']\n    contrasts = [('left', 'right')]  # Note we pass a tuple inside the list!\n    ```\n\n    Contrast the \"left\" and the \"right\" conditions within the \"auditory\" and\n    the \"visual\" modality, and \"auditory\" vs \"visual\" regardless of side:\n    ```python\n    conditions = ['auditory/left', 'auditory/right',\n                  'visual/left', 'visual/right']\n    contrasts = [('auditory/left', 'auditory/right'),\n                 ('visual/left', 'visual/right'),\n                 ('auditory', 'visual')]\n    ```","default":"","_order":31,"pid":0.23890928978212822,"optional":true,"multiline":false},"ica_algorithm":{"id":"ica_algorithm","type":"enum","placeholder":"","advanced":true,"desc":"","default":"picard","_order":34,"pid":0.4423285710803092,"options":[{"desc":"","label":"","value":"picard"},{"desc":"","label":"","value":"fastica"},{"desc":"","label":"","value":"extended_infomax"}],"optional":true},"ica_l_freq":{"id":"ica_l_freq","type":"number","placeholder":"1","advanced":true,"desc":"The cutoff frequency of the high-pass filter to apply before running ICA.\nUsing a relatively high cutoff like 1 Hz will remove slow drifts from the\ndata, yielding improved ICA results. Must be set to 1 Hz or above.\n\nSet to ``None`` to not apply an additional high-pass filter.\n\nNote: Note\n      The filter will be applied to raw data which was already filtered\n      according to the ``l_freq`` and ``h_freq`` settings. After filtering, the\n      data will be epoched, and the epochs will be submitted to ICA.\n\n!!! info\n    The Pipeline will only allow you to perform ICA on data that has been\n    high-pass filtered with a 1 Hz cutoff or higher. This is a conscious,\n    opinionated (but partially data-driven) decision made by the developers.\n    If you have reason to challenge this behavior, please get in touch with\n    us so we can discuss.","default":"","_order":35,"pid":0.8304363947701766,"optional":true},"ica_max_iterations":{"id":"ica_max_iterations","type":"number","placeholder":"500","advanced":true,"desc":"Maximum number of iterations to decompose the data into independent\ncomponents. A low number means to finish earlier, but the consequence is\nthat the algorithm may not have finished converging. To ensure\nconvergence, pick a high number here (e.g. 3000); yet the algorithm will\nterminate as soon as it determines that is has successfully converged, and\nnot necessarily exhaust the maximum number of iterations. Note that the\ndefault of 200 seems to be sufficient for Picard in many datasets, because\nit converges quicker than the other algorithms; but e.g. for FastICA, this\nlimit may be too low to achieve convergence.","default":"","_order":36,"pid":0.37023962188211346,"optional":true},"ica_n_components":{"id":"ica_n_components","type":"number","placeholder":"0.8","advanced":true,"desc":"MNE conducts ICA as a sort of a two-step procedure: First, a PCA is run\non the data (trying to exclude zero-valued components in rank-deficient\ndata); and in the second step, the principal componenets are passed\nto the actual ICA. You can select how many of the total principal\ncomponents to pass to ICA – it can be all or just a subset. This determines\nhow many independent components to fit, and can be controlled via this\nsetting.\n\nIf int, specifies the number of principal components that are passed to the\nICA algorithm, which will be the number of independent components to\nfit. It must not be greater than the rank of your data (which is typically\nthe number of channels, but may be less in some cases).\n\nIf float between 0 and 1, all principal components with cumulative\nexplained variance less than the value specified here will be passed to\nICA.\n\nIf ``None``, **all** principal components will be used.\n\nThis setting may drastically alter the time required to compute ICA.","default":"","_order":37,"pid":0.9115109992684522,"optional":true},"ica_decim":{"id":"ica_decim","type":"number","placeholder":"","advanced":true,"desc":"The decimation parameter to compute ICA. If 5 it means\nthat 1 every 5 sample is used by ICA solver. The higher the faster\nit is to run but the less data you have to compute a good ICA. Set to\n``1`` or ``None`` to not perform any decimation.","default":null,"_order":38,"pid":0.4829611553261717,"optional":true},"ica_ctps_ecg_threshold":{"id":"ica_ctps_ecg_threshold","type":"number","placeholder":"0.1","advanced":true,"desc":"The threshold parameter passed to `find_bads_ecg` method.","default":"","_order":39,"pid":0.2909369307250559,"optional":true},"ica_eog_threshold":{"id":"ica_eog_threshold","type":"number","placeholder":"3","advanced":true,"desc":"The threshold to use during automated EOG classification. Lower values mean that more ICs will be identified as EOG-related. If too low, the false-alarm rate increases dramatically.","default":"","_order":40,"pid":0.5028495728537501,"optional":true},"process_er":{"id":"process_er","type":"boolean","placeholder":"","advanced":false,"desc":"Whether to apply the same pre-processing steps to the empty-room data as\nto the experimental data (up until including frequency filtering). This\nis required if you wish to use the empty-room recording to estimate noise\ncovariance (via ``noise_cov='emptyroom'``). The empty-room recording\ncorresponding to the processed experimental data will be retrieved\nautomatically.","default":false,"_order":41,"pid":0.35312590091297347},"eog_channels":{"id":"eog_channels","type":"string","placeholder":"","advanced":true,"desc":"Specify EOG channels to use, or create virtual EOG channels.\n\nAllows the specification of custom channel names that shall be used as\n(virtual) EOG channels. For example, say you recorded EEG **without** dedicated\nEOG electrodes, but with some EEG electrodes placed close to the eyes, e.g.\nFp1 and Fp2. These channels can be expected to have captured large quantities\nof ocular activity, and you might want to use them as \"virtual\" EOG channels,\nwhile also including them in the EEG analysis. By default, MNE won't know that\nthese channels are suitable for recovering EOG, and hence won't be able to\nperform tasks like automated blink removal, unless a \"true\" EOG sensor is\npresent in the data as well. Specifying channel names here allows MNE to find\nthe respective EOG signals based on these channels.\n\nYou can specify one or multiple channel names. Each will be treated as if it\nwere a dedicated EOG channel, without excluding it from any other analyses.\n\nIf ``None``, only actual EOG channels will be used for EOG recovery.\n\nIf there are multiple actual EOG channels in your data, and you only specify\na subset of them here, only this subset will be used during processing.\n\n???+ example \"Example\"\n    Treat ``Fp1`` as virtual EOG channel:\n    ```python\n    eog_channels = ['Fp1']\n    ```\n\n    Treat ``Fp1`` and ``Fp2`` as virtual EOG channels:\n    ```python\n    eog_channels = ['Fp1', 'Fp2']\n    ```","default":"None","_order":44,"pid":0.9249284187908736,"optional":true},"eeg_bipolar_channels":{"id":"eeg_bipolar_channels","type":"string","placeholder":"","advanced":true,"desc":"Combine two channels into a bipolar channel, whose signal is the **difference**\nbetween the two combined channels, and add it to the data.\nA typical use case is the combination of two EOG channels – for example, a\nleft and a right horizontal EOG – into a single, bipolar EOG channel. You need\nto pass a dictionary whose **keys** are the name of the new bipolar channel you\nwish to create, and whose **values** are tuples consisting of two strings: the\nname of the channel acting as anode and the name of the channel acting as\ncathode, i.e. `{'ch_name': ('anode', 'cathode')}`. You can request\nto construct more than one bipolar channel by specifying multiple key/value\npairs. See the examples below.\n\nCan also be `None` if you do not want to create bipolar channels.\n\nNote: Note\n    The channels used to create the bipolar channels are **not** automatically\n    dropped from the data. To drop channels, set `drop_channels`.\n\n???+ example \"Example\"\n    Combine the existing channels `HEOG_left` and `HEOG_right` into a new,\n    bipolar channel, `HEOG`:\n    ```python\n    eeg_add_bipolar_channels = {'HEOG': ('HEOG_left', 'HEOG_right')}\n    ```\n\n    Create two bipolar channels, `HEOG` and `VEOG`:\n    ```python\n    eeg_add_bipolar_channels = {'HEOG': ('HEOG_left', 'HEOG_right'),\n                                'VEOG': ('VEOG_lower', 'VEOG_upper')}\n    ```","default":"None","_order":45,"pid":0.3042072357491725,"optional":true,"multiline":true},"eeg_reference":{"id":"eeg_reference","type":"string","placeholder":"","advanced":true,"desc":"The EEG reference to use. If ``average``, will use the average reference,\ni.e. the average across all channels. If a string, must be the name of a single\nchannel. To use multiple channels as reference, set to a list of channel names.\n\n???+ example \"Example\"\n    Use the average reference:\n    ```python\n    eeg_reference = 'average'\n    ```\n\n    Use the `P9` channel as reference:\n    ```python\n    eeg_reference = 'P9'\n    ```\n\n    Use the average of the `P9` and `P10` channels as reference:\n    ```python\n    eeg_reference = ['P9', 'P10']\n    ```","default":"average","_order":46,"pid":0.5578293707456425,"optional":true},"eeg_template_montage":{"id":"eeg_template_montage","type":"string","placeholder":"","advanced":true,"desc":"In situations where you wish to process EEG data and no individual\ndigitization points (measured channel locations) are available, you can apply\na \"template\" montage. This means we will assume the EEG cap was placed\neither according to an international system like 10/20, or as suggested by\nthe cap manufacturers in their respective manual.\n\nPlease be aware that the actual cap placement most likely deviated somewhat\nfrom the template, and, therefore, source reconstruction may be impaired.\n\nIf ``None``, do not apply a template montage. If a string, must be the\nname of a built-in template montage in MNE-Python.\nYou can find an overview of supported template montages at\nhttps://mne.tools/stable/generated/mne.channels.make_standard_montage.html\n\n???+ example \"Example\"\n    Do not apply template montage:\n    ```python\n    eeg_template_montage = None\n    ```\n\n    Apply 64-channel Biosemi 10/20 template montage:\n    ```python\n    eeg_template_montage = 'biosemi64'\n    ```","default":"None","_order":47,"pid":0.9990074062577913,"optional":true},"drop_channels":{"id":"drop_channels","type":"string","placeholder":"","advanced":true,"desc":"Names of channels to remove from the data. This can be useful, for example,\nif you have added a new bipolar channel via `eeg_bipolar_channels` and now wish\nto remove the anode, cathode, or both.\n\n???+ example \"Example\"\n    Exclude channels `Fp1` and `Cz` from processing:\n    ```python\n    drop_channels = ['Fp1', 'Cz]\n    ```","default":"[]","_order":48,"pid":0.5116606969433019,"optional":true},"analyze_channels":{"id":"analyze_channels","type":"string","placeholder":"","advanced":true,"desc":"The names of the channels to analyze during ERP/ERF and time-frequency analysis\nsteps. For certain paradigms, e.g. EEG ERP research, it is common to contrain\nsensor-space analysis to only a few specific sensors. If `'all'`, do not\nexclude any channels (except for those selected for removal via the\n`drop_channels` setting). The constraint will be applied to all sensor-level\nanalyses after the preprocessing stage, but not to the preprocessing stage\nitself, nor to the source analysis stage.\n\n???+ example \"Example\"\n    Only use channel `Pz` for ERP, evoked contrasts, time-by-time\n    decoding, and time-frequency analysis:\n    ```python\n    analyze_channels = ['Pz']\n    ```","default":"'all'","_order":49,"pid":0.01933837737640598,"readonly":false,"optional":true},"spatial_filter":{"id":"spatial_filter","type":"enum","placeholder":"","advanced":false,"desc":"Whether to use a spatial filter to detect and remove artifacts. The BIDS\nPipeline offers the use of signal-space projection (SSP) and independent\ncomponent analysis (ICA).\n\nUse `'ssp'` for SSP, `'ica'` for ICA, and `None` if you do not wish to apply\na spatial filter for artifact removal.\n\nThe Pipeline will try to automatically discover EOG and ECG artifacts. For SSP,\nit will then produce projection vectors that remove (\"project out\") these\nartifacts from the data. For ICA, the independent components related to\nEOG and ECG activity will be omitted during the signal reconstruction step in\norder to remove the artifacts. The ICA procedure can be configured in various\nways using the configuration options you can find below.","default":"None","_order":50,"pid":0.49055602142397603,"options":[{"desc":"Use SSP","label":"use ssp","value":"ssp"},{"desc":"Use ICA","label":"use ica","value":"ica"},{"desc":"-","label":"none","value":"None"}],"optional":true},"ch_types":{"id":"ch_types","type":"string","placeholder":"","advanced":false,"desc":"The channel types to consider.\n\n!!! info\n    Currently, MEG and EEG data cannot be processed together.\n\n???+ example \"Example\"\n    ```python\n    # Use EEG channels:\n    ch_types = ['eeg']\n\n    # Use magnetometer and gradiometer MEG channels:\n    ch_types = ['mag', 'grad']\n\n    # Currently does not work and will raise an error message:\n    ch_types = ['meg', 'eeg']\n    ```","default":"['meg']","_order":51,"pid":0.3868647296983354},"data_type":{"id":"data_type","type":"string","placeholder":"","advanced":false,"desc":"The BIDS data type.\n\nFor MEG recordings, this will usually be 'meg'; and for EEG, 'eeg'.\nHowever, if your dataset contains simultaneous recordings of MEG and EEG,\nstored in a single file, you will typically need to set this to 'meg'.\nIf ``None``, we will assume that the data type matches the channel type.\n\n???+ example \"Example\"\n    The dataset contains simultaneous recordings of MEG and EEG, and we only\n    wish to process the EEG data, which is stored inside the MEG files:\n\n    ```python\n    ch_types = ['eeg']\n    data_type = 'eeg'\n    ```\n\n    The dataset contains simultaneous recordings of MEG and EEG, and we only\n    wish to process the gradiometer data:\n\n    ```python\n    ch_types = ['grad']\n    data_type = 'meg'  # or data_type = None\n    ```\n\n    The dataset contains only EEG data:\n\n    ```python\n    ch_types = ['eeg']\n    data_type = 'eeg'  # or data_type = None","default":"None","_order":52,"pid":0.060677422127352054}},"inputs":[{"datatype_tags":["bids"],"optional":false,"multi":false,"advanced":false,"_id":"601456f6e7e1b75e7daa40fb","id":"raw","datatype":"59c3eae633fc1cf9ead71679"}],"outputs":[{"datatype_tags":["mne","preprocessed"],"output_on_root":false,"archive":true,"_id":"601d4c6aab40ca02e94aa37a","id":"out_dir","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null,"desc":"output files"},{"datatype_tags":["mne","preprocessed"],"output_on_root":false,"archive":true,"_id":"6080790089df43d8ea662c37","id":"html_report","datatype":"5e56dc330f7fa604cc3cc291","datatype_tags_pass":null,"files":null}],"github_branch":"master","github":"guiomar/app-mne-1","name":"MNE-BIDS-Pipeline: [1] MEEG preprocessing","desc_override":"This Brainlife App imports and preprocess MEG (and EEG) files using MNE-BIDS-Pipeline (https://mne.tools/mne-bids-pipeline).","user_id":"1348","contributors":[{"name":"Julia Guiomar Niso Galán","email":null,"_id":"634a3ec662f3d3800f12c2df"},{"name":"Franco Pestilli","email":null,"_id":"634a3ec662f3d3800f12c2e0"}],"create_date":"2021-01-29T18:41:58.051Z","desc":null,"__v":3443,"doi":"10.25663/brainlife.app.469","avatar":"https://mne.tools/stable/_images/mne_logo.svg","_canedit":true},{"_id":"60a2ba4d03bcadb1d77ce874","projects":["5d64733db29ac960ca2e797f","6047933aebfe4578313a8fbe"],"admins":["1348"],"tags":[],"removed":false,"stats":{"resources":[],"success_rate":63.1578947368421,"users":1,"runtime_mean":24321,"runtime_std":13803.239988012476,"requested":19,"examples":1,"groups":1},"config":{"output":{"type":"input","file_id":"output","input_id":"raw"},"contrasts":{"id":"contrasts","type":"string","placeholder":"","advanced":false,"desc":"The conditions to contrast via a subtraction of ERPs / ERFs. Each tuple\nin the list corresponds to one contrast. The condition names must be\nspecified in ``conditions`` above. Pass an empty list to avoid calculation\nof contrasts.\n\n???+ example \"Example\"\n    Contrast the \"left\" and the \"right\" conditions by calculating\n    ``left - right`` at every time point of the evoked responses:\n    ```python\n    conditions = ['left', 'right']\n    contrasts = [('left', 'right')]  # Note we pass a tuple inside the list!\n    ```\n\n    Contrast the \"left\" and the \"right\" conditions within the \"auditory\" and\n    the \"visual\" modality, and \"auditory\" vs \"visual\" regardless of side:\n    ```python\n    conditions = ['auditory/left', 'auditory/right',\n                  'visual/left', 'visual/right']\n    contrasts = [('auditory/left', 'auditory/right'),\n                 ('visual/left', 'visual/right'),\n                 ('auditory', 'visual')]\n    ```","default":"","_order":31,"pid":0.3897575355295161,"optional":true,"multiline":false},"eog_channels":{"id":"eog_channels","type":"string","placeholder":"","advanced":true,"desc":"Specify EOG channels to use, or create virtual EOG channels.\n\nAllows the specification of custom channel names that shall be used as\n(virtual) EOG channels. For example, say you recorded EEG **without** dedicated\nEOG electrodes, but with some EEG electrodes placed close to the eyes, e.g.\nFp1 and Fp2. These channels can be expected to have captured large quantities\nof ocular activity, and you might want to use them as \"virtual\" EOG channels,\nwhile also including them in the EEG analysis. By default, MNE won't know that\nthese channels are suitable for recovering EOG, and hence won't be able to\nperform tasks like automated blink removal, unless a \"true\" EOG sensor is\npresent in the data as well. Specifying channel names here allows MNE to find\nthe respective EOG signals based on these channels.\n\nYou can specify one or multiple channel names. Each will be treated as if it\nwere a dedicated EOG channel, without excluding it from any other analyses.\n\nIf ``None``, only actual EOG channels will be used for EOG recovery.\n\nIf there are multiple actual EOG channels in your data, and you only specify\na subset of them here, only this subset will be used during processing.\n\n???+ example \"Example\"\n    Treat ``Fp1`` as virtual EOG channel:\n    ```python\n    eog_channels = ['Fp1']\n    ```\n\n    Treat ``Fp1`` and ``Fp2`` as virtual EOG channels:\n    ```python\n    eog_channels = ['Fp1', 'Fp2']\n    ```","default":"None","_order":44,"pid":0.5041770465800222,"optional":true},"eeg_bipolar_channels":{"id":"eeg_bipolar_channels","type":"string","placeholder":"","advanced":true,"desc":"Combine two channels into a bipolar channel, whose signal is the **difference**\nbetween the two combined channels, and add it to the data.\nA typical use case is the combination of two EOG channels – for example, a\nleft and a right horizontal EOG – into a single, bipolar EOG channel. You need\nto pass a dictionary whose **keys** are the name of the new bipolar channel you\nwish to create, and whose **values** are tuples consisting of two strings: the\nname of the channel acting as anode and the name of the channel acting as\ncathode, i.e. `{'ch_name': ('anode', 'cathode')}`. You can request\nto construct more than one bipolar channel by specifying multiple key/value\npairs. See the examples below.\n\nCan also be `None` if you do not want to create bipolar channels.\n\nNote: Note\n    The channels used to create the bipolar channels are **not** automatically\n    dropped from the data. To drop channels, set `drop_channels`.\n\n???+ example \"Example\"\n    Combine the existing channels `HEOG_left` and `HEOG_right` into a new,\n    bipolar channel, `HEOG`:\n    ```python\n    eeg_add_bipolar_channels = {'HEOG': ('HEOG_left', 'HEOG_right')}\n    ```\n\n    Create two bipolar channels, `HEOG` and `VEOG`:\n    ```python\n    eeg_add_bipolar_channels = {'HEOG': ('HEOG_left', 'HEOG_right'),\n                                'VEOG': ('VEOG_lower', 'VEOG_upper')}\n    ```","default":"None","_order":45,"pid":0.9444453223042498,"optional":true,"multiline":true},"eeg_reference":{"id":"eeg_reference","type":"string","placeholder":"","advanced":true,"desc":"The EEG reference to use. If ``average``, will use the average reference,\ni.e. the average across all channels. If a string, must be the name of a single\nchannel. To use multiple channels as reference, set to a list of channel names.\n\n???+ example \"Example\"\n    Use the average reference:\n    ```python\n    eeg_reference = 'average'\n    ```\n\n    Use the `P9` channel as reference:\n    ```python\n    eeg_reference = 'P9'\n    ```\n\n    Use the average of the `P9` and `P10` channels as reference:\n    ```python\n    eeg_reference = ['P9', 'P10']\n    ```","default":"average","_order":46,"pid":0.826828646711723,"optional":true},"eeg_template_montage":{"id":"eeg_template_montage","type":"string","placeholder":"","advanced":true,"desc":"In situations where you wish to process EEG data and no individual\ndigitization points (measured channel locations) are available, you can apply\na \"template\" montage. This means we will assume the EEG cap was placed\neither according to an international system like 10/20, or as suggested by\nthe cap manufacturers in their respective manual.\n\nPlease be aware that the actual cap placement most likely deviated somewhat\nfrom the template, and, therefore, source reconstruction may be impaired.\n\nIf ``None``, do not apply a template montage. If a string, must be the\nname of a built-in template montage in MNE-Python.\nYou can find an overview of supported template montages at\nhttps://mne.tools/stable/generated/mne.channels.make_standard_montage.html\n\n???+ example \"Example\"\n    Do not apply template montage:\n    ```python\n    eeg_template_montage = None\n    ```\n\n    Apply 64-channel Biosemi 10/20 template montage:\n    ```python\n    eeg_template_montage = 'biosemi64'\n    ```","default":"None","_order":47,"pid":0.4771627463588417,"optional":true},"drop_channels":{"id":"drop_channels","type":"string","placeholder":"","advanced":true,"desc":"Names of channels to remove from the data. This can be useful, for example,\nif you have added a new bipolar channel via `eeg_bipolar_channels` and now wish\nto remove the anode, cathode, or both.\n\n???+ example \"Example\"\n    Exclude channels `Fp1` and `Cz` from processing:\n    ```python\n    drop_channels = ['Fp1', 'Cz]\n    ```","default":"[]","_order":48,"pid":0.24908778818114907,"optional":true},"analyze_channels":{"id":"analyze_channels","type":"string","placeholder":"","advanced":true,"desc":"The names of the channels to analyze during ERP/ERF and time-frequency analysis\nsteps. For certain paradigms, e.g. EEG ERP research, it is common to contrain\nsensor-space analysis to only a few specific sensors. If `'all'`, do not\nexclude any channels (except for those selected for removal via the\n`drop_channels` setting). The constraint will be applied to all sensor-level\nanalyses after the preprocessing stage, but not to the preprocessing stage\nitself, nor to the source analysis stage.\n\n???+ example \"Example\"\n    Only use channel `Pz` for ERP, evoked contrasts, time-by-time\n    decoding, and time-frequency analysis:\n    ```python\n    analyze_channels = ['Pz']\n    ```","default":"'all'","_order":49,"pid":0.026796102639147223,"readonly":false,"optional":true},"ch_types":{"id":"ch_types","type":"string","placeholder":"","advanced":false,"desc":"The channel types to consider.\n\n!!! info\n    Currently, MEG and EEG data cannot be processed together.\n\n???+ example \"Example\"\n    ```python\n    # Use EEG channels:\n    ch_types = ['eeg']\n\n    # Use magnetometer and gradiometer MEG channels:\n    ch_types = ['mag', 'grad']\n\n    # Currently does not work and will raise an error message:\n    ch_types = ['meg', 'eeg']\n    ```","default":"['meg']","_order":51,"pid":0.9578638149667386},"data_type":{"id":"data_type","type":"string","placeholder":"","advanced":false,"desc":"The BIDS data type.\n\nFor MEG recordings, this will usually be 'meg'; and for EEG, 'eeg'.\nHowever, if your dataset contains simultaneous recordings of MEG and EEG,\nstored in a single file, you will typically need to set this to 'meg'.\nIf ``None``, we will assume that the data type matches the channel type.\n\n???+ example \"Example\"\n    The dataset contains simultaneous recordings of MEG and EEG, and we only\n    wish to process the EEG data, which is stored inside the MEG files:\n\n    ```python\n    ch_types = ['eeg']\n    data_type = 'eeg'\n    ```\n\n    The dataset contains simultaneous recordings of MEG and EEG, and we only\n    wish to process the gradiometer data:\n\n    ```python\n    ch_types = ['grad']\n    data_type = 'meg'  # or data_type = None\n    ```\n\n    The dataset contains only EEG data:\n\n    ```python\n    ch_types = ['eeg']\n    data_type = 'eeg'  # or data_type = None","default":"None","_order":52,"pid":0.9361649614423546},"decode":{"id":"decode","type":"boolean","placeholder":"","advanced":false,"desc":"Whether to perform decoding (MVPA) on the contrasts specified above as\n\"contrasts\". MVPA will be performed on the level of individual epochs.","default":true,"_order":53,"pid":0.027642855107560926},"decoding_metric":{"id":"decoding_metric","type":"string","placeholder":"","advanced":false,"desc":"The metric to use for cross-validation. It can be `'roc_auc'` or `'accuracy'`\nor any other metric supported by `scikit-learn`.\n\nWith AUC, chance level is the same regardless of class balance.\n","default":"'roc_auc'","_order":54,"pid":0.25661894947219843},"decoding_n_splits":{"id":"decoding_n_splits","type":"number","placeholder":"","advanced":false,"desc":"The number of folds (a.k.a. splits) to use in the cross-validation.\n","default":5,"_order":55,"pid":0.6237270097687619},"n_boot":{"id":"n_boot","type":"number","placeholder":"","advanced":false,"desc":"The number of bootstrap resamples when estimating the standard error and\nconfidence interval of the mean decoding score.\n","default":5000,"_order":56,"pid":0.5732357020394936},"interpolate_bads_grand_average":{"id":"interpolate_bads_grand_average","type":"boolean","placeholder":"","advanced":false,"desc":"Interpolate bad sensors in each dataset before calculating the grand\naverage. This parameter is passed to the `mne.grand_average` function via\nthe keyword argument `interpolate_bads`. It requires to have channel\nlocations set.\n\n???+ example \"Example\"\n    ```python\n    interpolate_bads_grand_average = True\n    ```","default":true,"_order":57,"pid":0.841779142786622},"time_frequency_conditions":{"id":"time_frequency_conditions","type":"string","placeholder":"","advanced":false,"desc":"The conditions to compute time-frequency decomposition on.\n\n???+ example \"Example\"\n    ```python\n    time_frequency_conditions = ['left', 'right']\n    ```","default":"[]","_order":58,"pid":0.8646252601234575,"optional":true}},"inputs":[{"datatype_tags":["mne","preprocessed"],"optional":false,"multi":false,"advanced":false,"_id":"601456f6e7e1b75e7daa40fb","id":"raw","datatype":"59c3eae633fc1cf9ead71679"}],"outputs":[{"datatype_tags":["mne","sensor"],"output_on_root":false,"archive":true,"_id":"601d4c6aab40ca02e94aa37a","id":"out_dir","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null,"desc":"output files"},{"datatype_tags":["mne","sensor"],"output_on_root":false,"archive":true,"_id":"6080790089df43d8ea662c37","id":"html_report","datatype":"5e56dc330f7fa604cc3cc291","datatype_tags_pass":null,"files":null}],"github_branch":"main","github":"guiomar/app-mne-2","name":"MNE-BIDS-Pipeline: [2] MEEG sensor analysis","desc_override":"This Brainlife App analyses MEG (and EEG) data at the sensor-level using MNE-BIDS-Pipeline (https://mne.tools/mne-bids-pipeline).","user_id":"1348","contributors":[{"name":"Julia Guiomar Niso Galán","email":null,"_id":"634a409762f3d3800f12d7b5"},{"name":"Franco Pestilli","email":null,"_id":"634a409762f3d3800f12d7b6"}],"desc":null,"__v":2633,"create_date":"2021-05-17T18:47:41.565Z","doi":"10.25663/brainlife.app.520","avatar":"https://mne.tools/stable/_images/mne_logo.svg","_canedit":true},{"_id":"60a3e9b403bcad29587d2f27","projects":["5d64733db29ac960ca2e797f","6047933aebfe4578313a8fbe"],"admins":["1348"],"tags":[],"removed":false,"stats":{"resources":[],"success_rate":100,"users":1,"runtime_mean":10735,"runtime_std":1000.6597823436296,"requested":5,"examples":1,"groups":1},"config":{"output":{"type":"input","file_id":"output","input_id":"raw"},"eog_channels":{"id":"eog_channels","type":"string","placeholder":"","advanced":true,"desc":"Specify EOG channels to use, or create virtual EOG channels.\n\nAllows the specification of custom channel names that shall be used as\n(virtual) EOG channels. For example, say you recorded EEG **without** dedicated\nEOG electrodes, but with some EEG electrodes placed close to the eyes, e.g.\nFp1 and Fp2. These channels can be expected to have captured large quantities\nof ocular activity, and you might want to use them as \"virtual\" EOG channels,\nwhile also including them in the EEG analysis. By default, MNE won't know that\nthese channels are suitable for recovering EOG, and hence won't be able to\nperform tasks like automated blink removal, unless a \"true\" EOG sensor is\npresent in the data as well. Specifying channel names here allows MNE to find\nthe respective EOG signals based on these channels.\n\nYou can specify one or multiple channel names. Each will be treated as if it\nwere a dedicated EOG channel, without excluding it from any other analyses.\n\nIf ``None``, only actual EOG channels will be used for EOG recovery.\n\nIf there are multiple actual EOG channels in your data, and you only specify\na subset of them here, only this subset will be used during processing.\n\n???+ example \"Example\"\n    Treat ``Fp1`` as virtual EOG channel:\n    ```python\n    eog_channels = ['Fp1']\n    ```\n\n    Treat ``Fp1`` and ``Fp2`` as virtual EOG channels:\n    ```python\n    eog_channels = ['Fp1', 'Fp2']\n    ```","default":"None","_order":44,"pid":0.5848359744344567,"optional":true},"eeg_bipolar_channels":{"id":"eeg_bipolar_channels","type":"string","placeholder":"","advanced":true,"desc":"Combine two channels into a bipolar channel, whose signal is the **difference**\nbetween the two combined channels, and add it to the data.\nA typical use case is the combination of two EOG channels – for example, a\nleft and a right horizontal EOG – into a single, bipolar EOG channel. You need\nto pass a dictionary whose **keys** are the name of the new bipolar channel you\nwish to create, and whose **values** are tuples consisting of two strings: the\nname of the channel acting as anode and the name of the channel acting as\ncathode, i.e. `{'ch_name': ('anode', 'cathode')}`. You can request\nto construct more than one bipolar channel by specifying multiple key/value\npairs. See the examples below.\n\nCan also be `None` if you do not want to create bipolar channels.\n\nNote: Note\n    The channels used to create the bipolar channels are **not** automatically\n    dropped from the data. To drop channels, set `drop_channels`.\n\n???+ example \"Example\"\n    Combine the existing channels `HEOG_left` and `HEOG_right` into a new,\n    bipolar channel, `HEOG`:\n    ```python\n    eeg_add_bipolar_channels = {'HEOG': ('HEOG_left', 'HEOG_right')}\n    ```\n\n    Create two bipolar channels, `HEOG` and `VEOG`:\n    ```python\n    eeg_add_bipolar_channels = {'HEOG': ('HEOG_left', 'HEOG_right'),\n                                'VEOG': ('VEOG_lower', 'VEOG_upper')}\n    ```","default":"None","_order":45,"pid":0.1838111608399673,"optional":true,"multiline":true},"eeg_reference":{"id":"eeg_reference","type":"string","placeholder":"","advanced":true,"desc":"The EEG reference to use. If ``average``, will use the average reference,\ni.e. the average across all channels. If a string, must be the name of a single\nchannel. To use multiple channels as reference, set to a list of channel names.\n\n???+ example \"Example\"\n    Use the average reference:\n    ```python\n    eeg_reference = 'average'\n    ```\n\n    Use the `P9` channel as reference:\n    ```python\n    eeg_reference = 'P9'\n    ```\n\n    Use the average of the `P9` and `P10` channels as reference:\n    ```python\n    eeg_reference = ['P9', 'P10']\n    ```","default":"average","_order":46,"pid":0.8658821459899722,"optional":true},"eeg_template_montage":{"id":"eeg_template_montage","type":"string","placeholder":"","advanced":true,"desc":"In situations where you wish to process EEG data and no individual\ndigitization points (measured channel locations) are available, you can apply\na \"template\" montage. This means we will assume the EEG cap was placed\neither according to an international system like 10/20, or as suggested by\nthe cap manufacturers in their respective manual.\n\nPlease be aware that the actual cap placement most likely deviated somewhat\nfrom the template, and, therefore, source reconstruction may be impaired.\n\nIf ``None``, do not apply a template montage. If a string, must be the\nname of a built-in template montage in MNE-Python.\nYou can find an overview of supported template montages at\nhttps://mne.tools/stable/generated/mne.channels.make_standard_montage.html\n\n???+ example \"Example\"\n    Do not apply template montage:\n    ```python\n    eeg_template_montage = None\n    ```\n\n    Apply 64-channel Biosemi 10/20 template montage:\n    ```python\n    eeg_template_montage = 'biosemi64'\n    ```","default":"None","_order":47,"pid":0.6483348532931946,"optional":true},"drop_channels":{"id":"drop_channels","type":"string","placeholder":"","advanced":true,"desc":"Names of channels to remove from the data. This can be useful, for example,\nif you have added a new bipolar channel via `eeg_bipolar_channels` and now wish\nto remove the anode, cathode, or both.\n\n???+ example \"Example\"\n    Exclude channels `Fp1` and `Cz` from processing:\n    ```python\n    drop_channels = ['Fp1', 'Cz]\n    ```","default":"[]","_order":48,"pid":0.13643977579313882,"optional":true},"analyze_channels":{"id":"analyze_channels","type":"string","placeholder":"","advanced":true,"desc":"The names of the channels to analyze during ERP/ERF and time-frequency analysis\nsteps. For certain paradigms, e.g. EEG ERP research, it is common to contrain\nsensor-space analysis to only a few specific sensors. If `'all'`, do not\nexclude any channels (except for those selected for removal via the\n`drop_channels` setting). The constraint will be applied to all sensor-level\nanalyses after the preprocessing stage, but not to the preprocessing stage\nitself, nor to the source analysis stage.\n\n???+ example \"Example\"\n    Only use channel `Pz` for ERP, evoked contrasts, time-by-time\n    decoding, and time-frequency analysis:\n    ```python\n    analyze_channels = ['Pz']\n    ```","default":"'all'","_order":49,"pid":0.7885142865518784,"readonly":false,"optional":true},"ch_types":{"id":"ch_types","type":"string","placeholder":"","advanced":false,"desc":"The channel types to consider.\n\n!!! info\n    Currently, MEG and EEG data cannot be processed together.\n\n???+ example \"Example\"\n    ```python\n    # Use EEG channels:\n    ch_types = ['eeg']\n\n    # Use magnetometer and gradiometer MEG channels:\n    ch_types = ['mag', 'grad']\n\n    # Currently does not work and will raise an error message:\n    ch_types = ['meg', 'eeg']\n    ```","default":"","_order":51,"pid":0.4545513108483159},"data_type":{"id":"data_type","type":"string","placeholder":"","advanced":false,"desc":"The BIDS data type.\n\nFor MEG recordings, this will usually be 'meg'; and for EEG, 'eeg'.\nHowever, if your dataset contains simultaneous recordings of MEG and EEG,\nstored in a single file, you will typically need to set this to 'meg'.\nIf ``None``, we will assume that the data type matches the channel type.\n\n???+ example \"Example\"\n    The dataset contains simultaneous recordings of MEG and EEG, and we only\n    wish to process the EEG data, which is stored inside the MEG files:\n\n    ```python\n    ch_types = ['eeg']\n    data_type = 'eeg'\n    ```\n\n    The dataset contains simultaneous recordings of MEG and EEG, and we only\n    wish to process the gradiometer data:\n\n    ```python\n    ch_types = ['grad']\n    data_type = 'meg'  # or data_type = None\n    ```\n\n    The dataset contains only EEG data:\n\n    ```python\n    ch_types = ['eeg']\n    data_type = 'eeg'  # or data_type = None","default":"None","_order":52,"pid":0.4101967269154967},"run_source_estimation":{"id":"run_source_estimation","type":"boolean","placeholder":"","advanced":false,"desc":"Whether to run source estimation processing steps if not explicitly requested.\n","default":true,"_order":53,"pid":0.1873442388454355},"bem_mri_images":{"id":"bem_mri_images","type":"string","placeholder":"","advanced":false,"desc":"Which types of MRI images to use when creating the BEM model.\nIf ``'FLASH'``, use FLASH MRI images, and raise an exception if they cannot be\nfound.\n\n???+ info \"Advice\"\n    It is recommended to use the FLASH images if available, as the quality\n    of the extracted BEM surfaces will be higher.\n\nIf ``'T1'``, create the BEM surfaces from the T1-weighted images using the\n``watershed`` algorithm.\n\nIf ``'auto'``, use FLASH images if available, and use the ``watershed``\nalgorithm with the T1-weighted images otherwise.\n\n*[FLASH MRI]: Fast low angle shot magnetic resonance imaging","default":"'auto'","_order":54,"pid":0.23814501354852236,"optional":true},"recreate_bem":{"id":"recreate_bem","type":"boolean","placeholder":"","advanced":false,"desc":"Whether to re-create the BEM surfaces, even if existing surfaces have been\nfound. If ``False``, the BEM surfaces are only created if they do not exist\nalready. ``True`` forces their recreation, overwriting existing BEM surfaces.","default":false,"_order":55,"pid":0.16673921725996987},"mri_t1_path_generator":{"id":"mri_t1_path_generator","type":"string","placeholder":"","advanced":true,"desc":"To perform source-level analyses, the Pipeline needs to generate a\ntransformation matrix that translates coordinates from MEG and EEG sensor\nspace to MRI space, and vice versa. This process, called \"coregistration\",\nrequires access to both, the electrophyisiological recordings as well as\nT1-weighted MRI images of the same participant. If both are stored within\nthe same session, the Pipeline (or, more specifically, MNE-BIDS) can find the\nrespective files automatically.\n\nHowever, in certain situations, this is not possible. Examples include:\n\n- MRI was conducted during a different session than the electrophysiological\n  recording.\n- MRI was conducted in a single session, while electrophysiological recordings\n  spanned across several sessions.\n- MRI and electrophysiological data are stored in separate BIDS datasets to\n  allow easier storage and distribution in certain situations.\n\nTo allow the Pipeline to find the correct MRI images and perform coregistration\nautomatically, we provide a \"hook\" that allows you to provide in a custom\nfunction whose output tells the Pipeline where to find the T1-weighted image.\n\nThe function is expected to accept a single parameter. The Pipeline will pass\na `BIDSPath` with the following parameters set based on the currently processed\nelectrophysiological data:\n\n- the subject ID, `BIDSPath.subject`\n- the experimental session, `BIDSPath.session`\n- the BIDS root, `BIDSPath.root`\n\nThis `BIDSPath` can then be modified – or an entirely new `BIDSPath` can be\ngenerated – and returned by the function, pointing to the T1-weighted image.\n\nNote: Note\n    The function accepts and returns a single `BIDSPath`.\n\n???+ example \"Example\"\n    The MRI session is different than the electrophysiological session:\n    ```python\n    def get_t1_from_meeg(bids_path):\n        bids_path.session = 'MRI'\n        return bids_path\n\n\n    mri_t1_path_generator = get_t1_from_meeg\n    ```\n\n    The MRI recording is stored in a different BIDS dataset than the\n    electrophysiological data:\n    ```python\n    def get_t1_from_meeg(bids_path):\n        bids_path.root = '/data/mri'\n        return bids_path\n\n\n    mri_t1_path_generator = get_t1_from_meeg\n    ```","default":"None","_order":56,"pid":0.8999543126866594,"optional":true},"spacing":{"id":"spacing","type":"string","placeholder":"","advanced":false,"desc":"The spacing to use. Can be ``'ico#'`` for a recursively subdivided\nicosahedron, ``'oct#'`` for a recursively subdivided octahedron,\n``'all'`` for all points, or an integer to use approximate\ndistance-based spacing (in mm). See (the respective MNE-Python documentation)\n[https://mne.tools/dev/overview/cookbook.html#setting-up-the-source-space]\nfor more info.","default":"'oct6'","_order":57,"pid":0.9932770755307266,"optional":true},"mindist":{"id":"mindist","type":"number","placeholder":"","advanced":false,"desc":"Exclude points closer than this distance (mm) to the bounding surface.\n","default":5,"_order":58,"pid":0.15608704982443877},"inverse_method":{"id":"inverse_method","type":"string","placeholder":"","advanced":false,"desc":"Use minimum norm, dSPM (default), sLORETA, or eLORETA to calculate the inverse\nsolution.","default":"'dSPM'","_order":59,"pid":0.21555013263701928},"noise_cov":{"id":"noise_cov","type":"string","placeholder":"","advanced":false,"desc":"Specify how to estimate the noise covariance matrix, which is used in\ninverse modeling.\n\nIf a tuple, it takes the form ``(tmin, tmax)`` with the time specified in\nseconds. If the first value of the tuple is ``None``, the considered\nperiod starts at the beginning of the epoch. If the second value of the\ntuple is ``None``, the considered period ends at the end of the epoch.\nThe default, ``(None, 0)``, includes the entire period before the event,\nwhich is typically the pre-stimulus period.\n\nIf ``emptyroom``, the noise covariance matrix will be estimated from an\nempty-room MEG recording. The empty-room recording will be automatically\nselected based on recording date and time.\n\nPlease note that when processing data that contains EEG channels, the noise\ncovariance can ONLY be estimated from the pre-stimulus period.\n\n???+ example \"Example\"\n    Use the period from start of the epoch until 100 ms before the experimental\n    event:\n    ```python\n    noise_cov = (None, -0.1)\n    ```\n\n    Use the time period from the experimental event until the end of the epoch:\n    ```python\n    noise_cov = (0, None)\n    ```\n\n    Use an empty-room recording:\n    ```python\n    noise_cov = 'emptyroom'\n    ```","default":"","_order":60,"pid":0.31944243615654977,"optional":true}},"inputs":[{"datatype_tags":["mne"],"optional":false,"multi":false,"advanced":false,"_id":"601456f6e7e1b75e7daa40fb","id":"raw","datatype":"59c3eae633fc1cf9ead71679"}],"outputs":[{"datatype_tags":["mne","sources"],"output_on_root":false,"archive":true,"_id":"601d4c6aab40ca02e94aa37a","id":"out_dir","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null,"desc":"output files"},{"datatype_tags":["mne","sources"],"output_on_root":false,"archive":true,"_id":"6080790089df43d8ea662c37","id":"html_report","datatype":"5e56dc330f7fa604cc3cc291","datatype_tags_pass":null,"files":null}],"github_branch":"main","github":"guiomar/app-mne-3","name":"MNE-BIDS-Pipeline: [3] MEEG source analysis","desc_override":"This Brainlife App analyses MEG (and EEG) data at the source-level using MNE-BIDS-Pipeline (https://mne.tools/mne-bids-pipeline).","user_id":"1348","contributors":[{"name":"Julia Guiomar Niso Galán","email":null,"_id":"634a40a062f3d3800f12d7d1"},{"name":"Franco Pestilli","email":null,"_id":"634a40a062f3d3800f12d7d2"}],"desc":null,"__v":2619,"create_date":"2021-05-18T16:22:12.270Z","doi":"10.25663/brainlife.app.521","avatar":"https://mne.tools/stable/_images/mne_logo.svg","_canedit":true},{"_id":"599a387b321afa0023e821ee","name":"MRIQC","desc":"Runs MRIQC pipeline (http://mriqc.readthedocs.io/en/stable/reports/smri.html) from Poldrack Lab on selected T1 anatomy.","github":"brainlife/app-mriqc","github_branch":"0.14.2","config":{"t1":{"type":"input","input_id":"t1","file_id":"t1"}},"user_id":"30","create_date":"2017-08-21T01:33:47.086Z","removed":false,"_rate":0,"outputs":[{"datatype_tags":["mriqc"],"output_on_root":true,"archive":true,"_id":"5c47df1cf0b03401b991bc16","id":"output","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":"t1","files":null}],"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"599a387b321afa0023e821ef","id":"t1","datatype":"58c33bcee13a50849b25879a"}],"tags":["qa"],"admins":["16","41","146","1"],"__v":14282,"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a310e62f3d3800f11663e"}],"projects":[],"references":[],"stats":{"stars":0,"requested":22159,"users":38,"success_rate":85.38623966215027,"serviceinfo":{"_id":"5d9a84741316625da551b273","counts":{"_id":"5e5c688387cac797e9ab1ba9","failed":2,"finished":31,"removed":32,"requested":39,"running":39,"running_sync":0,"stop_requested":6},"success_rate":93.93939393939394,"users":5,"readme_status":"too short","runtime_mean":8462088.741935484,"runtime_std":35030107.52730543,"service":"brainlife/app-mriqc","__v":0},"gitinfo":{"desc":"Runs MRIQC pipeline (http://mriqc.readthedocs.io/en/stable/reports/smri.html) from Poldrack Lab on selected T1 anatomy.","tags":["quality-check"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":14677481.19,"runtime_std":17178883.53095533,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a310d62f3d3800f11663c"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a310d62f3d3800f11663d"}],"examples":2,"groups":58},"doi":"10.25663/bl.app.52","_canedit":true},{"_id":"5baaa881d0be8b002776b954","projects":[],"admins":["16","41","146","43","1"],"tags":["tracking"],"removed":false,"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"lmax":{"id":"lmax","type":"number","placeholder":"Auto calculate the max lmax from number of bvecs","desc":"","default":null,"_order":2,"pid":0.06769878689219655,"optional":true},"fibers":{"id":"fibers","type":"number","placeholder":"","desc":"set the desired number of tracks. streamtrack will continue to generate tracks until this number of tracks have been selected and written to the output file.","default":500000,"_order":3,"pid":0.95537602338996},"fibers_max":{"id":"fibers_max","type":"number","placeholder":"","desc":"set the maximum number of tracks to generate. streamtrack will not generate more tracks than this number, even if the desired number of tracks hasn't yet been reached (default is 100 x fibers). Specifying zero for this option removes any limit - the algorithm will keep generating tracks until the number required has been reached","default":1000000,"_order":4,"pid":0.7911112528545792}},"inputs":[{"datatype_tags":["single_shell"],"optional":false,"multi":false,"advanced":false,"_id":"5baaa881d0be8b002776b956","id":"dwi","datatype":"58c33c5fe13a50849b25879b"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5baaa881d0be8b002776b955","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e"}],"outputs":[{"datatype_tags":["dt_stream"],"output_on_root":true,"archive":true,"_id":"5baaa881d0be8b002776b95a","id":"dt_stream","datatype":"5907d922436ee50ffde9c549","datatype_tags_pass":null,"files":{"track":"output.DT_STREAM.tck"}},{"datatype_tags":["sd_stream"],"output_on_root":true,"archive":true,"_id":"5baaa881d0be8b002776b959","id":"sd_stream","datatype":"5907d922436ee50ffde9c549","datatype_tags_pass":null,"files":{"track":"output.SD_STREAM.tck"}},{"datatype_tags":["sd_prob"],"output_on_root":true,"archive":true,"_id":"5baaa881d0be8b002776b958","id":"sd_prob","datatype":"5907d922436ee50ffde9c549","datatype_tags_pass":null,"files":{"track":"output.SD_PROB.tck"}},{"datatype_tags":[],"output_on_root":true,"archive":true,"_id":"5baaa881d0be8b002776b957","id":"recon","datatype":"5a04b08b2c214c9ba8033391","datatype_tags_pass":null,"files":null}],"name":"MRtrix2 Tracking (dwi)","github":"brainlife/app-tracking","user_id":"1","references":[],"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a33ea62f3d3800f11846a"},{"name":"Franco Pestilli","email":null,"_id":"634a33ea62f3d3800f11846b"},{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a33ea62f3d3800f11846c"},{"name":"Paolo Avesani","email":null,"_id":"634a33ea62f3d3800f11846d"}],"create_date":"2018-09-25T21:28:33.734Z","desc":"This service uses mrtrix 2.0 to track using three methods DTI-based Deterministic, CSD-based Probabilistic and Deterministic. It generates three separate tractograms (TCK), one for each algorithm.","stats":{"stars":0,"requested":772,"users":10,"success_rate":0,"serviceinfo":{"_id":"5d729e1f78356a109788b349","counts":{"_id":"5e5c3dbe87cac79585ab13d2","failed":131,"finished":611,"removed":924,"requested":1041,"running":913,"running_sync":0,"stop_requested":232},"success_rate":82.34501347708894,"users":25,"readme_status":"ok","runtime_mean":4947548.36,"runtime_std":4929968.26576655,"service":"brain-life/app-tracking","__v":0},"gitinfo":{"desc":"This service uses mrtrix 2.0 to track using three methods DTI-based Deterministic, CSD-based Probabilistic and Deterministic. It generates three separate tractograms (TCK), one for each algorithm.","tags":["tracking"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null},{"name":"Lindsey Kitchell","email":null},{"name":"Paolo Avesani","email":null}]},"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a33e962f3d3800f118469"}],"examples":0,"groups":12},"doi":"10.25663/bl.app.105","__v":10393,"github_branch":"1.5","_canedit":true},{"_id":"58cdf136e13a50849b258836","user_id":"1","create_date":"2017-02-18T01:05:51.509Z","name":"MRtrix2 Tracking with dtiInit","desc":"This service uses mrtrix 2.0 to track using three methods DTI-based Deterministic, CSD-based Probabilistic and Deterministic. It generates three separate tractograms (TCK), one for each algorithm.","github":"brainlife/app-tracking","admins":["16","41","146","43","1"],"config":{"dtiinit":{"type":"input","file_id":"output","input_id":"dwi"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"lmax":{"id":"lmax","type":"number","placeholder":"Auto calculate the max lmax from number of bvecs","desc":"","default":null,"_order":3,"pid":0.48278350833111894,"optional":true},"fibers":{"desc":"set the desired number of tracks. streamtrack will continue to generate tracks until this number of tracks have been selected and written to the output file.","default":500000,"type":"integer","id":"fibers","pid":0.07244878928011822,"_order":4},"fibers_max":{"desc":"set the maximum number of tracks to generate. streamtrack will not generate more tracks than this number, even if the desired number of tracks hasn't yet been reached (default is 100 x fibers). Specifying zero for this option removes any limit - the algorithm will keep generating tracks until the number required has been reached","default":1000000,"type":"integer","id":"fibers_max","pid":0.568087931936494,"_order":5}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"58fa821daf44920021b9e0d3","id":"dwi","datatype":"58cb234be13a50849b25882f"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"58fa821daf44920021b9e0d2","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e"}],"outputs":[{"datatype_tags":["dt_stream"],"output_on_root":true,"archive":true,"_id":"59526ba7d9f0e20021415ca8","id":"dt_stream","datatype":"5907d922436ee50ffde9c549","files":{"track":"output.DT_STREAM.tck"}},{"datatype_tags":["sd_stream"],"output_on_root":true,"archive":true,"_id":"59526ba7d9f0e20021415ca7","id":"sd_stream","datatype":"5907d922436ee50ffde9c549","files":{"track":"output.SD_STREAM.tck"}},{"datatype_tags":["sd_prob"],"output_on_root":true,"archive":true,"_id":"59526ba7d9f0e20021415ca6","id":"sd_prob","datatype":"5907d922436ee50ffde9c549","files":{"track":"output.SD_PROB.tck"}},{"datatype_tags":[],"output_on_root":true,"archive":true,"_id":"5a04d51dd76a2a002737e571","id":"recon","datatype":"5a04b08b2c214c9ba8033391","files":null}],"__v":14340,"tags":["tracking"],"removed":false,"projects":[],"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a306862f3d3800f1160b3"},{"name":"Franco Pestilli","email":null,"_id":"634a306862f3d3800f1160b4"},{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a306862f3d3800f1160b5"},{"name":"Paolo Avesani","email":null,"_id":"634a306862f3d3800f1160b6"}],"references":[],"github_branch":"1.5","stats":{"stars":0,"requested":772,"users":10,"success_rate":0,"serviceinfo":{"_id":"5d729e1f78356a109788b2a3","counts":{"_id":"5e5c687287cac70b79ab1b95","failed":98,"finished":0,"removed":146,"requested":168,"running":110,"running_sync":0,"stop_requested":18},"success_rate":0,"users":6,"readme_status":"ok","service":"brainlife/app-tracking","__v":0},"gitinfo":{"desc":"This service uses mrtrix 2.0 to track using three methods DTI-based Deterministic, CSD-based Probabilistic and Deterministic. It generates three separate tractograms (TCK), one for each algorithm.","tags":["tracking"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null},{"name":"Lindsey Kitchell","email":null},{"name":"Paolo Avesani","email":null}]},"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a306762f3d3800f1160b2"}],"examples":0,"groups":12},"doi":"10.25663/bl.app.59","_canedit":true},{"_id":"5eb99e5ee8e7ace25d8a9dcc","stats":{"success_rate":99.9341672152732,"users":4,"runtime_mean":540314.07,"runtime_std":987513.5825359696,"requested":1520,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3a7862f3d3800f123dd9"}],"examples":1,"groups":4},"projects":[],"admins":["16"],"tags":[],"removed":false,"config":{"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5eb99e5ee8e7ac48bb8a9dcd","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e","desc":"The path to the freesurfer datatype"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5eb99e5ee8e7acaecb8a9dce","id":"dwi","datatype":"58c33c5fe13a50849b25879b","desc":"The path to the DWI datatype"}],"outputs":[{"datatype_tags":["white_matter"],"output_on_root":false,"archive":true,"_id":"5eb99e5ee8e7ac576e8a9dcf","id":"mask","datatype":"5a281aee2c214c9ba83ce620","datatype_tags_pass":null,"files":null,"desc":"The white matter mask from freesurfer in DWI space"}],"github_branch":"v1.0","github":"brainlife/app-make-white-matter-mask-freesurfer","name":"Make white matter mask in dwi space from Freesurfer","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3a7962f3d3800f123dda"}],"create_date":"2020-05-11T18:50:06.753Z","desc":null,"doi":"10.25663/brainlife.app.340","__v":4897,"_canedit":true},{"_id":"5eb99e8ee8e7ac579b8a9e25","projects":[],"admins":["16"],"tags":[],"removed":false,"stats":{"success_rate":99.9341672152732,"users":4,"runtime_mean":540314.07,"runtime_std":987513.5825359696,"requested":1520,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3a8162f3d3800f123ddc"}],"examples":0,"groups":4},"config":{"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"dtiinit":{"type":"input","file_id":"output","input_id":"dtiinit"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5eb99e5ee8e7ac48bb8a9dcd","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e","desc":"The path to the freesurfer datatype"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5eb99e5ee8e7acaecb8a9dce","id":"dtiinit","datatype":"58cb234be13a50849b25882f","desc":"The path to the DTIINIT datatype"}],"outputs":[{"datatype_tags":["white_matter"],"output_on_root":false,"archive":true,"_id":"5eb99e5ee8e7ac576e8a9dcf","id":"mask","datatype":"5a281aee2c214c9ba83ce620","datatype_tags_pass":null,"files":null,"desc":"White matter mask in DWI space"}],"github_branch":"v1.0","github":"brainlife/app-make-white-matter-mask-freesurfer","name":"Make white matter mask in dwi space from Freesurfer (dtiinit)","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3a8162f3d3800f123ddd"}],"desc":null,"__v":4897,"create_date":"2020-05-11T18:50:54.366Z","doi":"10.25663/brainlife.app.341","_canedit":true},{"_id":"613a314e584a76610e429ad9","projects":[],"admins":["16"],"tags":["postprocessing"],"removed":false,"stats":{"requested":19020,"users":15,"success_rate":76.42612120442129,"gitinfo":{"desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","tags":["postprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"runtime_mean":966510.03,"runtime_std":1250650.5328230064,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a427562f3d3800f12f598"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a427562f3d3800f12f599"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"634a427562f3d3800f12f59a"}],"examples":1,"groups":42},"config":{"rois":{"type":"input","file_id":"rois","input_id":"rois"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"warp":{"type":"input","file_id":"warp","input_id":"warp"},"inverse_warp":{"type":"input","file_id":"inverse-warp","input_id":"warp"},"cortexmap":{"type":"input","file_id":"cortexmap","input_id":"cortexmap"},"fsurfparc":{"id":"fsurfparc","type":"enum","placeholder":"","advanced":true,"desc":"Parcellation from freesurfer wanted to for future stats","default":"aparc.a2009s","_order":2,"pid":0.32646233052631757,"options":[{"desc":"Desikan-Killiany","label":"aparc","value":"aparc"},{"desc":"Destrieux Atlas ","label":"aparc.a2009s","value":"aparc.a2009s"},{"desc":"DKT Atlas","label":"aparc.DKTatlas","value":"aparc.DKTatlas"}]}},"inputs":[{"datatype_tags":["tractEndpointDensity"],"optional":false,"multi":false,"advanced":false,"_id":"613a314e584a7662e2429adc","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c61bbe114027a01b14adc97","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e","desc":"The path to the top directory containing the output from Freesurfer"},{"datatype_tags":["!linear"],"optional":false,"multi":false,"advanced":false,"_id":"5eea8548d39ceb71bda090f1","id":"warp","datatype":"5bbfb28071454db2a890fbce","desc":"These files are needed to generate surfaces in template space (usually MNI). If you need to generate these files, please look at brainlife app FSL Anat. A version of this app not requiring this input is being generated"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"613a314e584a7612d4429adf","id":"cortexmap","datatype":"5c58aa5ef9109beac4b52f61","desc":"If cortexmap datatype has already been generated, update the datatype with the endpoint ROIs"}],"outputs":[{"datatype_tags":["endpoints"],"output_on_root":false,"archive":true,"_id":"5c61bbe114027a01b14adc99","id":"cortexmap","datatype":"5c58aa5ef9109beac4b52f61","datatype_tags_pass":"rois","files":null,"desc":"The cortexmap output, containing the surfaces and mapped data"},{"datatype_tags":["cortexmap_derivatives"],"output_on_root":false,"archive":true,"_id":"5eea8548d39ceb9bcca090f3","id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null,"desc":"A directory containing all of the derivatives generated. Useful for QA and debugging"}],"github_branch":"endpoints-v1.0","github":"brainlife/app-cortex-tissue-mapping","name":"Map tract endpoint ROIs to cortical surface for quantitative analyses","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a427562f3d3800f12f59b"},{"name":"Franco Pestilli","email":null,"_id":"634a427562f3d3800f12f59c"}],"desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","__v":1860,"avatar":"https://raw.githubusercontent.com/brainlife/app-cortex-tissue-mapping/v1.1/cropped_glasser_ndi.png","create_date":"2021-09-09T16:07:42.618Z","doi":"10.25663/brainlife.app.572","_canedit":true},{"_id":"5f66ac1fcfa365f139c92998","stats":{"resources":[],"success_rate":0,"users":4,"requested":7,"examples":0,"groups":4},"projects":[],"admins":["41"],"tags":[],"removed":false,"config":{"t1":{"type":"input","file_id":"t1","input_id":"t1"},"outres":{"id":"outres","type":"string","placeholder":"","advanced":false,"desc":"","default":"1,1,1","_order":2,"pid":0.639571941777006}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5f66ac1fcfa365d886c92999","id":"t1","datatype":"58c33bcee13a50849b25879a"}],"outputs":[],"github_branch":"BLAPPV1.0","github":"brainlife/app-template-matlab","name":"MatLab App Example","desc_override":"","user_id":"41","contributors":[{"name":"Franco Pestilli","email":null,"_id":"634a3d2062f3d3800f12a065"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a3d2062f3d3800f12a066"},{"name":"Giulia Bertò","email":null,"_id":"634a3d2062f3d3800f12a067"}],"create_date":"2020-09-20T01:10:55.086Z","desc":"brainlife.io template for a basic matlab app.","doi":"10.25663/brainlife.app.419","__v":4151,"_canedit":true},{"_id":"601d6301ab40ca0bcf4aac34","stats":{"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"634a3ed862f3d3800f12c53b"}],"success_rate":20,"users":1,"runtime_mean":237778,"runtime_std":0,"requested":5,"examples":0,"groups":2},"projects":["5d64733db29ac960ca2e797f"],"admins":["704"],"tags":[],"removed":false,"config":{"network":{"type":"input","file_id":"network","input_id":"inputnet"},"threshold":{"id":"threshold","type":"number","placeholder":"weight","advanced":true,"desc":"Minimum weight to be considered","default":0,"_order":2,"pid":0.8351343381630135,"min":0,"max":1}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"601d6301ab40ca6f024aac35","id":"inputnet","datatype":"5ed0352de3f453b13b267dae","desc":"Input Network"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"601d6301ab40ca35024aac36","id":"output","datatype":"5ed53b69da664506f88e6df9","datatype_tags_pass":"inputnet","files":null,"desc":"Strength distribution as a pdf"}],"github_branch":"master","github":"filipinascimento/bl-network-template-matlab","name":"Matlab example","user_id":"704","contributors":[{"name":"Filipi Nascimento Silva","email":"filipinascimento@gmail.com","_id":"634a3ed862f3d3800f12c53c"}],"create_date":"2021-02-05T15:23:45.640Z","desc":"Example template for network analyses using matlab inside brainlife.","__v":3350,"doi":"10.25663/brainlife.app.471","_canedit":true},{"_id":"616d6d2dfc8eb97193ff219a","projects":[],"admins":["1348"],"tags":[],"removed":false,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a42db62f3d3800f12fbd7"}],"success_rate":99.44405837387075,"users":1,"runtime_mean":13363.22,"runtime_std":3411.0580926744706,"requested":8689,"examples":3,"groups":4},"config":{"psd":{"type":"input","file_id":"psd","input_id":"psd01"},"fmin":{"id":"fmin","type":"number","placeholder":"","advanced":false,"desc":"Fmin of frequency range for mean amplitude of PSD values","default":8,"_order":2,"pid":0.025399344687791814},"fmax":{"id":"fmax","type":"number","placeholder":"","advanced":false,"desc":"Fmax of frequency range for mean amplitude of PSD values","default":12,"_order":3,"pid":0.29749450440329306}},"inputs":[{"id":"psd01","datatype":"60c7669e7657d98fe5e128b1","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"60d08509cdfdb5a6b4ff56d2"}],"outputs":[{"id":"out_dir","datatype":"60c7669e7657d98fe5e128b1","datatype_tags":["peak_ampl"],"datatype_tags_pass":"psd01","output_on_root":false,"files":null,"archive":true,"_id":"610aec03548c0430535c6144"},{"id":"out_figs","datatype":"59c3eae633fc1cf9ead71679","datatype_tags":["peak_ampl"],"datatype_tags_pass":"psd01","output_on_root":false,"files":null,"archive":false,"_id":"60b895780ad40dae6bca61fe"}],"github_branch":"main","github":"guiomar/app-peak-amplitude","name":"Mean amplitude of PSD data","user_id":"1348","contributors":[{"name":"Julia Guiomar Niso Galán","email":null,"_id":"634a42db62f3d3800f12fbd8"}],"desc":null,"__v":1563,"desc_override":"Compute the mean amplitude of a frequency range of PSD values\n","create_date":"2021-10-18T12:48:45.503Z","doi":"10.25663/brainlife.app.583","_canedit":true},{"_id":"5e9d0d59f1745daf82f68016","stats":{"success_rate":55.55555555555556,"users":1,"runtime_mean":77038.2,"runtime_std":21479.396038064013,"requested":9,"resources":[],"examples":0,"groups":1},"projects":["5e5672430f7fa65e1d3c9621"],"admins":["16","126"],"tags":[],"removed":false,"config":{"rois":{"type":"input","file_id":"rois","input_id":"rois"},"rois1":{"id":"rois1","type":"string","placeholder":"","advanced":false,"desc":"currently the extension in front of the first set of rois from the combine ROIS app (i.e. rois1-ROI*.nii.gz)","default":"rois1","_order":2,"pid":0.16287769858433876},"rois2":{"id":"rois2","type":"string","placeholder":"","advanced":false,"desc":"currently the extension in front of the second set of rois from the combine ROIS app (i.e. rois2-ROI*.nii.gz)","default":"rois2","_order":3,"pid":0.6281177113657677},"roi1outname":{"id":"roi1outname","type":"string","placeholder":"","advanced":false,"desc":"outname you would like for first set. example: set this to hippocampal to name the merging of the first set of rois to ROIhippocampal.nii.gz","default":"","_order":4,"pid":0.9886701649069256},"roi2outname":{"id":"roi2outname","type":"string","placeholder":"","advanced":false,"desc":"outname you would like for first set. example: set this to parietal to name the merging of the first set of rois to ROIparietal.nii.gz","default":"","_order":5,"pid":0.1904093536644096}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e9d0d59f1745d2ee1f68017","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9"}],"outputs":[{"datatype_tags":["merged"],"output_on_root":false,"archive":true,"_id":"5e9d0d59f1745d7aa8f68018","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9","datatype_tags_pass":null,"files":null}],"github_branch":"master","github":"brainlife/app-merge-rois","name":"Merge ROIs (Sophia)","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a39b762f3d3800f122b7e"}],"create_date":"2020-04-20T02:47:53.220Z","desc":null,"doi":"10.25663/brainlife.app.316","__v":5063,"desc_override":"This app is purely designed for the way the data is currently set up after the Combine ROIs app is ran. This will not work in almost any other use case. Will amend later for more general use.","_canedit":true},{"_id":"62213ffe5d8ab5d5f02166c3","user_id":"16","projects":[],"admins":["16"],"name":"Merge Tractography (tcks) together with MRTrix3","github":"bacaron/app-mergeTCK","github_branch":"gttwo-tck","desc":"Merge multiple TCK files into one TCK file.","desc_override":"This app will merge multiple tcks together using MRTrix 3","tags":[],"contributors":[{"name":"Sophia Vinci-Booher","email":null,"_id":"634a43bc62f3d3800f130761"},{"name":"Brad Caron","email":null,"_id":"634a43bc62f3d3800f130762"},{"name":"Franco Pestilli","email":null,"_id":"634a43bc62f3d3800f130763"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a43bc62f3d3800f130764"}],"config":{"track":{"type":"input","file_id":"track","input_id":"track"}},"inputs":[{"id":"track","datatype":"5907d922436ee50ffde9c549","datatype_tags":[],"optional":false,"multi":true,"advanced":false,"_id":"5e8b5ae6952fef95327b097f"}],"outputs":[{"id":"track","datatype":"5907d922436ee50ffde9c549","datatype_tags":["merged"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5e8b5ae6952fefa7857b0981"}],"stats":{"success_rate":92.1875,"users":6,"runtime_mean":382453.65,"runtime_std":709015.1417774004,"requested":834,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a43bb62f3d3800f13075f"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a43bb62f3d3800f130760"}],"examples":0,"groups":12},"removed":false,"__v":751,"create_date":"2022-03-03T22:23:58.401Z","doi":"10.25663/brainlife.app.608","_canedit":true},{"_id":"5e8b98eb952fef035f7b1653","projects":[],"admins":["16"],"tags":[],"removed":false,"stats":{"success_rate":92.1875,"users":6,"runtime_mean":382453.65,"runtime_std":709015.1417774004,"requested":834,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a394662f3d3800f121926"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a394662f3d3800f121927"}],"examples":5,"groups":12},"config":{"track1":{"type":"input","file_id":"track","input_id":"track1"},"track2":{"type":"input","file_id":"track","input_id":"track2"}},"inputs":[{"id":"track1","datatype":"5907d922436ee50ffde9c549","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e8b5ae6952fef95327b097f"},{"id":"track2","datatype":"5907d922436ee50ffde9c549","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e8b5ae6952fef1f647b0980"}],"outputs":[{"id":"track","datatype":"5907d922436ee50ffde9c549","datatype_tags":["merged"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5e8b5ae6952fefa7857b0981"}],"github_branch":"two-tck","github":"bacaron/app-mergeTCK","name":"Merge Tractography (tcks) together with MRTrix3 (Two Tcks)","desc_override":"This is copy of the mergeTCK BL app (https://doi.org/10.25663/brainlife.app.219) modified to take two tractograms as input. This is a temporary workaround for the lack of functionality for multi-input datatypes in brainilfe Pipelines.","user_id":"16","contributors":[{"name":"Sophia Vinci-Booher","email":null,"_id":"634a394762f3d3800f121928"},{"name":"Brad Caron","email":null,"_id":"634a394762f3d3800f121929"},{"name":"Franco Pestilli","email":null,"_id":"634a394762f3d3800f12192a"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a394762f3d3800f12192b"}],"desc":"Merge multiple TCK files into one TCK file.","__v":5177,"create_date":"2020-04-06T21:02:35.591Z","doi":"10.25663/brainlife.app.305","_canedit":true},{"_id":"60f5b833b991116f18b47913","projects":[],"admins":["16"],"tags":[],"removed":false,"stats":{"success_rate":83.41739577972209,"users":25,"runtime_mean":799849.04,"runtime_std":1408516.1455727932,"requested":12365,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a418c62f3d3800f12e355"},{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a418c62f3d3800f12e356"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a418c62f3d3800f12e357"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"634a418c62f3d3800f12e358"}],"examples":1,"groups":53},"config":{"rois":{"type":"input","file_id":"rois","input_id":"rois"},"label":{"type":"input","file_id":"label","input_id":"rois"},"mergeROIsL":{"id":"mergeROIsL","type":"string","placeholder":"","advanced":false,"desc":"Left hemisphere ROI numbers you would like to merge into a single ROI\n\nif the user wants to merge multiple ROIs made from subset of all ROIs, enter each set of ROIs on a new line. the mergename field will need to correspond to these pairings (i.e. same number of pairings per left and right hemisphere, same order)\n\nex. freesurfer-11111 freesurfer-111112\nfreesurfer-11113 freesurfer-11114 freesurfer-11115","default":"","_order":9,"pid":0.2588495439847467,"optional":true,"multiline":true},"mergeROIsR":{"id":"mergeROIsR","type":"string","placeholder":"","advanced":false,"desc":"Right hemisphere ROI numbers you would like to merge into a single ROI.\n\nif the user wants to merge multiple ROIs made from subset of all ROIs, enter each set of ROIs on a new line. the mergename field will need to correspond to these pairings (i.e. same number of pairings per left and right hemisphere, same order)\n\nex. freesurfer-12111 freesurfer-121112\nfreesurfer-12113 freesurfer-12114 freesurfer-12115","default":"","_order":10,"pid":0.6092888232738956,"optional":true,"multiline":true},"mergename":{"id":"mergename","type":"string","placeholder":"","advanced":false,"desc":"Name for the ROI that you would like merged. The output will be in the following format: ROI${mergename}.nii.gz\n\nif the user wants to merge multiple ROIs made from subset of all ROIs, enter each name on a line. this field will need to correspond to these pairings (i.e. same number of pairings per left and right hemisphere, same order)\n\nex. test1\ntest2","default":"","_order":11,"pid":0.5757907977654704,"optional":true,"multiline":true}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"60f5b833b99111f475b47917","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9"}],"outputs":[{"datatype_tags":["merged"],"output_on_root":false,"archive":true,"_id":"5dbb497c8aeeeeb60bf34e7c","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9","datatype_tags_pass":"rois","files":null,"desc":"The directory containing all of the ROIs"},{"datatype_tags":["merged"],"output_on_root":false,"archive":false,"_id":"60f5b833b9911170dbb47919","id":"parc","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags_pass":"rois","files":null}],"github_branch":"merge-rois-v1.0","github":"brainlife/app-roiGenerator","name":"Merge multiple ROIs together using AFNI","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a418d62f3d3800f12e359"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a418d62f3d3800f12e35a"},{"name":"Franco Pestilli","email":null,"_id":"634a418d62f3d3800f12e35b"}],"desc":"Generate a parcellation volume (and roi nifti files split into each label) for specific ROIs, or every ROI, for a parcellation from freesurfer output and/or input parcellation volume. This App can also inflate input parcellation volume toward non-white matter voxels.","__v":2263,"desc_override":"This app will merge ROIs together using functions provided by AFNI to aid in functional and diffusion tractography analyses.","create_date":"2021-07-19T17:36:51.720Z","doi":"10.25663/brainlife.app.547","_canedit":true},{"_id":"5aa08aa96f97ad0033d4d86b","name":"Mouse Segmentation Pipeline","desc":"Pipeline for mouse brain skull-stripping and ROI segmentation","citation":null,"github":"kathrynalpert/app-mouse_seg","github_branch":"v0.0","config":{"anat":{"type":"input","file_id":"t1","input_id":"t1"},"orient":{"default":"","desc":"leave blank unless orientation string is incorrect for image (3dinfo)","placeholder":"","type":"string","optional":true,"id":"orient","pid":0.17746371860259136,"_order":2},"reg_type":{"options":[{"value":"affine","label":"Affine","desc":""},{"value":"rigid","label":"Rigid","desc":""}],"default":"affine","desc":"When skull-stripping, register target to template affinely (allows scaling) or rigidly (no scaling).","placeholder":"","type":"enum","id":"reg_type","pid":0.3772828544047644,"_order":3},"do_hist_match":{"default":true,"desc":"When skull-stripping, use histogram matching to propagate template tissue segmentations onto the target image.","placeholder":"","type":"boolean","id":"do_hist_match","pid":0.048430592574822295,"_order":4},"do_n4":{"default":true,"desc":"Perform N4 (improved nonparametric nonuniform normalization) bias field correction on input.","placeholder":"","type":"boolean","id":"do_n4","pid":0.002005150751243523,"_order":5}},"user_id":"1","create_date":"2018-03-08T00:58:17.769Z","removed":false,"_rate":0,"outputs":[{"datatype_tags":["mouse_seg"],"output_on_root":true,"archive":true,"_id":"5aa08aa96f97ad0033d4d86c","id":"output","datatype":"59c3eae633fc1cf9ead71679","files":null}],"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5aa08aa96f97ad0033d4d86d","id":"t1","datatype":"58c33bcee13a50849b25879a"}],"contributors":[{"name":null,"email":null,"_id":"634a322962f3d3800f116fdf"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a322962f3d3800f116fe0"}],"tags":["pipeline"],"references":[],"admins":["16","41","146","121","120","1"],"projects":[],"__v":14242,"stats":{"stars":0,"requested":23,"users":5,"success_rate":38.88888888888889,"serviceinfo":{"_id":"5d729e1f78356a109788b37d","counts":{"_id":"5e5c68a187cac77635ab1bcc","failed":3,"finished":7,"removed":7,"requested":14,"running":8,"running_sync":0,"stop_requested":0},"success_rate":70,"users":4,"readme_status":"too short","runtime_mean":3102458.4285714286,"runtime_std":1554118.2280425916,"service":"kathrynalpert/app-mouse_seg","__v":0},"gitinfo":{"desc":"Pipeline for mouse brain skull-stripping and ROI segmentation","tags":["pipeline"],"stats":{"stars":0},"contributors":[{"name":null,"email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":3102458.4285714286,"runtime_std":1554118.2280425916,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a322862f3d3800f116fde"}],"examples":0,"groups":3},"doi":"10.25663/bl.app.75","_canedit":true},{"_id":"5de1664e936ca31ee1c610f5","stats":{"stars":0,"serviceinfo":{"_id":"5de1b6064c234e10113d521e","counts":{"_id":"5e5c3e2e87cac7e897ab1443","failed":33,"finished":813,"removed":1122,"requested":1283,"running":811,"running_sync":0,"stop_requested":2},"success_rate":96.09929078014184,"users":2,"readme_status":"too short","runtime_mean":14288839.39,"runtime_std":51827383.30578027,"service":"brainlife/app-mrtrix2-csd","__v":0},"success_rate":95.42790152403282,"users":7,"runtime_mean":14331230.41,"runtime_std":51818144.95806107,"requested":1295,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a37d662f3d3800f11e56f"}],"examples":0,"groups":10},"projects":[],"admins":["16"],"tags":[],"removed":false,"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"brainmask":{"type":"input","file_id":"mask","input_id":"brainmask"},"max_lmax":{"id":"max_lmax","type":"number","placeholder":"","advanced":false,"desc":"maximum spherical harmonic order (i.e. lmax). If blank, will automatically calculate based on number of shells in data.","default":null,"_order":2,"pid":0.6476212509999897,"optional":true}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5de1664e936ca33e2ac610f8","id":"dwi","datatype":"58c33c5fe13a50849b25879b","desc":"The path to the DWI datatype"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5de1664e936ca35b4bc610f6","id":"brainmask","datatype":"5a281aee2c214c9ba83ce620","desc":"The path to the mask datatype containing the brainmask of the DWI"}],"outputs":[{"datatype_tags":["mrtrix2"],"output_on_root":false,"archive":true,"_id":"5de1664e936ca3c405c610f9","id":"csd","datatype":"5c536bf0f9109beac46adb45","datatype_tags_pass":null,"files":null,"desc":"FODs from the CSD model fit using MRtrix2"}],"github_branch":"v1.0","github":"brainlife/app-mrtrix2-csd","name":"Mrtrix2 CSD","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a37d662f3d3800f11e570"}],"create_date":"2019-11-29T18:41:18.609Z","desc":null,"doi":"10.25663/brainlife.app.255","__v":6560,"_canedit":true},{"_id":"5ec2c8f541ba11eecbf40ba5","projects":[],"admins":["16"],"tags":[],"removed":false,"stats":{"success_rate":95.42790152403282,"users":7,"runtime_mean":14331230.41,"runtime_std":51818144.95806107,"requested":1295,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3a9c62f3d3800f123def"}],"examples":0,"groups":10},"config":{"brainmask":{"type":"input","file_id":"mask","input_id":"brainmask"},"dtiinit":{"type":"input","file_id":"output","input_id":"dtiinit"},"max_lmax":{"id":"max_lmax","type":"number","placeholder":"","advanced":false,"desc":"maximum spherical harmonic order (i.e. lmax). If blank, will automatically calculate based on number of shells in data.","default":null,"_order":2,"pid":0.17023521192910418,"optional":true}},"inputs":[{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5de1664e936ca35b4bc610f6","id":"brainmask","datatype":"5a281aee2c214c9ba83ce620","desc":"The path to the mask datatype containing the brainmask of the DWI"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ec2c8f541ba115762f40ba7","id":"dtiinit","datatype":"58cb234be13a50849b25882f","desc":"The path to the DTIINIT datatype"}],"outputs":[{"datatype_tags":["mrtrix2"],"output_on_root":false,"archive":true,"_id":"5de1664e936ca3c405c610f9","id":"csd","datatype":"5c536bf0f9109beac46adb45","datatype_tags_pass":null,"files":null,"desc":"FODs from the CSD model fit using MRtrix2"}],"github_branch":"v1.0","github":"brainlife/app-mrtrix2-csd","name":"Mrtrix2 CSD (dtiinit)","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3a9d62f3d3800f123df0"}],"desc":null,"__v":4845,"create_date":"2020-05-18T17:42:13.655Z","doi":"10.25663/brainlife.app.344","_canedit":true},{"_id":"5eb875c6d856c0da37270c3c","projects":[],"admins":["16"],"tags":["tracking"],"removed":false,"stats":{"success_rate":52.65700483091788,"users":8,"runtime_mean":6096105.52,"runtime_std":7555933.599048861,"requested":12206,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3a6f62f3d3800f123dcc"}],"examples":0,"groups":17},"config":{"dtiinit":{"type":"input","file_id":"output","input_id":"dtiinit"},"response":{"type":"input","file_id":"response","input_id":"csd"},"lmax2":{"type":"input","file_id":"lmax2","input_id":"csd"},"lmax4":{"type":"input","file_id":"lmax4","input_id":"csd"},"lmax6":{"type":"input","file_id":"lmax6","input_id":"csd"},"lmax8":{"type":"input","file_id":"lmax8","input_id":"csd"},"lmax10":{"type":"input","file_id":"lmax10","input_id":"csd"},"lmax12":{"type":"input","file_id":"lmax12","input_id":"csd"},"lmax14":{"type":"input","file_id":"lmax14","input_id":"csd"},"rois":{"type":"input","file_id":"rois","input_id":"rois"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"brainmask":{"type":"input","file_id":"mask","input_id":"brainmask"},"anat":{"type":"input","file_id":"t1","input_id":"anat"},"min_length":{"id":"min_length","type":"number","placeholder":"","advanced":false,"desc":"The minimum allowable streamline length to be generated (number)\nexample: 10","default":10,"_order":2,"pid":0.4553450300552826},"max_length":{"id":"max_length","type":"number","placeholder":"","advanced":false,"desc":"The maximum allowable streamline length to be generated (number)\nexample: 10","default":200,"_order":3,"pid":0.1008060297592932},"lmax":{"id":"lmax","type":"number","placeholder":"","advanced":false,"desc":"The maxmium spherical harmonic order (lmax) to use. If left empty, this will be identified automatically. (number)","default":8,"_order":4,"pid":0.5385646692020032,"optional":true},"minfodamp":{"id":"minfodamp","type":"string","placeholder":"","advanced":false,"desc":"The minimum FOD amplitude to use as a cutoff (mrtrix3 flag -cutoff) (number)\nex: 0.025","default":"0.025","_order":9,"pid":0.19219310634601183},"roiPair":{"id":"roiPair","type":"string","placeholder":"","advanced":false,"desc":"roiPair for tracking. input seed roi first and termination roi second. This should be the exact same string as identified in the rois datatype following the 'ROI' prefeix and before the '.nii.gz' extension\nex. \"seed term\"","default":"","_order":10,"pid":0.9178094054097721,"multiline":true},"exclusion":{"id":"exclusion","type":"string","placeholder":"","advanced":false,"desc":"these are the names of the exclusion ROIs you would like to use. Follows the same format as roiPair field. For example, if you want to track in both hemispheres, you could enter \"exclusion_L exclusion_R\". \n\nPlease look at your ROIs datatype for the exact name of your exclusion ROI.\n\nIf you do not want to include exclusion ROIs, leave this empty","default":"","_order":12,"pid":0.29027847121556083,"optional":true,"multiline":true},"stepsize":{"id":"stepsize","type":"string","placeholder":"","advanced":false,"desc":"Step size to use for tracking (number)\nex: 0.25","default":"0.25","_order":12,"pid":0.9334637174343379},"count":{"id":"count","type":"number","placeholder":"","advanced":false,"desc":"total number of streamlines","default":500,"_order":14,"pid":0.9190949573846163},"curvatures":{"id":"curvatures","type":"string","placeholder":"","advanced":false,"desc":"maximum angle of curvature (in degrees). can be multiple (i.e. ensemble) or one value. default: 45","default":"45","_order":16,"pid":0.3980051003846312},"maxtrials":{"id":"maxtrials","type":"number","placeholder":"","advanced":false,"desc":"Sets the maximum number of attempts to generate streamline from the seed point. Default=1000000.","default":1000000,"_order":17,"pid":0.974171813478184},"single_lmax":{"id":"single_lmax","type":"boolean","placeholder":"","advanced":false,"desc":"Determines whether single lmax (true) or ensemble lmax (false) will be performed","default":true,"_order":20,"pid":0.9626606008684588},"reslice":{"id":"reslice","type":"boolean","placeholder":"","advanced":false,"desc":"reslice rois into diffusion space if true","default":false,"_order":24,"pid":0.4969165847402721},"multiple_seed":{"id":"multiple_seed","type":"boolean","placeholder":"","advanced":false,"desc":"If true, this will set the seeds of tractography to be present in both the seeding and termination ROIs. This will also set the tracking to be bidirectional.","default":false,"_order":25,"pid":0.29160067620082253},"act":{"id":"act","type":"boolean","placeholder":"","advanced":false,"desc":"If true, this will use the anatomically constrained tractography framework for tracking. This will include backtracking. \n\nIf false, the white matter mask will be used as a tracking mask. The ROIs will be added to the white matter mask. If the ROIs haven't been resliced to diffusion space, set reslice to true in order to get this to work.","default":true,"_order":26,"pid":0.23955166747489653}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5eb875c6d856c04723270c3d","id":"dtiinit","datatype":"58cb234be13a50849b25882f","desc":"The path to the DTIINIT datatype"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5db737fe8aeeee0b74f2dc11","id":"csd","datatype":"5c536bf0f9109beac46adb45","desc":"This is the path to the constrained spherical deconvolution (CSD) outputs, including all lmax csd images generated and the response.txt file."},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5db737fe8aeeeea727f2dc10","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9","desc":"This is the path to the rois directory including both the ROIs listed in the 'roiPair' config"},{"datatype_tags":["5tt_masks"],"optional":true,"multi":false,"advanced":false,"_id":"5db737fe8aeeee4e46f2dc0f","id":"mask","datatype":"5a281aee2c214c9ba83ce620","desc":"This is the path to the five tissue type brain image generated from mrtrix3's 5ttgen function. "},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5db737fe8aeeeedb0af2dc0e","id":"brainmask","datatype":"5a281aee2c214c9ba83ce620","desc":"This is the path to the brain mask of the DWI image. This is optional. If left empty, app will generate brainmask automatically."},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e9d31b2f1745d6b8af6830c","id":"anat","datatype":"58c33bcee13a50849b25879a","desc":"This is the path to the anatomical t1w image. This is only used if a 5tt mask has not been provided"}],"outputs":[{"datatype_tags":["roi_mrtrix3_ifod2"],"output_on_root":false,"archive":true,"_id":"5db737fe8aeeee8147f2dc15","id":"track","datatype":"5907d922436ee50ffde9c549","datatype_tags_pass":null,"files":null,"desc":"This is the output tractogram containing all of the tracks generated"},{"datatype_tags":["roi_mrtrix3_ifod2"],"output_on_root":false,"archive":true,"_id":"5db737fe8aeeee899bf2dc13","id":"wmc","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags_pass":null,"files":null,"desc":"This is the classification structure that refers to the generated tractogram"},{"datatype_tags":["brain_mask"],"output_on_root":false,"archive":false,"_id":"5db737fe8aeeeee32ff2dc14","id":"brainmask","datatype":"5a281aee2c214c9ba83ce620","datatype_tags_pass":null,"files":null,"desc":"This is the brainmask output. If input was used, this is just a copy and doesn't need to be archived."},{"datatype_tags":[],"output_on_root":false,"archive":false,"_id":"5e5430545b9d90120672cf73","id":"5tt","datatype":"5a281aee2c214c9ba83ce620","datatype_tags_pass":null,"files":null,"desc":"This is the 5tt gen output. If input was used, this is just a copy and doesn't need to be archived."}],"github_branch":"v1.0","github":"brainlife/app-mrtrix3-roi2roi-tracking","name":"Mrtrix3 iFOD2 ROI Tracking (dtiinit)","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3a7062f3d3800f123dcd"}],"desc":null,"__v":4909,"desc_override":"This app will generate multiple ROI to ROI tractograms using mrtrix3's probabilistic iFOD2 algorithm and anatomically constrained tractography framework (ACT). ","create_date":"2020-05-10T21:44:38.179Z","doi":"10.25663/brainlife.app.339","deprecated_by":"5eb5d968dca08712b9a766fd","_canedit":true},{"_id":"5eb5d968dca08712b9a766fd","projects":[],"admins":["16"],"tags":["tracking"],"removed":false,"stats":{"success_rate":52.65700483091788,"users":8,"runtime_mean":6096105.52,"runtime_std":7555933.599048861,"requested":12206,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3a5d62f3d3800f123dc5"}],"examples":2,"groups":17},"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"response":{"type":"input","file_id":"response","input_id":"csd"},"lmax2":{"type":"input","file_id":"lmax2","input_id":"csd"},"lmax4":{"type":"input","file_id":"lmax4","input_id":"csd"},"lmax6":{"type":"input","file_id":"lmax6","input_id":"csd"},"lmax8":{"type":"input","file_id":"lmax8","input_id":"csd"},"lmax10":{"type":"input","file_id":"lmax10","input_id":"csd"},"lmax12":{"type":"input","file_id":"lmax12","input_id":"csd"},"lmax14":{"type":"input","file_id":"lmax14","input_id":"csd"},"rois":{"type":"input","file_id":"rois","input_id":"rois"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"brainmask":{"type":"input","file_id":"mask","input_id":"brainmask"},"anat":{"type":"input","file_id":"t1","input_id":"anat"},"wm_mask":{"type":"input","file_id":"mask","input_id":"wm_mask"},"min_length":{"id":"min_length","type":"number","placeholder":"","advanced":false,"desc":"The minimum allowable streamline length to be generated (number)\nexample: 10","default":10,"_order":2,"pid":0.5104029666743661},"max_length":{"id":"max_length","type":"number","placeholder":"","advanced":false,"desc":"The maximum allowable streamline length to be generated (number)\nexample: 10","default":200,"_order":3,"pid":0.1344502454965808},"lmax":{"id":"lmax","type":"number","placeholder":"","advanced":false,"desc":"The maxmium spherical harmonic order (lmax) to use. If left empty, this will be identified automatically. (number)","default":8,"_order":4,"pid":0.05752893466154174,"optional":true},"minfodamp":{"id":"minfodamp","type":"string","placeholder":"","advanced":false,"desc":"The minimum FOD amplitude to use as a cutoff (mrtrix3 flag -cutoff) (number)\nex: 0.025","default":"0.025","_order":9,"pid":0.1358575886531943},"roiPair":{"id":"roiPair","type":"string","placeholder":"","advanced":false,"desc":"roiPair for tracking. input seed roi first and termination roi second. This should be the exact same string as identified in the rois datatype following the 'ROI' prefeix and before the '.nii.gz' extension\nex. \"001 002\"","default":"","_order":10,"pid":0.15615535318736828,"multiline":true},"stepsize":{"id":"stepsize","type":"string","placeholder":"","advanced":false,"desc":"Step size to use for tracking (number)\nex: 0.25","default":"0.25","_order":12,"pid":0.38461949824034125},"exclusion":{"id":"exclusion","type":"string","placeholder":"","advanced":false,"desc":"these are the names of the exclusion ROIs you would like to use. Follows the same format as roiPair field. For example, if you want to track in both hemispheres, you could enter \"exclusion_L exclusion_R\". \n\nPlease look at your ROIs datatype for the exact name of your exclusion ROI.\n\nIf you do not want to include exclusion ROIs, leave this empty","default":"","_order":12,"pid":0.4634376110580438,"optional":true,"multiline":true},"count":{"id":"count","type":"number","placeholder":"","advanced":false,"desc":"total number of streamlines","default":500,"_order":14,"pid":0.878907794987122},"curvatures":{"id":"curvatures","type":"string","placeholder":"","advanced":false,"desc":"maximum angle of curvature (in degrees). can be multiple (i.e. ensemble) or one value. default: 45","default":"45","_order":16,"pid":0.3146707806599214},"maxtrials":{"id":"maxtrials","type":"number","placeholder":"","advanced":false,"desc":"Sets the maximum number of attempts to generate streamline from the seed point. Default=1000000.","default":1000000,"_order":17,"pid":0.45135483239936813},"single_lmax":{"id":"single_lmax","type":"boolean","placeholder":"","advanced":false,"desc":"Determines whether single lmax (true) or ensemble lmax (false) will be performed","default":true,"_order":20,"pid":0.7712702632204045},"reslice":{"id":"reslice","type":"boolean","placeholder":"","advanced":false,"desc":"reslice rois into diffusion space if true","default":false,"_order":24,"pid":0.43608151066536527},"multiple_seed":{"id":"multiple_seed","type":"boolean","placeholder":"","advanced":false,"desc":"If true, this will set the seeds of tractography to be present in both the seeding and termination ROIs. This will also set the tracking to be bidirectional.","default":false,"_order":25,"pid":0.2847181419818041},"act":{"id":"act","type":"boolean","placeholder":"","advanced":false,"desc":"If true, this will use the anatomically constrained tractography framework for tracking. This will include backtracking. \n\nIf false, the white matter mask will be used as a tracking mask. The ROIs will be added to the white matter mask. If the ROIs haven't been resliced to diffusion space, set reslice to true in order to get this to work.","default":true,"_order":26,"pid":0.9931365072232157}},"inputs":[{"id":"dwi","desc":"This is the path's to the DWI image and it's associated bvals and bvecs.","datatype":"58c33c5fe13a50849b25879b","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5db737fe8aeeee68c6f2dc12"},{"id":"csd","desc":"This is the path to the constrained spherical deconvolution (CSD) outputs, including all lmax csd images generated and the response.txt file.","datatype":"5c536bf0f9109beac46adb45","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5db737fe8aeeee0b74f2dc11"},{"id":"rois","desc":"This is the path to the rois directory including both the ROIs listed in the 'roiPair' config","datatype":"5be9ea0315a8683a39a1ebd9","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5db737fe8aeeeea727f2dc10"},{"id":"mask","desc":"This is the path to the five tissue type brain image generated from mrtrix3's 5ttgen function. ","datatype":"5a281aee2c214c9ba83ce620","datatype_tags":["5tt_masks"],"optional":true,"multi":false,"advanced":false,"_id":"5db737fe8aeeee4e46f2dc0f"},{"id":"brainmask","desc":"This is the path to the brain mask of the DWI image. This is optional. If left empty, app will generate brainmask automatically.","datatype":"5a281aee2c214c9ba83ce620","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5db737fe8aeeeedb0af2dc0e"},{"id":"anat","desc":"This is the path to the anatomical t1w image. This is only used if a 5tt mask has not been provided","datatype":"58c33bcee13a50849b25879a","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e9d31b2f1745d6b8af6830c"},{"id":"wm_mask","desc":"This is the path to the precomputed white matter mask. if left empty, one will be generated automatically","datatype":"5a281aee2c214c9ba83ce620","datatype_tags":["white_matter"],"optional":true,"multi":false,"advanced":false,"_id":"5eb99fdae8e7ac1a978a9fe2"}],"outputs":[{"id":"track","desc":"This is the output tractogram containing all of the tracks generated","datatype":"5907d922436ee50ffde9c549","datatype_tags":["roi_mrtrix3_ifod2"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5db737fe8aeeee8147f2dc15"},{"id":"wmc","desc":"This is the classification structure that refers to the generated tractogram","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags":["roi_mrtrix3_ifod2"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5db737fe8aeeee899bf2dc13"},{"id":"brainmask","desc":"This is the brainmask output. If input was used, this is just a copy and doesn't need to be archived.","datatype":"5a281aee2c214c9ba83ce620","datatype_tags":["brain_mask"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":false,"_id":"5db737fe8aeeeee32ff2dc14"},{"id":"5tt","desc":"This is the 5tt gen output. If input was used, this is just a copy and doesn't need to be archived.","datatype":"5a281aee2c214c9ba83ce620","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":false,"_id":"5e5430545b9d90120672cf73"}],"github_branch":"v1.0","github":"brainlife/app-mrtrix3-roi2roi-tracking","name":"Mrtrix3 iFOD2 ROI Tracking (dwi)","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3a5e62f3d3800f123dc6"}],"desc":null,"__v":4935,"create_date":"2020-05-08T22:12:56.892Z","doi":"10.25663/brainlife.app.337","desc_override":"This app will generate multiple ROI to ROI tractograms using mrtrix3's probabilistic iFOD2 algorithm and anatomically constrained tractography framework (ACT). ","_canedit":true},{"_id":"6016dcdc321a4aafce6decd5","projects":[],"admins":["1","239","41","19","16"],"tags":[],"removed":false,"stats":{"requested":141997,"users":122,"success_rate":74.89502451382862,"gitinfo":{"desc":"brainlife.io version of maTT","tags":[],"stats":{"stars":0},"contributors":[{"name":"Josh Faskowitz","email":null},{"name":"Brent McPherson","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":3531098.22,"runtime_std":7328115.446656932,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3ecf62f3d3800f12c535"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3ecf62f3d3800f12c536"}],"examples":5,"groups":229},"name":"Multi-Atlas Transfer Tool","desc":"brainlife.io version of maTT","avatar":"https://cdn190.picsart.com/231983904007202.gif?c256x256","github":"faskowit/app-multiAtlasTT","github_branch":"0.0.9","config":{"fsin":{"type":"input","file_id":"output","input_id":"fsin"},"atlas":{"type":"enum","placeholder":"","desc":"","default":"","options":[{"desc":"","label":"gordon333dil","value":"gordon333dil"},{"desc":"","label":"yeo17dil","value":"yeo17dil"},{"desc":"","label":"hcp-mmp-b","value":"hcp-mmp-b"},{"desc":"","label":"schaefer100-yeo17","value":"schaefer100-yeo17"},{"desc":"","label":"schaefer200-yeo17","value":"schaefer200-yeo17"},{"desc":"","label":"schaefer400-yeo17 ","value":"schaefer400-yeo17 "},{"desc":"","label":"schaefer500-yeo17","value":"schaefer500-yeo17"},{"desc":"","label":"schaefer300-yeo17","value":"schaefer300-yeo17"},{"desc":"","label":"shen268cort","value":"shen268cort"},{"desc":"","label":"baldassano","value":"baldassano"},{"desc":"","label":"arslan","value":"arslan"},{"desc":"","label":"aal","value":"aal"},{"desc":"","label":"nspn500","value":"nspn500"},{"desc":"","label":"aicha","value":"aicha"},{"desc":"does not actually do ICA!!!","label":"ica","value":"ica"}],"id":"atlas","pid":0.7366228908183801,"_order":2}},"user_id":"239","outputs":[{"datatype_tags":["SupraTentorial"],"output_on_root":false,"archive":true,"_id":"5c33813a836af601cc858573","id":"parc-vol","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags_pass":null,"files":null},{"datatype_tags":["brain","anat"],"output_on_root":false,"archive":true,"_id":"5c33813a836af601cc858572","id":"mask","datatype":"5a281aee2c214c9ba83ce620","datatype_tags_pass":null,"files":null}],"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5aeb34f2f446980028b15ef2","id":"fsin","datatype":"58cb22c8e13a50849b25882e"}],"contributors":[{"name":"Josh Faskowitz","email":null,"_id":"634a3ecf62f3d3800f12c537"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a3ecf62f3d3800f12c538"},{"name":"Brent McPherson","email":"bcmcpher@gmail.com","_id":"634a3ecf62f3d3800f12c539"}],"__v":3391,"desc_override":"brainlife.io version of multi atlas transfer tools (maTT). \n\nSpecifically, this is an implementation of maTT2, which uses the gcs files trained on the mindboggle-101 data.  Outputs include: parc.nii.gz (for each atlas indicated) & remapped LUT text file (for each atlas indicated). Please consult the output parcellation key for the names of the nodes produced. These outputs are in the space of the T1w that was submitted to FreeSurfer's recon-all processes. In other words, the parc.nii.gz is re-sliced based on the file `rawavg.mgz` in the FreeSurfer directory. \n\nNOTE: This tool fits atlas to subject space using FreeSurfer's warp, which is based on structural information. However, for many of these atlases, this is a different fitting method than originally proposed. Please consider this when choosing an atlas and/or interpreting your results. Check out the maTT github repo (https://github.com/faskowit/multiAtlasTT) for more info and documentation. ","create_date":"2021-01-31T16:37:48.533Z","doi":"10.25663/brainlife.app.470","_canedit":true},{"_id":"5aeb34f2f446980028b15ef0","doi":"10.25663/bl.app.23","stats":{"stars":0,"requested":141997,"users":122,"success_rate":74.89502451382862,"serviceinfo":{"_id":"5d729e1f78356a109788b369","counts":{"_id":"5e5c3d9d87cac7c003ab13ad","failed":1185,"finished":18829,"removed":18563,"requested":22601,"running":19877,"running_sync":0,"stop_requested":105},"success_rate":94.07914459878086,"users":25,"readme_status":"too short","runtime_mean":791624.62,"runtime_std":456318.02287104074,"service":"faskowit/app-multiAtlasTT","__v":0},"gitinfo":{"desc":"brainlife.io version of maTT","tags":[],"stats":{"stars":0},"contributors":[{"name":"Josh Faskowitz","email":null},{"name":"Brent McPherson","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":3531098.22,"runtime_std":7328115.446656932,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a32b462f3d3800f117a7d"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a32b462f3d3800f117a7e"}],"examples":5,"groups":229},"name":"Multi-Atlas Transfer Tool - old (w/surface output)","desc":"brainlife.io version of maTT","citation":null,"avatar":"https://cdn190.picsart.com/231983904007202.gif?c256x256","github":"faskowit/app-multiAtlasTT","github_branch":"0.0.7","config":{"fsin":{"type":"input","file_id":"output","input_id":"fsin"},"atlas":{"type":"enum","placeholder":"","desc":"","default":"","options":[{"desc":"","label":"gordon333dil","value":"gordon333dil"},{"desc":"","label":"yeo17dil","value":"yeo17dil"},{"desc":"","label":"hcp-mmp-b","value":"hcp-mmp-b"},{"desc":"","label":"schaefer100-yeo17","value":"schaefer100-yeo17"},{"desc":"","label":"schaefer200-yeo17","value":"schaefer200-yeo17"},{"desc":"","label":"schaefer400-yeo17 ","value":"schaefer400-yeo17 "},{"desc":"","label":"schaefer500-yeo17","value":"schaefer500-yeo17"},{"desc":"","label":"schaefer300-yeo17","value":"schaefer300-yeo17"},{"desc":"","label":"shen268cort","value":"shen268cort"},{"desc":"","label":"baldassano","value":"baldassano"},{"desc":"","label":"arslan","value":"arslan"},{"desc":"","label":"aal","value":"aal"},{"desc":"","label":"nspn500","value":"nspn500"},{"desc":"","label":"aicha","value":"aicha"},{"desc":"does not actually do ICA!!!","label":"ica","value":"ica"}],"id":"atlas","pid":0.9094095543558498,"_order":2}},"user_id":"19","create_date":"2018-05-03T16:12:34.843Z","removed":false,"outputs":[{"datatype_tags":["SupraTentorial"],"output_on_root":false,"archive":true,"_id":"5c33813a836af601cc858573","id":"parc-vol","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags_pass":null,"files":null},{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5c4b91589348a100326383a8","id":"parc-surf","datatype":"5c478b7bf9109beac4520be6","datatype_tags_pass":null,"files":null},{"datatype_tags":["brain","anat"],"output_on_root":false,"archive":true,"_id":"5c33813a836af601cc858572","id":"mask","datatype":"5a281aee2c214c9ba83ce620","datatype_tags_pass":null,"files":null}],"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5aeb34f2f446980028b15ef2","id":"fsin","datatype":"58cb22c8e13a50849b25882e"}],"contributors":[{"name":"Josh Faskowitz","email":null,"_id":"634a32b562f3d3800f117a7f"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a32b562f3d3800f117a80"},{"name":"Brent McPherson","email":"bcmcpher@gmail.com","_id":"634a32b562f3d3800f117a81"}],"tags":[],"references":[],"admins":["1","239","41","19","16"],"projects":[],"__v":13753,"desc_override":"brainlife.io version of multi atlas transfer tools (maTT). Specifically, this is an implemenation of maTT2, which uses the gcs files trained on the mindboggle-101 data. The GCS files are automatically pulled from the maTT fishare directory if not present locally.  Inputs include: freesurfer, t1, atlas.  Outputs include: parc.nii.gz (for each atlas indicated) & remapped LUT text file (for each atlas indicated). These outputs are in the space of the T1w that was submitted to FreeSurfer's recon-all processes. In other words, the parc.nii.gz is resliced based on the file `rawavg.mgz` in the FreeSurfer directory. \n\nAtlases include: gordon333, nspn500, yeo17, yeo17dil, hcp-mmp, schaefer100-yeo17, and schaefer-yeo17 (200, 400, 600, 800, 1000).\n\nCheck out the maTT github repo for more info and the latest version of maTT.","deprecated_by":"6016dcdc321a4aafce6decd5","_canedit":true},{"_id":"5ed02ca70a8ed8a9c04831d3","projects":[],"admins":["16"],"tags":["postprocessing"],"removed":false,"stats":{"success_rate":80.55006717774441,"users":28,"runtime_mean":926049.16,"runtime_std":1069495.2315192036,"requested":17488,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3b7462f3d3800f1260b6"},{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a3b7462f3d3800f1260b7"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3b7462f3d3800f1260b8"}],"examples":4,"groups":55},"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"mask":{"type":"input","file_id":"mask","input_id":"1"},"dPar":{"id":"dPar","type":"number","placeholder":"","advanced":false,"desc":"","default":0.0017,"_order":2,"pid":0.9918695025062163},"advancedMask":{"id":"advancedMask","type":"boolean","placeholder":"","advanced":false,"desc":"Sometimes mask generation does not remove all of the non-brain material. If True, this will make sure the non-brain material is fully removed. Only check if inputting a mask that contains non-brain material","default":false,"_order":3,"pid":0.7297223704461686},"debias":{"id":"debias","type":"boolean","placeholder":"","advanced":false,"desc":"Select this if you want to perform signal debiasing before NODDI fit","default":false,"_order":4,"pid":0.8971868318223513}},"inputs":[{"datatype_tags":["single_shell"],"optional":false,"multi":false,"advanced":false,"_id":"5d781dc0281b958208820fea","id":"dwi","datatype":"58c33c5fe13a50849b25879b","desc":"this should be single shell dwi data"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5d781dc0281b95d0f3820fe9","id":"1","datatype":"5a281aee2c214c9ba83ce620","desc":"mask needs to be made from DWI image"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5d781dc0281b9579ce820fec","id":"noddi","datatype":"5ed02a620a8ed8e39c482a61","datatype_tags_pass":null,"files":null,"desc":"only the orientation dispersion (OD) measure should be trusted"},{"datatype_tags":["noddi"],"output_on_root":true,"archive":true,"_id":"5d781dc0281b956e32820feb","id":"1","datatype":"5a281aee2c214c9ba83ce620","datatype_tags_pass":null,"files":null}],"github_branch":"1.3","github":"brainlife/app-noddi-amico","name":"NODDI Amico (single shell)","desc_override":"This fits the NODDI model on single shell data. The only value that should be trusted is orientation dispersion (OD), as this measure can be fit accurately with single shell data","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3b7562f3d3800f1260b9"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a3b7562f3d3800f1260ba"},{"name":"Franco Pestilli","email":null,"_id":"634a3b7562f3d3800f1260bb"},{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a3b7562f3d3800f1260bc"}],"desc":"This app will fit the Neurite Orientation Dispersion and Density Imaging (NODDI; Zhang et al, 2012) model to multi-shell, normalized DWI data using the Accelerated Microstructure Imaging via Convex Optimization (AMICO; Daducci et al, 2015) toolbox. Requires normalized, multi-shell DWI data (including bvals and bvecs) and an optional brainmask of the DWI. Will output the four NODDI output files: neurite density index (ndi), orientation dispersion index (odi), isotropic volume fraction (isovf), and the directions (dirs).","__v":4765,"create_date":"2020-05-28T21:27:03.483Z","doi":"10.25663/brainlife.app.366","_canedit":true},{"_id":"5d781dc0281b95c9b1820fe8","stats":{"stars":1,"serviceinfo":{"_id":"5d729e1f78356a109788b2ff","counts":{"_id":"5e5c3e1587cac77fc5ab142d","failed":1432,"finished":3375,"removed":7983,"requested":8628,"running":4929,"running_sync":0,"stop_requested":178},"success_rate":70.21011025587684,"users":12,"readme_status":"ok","runtime_mean":7179274.96,"runtime_std":6595445.539946354,"service":"brain-life/app-noddi-amico","__v":0},"success_rate":80.55006717774441,"users":28,"runtime_mean":926049.16,"runtime_std":1069495.2315192036,"requested":17488,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a370962f3d3800f11d320"},{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a370962f3d3800f11d321"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a370962f3d3800f11d322"}],"examples":0,"groups":55},"projects":[],"admins":["16"],"tags":["postprocessing"],"removed":false,"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"mask":{"type":"input","file_id":"mask","input_id":"1"},"dPar":{"id":"dPar","type":"number","placeholder":"","advanced":false,"desc":"","default":0.0017,"_order":2,"pid":0.0351539133579124},"advancedMask":{"id":"advancedMask","type":"boolean","placeholder":"","advanced":false,"desc":"Sometimes mask generation does not remove all of the non-brain material. If True, this will make sure the non-brain material is fully removed. Only check if inputting a mask that contains non-brain material","default":false,"_order":3,"pid":0.12302383491572555},"debias":{"id":"debias","type":"boolean","placeholder":"","advanced":false,"desc":"Select this if you want to perform signal debiasing before NODDI fit","default":false,"_order":4,"pid":0.5045874820444518}},"inputs":[{"datatype_tags":["single_shell"],"optional":false,"multi":false,"advanced":false,"_id":"5d781dc0281b958208820fea","id":"dwi","datatype":"58c33c5fe13a50849b25879b","desc":"this should be single shell dwi data"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5d781dc0281b95d0f3820fe9","id":"1","datatype":"5a281aee2c214c9ba83ce620","desc":"mask needs to be made from DWI image"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5d781dc0281b9579ce820fec","id":"noddi","datatype":"5bd77a8615a8683a39440dab","datatype_tags_pass":null,"files":null,"desc":"only the orientation dispersion (OD) measure should be trusted"},{"datatype_tags":["noddi"],"output_on_root":true,"archive":true,"_id":"5d781dc0281b956e32820feb","id":"1","datatype":"5a281aee2c214c9ba83ce620","datatype_tags_pass":null,"files":null}],"github_branch":"1.2","github":"brainlife/app-noddi-amico","name":"NODDI Amico (single shell) - Deprecated","desc_override":"This fits the NODDI model on single shell data. The only value that should be trusted is orientation dispersion (OD), as this measure can be fit accurately with single shell data","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a370a62f3d3800f11d323"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a370a62f3d3800f11d324"},{"name":"Franco Pestilli","email":null,"_id":"634a370a62f3d3800f11d325"},{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a370a62f3d3800f11d326"}],"create_date":"2019-09-10T22:03:44.769Z","desc":"This app will fit the Neurite Orientation Dispersion and Density Imaging (NODDI; Zhang et al, 2012) model to multi-shell, normalized DWI data using the Accelerated Microstructure Imaging via Convex Optimization (AMICO; Daducci et al, 2015) toolbox. Requires normalized, multi-shell DWI data (including bvals and bvecs) and an optional brainmask of the DWI. Will output the four NODDI output files: neurite density index (ndi), orientation dispersion index (odi), isotropic volume fraction (isovf), and the directions (dirs).","doi":"10.25663/brainlife.app.229","__v":6997,"deprecated_by":"5ed02ca70a8ed8a9c04831d3","_canedit":true},{"_id":"5e79cdc2dd840e9395e866a2","stats":{"success_rate":94.85530546623794,"users":8,"runtime_mean":23828.13,"runtime_std":19836.56613108983,"requested":316,"resources":[],"examples":0,"groups":12},"projects":[],"admins":["704"],"tags":["network"],"removed":false,"config":{"network":{"type":"input","file_id":"network","input_id":"network"},"method":{"id":"method","type":"enum","placeholder":"","advanced":false,"desc":"Community detection method\n- Louvain community detection algorithm, you can choose a variation by setting louvain-quality-function. Louvain quality functions works for negative weights.\n- Infomap community detection algorithm.\n- Stochastic block Model can handle layered networks, weighted, directed as well as negative weights.","default":"louvain","_order":2,"pid":0.8054739514804956,"options":[{"desc":"Louvain community detection algorithm, you can choose a variation by setting louvain-quality-function.","label":"Louvain","value":"louvain"},{"desc":"Infomap community detection algorithm.","label":"Infomap","value":"infomap"},{"desc":"Uses Stochastic Block Model.","label":"Stochastic Block Model (SBM)","value":"sbm"}]},"infomap-trials":{"id":"infomap-trials","type":"number","placeholder":"10","advanced":true,"desc":"Number of trials for the Infomap community detection algorithm. (ignored if used for other methods)","default":10,"_order":3,"pid":0.6255432838395418,"optional":true,"min":1},"louvain-quality-function":{"id":"louvain-quality-function","type":"enum","placeholder":"","advanced":true,"desc":"Partition quality function to be optimized for the Louvain method:\n- Modularity: Uses modularity optimization. Accepts weighted networks.\n- RBConfiguration: Reichardt and Bornholdt’s Potts model with a configuration null model. Accepts weighted networks.\n- RBER - Implements Reichardt and Bornholdt’s Potts model with an Erdős-Rényi null model. Accepts weighted networks.\n- Clique Percolation Method (CPM) method. Accepts weighted networks.\n- Significance: based on KL divergence comparing ER. Not suitable for weighted networks.\n- Surprise: based on KL divergence. Works with weighted networks.","default":"modularity","_order":4,"pid":0.041891167808029706,"options":[{"desc":"Optimizes modularity (weighted networks are permitted). Accepts weighted networks.","label":"Modularity","value":"modularity"},{"desc":"Reichardt and Bornholdt’s Potts model with a configuration null model. Accepts weighted networks.","label":"RBConfiguration","value":"rbconfiguration"},{"desc":"Implements Reichardt and Bornholdt’s Potts model with an Erdős-Rényi null model. Accepts weighted networks.","label":"RBER","value":"rber"},{"desc":"Clique Percolation Method (CPM) method. This works with negative weights as well.","label":"Clique Percolation Method (CPM)","value":"cpm"},{"desc":"Significance based on KL divergence comparing ER. Not suitable for weighted networks","label":"Significance","value":"significance"},{"desc":"Surprise: based on KL divergence. Works with weighted networks","label":"Surprise","value":"surprise"}],"optional":true},"louvain-resolution":{"id":"louvain-resolution","type":"number","placeholder":"Communities resolution for Louvain methods","advanced":true,"desc":"Defines the resolution parameter gamma for the quality functions.","default":1,"_order":5,"pid":0.08839724051820053,"min":0,"max":1,"optional":true},"assymetric-negative":{"id":"assymetric-negative","type":"boolean","placeholder":"","advanced":true,"desc":"If the network contains negative weights, the positive and negative partitions are weighted differently, according to Rubinov, Mikail, and Olaf Sporns. \"Weight-conserving characterization of complex functional brain networks.\" Neuroimage 56, no. 4 (2011): 2068-2079. This seems to be appropriate when analyzing brain networks.","default":true,"_order":6,"pid":0.4436814457747478}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e79cdc2dd840e90c5e866a3","id":"network","datatype":"5ed0352de3f453b13b267dae","desc":"Input network. Note that not all the methods support negative weights, please use the Network Preprocessor app before running this App if the network has negative weights."}],"outputs":[{"datatype_tags":["communities"],"output_on_root":false,"archive":true,"_id":"5e79cdc2dd840ebd62e866a4","id":"output","datatype":"5ed0352de3f453b13b267dae","datatype_tags_pass":"network","files":null,"desc":"A network containing the detected community structure."}],"github_branch":"0.3","github":"filipinascimento/bl-network-communities","name":"Network Communities","avatar":"https://raw.githubusercontent.com/filipinascimento/bl-network-communities/master/Media/Icon.png","user_id":"704","contributors":[{"name":"Filipi Nascimento Silva","email":"filipinascimento@gmail.com","_id":"634a38b462f3d3800f11f9ab"}],"create_date":"2020-03-24T09:07:14.462Z","desc":"App to obtain the community structure of networks by using the Louvain or Infomap methods. All the Louvain quality functions work for networks with negative weights.","doi":"10.25663/brainlife.app.290","__v":5284,"_canedit":true},{"_id":"60143233e7e1b77d78aa326b","stats":{"resources":[],"success_rate":0,"users":1,"requested":1,"examples":0,"groups":1},"projects":["5d64733db29ac960ca2e797f"],"admins":["704"],"tags":[],"removed":false,"config":{"network":{"type":"input","file_id":"network","input_id":"inputNetwork"},"threshold":{"id":"threshold","type":"number","placeholder":"Pruning threshold","advanced":true,"desc":"Threshold used to remove edges in the network.","default":0.5,"_order":2,"pid":0.9745307843890677,"min":0,"max":1}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"60143233e7e1b75537aa326c","id":"inputNetwork","datatype":"5ed0352de3f453b13b267dae","desc":"Input network"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"60143233e7e1b74387aa326d","id":"output","datatype":"5ed53b69da664506f88e6df9","datatype_tags_pass":"inputNetwork","files":null,"desc":"A PDF with the degree distribution."}],"github_branch":"main","github":"brainlife/bl-network-template","name":"Network Degree Distribution","desc_override":"","user_id":"704","contributors":[{"name":"Filipi Nascimento Silva","email":"filipinascimento@gmail.com","_id":"634a3ebe62f3d3800f12c2a7"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a3ebe62f3d3800f12c2a8"}],"create_date":"2021-01-29T16:05:07.516Z","desc":"Template app to build new network neuroscience apps for brainlife","__v":3403,"doi":"10.25663/brainlife.app.468","_canedit":true},{"_id":"5bcdefeadc47f70026e8c6ac","projects":[],"admins":["19"],"tags":[],"removed":false,"config":{"parc":{"type":"input","file_id":"parc","input_id":"1"},"key":{"type":"input","file_id":"key","input_id":"1"},"fibers":{"type":"input","file_id":"track","input_id":"2"},"fa":{"type":"input","file_id":"fa","input_id":"3"},"md":{"type":"input","file_id":"md","input_id":"3"},"rd":{"type":"input","file_id":"rd","input_id":"3"},"ad":{"type":"input","file_id":"ad","input_id":"3"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"infl":{"id":"infl","type":"number","placeholder":"","desc":"The number of voxels to dilate the labels into white matter.","default":2,"_order":2,"pid":0.062203193553449054,"optional":false},"microdat":{"id":"microdat","type":"enum","placeholder":"","desc":"Optionally select which microstructure measure to summarize","default":"","_order":3,"pid":0.267428995146767,"options":[{"desc":"","label":"FA","value":"fa"},{"desc":"","label":"MD","value":"md"},{"desc":"","label":"AD","value":"ad"},{"desc":"","label":"RD","value":"rd"}],"optional":true},"compshape":{"id":"compshape","type":"boolean","placeholder":"","desc":"Compute curvature and torsion of edges","default":false,"_order":4,"pid":0.5288425446354534},"compmicro":{"id":"compmicro","type":"boolean","placeholder":"","desc":"Compute mean / std of optional tensor property","default":false,"_order":5,"pid":0.0313212625056396},"comptprof":{"id":"comptprof","type":"boolean","placeholder":"","desc":"Compute tract profile of optional tensor property (requires more memory and runtime)","default":false,"_order":6,"pid":0.9841812199840185},"nnodes":{"id":"nnodes","type":"number","placeholder":"","desc":"The number of points to re-sample to for computing edge curves and tract profiles","default":100,"_order":7,"pid":0.3617673737086866,"readonly":false,"min":3,"max":250}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5bcdefeadc47f70026e8c6af","id":"1","datatype":"5c1a7489f9109beac4a88a1f","desc":"The nodes to build the networks"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5bcdefeadc47f70026e8c6ae","id":"2","datatype":"5907d922436ee50ffde9c549","desc":"The streamlines to create the edges"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5bcdefeadc47f70026e8c6ad","id":"3","datatype":"5a79df48d071a1753f1d661b","desc":"You can request average microstructure properties (FA/MD/AD/RD) or tract profiles for edge weights."},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c474e56f0b03401b991bc0d","id":"mask","datatype":"5a281aee2c214c9ba83ce620","desc":"Brain mask used to inflate the label slightly into the white matter so that we can capture more fibers that don't quite enter the gray matter volume. You can feed the mask output from Multi-atlas transfer tool App, or run FSL Brain extraction App. The mask should not include the ventricle. "}],"outputs":[{"datatype_tags":["networkmatrices"],"output_on_root":true,"archive":true,"_id":"5bcdefeadc47f70026e8c6b0","id":"1","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":"2","files":null}],"github":"bcmcpher/app-networkmatrices","name":"Network Matrices","desc_override":"create connectivity graphs from streamline tractography.","user_id":"19","references":[],"contributors":[{"name":"Brent McPherson","email":"bcmcpher@gmail.com","_id":"634a343e62f3d3800f118aa4"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a343e62f3d3800f118aa5"},{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a343e62f3d3800f118aa6"}],"create_date":"2018-10-22T15:42:34.499Z","desc":"more flexible network app","stats":{"stars":1,"requested":20939,"users":37,"success_rate":85.72527050035701,"serviceinfo":{"_id":"5d729e1f78356a109788b287","counts":{"_id":"5e5c3dc687cac727ffab13db","failed":1480,"finished":12919,"removed":14506,"requested":15311,"running":13950,"running_sync":0,"stop_requested":42},"success_rate":89.72150843808598,"users":11,"readme_status":"too short","runtime_mean":4361727.83,"runtime_std":6852602.1100817975,"service":"bcmcpher/app-networkmatrices","__v":0},"gitinfo":{"desc":"more flexible network app","tags":[],"stats":{"stars":0},"contributors":[{"name":"Brent McPherson","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Lindsey Kitchell","email":null}]},"runtime_mean":5625229.72,"runtime_std":3786630.1376958624,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a343d62f3d3800f118aa2"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a343d62f3d3800f118aa3"}],"examples":3,"groups":46},"doi":"10.25663/brainlife.app.121","__v":9796,"github_branch":"master","_canedit":true},{"_id":"5ea70853f1745db7d9f7b0dc","stats":{"success_rate":95.82825079287632,"users":9,"runtime_mean":55577.1,"runtime_std":67979.69658942294,"requested":5932,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a39e162f3d3800f12350a"}],"examples":5,"groups":17},"projects":[],"admins":["704"],"tags":["network"],"removed":false,"config":{"network":{"type":"input","file_id":"network","input_id":"network"},"richClubPercentage":{"id":"richClubPercentage","type":"number","placeholder":"","advanced":true,"desc":"Percentile of rich-club to calculate the rich-club coefficient.","default":80,"_order":3,"pid":0.4205959776835694,"max":100,"min":0,"optional":true}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ea70853f1745d0cb9f7b0dd","id":"network","datatype":"5ed0352de3f453b13b267dae","desc":"Input network, if the network contains null models, properties for null models are calculated as well. Note that most of the measurements do not work for negative weights, please use preprocessor App to generate separated signed versions of the network."}],"outputs":[{"datatype_tags":["measurements"],"output_on_root":false,"archive":true,"_id":"5ea70853f1745d5b04f7b0de","id":"output","datatype":"5ed0352de3f453b13b267dae","datatype_tags_pass":"network","files":null,"desc":"Output a network containing the calculated properties."}],"github_branch":"0.2","github":"filipinascimento/bl-network-measurements","desc_override":"","name":"Network Measurements","avatar":"https://raw.githubusercontent.com/filipinascimento/bl-network-measurements/master/Media/Icon.png","user_id":"704","contributors":[{"name":"Filipi Nascimento Silva","email":"filipinascimento@gmail.com","_id":"634a39e262f3d3800f12350b"}],"create_date":"2020-04-27T16:29:07.384Z","desc":"App to calculate several basic statistics for networks and their respective null model distributions.","doi":"10.25663/brainlife.app.321","__v":5004,"_canedit":true},{"_id":"58e6d875b1157a7f0f82c453","name":"Network Neuro","desc":"Build structural brain networks using diffusion-weighted MRI, tractography and a brain atlas for cortical and subcortical parcellation.","github":"brainlife/app-networkneuro","github_branch":"1.3","user_id":"1","create_date":"2017-04-07T00:08:21.513Z","outputs":[{"datatype_tags":[],"output_on_root":true,"archive":true,"_id":"58e6d97dd478c456adaa0183","id":"fine","datatype":"58e6e21e6cd4e826de4537ee","files":null,"datatype_tags_pass":"life"}],"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"58e6d97dd478c456adaa0182","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"58e6df093a7f8e6042f32025","id":"life","datatype":"58d15eaee13a50849b258844"}],"admins":["1","45","41","19"],"__v":14330,"config":{"fsdir":{"file_id":"output","input_id":"freesurfer","type":"input"},"fe":{"file_id":"fe","input_id":"life","type":"input"}},"tags":["analysis"],"removed":false,"_rate":5,"contributors":[{"name":"Brent McPherson","email":"bcmcpher@gmail.com","_id":"634a305e62f3d3800f1160ae"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a305e62f3d3800f1160af"},{"name":"Franco Pestilli","email":null,"_id":"634a305e62f3d3800f1160b0"}],"projects":[],"references":[],"stats":{"stars":2,"requested":12110,"users":29,"success_rate":36.85349065880039,"serviceinfo":{"_id":"5d729e1e78356a109788b201","counts":{"_id":"5e5c687187cac74fdeab1b94","failed":61,"finished":115,"removed":125,"requested":195,"running":172,"running_sync":0,"stop_requested":8},"success_rate":65.3409090909091,"users":14,"readme_status":"ok","runtime_mean":5663272.09,"runtime_std":15846236.322127793,"service":"brainlife/app-networkneuro","__v":0},"gitinfo":{"desc":"Build structural brain networks using diffusion-weighted MRI, tractography and a brain atlas for cortical and subcortical parcellation.","tags":["analysis"],"stats":{"stars":2},"contributors":[{"name":"Brent McPherson","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":12301491,"runtime_std":20169054.328930926,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a305e62f3d3800f1160ac"},{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a305e62f3d3800f1160ad"}],"examples":3,"groups":33},"doi":"10.25663/bl.app.47","desc_override":"Build structural brain networks using diffusion-weighted MRI, tractography and a brain atlas for cortical and subcortical parcellation.\n\nIt requires a fit LiFE model and a FreeSurfer output.\n\nIt produces network matrices and an interactive visualization. ","avatar":"//brainlife.io/images/ui-logos/nnview.png","_canedit":true},{"_id":"5b73494459b6e90027009955","projects":[],"admins":["16","41","146","1"],"tags":["analysis"],"removed":false,"config":{"outputs":{"type":"input","file_id":"output","input_id":"inputs"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":true,"advanced":false,"_id":"5b73494459b6e90027009956","id":"inputs","datatype":"58e6e21e6cd4e826de4537ee"}],"outputs":[],"name":"Network Neuro Aggregator","github":"brainlife/app-networkneuro-agg","user_id":"1","references":[],"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a338762f3d3800f117fe3"}],"create_date":"2018-08-14T21:27:32.619Z","desc":"This App will take multiple outputs from networkneuro (the connectivity matrices) and aggregate them by calculating the mean and sdev across all matrices.","stats":{"stars":0,"requested":30,"users":8,"success_rate":79.16666666666666,"serviceinfo":{"_id":"5d729e1f78356a109788b2a1","counts":{"_id":"5e5c3db487cac75fbaab13c7","failed":3,"finished":11,"removed":14,"requested":20,"running":13,"running_sync":0,"stop_requested":0},"success_rate":78.57142857142857,"users":6,"readme_status":"too short","runtime_mean":977260.7272727273,"runtime_std":1053239.1528133226,"service":"brainlife/app-networkneuro-agg","__v":0},"gitinfo":{"desc":"This App will take multiple outputs from networkneuro (the connectivity matrices) and aggregate them by calculating the mean and sdev across all matrices.","tags":["analysis"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":618304.7368421053,"runtime_std":917758.8931167191,"resources":[],"examples":0,"groups":7},"doi":"10.25663/bl.app.89","__v":11343,"avatar":"https://brainlife.io/images/app-logos/app-networkneuro-agg.png","_canedit":true},{"_id":"5e4ad2fd1eafff0efcf9d011","stats":{"stars":0,"serviceinfo":null,"success_rate":97.61904761904762,"users":5,"runtime_mean":49598.39024390244,"runtime_std":176818.78313408463,"requested":85,"resources":[],"examples":1,"groups":9},"projects":[],"admins":["704"],"tags":["network"],"removed":false,"config":{"network":{"type":"input","file_id":"network","input_id":"network"},"count":{"id":"count","type":"number","placeholder":"Number of Samples","advanced":false,"desc":"Number of null model samples to be generated.","default":100,"_order":2,"pid":0.7789625913114475,"min":1},"method":{"id":"method","type":"enum","placeholder":"","advanced":false,"desc":"Model to generate the null samples.\n- random: ER network with same number of nodes and edges as the original network.\n- barabasi: Scale-free model with similar number of nodes and edges as the original network.\n- configuration: Generates a network with same (or similar) degree sequence as the original.","default":"random","_order":3,"pid":0.4995416617954319,"options":[{"desc":"ER network with same number of nodes and edges as the original network.","label":"Erdős–Rényi (Random)","value":"random"},{"desc":"Scale-free model with similar number of nodes and edges as the original network.","label":"Barabási–Albert (scale-free)","value":"barabasi"},{"desc":"Generates a network with same (or similar) degree sequence as the original.","label":"Configuration","value":"configuration"}]},"weights":{"id":"weights","type":"enum","placeholder":"","advanced":false,"desc":"How weights should be handled? \n","default":"ignore","_order":4,"pid":0.3460126776357262,"options":[{"desc":"Weights are ignored and the output models are unweighted.","label":"Ignore","value":"ignore"},{"desc":"Samples the weights from the original weights in order to maintain weight distribution.","label":"Sample","value":"sample"},{"desc":"All weights have the average weight of the original network.","label":"Average","value":"average"}]},"configuration-method":{"id":"configuration-method","type":"enum","placeholder":"","advanced":true,"desc":"If configuration model is selected, this selects the method to be used.\n- Simple:  The generated null model may have self loops and multiple edges.\n- No self-loops and multiple edges: Avoids creating self-loops and multiple edges. (Much slower than \"simple\")\n- Monte-Carlo: Uses Monte-Carlo method to randomize the networks. Based on the Fabien Viger's method.","default":"simple","_order":5,"pid":0.8994874909666828,"options":[{"desc":"The generated null model may have self loops and multiple edges.","label":"Simple","value":"simple"},{"desc":"Avoids creating self-loops and multiple edges. (Much slower than \"simple\")","label":"No self-loops and multiple edges","value":"no_multiple"},{"desc":"Uses Monte-Carlo method to randomize the networks. Based on the Fabien Viger's method.","label":"Monte-Carlo","value":"vl"}]}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e8c7d2b952fef25c07b3203","id":"network","datatype":"5ed0352de3f453b13b267dae","desc":"Input network"}],"outputs":[{"datatype_tags":["null-model"],"output_on_root":false,"archive":true,"_id":"5e8c7d2b952fef9a517b3204","id":"output","datatype":"5ed0352de3f453b13b267dae","datatype_tags_pass":"network","files":null,"desc":"Network file containing the realizations of the null-model."}],"github_branch":"0.2","github":"filipinascimento/bl-network-nullmodel","name":"Network Null Model","avatar":"https://raw.githubusercontent.com/filipinascimento/bl-network-nullmodel/master/Media/Icon.png","user_id":"704","contributors":[{"name":"Filipi Nascimento Silva","email":"filipinascimento@gmail.com","_id":"634a384b62f3d3800f11ef0a"}],"create_date":"2020-02-17T17:53:01.212Z","desc":"Generates an esemble of networks according to null models that try to reproduce the data. Erdos reyni (random), Barabási-Albert and Configuration model are implemented","doi":"10.25663/brainlife.app.277","__v":5278,"_canedit":true},{"_id":"601d716fab40cae5124ab1a2","stats":{"resources":[{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"634a3ee162f3d3800f12c55f"}],"success_rate":20,"users":1,"runtime_mean":237778,"runtime_std":0,"requested":5,"examples":1,"groups":2},"projects":["5d64733db29ac960ca2e797f"],"admins":["704"],"tags":[],"removed":false,"config":{"network":{"type":"input","file_id":"network","input_id":"inputNetwork"},"threshold":{"id":"threshold","type":"number","placeholder":"threshold","advanced":true,"desc":"threshold applied to the network weights","default":0.5,"_order":2,"pid":0.11803434042522098,"readonly":false,"optional":true,"min":0,"max":1}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"601d716fab40ca02d24ab1a3","id":"inputNetwork","datatype":"5ed0352de3f453b13b267dae","desc":"Input network"}],"outputs":[{"datatype_tags":["histogram"],"output_on_root":false,"archive":true,"_id":"601d716fab40ca811b4ab1a4","id":"output","datatype":"5ed53b69da664506f88e6df9","datatype_tags_pass":"inputNetwork","files":null,"desc":"Histogram of node degree after applying a threshold"}],"github_branch":"v0.1","github":"filipinascimento/bl-network-template-matlab","name":"Network Plot Degree Distribution","user_id":"704","contributors":[{"name":"Filipi Nascimento Silva","email":"filipinascimento@gmail.com","_id":"634a3ee162f3d3800f12c560"}],"create_date":"2021-02-05T16:25:19.709Z","desc":"Example template for network analyses using matlab inside brainlife.","__v":3350,"doi":"10.25663/brainlife.app.472","_canedit":true},{"_id":"5e76ea90de643b5e7c2a9404","stats":{"success_rate":95.28183716075156,"users":8,"runtime_mean":3499942.75,"runtime_std":7954983.2536627455,"requested":5047,"resources":[],"examples":2,"groups":15},"projects":[],"admins":["704"],"tags":["network"],"removed":false,"config":{"network":{"type":"input","file_id":"network","input_id":"network"},"transform":{"id":"transform","type":"enum","placeholder":"","advanced":false,"desc":"Choose how to handle the sign of the weights. \nAbsolute: Uses the absolute value of entries as weights.\nPositive: Uses only positive weights.\nNegative: Set all negative weights to positive, and positive to zero weight.\nLayered: Keep weights unchanged but adds separated layers for negative and positive.\nNone : Makes no changes to the signs of entries.\n","default":"absolute","_order":2,"pid":0.3705095428848618,"options":[{"desc":"Uses the absolute value of entries as weights.","label":"Absolute Values","value":"absolute"},{"desc":"Uses only positive weights","label":"Positive","value":"positive"},{"desc":"Set all negative weights to positive, and positive to zero weight.","label":"Negative","value":"negative"},{"desc":"Keep weights unchanged but adds separated layers for negative and positive","label":"Layered","value":"layered"},{"desc":"Makes no changes to the signs of entries.","label":"No transformation","value":"none"}]},"retain-weights":{"id":"retain-weights","type":"boolean","placeholder":"","advanced":false,"desc":"Retain weights values after filtering (If not enabled, the resulting networks are unweighed.)","default":false,"_order":3,"pid":0.016309950550874364},"threshold":{"id":"threshold","type":"number","placeholder":"","advanced":false,"desc":"If a value is provided, all edges weighting less than threshold are removed.","default":null,"_order":4,"pid":0.3971778996809747,"optional":true},"percentile":{"id":"percentile","type":"number","placeholder":"","advanced":false,"desc":"Percentile of top edges to be kept in the network after thresholding edges.","default":"","_order":5,"pid":0.163566576866519,"optional":true,"min":0,"max":1},"selection-transform":{"id":"selection-transform","type":"enum","placeholder":"","advanced":true,"desc":". \nAbsolute: Uses the absolute value of entries as weights.\nPositive: Uses only positive weights.\nNegative: Set all negative weights to positive, and positive to zero weight.\nNone : Makes no changes to the signs of entries.\nSame: Use same transformation as transform.","default":"same","_order":6,"pid":0.3104982640473942,"options":[{"desc":"Uses the absolute value of entries as weights.","label":"Absolute","value":"absolute"},{"desc":"Uses only positive weights","label":"Positive","value":"positive"},{"desc":"Set all negative weights to positive, and positive to zero weight.","label":"Negative","value":"negative"},{"desc":"Makes no changes to the signs of entries.","label":"None","value":"none"},{"desc":"Use same transformation as transform.","label":"Same","value":"same"}],"optional":true},"strict-percentile":{"id":"strict-percentile","type":"boolean","placeholder":"","advanced":true,"desc":"Apply the percentile filter based on the order of weights.","default":false,"_order":7,"pid":0.6309600416241641},"keep-zero-weights":{"id":"keep-zero-weights","type":"boolean","placeholder":"","advanced":true,"desc":"Keep edges with weight zero before threshold and percentile filtering.","default":false,"_order":8,"pid":0.09564960534015576}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e76ea90de643b37942a9405","id":"network","datatype":"5ed0352de3f453b13b267dae","desc":"Input network files to preprocess."}],"outputs":[{"datatype_tags":["network-preprocess"],"output_on_root":false,"archive":true,"_id":"5e76ea90de643b6eb22a9406","id":"output","datatype":"5ed0352de3f453b13b267dae","datatype_tags_pass":"network","files":null,"desc":"Resulting preprocessed networks."}],"github_branch":"0.2","github":"filipinascimento/bl-network-preprocess","name":"Network Preprocess","avatar":"https://raw.githubusercontent.com/filipinascimento/bl-network-preprocess/master/Media/Icon.png","user_id":"704","contributors":[{"name":"Filipi Nascimento Silva","email":"filipinascimento@gmail.com","_id":"634a38ab62f3d3800f11f8ff"}],"create_date":"2020-03-22T04:33:20.362Z","desc":"App to preprocess connectivity/similarity matrices (conmat) and generate a filtered version of the network, which can be directed or undirected, weighted or unweighted.","doi":"10.25663/brainlife.app.289","__v":5288,"_canedit":true},{"_id":"5f718f9e6bbee362ba9adef2","stats":{"resources":[],"success_rate":46.666666666666664,"users":7,"runtime_mean":4716136.948051948,"runtime_std":7866371.736909718,"requested":186,"examples":1,"groups":10},"projects":[],"admins":["704"],"tags":["network"],"removed":false,"config":{"network":{"type":"input","file_id":"network","input_id":"network"},"nullmodels":{"type":"input","file_id":"network","input_id":"nullmodels"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5f718f9e6bbee33a4d9adef3","id":"network","datatype":"5ed0352de3f453b13b267dae","desc":"Input network used to generate a report."},{"datatype_tags":["null-model"],"optional":true,"multi":false,"advanced":false,"_id":"5f718f9e6bbee3090b9adef4","id":"nullmodels","datatype":"5ed0352de3f453b13b267dae","desc":"Null model to be used as comparison for the distributions."}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5f718f9e6bbee3de479adef5","id":"output","datatype":"5e56dc330f7fa604cc3cc291","datatype_tags_pass":"network","files":null,"desc":"Report of the network, with plots and tables describing network properties."}],"github_branch":"0.2","github":"filipinascimento/bl-network-report","name":"Network Report","avatar":"https://raw.githubusercontent.com/filipinascimento/bl-network-report/master/Media/Icon.png","user_id":"704","contributors":[{"name":"Filipi Nascimento Silva","email":"filipinascimento@gmail.com","_id":"634a3d8f62f3d3800f12a691"}],"create_date":"2020-09-28T07:24:14.470Z","desc":"App to generate reports from networks. This includes network properties, node attributes and their respective distributions.","doi":"10.25663/brainlife.app.435","__v":4152,"_canedit":true},{"_id":"5e8ccbef952fef68c17b4095","stats":{"success_rate":94.76713762428048,"users":41,"runtime_mean":69108.75,"runtime_std":108348.88183967335,"requested":1984,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a395262f3d3800f121d20"}],"examples":5,"groups":56},"projects":[],"admins":["704"],"tags":["network"],"removed":false,"config":{"network":{"type":"input","file_id":"network","input_id":"network"},"color-property":{"id":"color-property","type":"string","placeholder":"","advanced":false,"desc":"Uses the provided property as color. If the network has communities detected by the \"Network Communities\" App, you can provide \"communitiy\" to plot communities as colors.","default":"degree","_order":2,"pid":0.7855916935195848,"optional":false},"size-property":{"id":"size-property","type":"string","placeholder":"","advanced":false,"desc":"Makes the size of nodes proportional to the provided property.","default":"degree","_order":3,"pid":0.12331545279835132},"plot-labels":{"id":"plot-labels","type":"boolean","placeholder":"","advanced":false,"desc":"Plot labels on top of nodes.","default":true,"_order":4,"pid":0.801961370407409}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e8ccbef952fef1ad97b4096","id":"network","datatype":"5ed0352de3f453b13b267dae","desc":"Input network. Currently, visualization only works if the edge weights are non negative. Please use the preprocess app to prepare the network."}],"outputs":[{"datatype_tags":["visualization"],"output_on_root":false,"archive":true,"_id":"5e8ccbef952fef88397b4097","id":"output","datatype":"5ed53b69da664506f88e6df9","datatype_tags_pass":"network","files":null,"desc":"Static visualization of the network in pdf."}],"github_branch":"0.2","github":"filipinascimento/bl-network-visualization","name":"Network Visualization","avatar":"https://raw.githubusercontent.com/filipinascimento/bl-network-visualization/master/Media/Icon.png","user_id":"704","contributors":[{"name":"Filipi Nascimento Silva","email":"filipinascimento@gmail.com","_id":"634a395262f3d3800f121d21"}],"create_date":"2020-04-07T18:52:31.796Z","desc":"This app generates simple 2D static visualizations for networks by using a force-directed algorithm. The current implementation uses the Large Graph Layout (LGL) algorithm.","doi":"10.25663/brainlife.app.306","__v":5169,"_canedit":true},{"_id":"5d54568576a4090027b0a0da","stats":{"stars":2,"serviceinfo":{"_id":"5d729e1e78356a109788b1df","counts":{"_id":"5e5c3e0c87cac7ddd4ab1424","failed":30,"finished":22,"removed":45,"requested":58,"running":47,"running_sync":0,"stop_requested":3},"success_rate":42.30769230769231,"users":6,"readme_status":"ok","runtime_mean":4506876.7727272725,"runtime_std":5949601.183849483,"service":"ngoyal95/kwyk_neuronet","__v":0},"gitinfo":{"desc":"This App uses a pretrained deep neural network to predict FreeSurfer segmentations in minutes. The network was trained and evaluated on a large dataset (n = 11,148) obtained by combining data from more than a hundred sites. This App also produces the prediction uncertainty of the network at each voxel using two different uncertainty measures (entropy and variance). For more information please read https://arxiv.org/abs/1812.01719.","tags":["segmentation"],"stats":{"stars":1},"contributors":[{"name":"Jakub Kaczmarzyk","email":"jakub.kaczmarzyk@gmail.com"},{"name":"john lee","email":null},{"name":"Nikhil Goyal","email":"nikhil.r.goyal@gmail.com"},{"name":"Satrajit Ghosh","email":null},{"name":"Patrick McClure","email":null},{"name":null,"email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"success_rate":0.055643141982750624,"users":6,"runtime_mean":957431.3333333334,"runtime_std":1267734.1566918604,"requested":10833,"resources":[{"resource_id":"5ffc99da0df8ff7fc740c95a","name":"Bridges2 @ PSC (GPU-Shared)","_id":"634a36c862f3d3800f11d0b8"}],"examples":0,"groups":7},"projects":[],"admins":["41","1"],"tags":[],"removed":false,"config":{"t1":{"type":"input","file_id":"t1","input_id":"t1"},"samples":{"id":"samples","type":"number","placeholder":"","advanced":false,"desc":"Number of samples you wish to run (ignored for bwn/MAP)","default":10,"_order":3,"pid":0.6106716227134394,"min":2},"model":{"id":"model","type":"enum","placeholder":"","advanced":false,"desc":"","default":"","_order":5,"pid":0.6958207480053211,"options":[{"desc":"Generates mean,variance and entropy","label":"Spike-and-slab dropout","value":"bvwn_multi_prior"},{"desc":"Generates mean,variance and entropy","label":"MC Bernoulli dropout ","value":"bwn_multi"},{"desc":"Generates mean and entropy","label":"MAP","value":"bwn"}]}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d5457d076a4090027b0a0dc","id":"t1","datatype":"58c33bcee13a50849b25879a"}],"outputs":[{"datatype_tags":["freesurfer","kwyk","freesurfer_space"],"output_on_root":false,"archive":true,"_id":"5d5ddfbe4cfacf00366c1089","id":"parc","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags_pass":"t1","files":null,"desc":"Predicted parcellation/volume in freesurfer_space."},{"datatype_tags":["freesurfer","kwyk"],"output_on_root":false,"archive":true,"_id":"5d5ddfbe4cfacf00366c1088","id":"parc_fs","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags_pass":"t1","files":null,"desc":"Predicted parcellation/volume in subject space."},{"datatype_tags":["nobrainer"],"output_on_root":false,"archive":true,"_id":"5d5457d076a4090027b0a0dd","id":"output","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":"t1","files":null,"desc":"contains entrypy and variance (optiona) for prediction uncertainty. "},{"datatype_tags":["nobrainer","freesurfer"],"output_on_root":false,"archive":true,"_id":"5d5c50844cfacf00366c1025","id":"output_fs","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":"t1","files":null,"desc":"contains entrypy and variance (optiona) for prediction uncertainty. "}],"github_branch":"master","github":"brainlife/app-nobrainer","name":"Nobrainer - BrainParcellation","user_id":"548","contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a36c962f3d3800f11d0b9"},{"name":"Franco Pestilli","email":null,"_id":"634a36c962f3d3800f11d0ba"}],"create_date":"2019-08-14T18:44:21.295Z","desc":"brainlife wrapper for https://github.com/neuronets/kwyk -Bayesian Neural Network for brain parcellation and uncertainty estimation. ","doi":"10.25663/brainlife.app.218","__v":7331,"_canedit":true},{"_id":"5ed02c520a8ed8e7bb483031","projects":[],"admins":["16"],"tags":["postprocessing"],"removed":false,"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"mask":{"type":"input","file_id":"mask","input_id":"1"},"dPar":{"id":"dPar","type":"number","placeholder":"","desc":"The parallel diffusivity measure. For white matter analyses, use 0.0017. For cortical mapping, use 0.0011","default":0.0017,"_order":2,"pid":0.4664769313818864},"advancedMask":{"id":"advancedMask","type":"boolean","placeholder":"","desc":"Sometimes mask generation does not remove all of the non-brain material. If True, this will make sure the non-brain material is fully removed. Only check if inputting a mask that contains non-brain material","default":false,"_order":3,"pid":0.08559826514903013},"debias":{"id":"debias","type":"boolean","placeholder":"","desc":"Select this if you want to perform signal debiasing before NODDI fit","default":false,"_order":4,"pid":0.15031114452034}},"inputs":[{"datatype_tags":["!single_shell","!dtiinit"],"optional":false,"multi":false,"advanced":false,"_id":"5bc7ac1244f3980027a7aafe","id":"dwi","datatype":"58c33c5fe13a50849b25879b","desc":"The path to the DWI datatype"},{"datatype_tags":["dwi","brain"],"optional":true,"multi":false,"advanced":false,"_id":"5be0bf4a18c7cd002708d7ce","id":"1","datatype":"5a281aee2c214c9ba83ce620","desc":"brain mask in dwi space where you want to compute NODDI measurements. "}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5bc7ac1244f3980027a7aaff","id":"noddi","datatype":"5ed02a620a8ed8e39c482a61","datatype_tags_pass":null,"files":null,"desc":"The NODDI measures fit using AMICO"},{"datatype_tags":["brain","dwi"],"output_on_root":false,"archive":true,"_id":"5bdcad1a18c7cd002708d7af","id":"mask","datatype":"5a281aee2c214c9ba83ce620","datatype_tags_pass":null,"files":null,"desc":"If you provide the optional mask input, this will be the same mask image. If you don't provide the mask, this App will generate the mask for you and output the mask here."}],"name":"Noddi Amico","github":"brainlife/app-noddi-amico","github_branch":"1.3","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3b6b62f3d3800f125f89"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a3b6b62f3d3800f125f8a"},{"name":"Franco Pestilli","email":null,"_id":"634a3b6b62f3d3800f125f8b"},{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a3b6b62f3d3800f125f8c"}],"desc":"This app will fit the Neurite Orientation Dispersion and Density Imaging (NODDI; Zhang et al, 2012) model to multi-shell, normalized DWI data using the Accelerated Microstructure Imaging via Convex Optimization (AMICO; Daducci et al, 2015) toolbox. Requires normalized, multi-shell DWI data (including bvals and bvecs) and an optional brainmask of the DWI. Will output the four NODDI output files: neurite density index (ndi), orientation dispersion index (odi), isotropic volume fraction (isovf), and the directions (dirs).","stats":{"requested":17488,"users":28,"success_rate":80.55006717774441,"gitinfo":{"desc":"This app will fit the Neurite Orientation Dispersion and Density Imaging (NODDI; Zhang et al, 2012) model to multi-shell, normalized DWI data using the Accelerated Microstructure Imaging via Convex Optimization (AMICO; Daducci et al, 2015) toolbox. Requires normalized, multi-shell DWI data (including bvals and bvecs), and the single shell dwi file that has been aligned to the subject's T1 (i.e. dtiinit output) as input. The app will align the multi-shell data to the single-shell data (if dtiinit was used for tracking; otherwise single shell data is not necessary) in order to assure that NODDI outputs are in the same space as the tensor outputs for later analyses. Will output the five NODDI output files: FIT_ICVF_NEW, FIT_OD_NEW, FIT_ISOVF_NEW, FIT_dir, and config.pickle.","tags":["postprocessing"],"stats":{"stars":1},"contributors":[{"name":"Brad Caron","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":926049.16,"runtime_std":1069495.2315192036,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3b6a62f3d3800f125f86"},{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a3b6a62f3d3800f125f87"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3b6a62f3d3800f125f88"}],"examples":5,"groups":55},"__v":4767,"create_date":"2020-05-28T21:25:38.479Z","doi":"10.25663/brainlife.app.365","_canedit":true},{"_id":"5bc7ac1244f3980027a7aafd","projects":[],"admins":["16"],"tags":["postprocessing"],"removed":false,"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"mask":{"type":"input","file_id":"mask","input_id":"1"},"dPar":{"id":"dPar","type":"number","placeholder":"","desc":"The parallel diffusivity parameter. For white matter analyses, use 0.0017. For cortical mapping, use 0.0011","default":0.0017,"_order":2,"pid":0.6681346663731731},"advancedMask":{"id":"advancedMask","type":"boolean","placeholder":"","desc":"Sometimes mask generation does not remove all of the non-brain material. If True, this will make sure the non-brain material is fully removed. Only check if inputting a mask that contains non-brain material","default":false,"_order":3,"pid":0.052186028062792156},"debias":{"id":"debias","type":"boolean","placeholder":"","desc":"Select this if you want to perform signal debiasing before NODDI fit","default":false,"_order":4,"pid":0.7363448267997565}},"inputs":[{"datatype_tags":["!single_shell","!dtiinit"],"optional":false,"multi":false,"advanced":false,"_id":"5bc7ac1244f3980027a7aafe","id":"dwi","datatype":"58c33c5fe13a50849b25879b","desc":"The path to the DWI datatype"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5be0bf4a18c7cd002708d7ce","id":"1","datatype":"5a281aee2c214c9ba83ce620","desc":"mask needs to be made from DWI image"}],"outputs":[{"datatype_tags":[],"output_on_root":true,"archive":true,"_id":"5bc7ac1244f3980027a7aaff","id":"noddi","datatype":"5bd77a8615a8683a39440dab","datatype_tags_pass":null,"files":null,"desc":"The NODDI (deprecated) measures fit using AMICO"},{"datatype_tags":["noddi"],"output_on_root":true,"archive":true,"_id":"5bdcad1a18c7cd002708d7af","id":"1","datatype":"5a281aee2c214c9ba83ce620","datatype_tags_pass":null,"files":null,"desc":"The brainmask of the DWI"}],"name":"Noddi Amico - Deprecated","github":"brainlife/app-noddi-amico","github_branch":"1.2","user_id":"16","references":[],"contributors":[{"name":"Brad Caron","email":null,"_id":"634a342962f3d3800f118625"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a342962f3d3800f118626"},{"name":"Franco Pestilli","email":null,"_id":"634a342962f3d3800f118627"},{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a342962f3d3800f118628"}],"create_date":"2018-10-17T21:39:30.368Z","desc":"This app will fit the Neurite Orientation Dispersion and Density Imaging (NODDI; Zhang et al, 2012) model to multi-shell, normalized DWI data using the Accelerated Microstructure Imaging via Convex Optimization (AMICO; Daducci et al, 2015) toolbox. Requires normalized, multi-shell DWI data (including bvals and bvecs) and an optional brainmask of the DWI. Will output the four NODDI output files: neurite density index (ndi), orientation dispersion index (odi), isotropic volume fraction (isovf), and the directions (dirs).","stats":{"stars":1,"requested":17488,"users":28,"success_rate":80.55006717774441,"serviceinfo":{"_id":"5d729e1f78356a109788b2ff","counts":{"_id":"5e5c3dc487cac7f6bdab13d9","failed":1432,"finished":3375,"removed":7983,"requested":8628,"running":4929,"running_sync":0,"stop_requested":178},"success_rate":70.21011025587684,"users":12,"readme_status":"ok","runtime_mean":7179274.96,"runtime_std":6595445.539946354,"service":"brain-life/app-noddi-amico","__v":0},"gitinfo":{"desc":"This app will fit the Neurite Orientation Dispersion and Density Imaging (NODDI; Zhang et al, 2012) model to multi-shell, normalized DWI data using the Accelerated Microstructure Imaging via Convex Optimization (AMICO; Daducci et al, 2015) toolbox. Requires normalized, multi-shell DWI data (including bvals and bvecs), and the single shell dwi file that has been aligned to the subject's T1 (i.e. dtiinit output) as input. The app will align the multi-shell data to the single-shell data (if dtiinit was used for tracking; otherwise single shell data is not necessary) in order to assure that NODDI outputs are in the same space as the tensor outputs for later analyses. Will output the five NODDI output files: FIT_ICVF_NEW, FIT_OD_NEW, FIT_ISOVF_NEW, FIT_dir, and config.pickle.","tags":["postprocessing"],"stats":{"stars":1},"contributors":[{"name":"Brad Caron","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":926049.16,"runtime_std":1069495.2315192036,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a342862f3d3800f118622"},{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a342862f3d3800f118623"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a342862f3d3800f118624"}],"examples":0,"groups":55},"doi":"10.25663/brainlife.app.117","__v":9894,"deprecated_by":"5ed02c520a8ed8e7bb483031","_canedit":true},{"_id":"5c5a5ddf464fde003639ebbf","stats":{"stars":0,"requested":23,"users":4,"success_rate":0,"serviceinfo":{"_id":"5d729e1f78356a109788b24b","counts":{"_id":"5e5c3de087cac70757ab13f2","failed":11,"finished":0,"removed":17,"requested":23,"running":9,"running_sync":0,"stop_requested":3},"success_rate":0,"users":4,"readme_status":"too short","service":"brainlife/app-noddi-matlab","__v":0},"gitinfo":{"desc":null,"tags":["postprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null}]},"resources":[],"examples":0,"groups":2},"projects":["5cb8973c71a8630036207a6a"],"admins":["16"],"tags":["postprocessing"],"removed":false,"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"mask":{"type":"input","file_id":"mask","input_id":"1"},"advancedMask":{"id":"advancedMask","type":"boolean","placeholder":"","desc":"Sometimes mask generation does not remove all of the non-brain material. If True, this will make sure the non-brain material is fully removed. Only check if inputting a mask that contains non-brain material","default":false,"_order":2,"pid":0.3855545642749012}},"inputs":[{"datatype_tags":["!single_shell","!dtiinit"],"optional":false,"multi":false,"advanced":false,"_id":"5c5a5ddf464fde003639ebc1","id":"dwi","datatype":"58c33c5fe13a50849b25879b"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5c5a5ddf464fde003639ebc0","id":"1","datatype":"5a281aee2c214c9ba83ce620"}],"outputs":[{"datatype_tags":[],"output_on_root":true,"archive":true,"_id":"5c5a5ddf464fde003639ebc3","id":"0","datatype":"5bd77a8615a8683a39440dab","datatype_tags_pass":null,"files":null},{"datatype_tags":["noddi"],"output_on_root":true,"archive":true,"_id":"5c5a5ddf464fde003639ebc2","id":"1","datatype":"5a281aee2c214c9ba83ce620","datatype_tags_pass":null,"files":null}],"github_branch":"master","github":"brainlife/app-noddi-matlab","name":"Noddi Matlab","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a351262f3d3800f118f11"}],"create_date":"2019-02-06T04:09:03.498Z","desc":null,"doi":"10.25663/brainlife.app.158","__v":8802,"_canedit":true},{"_id":"6172e5864fd85c20b7533e94","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a431162f3d3800f12fe18"}],"success_rate":31.57894736842105,"users":1,"runtime_mean":434971.6666666667,"runtime_std":702188.6661870552,"requested":19,"examples":1,"groups":1},"projects":[],"admins":["386"],"tags":[],"removed":false,"config":{"bold":{"type":"input","file_id":"bold","input_id":"fmri"},"events":{"type":"input","file_id":"events","input_id":"fmri"},"events_json":{"type":"input","file_id":"events_json","input_id":"fmri"},"stim":{"type":"input","file_id":"stim","input_id":"stimuli"},"stimulus_diameter":{"id":"stimulus_diameter","type":"number","placeholder":"Diameter (in cm.)","advanced":false,"desc":"Diameter of the circle within which apertures are shown","default":null,"_order":2,"pid":0.9534964847007692}},"inputs":[{"id":"fmri","datatype":"59b685a08e5d38b0b331ddc5","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"6172e5864fd85c2994533e95"},{"id":"stimuli","datatype":"5afc7c555858d874a40c6dda","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"617b08e9b0856ce5c6e92898"}],"outputs":[{"id":"prf","datatype":"5d9d18d8e30ae43bb0612715","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"6172e5864fd85c5048533e96"}],"github_branch":"main","github":"anibalsolon/PRFmodel-app","name":"PRFmodel","user_id":"386","contributors":[{"name":"Anibal Sólon","email":"anibalsolon@gmail.com","_id":"634a431162f3d3800f12fe19"}],"create_date":"2021-10-22T16:23:34.606Z","desc":null,"__v":1528,"doi":"10.25663/brainlife.app.589","_canedit":true},{"_id":"60b7589f0ad40d957dca311a","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a40f462f3d3800f12dd54"}],"success_rate":80.3030303030303,"users":4,"runtime_mean":14998.39,"runtime_std":8950.880605722548,"requested":312,"examples":3,"groups":12},"projects":[],"admins":["1348"],"tags":["meg"],"removed":false,"config":{"mne":{"type":"input","file_id":"mne","input_id":"megfif"},"fmin":{"id":"fmin","type":"number","placeholder":"","advanced":false,"desc":"Min frequency of interest.\n","default":0,"_order":2,"pid":0.6687896607069579},"fmax":{"id":"fmax","type":"number","placeholder":"","advanced":false,"desc":"Max frequency of interest.","default":100,"_order":3,"pid":0.7372906616857525,"optional":false},"tmin":{"id":"tmin","type":"number","placeholder":"None","advanced":true,"desc":"Min time of interest.","default":null,"_order":4,"pid":0.2768610205554818,"optional":true},"tmax":{"id":"tmax","type":"number","placeholder":"None","advanced":true,"desc":"Max time of interest.","default":null,"_order":5,"pid":0.8761872333152535,"optional":true},"n_fft":{"id":"n_fft","type":"number","placeholder":"","advanced":false,"desc":"The length of FFT used, must be >= n_per_seg. \nThe segments will be zero-padded if n_fft > n_per_seg. If n_per_seg is None, n_fft must be <= number of time points in the data.","default":4096,"_order":6,"pid":0.02599171558497604},"n_overlap":{"id":"n_overlap","type":"number","placeholder":"","advanced":false,"desc":"The number of points of overlap between segments. \nWill be adjusted to be <= n_per_seg.","default":2000,"_order":7,"pid":0.8568964444290814},"n_per_seg":{"id":"n_per_seg","type":"number","placeholder":"None","advanced":false,"desc":"Length of each Welch segment (windowed with a Hamming window). Defaults to None, which sets n_per_seg equal to n_fft","default":null,"_order":8,"pid":0.7726293856111262,"optional":true,"readonly":false},"window":{"id":"window","type":"string","placeholder":"","advanced":true,"desc":"Windowing function to use. See scipy.signal.get_window().","default":"hamming","_order":9,"pid":0.025353382462264595},"proj":{"id":"proj","type":"boolean","placeholder":"","advanced":true,"desc":"Apply SSP projection vectors. \n","default":false,"_order":10,"pid":0.3043649065159826},"reject_by_annotation":{"id":"reject_by_annotation","type":"boolean","placeholder":"","advanced":true,"desc":"Whether to omit bad segments from the data before fitting. If True (default), annotated segments whose description begins with 'bad' are omitted. If False, no rejection based on annotations is performed.","default":true,"_order":11,"pid":0.8110379261557826},"picks":{"id":"picks","type":"string","placeholder":"","advanced":true,"desc":"Channels to include. In lists, channel type strings (e.g., [meg, eeg]) will pick channels of those types, channel name strings (e.g., [MEG0111, MEG2623]) will pick the given channels. When you use a list, don't forget to use the square brackets. Can also be the string values “all” to pick all channels, or “data” to pick data channels. None will pick all data channels. Note that channels in info['bads'] will be included if their names are explicitly provided.\n","default":"None","_order":13,"pid":0.1271683121102959,"optional":false,"multiline":null,"readonly":true},"average":{"id":"average","type":"enum","placeholder":"","advanced":false,"desc":"How to average the segments. \n- If 'mean (default), calculate the arithmetic mean. \n- If 'median', calculate the median, corrected for its bias relative to the mean. \n- If 'None', returns the unaggregated segments.","default":"mean","_order":14,"pid":0.5908451947464008,"options":[{"desc":"arithmetic mean","label":"Mean","value":"mean"},{"desc":"corrected for its bias relative to the mean","label":"Median","value":"median"},{"desc":"returns the unaggregated segments","label":"None","value":"None"}]}},"inputs":[{"id":"megfif","datatype":"61893398e8be76b34cb9826e","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"60b7589f0ad40d167dca311b"}],"outputs":[{"id":"out_grad","datatype":"60c7669e7657d98fe5e128b1","datatype_tags":["psd","grad"],"datatype_tags_pass":"megfif","output_on_root":false,"files":null,"archive":true,"_id":"60b7589f0ad40d4650ca311c"},{"id":"out_mag","datatype":"60c7669e7657d98fe5e128b1","datatype_tags":["psd","mag"],"datatype_tags_pass":"megfif","output_on_root":false,"files":null,"archive":true,"_id":"6172f83e4fd85c2279535f9a"},{"id":"out_eeg","datatype":"60c7669e7657d98fe5e128b1","datatype_tags":["psd","eeg"],"datatype_tags_pass":"megfif","output_on_root":false,"files":null,"archive":false,"_id":"6172f83e4fd85ce58a535f9b"},{"id":"out_figs","datatype":"59c3eae633fc1cf9ead71679","datatype_tags":["psd_image"],"datatype_tags_pass":"megfif","output_on_root":false,"files":null,"archive":false,"_id":"614072492012730b7acb0439"}],"github_branch":"main","github":"guiomar/app-psd","name":"PSD: Power Spectral Density (Welch method)","user_id":"1348","contributors":[{"name":"Julia Guiomar Niso Galán","email":null,"_id":"634a40f462f3d3800f12dd55"}],"create_date":"2021-06-02T10:08:31.318Z","desc":null,"__v":2583,"doi":"10.25663/brainlife.app.530","_canedit":true},{"_id":"616fe817fc8eb96a43000442","projects":[],"admins":["1348"],"tags":[],"removed":false,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a42ff62f3d3800f12fdae"}],"success_rate":99.27673497503014,"users":1,"runtime_mean":20967.52,"runtime_std":11731.65666858692,"requested":6122,"examples":2,"groups":5},"config":{"epo":{"type":"input","file_id":"epo","input_id":"megfif"},"fmin":{"id":"fmin","type":"number","placeholder":"","advanced":false,"desc":"Min frequency of interest.\n","default":0,"_order":2,"pid":0.4438146305299947},"fmax":{"id":"fmax","type":"number","placeholder":"","advanced":false,"desc":"Max frequency of interest.","default":100,"_order":3,"pid":0.4617306042770678,"optional":false},"tmin":{"id":"tmin","type":"number","placeholder":"None","advanced":true,"desc":"Min time of interest.","default":null,"_order":4,"pid":0.9809003955565266,"optional":true},"tmax":{"id":"tmax","type":"number","placeholder":"None","advanced":true,"desc":"Max time of interest.","default":null,"_order":5,"pid":0.4356242701098737,"optional":true},"bandwidth":{"id":"bandwidth","type":"number","placeholder":"","advanced":false,"desc":"The bandwidth of the multi taper windowing function in Hz. The default value is a window half-bandwidth of 4.","default":4,"_order":6,"pid":0.53733272277969},"adaptive":{"id":"adaptive","type":"boolean","placeholder":"","advanced":true,"desc":"Use adaptive weights to combine the tapered spectra into PSD (slow, use n_jobs >> 1 to speed up computation).","default":false,"_order":7,"pid":0.7667243322298631},"low_bias":{"id":"low_bias","type":"boolean","placeholder":"","advanced":true,"desc":"Only use tapers with more than 90% spectral concentration within bandwidth.\n","default":true,"_order":9,"pid":0.7801528619882697},"normalization":{"id":"normalization","type":"enum","placeholder":"","advanced":true,"desc":"Either “full” or “length” (default). If “full”, the PSD will be normalized by the sampling rate as well as the length of the signal (as in nitime).","default":"full","_order":13,"pid":0.8823142369319434,"options":[{"desc":"PSD will be normalized by the length of the signal","label":"Full","value":"full"},{"desc":"the PSD will be normalized by the sampling rate as well as the length of the signal","label":"Length","value":"length"}]},"proj":{"id":"proj","type":"boolean","placeholder":"","advanced":true,"desc":"Apply SSP projection vectors. \n","default":false,"_order":14,"pid":0.5538142204793939},"picks":{"id":"picks","type":"string","placeholder":"","advanced":true,"desc":"Channels to include. In lists, channel type strings (e.g., [meg, eeg]) will pick channels of those types, channel name strings (e.g., [MEG0111, MEG2623]) will pick the given channels. When you use a list, don't forget to use the square brackets. Can also be the string values “all” to pick all channels, or “data” to pick data channels. None will pick all data channels. Note that channels in info['bads'] will be included if their names are explicitly provided.\n","default":"None","_order":15,"pid":0.32351658343587175,"optional":false,"multiline":null,"readonly":true}},"inputs":[{"id":"megfif","datatype":"61797fc39538685e5db952b0","datatype_tags":["epochs"],"optional":false,"multi":false,"advanced":false,"_id":"60b7589f0ad40d167dca311b"}],"outputs":[{"id":"out_psd_grad","datatype":"60c7669e7657d98fe5e128b1","datatype_tags":["psd","grad"],"datatype_tags_pass":"megfif","output_on_root":false,"files":null,"archive":true,"_id":"60b7589f0ad40d4650ca311c"},{"id":"out_psd_mag","datatype":"60c7669e7657d98fe5e128b1","datatype_tags":["psd","mag"],"datatype_tags_pass":"megfif","output_on_root":false,"files":null,"archive":true,"_id":"61726c744fd85c147452b0c8"},{"id":"out_psd_eeg","datatype":"60c7669e7657d98fe5e128b1","datatype_tags":["psd","eeg"],"datatype_tags_pass":"megfif","output_on_root":false,"files":null,"archive":false,"_id":"61726c744fd85c10ff52b0c9"},{"id":"out_figs","datatype":"59c3eae633fc1cf9ead71679","datatype_tags":["psd_image"],"datatype_tags_pass":"megfif","output_on_root":false,"files":null,"archive":false,"_id":"614072492012730b7acb0439"}],"github_branch":"main","github":"guiomar/app-epoch-psd","name":"PSD: Power Spectral Density (Welch method) - epochs","user_id":"1348","contributors":[{"name":"Julia Guiomar Niso Galán","email":null,"_id":"634a430062f3d3800f12fdaf"}],"desc":null,"__v":1553,"desc_override":"PSD: Power Spectral Density (Welch method) - epochs","create_date":"2021-10-20T09:57:43.022Z","doi":"10.25663/brainlife.app.587","_canedit":true},{"_id":"5f93720f60a969050d973859","projects":[],"admins":["16"],"tags":[],"removed":false,"stats":{"success_rate":80.6976418279337,"users":84,"runtime_mean":566450.48,"runtime_std":1502852.264375946,"requested":118550,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3de962f3d3800f12b994"}],"examples":1,"groups":168},"config":{"parcellation":{"type":"input","file_id":"parc","input_id":"parcellation"},"key":{"type":"input","file_id":"key","input_id":"parcellation"},"label":{"type":"input","file_id":"label","input_id":"parcellation"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5edff77cc5972b5332b413e4","id":"parcellation","datatype":"5c1a7489f9109beac4a88a1f"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5f93720f60a969027697385d","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e","desc":""}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5edff6acc5972b7f97b41356","id":"parc-stats","datatype":"5edd3b77c5972b8c47b3a2c3","datatype_tags_pass":"parcellation","files":null}],"github_branch":"parc-stats-v1.2","github":"brainlife/app-freesurfer-stats","name":"Parcellation Statistics","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3de962f3d3800f12b995"}],"desc":null,"__v":4062,"desc_override":"This app will convert important parcellation statistics, including volume of each individual ROI given in a parcellation. These can be used for group analyses.","create_date":"2020-10-24T00:15:11.187Z","doi":"10.25663/brainlife.app.443","deprecated_by":"5fea87ed0cd861261e168fe5","_canedit":true},{"_id":"5edff75dc5972b30f6b41394","projects":[],"admins":["16"],"tags":[],"removed":false,"stats":{"success_rate":80.6976418279337,"users":84,"runtime_mean":566450.48,"runtime_std":1502852.264375946,"requested":118550,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3bb862f3d3800f12681e"}],"examples":1,"groups":168},"config":{"parcellation":{"type":"input","file_id":"parc","input_id":"parcellation"},"key":{"type":"input","file_id":"key","input_id":"parcellation"},"label":{"type":"input","file_id":"label","input_id":"parcellation"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5edff77cc5972b5332b413e4","id":"parcellation","datatype":"5c1a7489f9109beac4a88a1f"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5edff6acc5972b7f97b41356","id":"parc-stats","datatype":"5edd3b77c5972b8c47b3a2c3","datatype_tags_pass":"parcellation","files":null}],"github_branch":"parc-stats-v1.0","github":"brainlife/app-freesurfer-stats","name":"Parcellation Statistics - Deprecated","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3bb962f3d3800f12681f"}],"desc":null,"__v":4672,"desc_override":"This app will convert important parcellation statistics, including volume of each individual ROI given in a parcellation. These can be used for group analyses.","create_date":"2020-06-09T20:55:57.388Z","doi":"10.25663/brainlife.app.374","deprecated_by":"5f93720f60a969050d973859","_canedit":true},{"_id":"603b047b78e65dec6fd1b5dc","projects":[],"admins":["16"],"tags":[],"removed":false,"stats":{"success_rate":80.6976418279337,"users":84,"runtime_mean":566450.48,"runtime_std":1502852.264375946,"requested":118550,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3f5162f3d3800f12ccea"}],"examples":0,"groups":168},"config":{"lh_annot":{"type":"input","file_id":"left","input_id":"parcellation"},"rh_annot":{"type":"input","file_id":"right","input_id":"parcellation"},"label":{"type":"input","file_id":"label","input_id":"parcellation"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"603b047b78e65d75b7d1b5e2","id":"parcellation","datatype":"5f78b377268f76598c29b27a"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5f93720f60a969027697385d","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e","desc":""}],"outputs":[{"datatype_tags":["surface"],"output_on_root":false,"archive":true,"_id":"5edff6acc5972b7f97b41356","id":"parc-stats","datatype":"5edd3b77c5972b8c47b3a2c3","datatype_tags_pass":"parcellation","files":null}],"github_branch":"updated-parc-stats-surface-v1.0","github":"brainlife/app-freesurfer-stats","name":"Parcellation Statistics - Surface","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3f5162f3d3800f12cceb"}],"desc":null,"__v":3177,"desc_override":"This app will convert important parcellation statistics, including volume of each individual ROI given in a parcellation. These can be used for group analyses. This app should be used whenever possible to compute parcellation statistics (uses freesurfer's mri_annotation_stats).","create_date":"2021-02-28T02:48:27.162Z","doi":"10.25663/brainlife.app.484","_canedit":true},{"_id":"5fea87ed0cd861261e168fe5","projects":[],"admins":["16"],"tags":[],"removed":false,"stats":{"success_rate":80.6976418279337,"users":84,"runtime_mean":566450.48,"runtime_std":1502852.264375946,"requested":118550,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3e9962f3d3800f12c1b8"}],"examples":5,"groups":168},"config":{"lh_annot":{"type":"input","file_id":"lh_annot","input_id":"parcellation"},"rh_annot":{"type":"input","file_id":"rh_annot","input_id":"parcellation"},"key":{"type":"input","file_id":"key","input_id":"parcellation"},"label":{"type":"input","file_id":"label","input_id":"parcellation"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5edff77cc5972b5332b413e4","id":"parcellation","datatype":"5c478b7bf9109beac4520be6"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5f93720f60a969027697385d","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e","desc":""}],"outputs":[{"datatype_tags":["surface"],"output_on_root":false,"archive":true,"_id":"5edff6acc5972b7f97b41356","id":"parc-stats","datatype":"5edd3b77c5972b8c47b3a2c3","datatype_tags_pass":"parcellation","files":null}],"github_branch":"parc-stats-surface-v1.0","github":"brainlife/app-freesurfer-stats","name":"Parcellation Statistics - Surface - Deprecated Datatype","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3e9962f3d3800f12c1b9"}],"desc":null,"__v":3645,"desc_override":"This app will convert important parcellation statistics, including volume of each individual ROI given in a parcellation. These can be used for group analyses. This app should be used whenever possible to compute parcellation statistics (uses freesurfer's mri_annotation_stats).","create_date":"2020-12-29T01:35:41.144Z","doi":"10.25663/brainlife.app.464","deprecated_by":"603b047b78e65dec6fd1b5dc","_canedit":true},{"_id":"5fea87300cd861959f168ef8","projects":[],"admins":["16"],"tags":[],"removed":false,"stats":{"success_rate":80.6976418279337,"users":84,"runtime_mean":566450.48,"runtime_std":1502852.264375946,"requested":118550,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3e9062f3d3800f12c00e"}],"examples":5,"groups":168},"config":{"parcellation":{"type":"input","file_id":"parc","input_id":"parcellation"},"key":{"type":"input","file_id":"key","input_id":"parcellation"},"label":{"type":"input","file_id":"label","input_id":"parcellation"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5edff77cc5972b5332b413e4","id":"parcellation","datatype":"5c1a7489f9109beac4a88a1f"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5f93720f60a969027697385d","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e","desc":""}],"outputs":[{"datatype_tags":["volume"],"output_on_root":false,"archive":true,"_id":"5edff6acc5972b7f97b41356","id":"parc-stats","datatype":"5edd3b77c5972b8c47b3a2c3","datatype_tags_pass":"parcellation","files":null}],"github_branch":"parc-stats-volume-v1.0","github":"brainlife/app-freesurfer-stats","name":"Parcellation Statistics - Volume","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3e9062f3d3800f12c00f"}],"desc":null,"__v":3643,"desc_override":"This app will convert important parcellation statistics, including volume and cortical of each individual ROI given in a parcellation. These can be used for group analyses.\n\n* NOTE: This app is intended to be used when a surface parcellation/annotation is not available. The volume and cortical thickness values will slightly differ from computations on the surface, although within standard deviation.","create_date":"2020-12-29T01:32:32.962Z","doi":"10.25663/brainlife.app.463","_canedit":true},{"_id":"61d7351c33cb3deb4984e8d5","user_id":"1","projects":[],"admins":["1"],"avatar":"https://images.unsplash.com/photo-1460925895917-afdab827c52f?ixlib=rb-1.2.1&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=300","name":"Participant Report","github":"brainlife/app-participant-report","github_branch":"main","desc_override":"This app will generate participant friendly report for various input/output derivatives","tags":[],"config":{"fs":{"type":"input","file_id":"output","input_id":"fs"},"wmctracts":{"type":"input","file_id":"tracts","input_id":"wmc"},"wmcsurfaces":{"type":"input","file_id":"surfaces","input_id":"wmc"},"bold":{"type":"input","file_id":"bold","input_id":"task"},"t1":{"type":"input","file_id":"t1","input_id":"anat"}},"inputs":[{"id":"fs","datatype":"58cb22c8e13a50849b25882e","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"61d7357433cb3deb4984f0e0"},{"id":"wmc","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"61d7357433cb3deb4984f0e1"},{"id":"task","datatype":"59b685a08e5d38b0b331ddc5","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"61d7357433cb3deb4984f0e2"},{"id":"anat","datatype":"58c33bcee13a50849b25879a","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"621e303c5d8ab5d5f01a814a"}],"outputs":[{"id":"output","datatype":"5e56dc330f7fa604cc3cc291","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"61d7357433cb3deb4984f0e3"}],"stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a437762f3d3800f130117"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a437762f3d3800f130118"}],"examples":2,"success_rate":52.892561983471076,"users":5,"runtime_mean":41420.9375,"runtime_std":20453.184843590832,"requested":135,"groups":6},"removed":false,"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a437762f3d3800f130119"},{"name":"Franco Pestilli","email":null,"_id":"634a437762f3d3800f13011a"},{"name":"Sophia Vinci-Booher","email":null,"_id":"634a437762f3d3800f13011b"}],"create_date":"2022-01-06T18:29:48.379Z","desc":"App to generate report HTML for study participants","__v":1062,"doi":"10.25663/brainlife.app.601","_canedit":true},{"_id":"5c8189cd2fbcc20034b39e60","stats":{"stars":0,"requested":155,"users":3,"success_rate":37.22627737226277,"serviceinfo":{"_id":"5d729e1e78356a109788b239","counts":{"_id":"5e5c3dec87cac73080ab13fe","failed":176,"finished":553,"removed":686,"requested":814,"running":788,"running_sync":0,"stop_requested":65},"success_rate":75.85733882030178,"users":1,"readme_status":"no README.md","runtime_mean":5070024.94,"runtime_std":1633575.6997710194,"service":"giulia-berto/app-compute-peaks","__v":0},"gitinfo":{"desc":"App to extract the peaks of a spherical harmonic function at each voxel.","tags":[],"stats":{"stars":0},"contributors":[{"name":"Giulia Bertò","email":null}]},"runtime_mean":11945970,"runtime_std":9456283.274750013,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a356b62f3d3800f11a1fa"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a356b62f3d3800f11a1fb"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"634a356b62f3d3800f11a1fc"}],"examples":3,"groups":5},"projects":[],"admins":["146"],"tags":["diffusion-reconstruction"],"removed":false,"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"0"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"0"},"bvals":{"type":"input","file_id":"bvals","input_id":"0"},"t1":{"type":"input","file_id":"t1","input_id":"1"},"mask":{"type":"input","file_id":"mask","input_id":"2"},"csd":{"id":"csd","type":"enum","placeholder":"","desc":"CSD type","default":"","_order":3,"pid":0.09929434926628056,"options":[{"desc":"","label":"CSD multi-shell multi-tissue 5 tissue types","value":"csd_msmt_5tt"},{"desc":"","label":"CSD multi-shell multi-tissue","value":"csd_msmt"},{"desc":"","label":"CSD","value":"csd"}]}},"inputs":[{"id":"0","desc":"Dwi raw data","datatype":"58c33c5fe13a50849b25879b","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c8189cd2fbcc20034b39e62"},{"id":"1","desc":"T1w image. It should be aligned with the dwi data and all non-brain tissue should be removed.","datatype":"58c33bcee13a50849b25879a","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c8189cd2fbcc20034b39e61"},{"id":"2","desc":"Brain mask. It should be aligned with the dwi data. If not provided, the BET algorithm will be used for brain extraction.","datatype":"5a281aee2c214c9ba83ce620","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5c93604189ce9100304df305"}],"outputs":[{"id":"output","desc":"CSD peaks","datatype":"5c9276dc44947d8aea7d6454","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5c8245792fbcc20034b39e6c"}],"github_branch":"1.1","github":"giulia-berto/app-extract-peaks","name":"Peaks extraction with MRtrix","user_id":"146","contributors":[{"name":"Giulia Bertò","email":null,"_id":"634a356c62f3d3800f11a1fd"}],"create_date":"2019-03-07T21:14:53.333Z","desc":"App to extract the peaks of a spherical harmonic function at each voxel  using the MRtrix command sh2peaks.","doi":"10.25663/brainlife.app.172","__v":8537,"_canedit":true},{"_id":"5dfabeea32bff0714de25e9f","stats":{"stars":0,"serviceinfo":{"_id":"5dfc13f2150a9b4c0383c455","counts":{"_id":"5e5c3e3387cac72b67ab1449","failed":0,"finished":8,"removed":8,"requested":9,"running":8,"running_sync":0,"stop_requested":0},"success_rate":100,"users":1,"readme_status":"too short","runtime_mean":279604.875,"runtime_std":81472.5994498112,"service":"brainlife/app-penumbra-analysis","__v":0},"success_rate":100,"users":1,"runtime_mean":279604.875,"runtime_std":81472.5994498112,"requested":9,"resources":[],"examples":0,"groups":1},"projects":["5c54775812cbcc01e1635a9a"],"admins":["16","392"],"tags":[],"removed":false,"config":{"rois":{"type":"input","file_id":"rois","input_id":"rois"},"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"fa":{"type":"input","file_id":"fa","input_id":"tensor"},"md":{"type":"input","file_id":"md","input_id":"tensor"},"rd":{"type":"input","file_id":"rd","input_id":"tensor"},"ad":{"type":"input","file_id":"ad","input_id":"tensor"},"icvf":{"type":"input","file_id":"icvf","input_id":"noddi"},"isovf":{"type":"input","file_id":"isovf","input_id":"noddi"},"od":{"type":"input","file_id":"od","input_id":"noddi"},"smooth":{"id":"smooth","type":"number","placeholder":"","advanced":false,"desc":"smoothing kernel size (mm)","default":3,"_order":2,"pid":0.004774662287279519}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5dfabeea32bff094a5e25ea3","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5dfabeea32bff021d7e25ea2","id":"dwi","datatype":"58c33c5fe13a50849b25879b"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5dfabeea32bff0f1bde25ea1","id":"tensor","datatype":"5a79df48d071a1753f1d661b"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5dfabeea32bff04afee25ea0","id":"noddi","datatype":"5bd77a8615a8683a39440dab"}],"outputs":[{"datatype_tags":["inflated_roi_analysis"],"output_on_root":false,"archive":true,"_id":"5dfabeea32bff03cdce25ea4","id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null}],"github_branch":"master","github":"brainlife/app-penumbra-analysis","name":"Penumbra Analysis","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a380c62f3d3800f11e69b"}],"create_date":"2019-12-19T00:06:02.467Z","desc":null,"doi":"10.25663/brainlife.app.266","__v":6482,"deprecated_by":"5e5d6cd482b37f75bd8f310c","_canedit":true},{"_id":"596cdb1a88ae6f0021531d6a","name":"Plot 3D Surfaces ","desc":"This service creates images of 3D surfaces of the major tracts segmented by AFQ or WMA in 4 views: axial, coronal, left and right sagittal.","github":"kitchell/app-plot3Dobjects","github_branch":"master","config":{"surfaces":{"type":"input","file_id":"surfaces","input_id":"surfaces"},"remove_background":{"type":"boolean","placeholder":"","desc":"transparent background on the images","default":true,"id":"remove_background","pid":0.1022903315035042,"_order":2}},"user_id":"43","create_date":"2017-07-17T15:43:22.155Z","removed":false,"_rate":5,"outputs":[{"datatype_tags":["3Dsurfaces"],"output_on_root":true,"archive":true,"_id":"596cdb1a88ae6f0021531d6b","id":"images","datatype":"5967b799b09297d8d831709e","files":null,"datatype_tags_pass":"surfaces"}],"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"596cdb1a88ae6f0021531d6c","id":"surfaces","datatype":"59307a08436ee50ffd973278"}],"tags":["quality-check"],"admins":["43"],"__v":14289,"contributors":[{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a30ea62f3d3800f11652b"},{"name":null,"email":null,"_id":"634a30ea62f3d3800f11652c"}],"projects":[],"references":[],"stats":{"stars":0,"requested":9372,"users":5,"success_rate":94.54145469544892,"serviceinfo":{"_id":"5d729e1f78356a109788b315","counts":{"_id":"5e5c688087cac79d82ab1ba5","failed":396,"finished":6876,"removed":8192,"requested":9371,"running":7043,"running_sync":0,"stop_requested":30},"success_rate":94.55445544554455,"users":4,"readme_status":"ok","runtime_mean":361411.75,"runtime_std":151276.28163624165,"service":"kitchell/app-plot3Dobjects","__v":0},"gitinfo":{"desc":"This service creates images of 3D surfaces of the major tracts segmented by AFQ or WMA in 4 views: axial, coronal, left and right sagittal.","tags":["quality-check"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null}]},"runtime_mean":361411.75,"runtime_std":151276.28163624165,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a30ea62f3d3800f11652a"}],"examples":0,"groups":3},"doi":"10.25663/brainlife.app.131","desc_override":"This app needs to be updated so that it can run via singularity. Currently this app can not run on any resource.","_canedit":true},{"_id":"5a54f0b84f89380027a9a48d","name":"Plot Eigenfunctions","desc":"App to plot the eigenfunctions of the Laplace Beltrami Spectrum.","citation":null,"avatar":null,"github":"kitchell/app-plotEigenfunctions","github_branch":"1.0","config":{"surfaces":{"type":"input","placeholder":"","desc":"","default":"","file_id":"surfaces","input_id":1},"evecs_folder":{"input_id":0,"file_id":"output","default":"","desc":"","placeholder":"","type":"input"},"eigenvector_number":{"default":"","desc":"","placeholder":"choose an eigenvector number ","type":"number"}},"user_id":"43","create_date":"2018-01-09T16:41:28.013Z","removed":false,"_rate":0,"outputs":[{"datatype_tags":[],"_id":"5a54f0b84f89380027a9a48e","id":"0","datatype":"5967b799b09297d8d831709e","files":null,"output_on_root":true,"archive":true}],"inputs":[{"datatype_tags":["eigenvectors"],"optional":false,"multi":false,"_id":"5a54f0b84f89380027a9a48f","id":"0","datatype":"59c3eae633fc1cf9ead71679"},{"datatype_tags":[],"optional":false,"multi":false,"_id":"5a54fd3441fd04003f9d4890","id":"1","datatype":"59307a08436ee50ffd973278"}],"contributors":[{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a31de62f3d3800f116944"}],"tags":["analysis"],"references":[],"admins":["43"],"projects":[],"__v":14257,"stats":{"stars":0,"requested":56,"users":1,"success_rate":88.88888888888889,"serviceinfo":{"_id":"5d729e1f78356a109788b371","counts":{"_id":"5e5c689887cac76981ab1bc2","failed":4,"finished":32,"removed":37,"requested":56,"running":38,"running_sync":0,"stop_requested":1},"success_rate":88.88888888888889,"users":1,"readme_status":"ok","runtime_mean":3131357.65625,"runtime_std":2685650.2090408164,"service":"kitchell/app-plotEigenfunctions","__v":0},"gitinfo":{"desc":"App to plot the eigenfunctions of the Laplace Beltrami Spectrum.","tags":["analysis"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null}]},"runtime_mean":3131357.65625,"runtime_std":2685650.2090408164,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a31dd62f3d3800f116943"}],"examples":0,"groups":1},"doi":"10.25663/bl.app.55","_canedit":true},{"_id":"616e9266fc8eb95c38ff9532","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a42f662f3d3800f12fcf8"}],"success_rate":100,"users":2,"runtime_mean":47701.375,"runtime_std":45019.778139550785,"requested":9,"examples":1,"groups":2},"projects":[],"admins":["1348"],"tags":[],"removed":false,"config":{"epo":{"type":"input","file_id":"epo","input_id":"epochs01"}},"inputs":[{"id":"epochs01","datatype":"61797fc39538685e5db952b0","datatype_tags":["epochs"],"optional":false,"multi":false,"advanced":false,"_id":"616e9266fc8eb99609ff9533"}],"outputs":[{"id":"out_figs","datatype":"59666a40b09297d8d8271dfc","datatype_tags":["bands_topomap"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"616e9266fc8eb9dc29ff9534"}],"github_branch":"main","github":"guiomar/app-bands-topomap","name":"Plot bands topomap","desc_override":"MNE Plot bands topomap","user_id":"1348","contributors":[{"name":"Julia Guiomar Niso Galán","email":null,"_id":"634a42f662f3d3800f12fcf9"}],"create_date":"2021-10-19T09:39:50.115Z","desc":null,"__v":1553,"doi":"10.25663/brainlife.app.586","_canedit":true},{"_id":"5e922401300b4e122081c882","stats":{"success_rate":88.77737226277372,"users":17,"runtime_mean":128582.36,"runtime_std":347028.01242826256,"requested":1166,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a398762f3d3800f12285a"}],"examples":5,"groups":28},"projects":[],"admins":["16","45"],"tags":["qa"],"removed":false,"config":{"response":{"type":"input","file_id":"response","input_id":"response"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e922401300b4e896781c883","id":"response","datatype":"5c536bf0f9109beac46adb45","desc":"The path to the CSD datatype containing the response function"}],"outputs":[{"datatype_tags":["response_function"],"output_on_root":false,"archive":true,"_id":"5e922401300b4e275481c884","id":"images","datatype":"59666a40b09297d8d8271dfc","datatype_tags_pass":null,"files":null,"desc":"A png of the response function mapped to a sphere"}],"github_branch":"v1.0","github":"brainlife/app-plot-response","name":"Plot response function","desc_override":"Generate a png image of the response function from CSD projected onto a sphere. This code was originally written by Paolo Avesani for the O3D Nature Scientific Data paper (code: https://github.com/brain-life/o3d-code/blob/master/figures/plot_response.py;  paper: https://www.nature.com/articles/s41597-019-0073-y)","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a398762f3d3800f12285b"},{"name":"Franco Pestilli","email":null,"_id":"634a398762f3d3800f12285c"}],"create_date":"2020-04-11T20:09:37.012Z","desc":null,"doi":"10.25663/brainlife.app.311","__v":5121,"_canedit":true},{"_id":"5b1a549e73279e0028adfba2","projects":["5ad5215b363fd5002759a695","5aa01d2659b93903749bd01e","5a78c177340591004da75e6f"],"admins":["146"],"tags":[],"removed":false,"name":"Plot tract measures","desc":"Compute and plot total number of fibers, total number of nodes and average length of some tracts.","citation":null,"references":[],"avatar":null,"github":"giulia-berto/app-plot-tract-measures","github_branch":null,"config":{"segmentation":{"type":"input","file_id":"output","input_id":"0"},"t1":{"type":"input","file_id":"t1","input_id":"1"},"step_size":{"type":"number","placeholder":"","desc":"Step size","default":null,"readonly":false,"id":"step_size","pid":0.1986412440520573,"_order":2},"run":{"id":"run","type":"string","placeholder":"","desc":"Configuration tag","default":"","_order":3,"pid":0.6428871049971184},"tract1":{"id":"tract1","type":"number","placeholder":"","desc":"Tract 1","default":null,"_order":4,"pid":0.8583397758330223,"optional":true},"tract2":{"id":"tract2","type":"number","placeholder":"","desc":"Tract 2","default":null,"_order":5,"pid":0.02609010760606445,"optional":true},"tract3":{"id":"tract3","type":"number","placeholder":"","desc":"Tract 3","default":null,"_order":6,"pid":0.08395466680668495,"optional":true},"tract4":{"id":"tract4","type":"number","placeholder":"","desc":"Tract 4","default":null,"_order":7,"pid":0.6261159815943302,"optional":true},"tract5":{"id":"tract5","type":"number","placeholder":"","desc":"Tract 5","default":null,"_order":8,"pid":0.2630217539891887,"optional":true},"tract6":{"id":"tract6","type":"number","placeholder":"","desc":"Tract 6","default":null,"_order":9,"pid":0.1007929071902467,"optional":true},"tract7":{"id":"tract7","type":"number","placeholder":"","desc":"Tract 7","default":null,"_order":10,"pid":0.22664763138804533,"optional":true},"tract8":{"id":"tract8","type":"number","placeholder":"","desc":"Tract 8","default":null,"_order":11,"pid":0.4378349296759383,"optional":true}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"_id":"5b1a549e73279e0028adfba3","id":"0","datatype":"58f10a90436ee50ffd9063c5","desc":"Segmentation file. Could be AFQ segmentation or WMA segmentation."},{"datatype_tags":[],"optional":false,"multi":false,"_id":"5b35f747786e0f002791cd77","id":"1","datatype":"58c33bcee13a50849b25879a"}],"outputs":[{"datatype_tags":["tract_measures"],"_id":"5ba5147501381a0028908963","id":"0","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null,"output_on_root":true,"archive":true}],"user_id":"146","contributors":[{"name":"Giulia Bertò","email":null,"_id":"634a331062f3d3800f117b78"}],"create_date":"2018-06-08T10:04:14.442Z","stats":{"stars":0,"requested":482,"users":2,"success_rate":78.00511508951406,"serviceinfo":{"_id":"5d729e1f78356a109788b303","counts":{"_id":"5e5c3da887cac73f7dab13b9","failed":86,"finished":305,"removed":316,"requested":482,"running":384,"running_sync":0,"stop_requested":5},"success_rate":78.00511508951406,"users":2,"readme_status":"no README.md","runtime_mean":303397.44,"runtime_std":177194.31238774676,"service":"giulia-berto/app-plot-tract-measures","__v":0},"gitinfo":{"desc":"Compute and plot total number of fibers, total number of nodes and average length of some tracts.","tags":[],"stats":{"stars":0},"contributors":[]},"runtime_mean":303397.44,"runtime_std":177194.31238774676,"resources":[],"examples":0,"groups":1},"doi":"10.25663/bl.app.58","__v":6106,"_canedit":true},{"_id":"5b0f1c515858d874a472dea7","name":"Posterior Associative White Matter Tracts Segmentation","desc":"Classifies streamlines into known anatomical tracts.","citation":null,"avatar":"https://raw.githubusercontent.com/brain-life/app-wmaSeg/master/wmaSeg.png","github":"brainlife/app-wmaSeg","github_branch":"1.4","config":{"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"wbfg":{"type":"input","file_id":"track","input_id":"tracks"},"tracts":{"type":"string","placeholder":"","desc":"Only output specified set of tracts","default":"pArc TPC MdLF-SPL MdLF-Ang VOF","readonly":false,"id":"tracts","pid":0.38394442022614084,"_order":2,"optional":true}},"user_id":"1","create_date":"2018-04-07T15:17:42.733Z","removed":false,"_rate":0,"outputs":[{"datatype_tags":["wmaSeg"],"output_on_root":true,"archive":true,"_id":"5ac8e11671d0210718658ee3","id":"output","datatype":"58f10a90436ee50ffd9063c5","files":null}],"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ac8e11671d0210718658ee5","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ac8e11671d0210718658ee4","id":"tracks","datatype":"5907d922436ee50ffde9c549"}],"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a330762f3d3800f117b71"},{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a330762f3d3800f117b72"},{"name":"Daniel Bullock","email":"iisdanbul@gmail.com","_id":"634a330762f3d3800f117b73"},{"name":"Franco Pestilli","email":null,"_id":"634a330762f3d3800f117b74"},{"name":"Steven O'Riley","email":null,"_id":"634a330762f3d3800f117b75"},{"name":"Brad Caron","email":null,"_id":"634a330762f3d3800f117b76"}],"tags":["analysis"],"references":[],"admins":["16","56","41","146"],"projects":[],"doi":"10.25663/bl.app.46","stats":{"stars":1,"requested":38346,"users":55,"success_rate":68.61732452463195,"serviceinfo":{"_id":"5d729e1e78356a109788b20d","counts":{"_id":"5e5c3da687cac74ea5ab13b8","failed":3425,"finished":9221,"removed":16901,"requested":18537,"running":12116,"running_sync":0,"stop_requested":445},"success_rate":72.91633718171754,"users":20,"readme_status":"ok","runtime_mean":14985593.77,"runtime_std":3690815.7786162673,"service":"brainlife/app-wmaSeg","__v":0},"gitinfo":{"desc":"Classifies streamlines into known anatomical tracts.","tags":["analysis"],"stats":{"stars":1},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Lindsey Kitchell","email":null},{"name":"Daniel Bullock","email":null},{"name":"Franco Pestilli","email":null},{"name":"Steven O'Riley","email":null}]},"runtime_mean":12269634.63,"runtime_std":6622596.683443095,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a330662f3d3800f117b6f"},{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"634a330662f3d3800f117b70"}],"examples":0,"groups":118},"__v":13098,"desc_override":"This brainlife.io App implements the white matter segmentation of the vertical tracts described in Bullock et al. 2019. It segments 8 (4 per hemisphere) white matter tracts, the posterior Arcuate (pArc), temporal-parietal connection (TPC), middle-longitudinal fasciculus (MdLF-SPL MdLF-Ang) and the vertical occipital fasciculus (VOF).","_canedit":true},{"_id":"629a6d3c7f60950a54cc7a6e","user_id":"56","projects":[],"admins":["56"],"name":"Postprocess parcellation: island removal & inflation","github":"DanNBullock/app-de-island_parcellation","github_branch":"parc-statsVers","tags":[],"config":{"parc":{"type":"input","file_id":"parc","input_id":"parc"},"key":{"type":"input","file_id":"key","input_id":"parc"},"label":{"type":"input","file_id":"label","input_id":"parc"},"inflate":{"id":"inflate","type":"number","placeholder":"","advanced":false,"desc":"The number of inflation iterations to perform.  Proceeds voxel-wise (rather than mm-space).  Integer values ONLY!","default":0,"_order":2,"pid":0.28859641132701885},"retainOrigBorders":{"id":"retainOrigBorders","type":"boolean","placeholder":"","advanced":false,"desc":"Whether to retain the original borders of the input parcellation.  This essentially negates any inflation performed, other than filling in islands removed by the de-islanding process.","default":false,"_order":3,"pid":0.7607300355984795},"deisland":{"id":"deisland","type":"boolean","placeholder":"","advanced":false,"desc":"Remove \"islands\" from the parcellation.  \"Islands\" in this context, are sub-components of labels which are disconnected from the primary connected mask associated with those labels.  \n\nFor example, label 100 in a parcellation could be divided into two components, one with 1 voxel and one with 100.  This process would set the label for the 1 voxel component to 0 (thereby erasing it).","default":true,"_order":4,"pid":0.7495056328897679},"maintainIslandsLabels":{"id":"maintainIslandsLabels","type":"string","placeholder":"","advanced":false,"desc":"Which labels should be \"skipped\" for the de-islanding process.  Thus, for these labels, islands will be unmodified, should they exist.","default":"","_order":5,"pid":0.430172160300472,"optional":true},"erodeLabels":{"id":"erodeLabels","type":"string","placeholder":"","advanced":false,"desc":"Which labels should be treated as background (0) for the inflation process.  Thus, for these labels, it will be possible for adjacent labels to expand into these areas.  Surviving labeling for these labels will be retained after the inflation process.","default":"","_order":6,"pid":0.6262550291195963,"optional":true}},"inputs":[{"id":"parc","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"629a6d3c7f60950a54cc7a6f"}],"outputs":[{"id":"output_parc","desc":"The post-processed parcellation","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"629a6d3c7f60950a54cc7a70"},{"id":"output_islandcsv","desc":"A report detailing the effects of the de-islanding process","datatype":"5edd3b77c5972b8c47b3a2c3","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":false,"_id":"629e489f7f60950a54d2f90d"},{"id":"output_inflatecsv","desc":"A report detailing the effects of the inflation process\n","datatype":"5edd3b77c5972b8c47b3a2c3","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":false,"_id":"629e489f7f60950a54d2f90e"}],"stats":{"resources":[],"success_rate":60,"users":1,"groups":2,"runtime_mean":73923,"runtime_std":948.5030310968964,"requested":8,"examples":1},"removed":false,"contributors":[{"name":"Daniel Bullock","email":"iisdanbul@gmail.com","_id":"634a44ca62f3d3800f130e9e"}],"create_date":"2022-06-03T20:21:16.393Z","desc":"Remove islands (unconnected components) from and/or inflate a given volumetric parcellation.","__v":299,"doi":"10.25663/brainlife.app.639","_canedit":true},{"_id":"62a552e9ab3e66978060fa26","user_id":"1447","projects":[],"admins":["1447"],"name":"Predict functional connectivity from structural connectivity","github":"FarnazZE/bnbl-brainlife-predict-fc-from-sc","tags":[],"config":{"index":{"type":"input","file_id":"index","input_id":"conmat"},"label":{"type":"input","file_id":"label","input_id":"conmat"},"csv":{"type":"input","file_id":"csv","input_id":"conmat"},"gammavals":{"id":"gammavals","type":"number","placeholder":"gamma values","advanced":false,"desc":"convert edge weight to cost","default":0.5,"_order":2,"pid":0.09349713978596785},"predictors":{"id":"predictors","type":"enum","placeholder":"","advanced":false,"desc":"","default":"all","_order":4,"pid":0.9519344235035745,"options":[{"desc":"use all structural connectivity predictors","label":"use all structural connectivity predictors","value":"all"},{"desc":"","label":"Binary path length ","value":"PLbin"},{"desc":"","label":"Binary communicability","value":"Gbin"},{"desc":"","label":"Binary cosine distance","value":"Cosbin"},{"desc":"","label":"Binary mean first passage time","value":"mfptbin"},{"desc":"","label":"Binary matching index","value":"MIbin"},{"desc":"","label":"Binary search information","value":"SIbin"},{"desc":"","label":"Binary path transitivity","value":"PTbin"},{"desc":"","label":" Weighted communicability","value":"Gwei"},{"desc":"","label":" Weighted cosine distance","value":"Coswei"},{"desc":"","label":" Weighted mean first passage time","value":"mfptwei"},{"desc":"","label":" Weighted matching index","value":"MIwei"},{"desc":"","label":" Weighted search information","value":"SIwei"},{"desc":"","label":" Weighted path transitivity","value":"PTwei"},{"desc":"","label":" Weighted path length ","value":"PLwei"}],"optional":false,"readonly":null},"remove nodes":{"id":"remove nodes","type":"enum","placeholder":"","advanced":false,"desc":"remove isolated nodes (row/columns\n with all zero values)","default":"false","_order":5,"pid":0.9626835676550505,"options":[{"desc":"","label":"","value":"true"},{"desc":"","label":"","value":"false"}]}},"inputs":[{"id":"conmat","datatype":"5d34d9f744947d8aea0e0d2f","datatype_tags":[],"optional":false,"multi":true,"advanced":false,"_id":"62a552e9ab3e66978060fa27"}],"outputs":[{"id":"output","datatype":"5ed53b69da664506f88e6df9","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"62a552e9ab3e66978060fa28"}],"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a450962f3d3800f130f39"}],"examples":0,"users":1,"groups":2,"requested":21,"success_rate":9.523809523809524,"runtime_mean":59581.5,"runtime_std":37115.5},"removed":false,"contributors":[{"name":"Farnaz Zamani Esfahlani","email":null,"_id":"634a450962f3d3800f130f3a"}],"create_date":"2022-06-12T02:43:53.157Z","desc":null,"__v":281,"doi":"10.25663/brainlife.app.646","github_branch":"main","_canedit":true},{"_id":"6041f75166d5ce1daf6efb55","projects":[],"admins":["16","822","41","146","1"],"tags":[],"removed":false,"stats":{"resources":[{"resource_id":"5e309300e017b06c99948e0a","name":"stampede2(knl) @ TACC/UT","_id":"634a3f6462f3d3800f12cef3"},{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"634a3f6462f3d3800f12cef4"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3f6462f3d3800f12cef5"}],"success_rate":9.630859624473114,"users":10,"runtime_mean":22212223.2,"runtime_std":15784124.287120411,"requested":12682,"examples":5,"groups":22},"config":{"t1":{"type":"input","file_id":"t1","input_id":"anat"},"bold":{"type":"input","file_id":"bold","input_id":"task"},"events":{"type":"input","file_id":"events","input_id":"task"},"events_json":{"type":"input","file_id":"events_json","input_id":"task"},"sbref":{"type":"input","file_id":"sbref","input_id":"task"},"sbref_json":{"type":"input","file_id":"sbref_json","input_id":"task"},"physio":{"type":"input","file_id":"physio","input_id":"task"},"physio_json":{"type":"input","file_id":"physio_json","input_id":"task"},"regressors":{"type":"input","file_id":"regressors","input_id":"regressors"},"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"way":{"type":"input","file_id":"rois","input_id":"waymask"},"parc":{"type":"input","file_id":"parc","input_id":"uatlas"},"key":{"type":"input","file_id":"key","input_id":"uatlas"},"min_thr":{"id":"min_thr","type":"number","placeholder":"","advanced":false,"desc":"Multi-thresholding minimum threshold. This should be a float value 0-1 and should be smaller than max_thr. If this field is set, max_thr and step_thr must also be set.","default":0.2,"_order":2,"pid":0.3447617054851879,"min":0.01,"max":1,"optional":true},"max_thr":{"id":"max_thr","type":"number","placeholder":"","advanced":false,"desc":"Multi-thresholding maximum threshold. This should be a float value 0-1 and should be larger than min_thr. If this field is set, min_thr and step_thr must also be set.","default":1,"_order":3,"pid":0.1939232735316816,"min":0.01,"max":1,"optional":true},"step_thr":{"id":"step_thr","type":"number","placeholder":"","advanced":false,"desc":"Multi-thresholding step size. If this field is set, min_thr and max_thr must also be set.","default":0.2,"_order":4,"pid":0.8981658872376019,"min":0.01,"max":1,"optional":true},"thr":{"id":"thr","type":"number","placeholder":"Threshold","advanced":false,"desc":"Optionally specify a threshold indicating a proportion of weights to preserve in the graph. Defaults to no thresholding applied.","default":1,"_order":6,"pid":0.4636994167225117,"min":0.01,"max":1,"optional":true},"atlas":{"id":"atlas","type":"string","placeholder":"Atlas/parcellation name to define nodes","advanced":false,"desc":"Enter atlas name in each. choose from 'atlas_aal', 'atlas_talairach_gyrus', 'atlas_talairach_ba', 'atlas_talairach_lobe', 'atlas_harvard_oxford', 'atlas_msdl', 'coords_dosenbach_2010', 'coords_power_2011', 'atlas_pauli_2017', 'destrieux2009_rois', 'BrainnetomeAtlasFan2016', 'VoxelwiseParcellationt0515kLeadDBS', 'Juelichgmthr252mmEickhoff2005', 'CorticalAreaParcellationfromRestingStateCorrelationsGordon2014', 'whole_brain_cluster_labels_PCA100', 'AICHAreorderedJoliot2015', 'HarvardOxfordThr252mmWholeBrainMakris2006', 'VoxelwiseParcellationt058kLeadDBS', 'MICCAI2012MultiAtlasLabelingWorkshopandChallengeNeuromorphometrics', 'AALTzourioMazoyer2002', 'DesikanKlein2012', 'AAL2zourioMazoyer2002', 'VoxelwiseParcellationt0435kLeadDBS', 'AICHAJoliot2015', 'whole_brain_cluster_labels_PCA200', 'RandomParcellationsc05meanalll43Craddock2011', 'sub-colin27_label-L2018_desc-scale1_atlas', 'sub-colin27_label-L2018_desc-scale2_atlas', 'sub-colin27_label-L2018_desc-scale3_atlas', 'sub-colin27_label-L2018_desc-scale4_atlas', 'sub-colin27_label-L2018_desc-scale5_atlas', 'rsn-intersection_res-200', 'rsn-intersection_res-400', 'rsn-intersection_res-600', 'rsn-intersection_res-800', 'rsn-language_res-200', 'rsn-language_res-400', 'rsn-language_res-600', 'rsn-language_res-800', 'rsn-union_res-200', 'rsn-union_res-400', 'rsn-union_res-600', 'rsn-union_res-800', 'rsn-ventral_res-200', 'rsn-ventral_res-400', 'rsn-ventral_res-600', 'rsn-ventral_res-800'\n\nEither one or more supported atlas names or one or more file paths to a volume parcellation is required.\n\nsee https://pynets.readthedocs.io/en/latest/usage.html\n","default":"'net-Cont_scale-200'\n'net-Cont_scale-400'\n'net-Cont_scale-600'\n'net-Cont_scale-800'\n'net-Default_scale-200'\n'net-Default_scale-400'\n'net-Default_scale-600'\n'net-Default_scale-800'\n'net-DorsAttn_scale-200'\n'net-DorsAttn_scale-400'\n'net-DorsAttn_scale-600'\n'net-DorsAttn_scale-800'\n'net-Limbic_scale-200'\n'net-Limbic_scale-400'\n'net-Limbic_scale-600'\n'net-Limbic_scale-800'\n'net-SalVentAttn_scale-200'\n'net-SalVentAttn_scale-400'\n'net-SalVentAttn_scale-600'\n'net-SalVentAttn_scale-800'\n'net-SomMot_scale-200'\n'net-SomMot_scale-400'\n'net-SomMot_scale-600'\n'net-SomMot_scale-800'\n'net-Vis_scale-200'\n'net-Vis_scale-400'\n'net-Vis_scale-600'\n'net-Vis_scale-800'","_order":7,"pid":0.8190185143326503,"multiline":true,"optional":true},"mst":{"id":"mst","type":"boolean","placeholder":"","advanced":false,"desc":"Optionally use this flag if you wish to apply local thresholding via the Minimum Spanning Tree approach.  -thr values in this case correspond to a target density (if the -dt flag is also included), otherwise  a target proportional threshold.","default":false,"_order":8,"pid":0.11052307269230988},"dt":{"id":"dt","type":"boolean","placeholder":"","advanced":false,"desc":"Optionally use this flag if you wish to threshold to achieve a given density or densities indicated by the  -thr and -min_thr, -max_thr, -step_thr flags,  respectively.","default":false,"_order":10,"pid":0.1554047959670215},"embed":{"id":"embed","type":"boolean","placeholder":"","advanced":true,"desc":"Optionally use this flag if you wish to embed the ensemble(s) produced into Euclidean feature vector(s).","default":true,"_order":12,"pid":0.53070625493983},"df":{"id":"df","type":"boolean","placeholder":"","advanced":false,"desc":"Optionally use this flag if you wish to apply local thresholding via the disparity filter approach. -thr  values in this case correspond to α.","default":false,"_order":13,"pid":0.7473549988467221},"id":{"id":"id","type":"string","placeholder":"","advanced":true,"desc":"A subject identifier. Must be an alphanumeric string and can be arbitrarily chosen. If your preprocessed data is in BIDS format where the subject ID is sub-XXXX and the session is ses-2, then specify XXXX_2. If the input data is in BIDS format, this field is unnecessary and with be parsed automatically.","default":"null","_order":16,"pid":0.6699971645321485,"multiline":false,"optional":true},"mod":{"id":"mod","type":"string","placeholder":"(Structural and Functional Connectome Attribute): Connectivity Model","advanced":false,"desc":"Specify connectivity estimation model. \n\nFor fMRI, possible models include: corr for correlation, cov for covariance, sps for precision covariance, partcorr for partial correlation. skggm estimators are also exposed and include: QuicGraphicalLasso, QuicGraphicalLassoCV, QuicGraphicalLassoEBIC, and AdaptiveQuicGraphicalLasso. \n\nFor dMRI, current models include csa, csd, and sfm.","default":"csa sfm csd corr partcorr cov","_order":18,"pid":0.22377004363570308,"optional":false,"multiline":true},"es":{"id":"es","type":"string","placeholder":"(Functional Connectome Attribute): Time-Series Extraction Method","advanced":false,"desc":"Include this option if you are running functional connectometry using parcel labels and wish to specify the name of a specific function (i.e. other than the mean, the default) to reduce the label's time-series. \n\nOptions are: `sum`, `mean`, `median`, `mininum`, `maximum`, `variance`, `standard_deviation`.","default":"mean median maximum","_order":21,"pid":0.32149454974785074,"multiline":true,"optional":false},"dg":{"id":"dg","type":"string","placeholder":"(Structural Connectome Attribute): Diffusion Direction Extraction Method","advanced":false,"desc":"Include this flag to manually specify the statistical approach to tracking for dmri connectome estimation.\n\nOptions are: `det` (deterministic),`prob` (probabilistic), `clos` (closest-peak)","default":"det prob","_order":24,"pid":0.9394396075415548,"optional":false,"multiline":true},"plt":{"id":"plt","type":"boolean","placeholder":"","advanced":true,"desc":"Activates plotting","default":false,"_order":25,"pid":0.2574128063685206},"norm":{"id":"norm","type":"enum","placeholder":"","advanced":false,"desc":"Include this flag to normalize the graph(s).","default":"3","_order":25,"pid":0.5700179579990414,"options":[{"desc":"","label":"maximum edge weight","value":"1"},{"desc":"","label":"log10","value":"2"},{"desc":"","label":"pass-to-ranks for all non-zero edges","value":"3"},{"desc":"","label":"using pass-to-ranks for all non-zero edges relative to the number of nodes","value":"4"},{"desc":"","label":"pass-to-ranks with zero-edge boost","value":"5"},{"desc":"","label":"standardizes the matrix to values [0, 1]","value":"6"}],"optional":true,"readonly":false},"p":{"id":"p","type":"enum","placeholder":"","advanced":false,"desc":"Include this flag to implement various strategies for graph fragmentation protection (i.e. ensuring a connected graph before performing graph theoretical analysis).","default":"3","_order":26,"pid":0.363799637723653,"options":[{"desc":"disable fragmentation-protection","label":"no-fragmentation protection","value":"0"},{"desc":"","label":"prune the graph of any isolated + fully disconnected nodes ","value":"1"},{"desc":"","label":"prune the graph of all but hubs as defined by any of a variety of definitions ","value":"2"},{"desc":"","label":"retain only the largest connected component subgraph.","value":"3"}],"optional":true},"n":{"id":"n","type":"string","placeholder":"Yeo/Shaeffer  2011/2017 Restricted Subgraphs","advanced":false,"desc":"Optionally specify the name of any of the 2017 Yeo-Schaefer RSNs (7-network or 17-network): \nVis, SomMot, DorsAttn, SalVentAttn, Limbic, Cont, Default, VisCent, VisPeri, SomMotA, SomMotB, DorsAttnA, DorsAttnB, SalVentAttnA, SalVentAttnB, LimbicOFC, LimbicTempPole, ContA, ContB, ContC, DefaultA, DefaultB, DefaultC, TempPar. ","default":"null","_order":28,"pid":0.5521002493665608,"multiline":true,"optional":true},"mplx":{"id":"mplx","type":"number","placeholder":"","advanced":true,"desc":"Levels of multiplex graph analysis (only) if both structural and diffusion connectometry is run simultaneously. Include this flag to perform multiplex graph analysis across structural-functional connectome modalities. \n\nOptions include level:\n(0) Default, which is no multiplex analysis.\n(1) Create multiplex graphs using mutual information and adaptive thresholding; \n(2) Additionally perform multiplex graph embedding and analysis. ","default":2,"_order":29,"pid":0.47720356768311545,"min":0,"max":2,"optional":false},"ml":{"id":"ml","type":"string","placeholder":"(Structural Connectome Attribute): Minimum Fiber Length","advanced":false,"desc":"(Metaparameter): Include this flag to manually specify a minimum tract length (mm) for dmri connectome tracking. Default is 20. Safe range: [0-150]. Depending on the tissue classifier used and the restrictiveness of the parcellation or any way-masking, values >100mm may fail if you are not tracking across nodes where long-range association fibers are to be expected biologically.","default":"0 30 60","_order":30,"pid":0.46599715958222143,"multiline":true,"optional":false},"em":{"id":"em","type":"string","placeholder":"(Structural Connectome Attribute): Node-Fiber Tolerance Distance","advanced":false,"desc":"(Metaparameter): Distance (in the units of the streamlines, usually mm). If any coordinate in the streamline is within this distance from the center of any voxel in the ROI, the filtering criterion is set to `True` for this streamline, otherwise False. Defaults to the distance between the center of each voxel and the corner of the voxel. Default is 8. Safe range: [0-15].","default":"5 10 15","_order":31,"pid":0.9117147792270628,"multiline":true,"optional":false},"hp":{"id":"hp","type":"string","placeholder":"(Functional Connectome Attribute): High-Pass Filter Threshold","advanced":false,"desc":"Optionally specify high-pass filter thresholds to apply to node-extracted time-series for fMRI. Safe range: [0-0.15] for resting-state data.","default":"0 0.028 0.08","_order":32,"pid":0.23078401629995438,"multiline":true,"optional":false},"sm":{"id":"sm","type":"string","placeholder":"(Functional Connectome Attribute): Smoothing","advanced":false,"desc":"Optionally specify smoothing width(s) to apply to the node-extracted time-series for fMRI. Safe range: [0-8]","default":"0 3 6","_order":33,"pid":0.9167018201516992,"optional":false,"multiline":true},"spheres":{"id":"spheres","type":"boolean","placeholder":"","advanced":true,"desc":"Include this flag to use spheres instead of parcels as nodes. Safe range: [0-8]","default":false,"_order":34,"pid":0.6341376844482143},"bin":{"id":"bin","type":"boolean","placeholder":"","advanced":true,"desc":"Binarize the resulting graph such that edges are boolean and unweighted.","default":false,"_order":35,"pid":0.6516164458195213}},"inputs":[{"id":"anat","desc":"skull-stripped anatomical input","datatype":"58c33bcee13a50849b25879a","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5f1382ebcd745a1eba9c70a8"},{"id":"task","desc":"It should be in native/T1w space. Either task or dwi (or both) input should be present.","datatype":"59b685a08e5d38b0b331ddc5","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5f1382ebcd745a8b159c70a9"},{"id":"regressors","desc":"Confound regressor to reduce noise in the time-series estimation for the graph. If you include this, you should also include a bold functional image with an corresponding number of volumes.","datatype":"5c4f6a8af9109beac4b3dae0","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5f262cd7beafe9e290627231"},{"id":"dwi","desc":"Used for structural connectomes. Should be in native diffusion space. Either task or dwi (or both) input should be present.","datatype":"58c33c5fe13a50849b25879b","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5f1385d4cd745a2f7e9c71b3"},{"id":"mask","desc":"Optional binarized Nifti1Image in T1w space. This will be estimated automatically if not provided.","datatype":"5a281aee2c214c9ba83ce620","datatype_tags":["brain"],"optional":true,"multi":false,"advanced":false,"_id":"5f2899dbbeafe95ba6629c08"},{"id":"waymask","desc":"Binarized Nifti1Image ROI in MNI-space to constrain tractography.","datatype":"5be9ea0315a8683a39a1ebd9","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5f640df363571fd372cce4ce"},{"id":"uatlas","desc":"A volume parcellation file may be included instead of specifying a fetched or local atlas name as a configuration option.","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags":[],"optional":true,"multi":true,"advanced":false,"_id":"6080b4d189df43832666884d"}],"outputs":[{"id":"output","desc":"A base directory to save workflow outputs. ","datatype":"59c3eae633fc1cf9ead71679","datatype_tags":["derivatives"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5f1382ebcd745a76649c70ab"}],"github_branch":"v2.7","github":"brainlife/app-pynets","name":"PyNets","user_id":"822","contributors":[{"name":"Derek Pisner","email":null,"_id":"634a3f6462f3d3800f12cef6"},{"name":"Giulia Bertò","email":null,"_id":"634a3f6462f3d3800f12cef7"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a3f6462f3d3800f12cef8"}],"desc":"A Reproducible post-processing workflow for Structural and Functional Connectome Ensemble Learning. PyNets  leverages Nilearn and Dipy fMRI and dMRI libraries to specify any of a variety of methodological choices and sampling individual structural and functional connectome estimates. See https://pynets.readthedocs.io/","__v":3178,"avatar":"https://pynets.readthedocs.io/en/latest/_static/logo_small.png","desc_override":"A Reproducible Workflow for Structural and Functional Connectome Ensemble Learning","create_date":"2021-03-05T09:18:09.192Z","doi":"10.25663/brainlife.app.486","_canedit":true},{"_id":"5dc1c2e57f55b85a93bd3021","stats":{"stars":0,"serviceinfo":{"_id":"5dc211bf9c9bb24118b49b20","counts":{"_id":"5e5c3e2287cac79247ab143b","failed":4,"finished":3,"removed":6,"requested":9,"running":9,"running_sync":0,"stop_requested":2},"success_rate":42.857142857142854,"users":3,"readme_status":"ok","runtime_mean":4802304.333333333,"runtime_std":5130781.321276018,"service":"brainlife/app-qsiprep","__v":0},"success_rate":36.64815749621403,"users":20,"runtime_mean":27351352.9,"runtime_std":14433046.879300222,"requested":14005,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a377e62f3d3800f11e2c0"}],"examples":5,"groups":40},"projects":[],"admins":["16","41","146","1"],"tags":["pipeline","preprocessing"],"removed":false,"config":{"t1":{"type":"input","file_id":"t1","input_id":"t1"},"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"sbref":{"type":"input","file_id":"sbref","input_id":"dwi"},"sbref_json":{"type":"input","file_id":"sbref_json","input_id":"dwi"},"phasediff":{"type":"input","file_id":"phasediff","input_id":"fmap"},"phasediff_json":{"type":"input","file_id":"phasediff_json","input_id":"fmap"},"magnitude":{"type":"input","file_id":"magnitude","input_id":"fmap"},"magnitude_json":{"type":"input","file_id":"magnitude_json","input_id":"fmap"},"magnitude1":{"type":"input","file_id":"magnitude1","input_id":"fmap"},"magnitude1_json":{"type":"input","file_id":"magnitude1_json","input_id":"fmap"},"magnitude2":{"type":"input","file_id":"magnitude2","input_id":"fmap"},"magnitude2_json":{"type":"input","file_id":"magnitude2_json","input_id":"fmap"},"fieldmap":{"type":"input","file_id":"fieldmap","input_id":"fmap"},"fieldmap_json":{"type":"input","file_id":"fieldmap_json","input_id":"fmap"},"phase1":{"type":"input","file_id":"phase1","input_id":"fmap"},"phase1_json":{"type":"input","file_id":"phase1_json","input_id":"fmap"},"phase2":{"type":"input","file_id":"phase2","input_id":"fmap"},"phase2_json":{"type":"input","file_id":"phase2_json","input_id":"fmap"},"epi1":{"type":"input","file_id":"epi1","input_id":"fmap"},"epi1_json":{"type":"input","file_id":"epi1_json","input_id":"fmap"},"epi2":{"type":"input","file_id":"epi2","input_id":"fmap"},"epi2_json":{"type":"input","file_id":"epi2_json","input_id":"fmap"},"output_resolution":{"id":"output_resolution","type":"number","placeholder":"","advanced":false,"desc":"The isotropic voxel size in mm the data will be resampled to after preprocessing. NOTE: only dwi data will be resampled.","default":1.2,"_order":2,"pid":0.35526764015478984,"optional":false},"output_space":{"id":"output_space","type":"enum","placeholder":"","advanced":false,"desc":"Volume and surface spaces to resample dwis into. NOTE: If selecting T1w, the preprocessed T1w image defines the T1w space, not the native T1.  Reconstructed surfaces will be registered to the T1w space (ACPC), and not to the input images. WARNING: If selecting template, dwis will be still resampled to the T1w space (and not to the template).","default":"T1w","_order":3,"pid":0.8055917767896645,"options":[{"desc":"subject anatomical volume","label":"T1w","value":"T1w"},{"desc":"MNI space","label":"template","value":"MNI152NLin2009cAsym"}],"optional":false},"skipbidsvalidation":{"id":"skipbidsvalidation","type":"boolean","placeholder":"","advanced":false,"desc":"Skip the BIDS validation of input data. Try this option if your data is not BIDS compatible but you'd like to go ahead and process it through qsiprep anyway.","default":false,"_order":6,"pid":0.4306521392262499},"denoise_method":{"id":"denoise_method","type":"enum","placeholder":"","advanced":true,"desc":"Image-based denoising method.","default":"dwidenoise","_order":7,"pid":0.8221723374404504,"options":[{"desc":"“dwidenoise” (MRtrix)","label":"dwidenoise","value":"dwidenoise"},{"desc":"“patch2self” (DIPY)","label":"patch2self","value":"patch2self"},{"desc":"none","label":"none","value":"none"}],"optional":false},"distortion_group_merge":{"id":"distortion_group_merge","type":"enum","placeholder":"","advanced":true,"desc":"How to combine images across distorted groups (only in case of multi dwi inputs).  (at the moment only 'none' can be run).","default":"none","_order":8,"pid":0.41500661823980534,"options":[{"desc":"Default. Keep distorted groups separate.","label":"none","value":"none"},{"desc":"Average the corrected images of the same q-space coordinate.","label":"average","value":"average"},{"desc":"Append images in the 4th dimension.","label":"concat","value":"concat"}],"optional":false,"readonly":false},"unringing_method":{"id":"unringing_method","type":"enum","placeholder":"","advanced":true,"desc":"Method for Gibbs-ringing removal.","default":"none","_order":9,"pid":0.6339275958261315,"options":[{"desc":"no action","label":"none","value":"none"},{"desc":"use mrdegibbs from mrtrix3","label":"mrdegibbs","value":"mrdegibbs"}],"optional":false},"hmc_transform":{"id":"hmc_transform","type":"enum","placeholder":"","advanced":true,"desc":"Transformation to be optimized during head motion correction.","default":"Affine","_order":10,"pid":0.9855965618710476,"options":[{"desc":"","label":"Affine","value":"Affine"},{"desc":"","label":"Rigid","value":"Rigid"}],"optional":false},"infant":{"id":"infant","type":"boolean","placeholder":"","advanced":true,"desc":"Configure pipelines to process infant brains.","default":false,"_order":11,"pid":0.6551053494582575},"syn_sdc":{"id":"syn_sdc","type":"boolean","placeholder":"","advanced":true,"desc":"EXPERIMENTAL:  Use fieldmap-free distortion correction.","default":false,"_order":12,"pid":0.4124102827470333},"force_syn":{"id":"force_syn","type":"boolean","placeholder":"","advanced":true,"desc":"EXPERIMENTAL/TEMPORARY:  Use SyN correction in addition to fieldmap correction, if available.","default":false,"_order":13,"pid":0.5753533083143205},"xflip":{"id":"xflip","type":"boolean","placeholder":"","advanced":true,"desc":"Save output bvecs in MRtrix-style. If false (default), bvecs will be saved in FSL-style and will be compatible with DIPY and DSI Studio.","default":false,"_order":16,"pid":0.37205024338471193}},"inputs":[{"id":"t1","desc":"T1 anatomical image.","datatype":"58c33bcee13a50849b25879a","datatype_tags":["!qsiprep"],"optional":false,"multi":false,"advanced":false,"_id":"5dc1c2e57f55b8d0b9bd3023"},{"id":"dwi","desc":"DWI volume(s). If you input a second DWI, be sure that it has an opposite Phase Encoding Direction than the first DWI. At the moment, no more than 2 DWIs can be selected.","datatype":"58c33c5fe13a50849b25879b","datatype_tags":["!qsiprep","!preprocessed"],"optional":false,"multi":true,"advanced":false,"_id":"6022a515ab40ca1bc14c8aa1"},{"id":"fmap","desc":"fieldmap","datatype":"5c390505f9109beac42b00df","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"603e837778e65d55dcd711c5"}],"outputs":[{"id":"output_dwi","datatype":"58c33c5fe13a50849b25879b","datatype_tags":["qsiprep","preprocessed"],"datatype_tags_pass":"dwi","output_on_root":false,"files":null,"archive":true,"_id":"5dc1c2e57f55b84540bd3028"},{"id":"output_anat_preproc","datatype":"58c33bcee13a50849b25879a","datatype_tags":["qsiprep","preprocessed","brain_extracted"],"datatype_tags_pass":"t1","output_on_root":false,"files":null,"archive":true,"_id":"5dc1c2e57f55b836e7bd3027"},{"id":"output_dseg","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags":["qsiprep"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5dc1c2e57f55b83c09bd3026"},{"id":"output_brainmask","datatype":"5a281aee2c214c9ba83ce620","datatype_tags":["brain","anat","qsiprep"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5dc1c2e57f55b83f62bd3025"},{"id":"output_report","datatype":"5e56dc330f7fa604cc3cc291","datatype_tags":["qsiprep"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"60269814dea2e22a24793740"},{"id":"regressors","datatype":"5c4f6a8af9109beac4b3dae0","datatype_tags":["qsiprep"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"62336a615d8ab5d5f03d5a54"},{"id":"dwiqc","desc":"raw directory containing dwi QC reports in dwiqc.json","datatype":"59c3eae633fc1cf9ead71679","datatype_tags":["dwiqc"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"624785f75d8ab5d5f067b7b8"}],"github_branch":"0.13.0RC1-1","github":"brainlife/app-qsiprep","name":"QSIPrep - Preprocessing workflow","desc_override":"","user_id":"1","contributors":[{"name":"Giulia Bertò","email":null,"_id":"634a377e62f3d3800f11e2c1"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a377e62f3d3800f11e2c2"},{"name":"Brad Caron","email":null,"_id":"634a377e62f3d3800f11e2c3"},{"name":"Franco Pestilli","email":null,"_id":"634a377e62f3d3800f11e2c4"}],"create_date":"2019-11-05T18:43:49.856Z","desc":"Preprocessing of diffusion MRI data. It includes automatically generated preprocessing pipelines that correctly group, distortion correct, motion correct, denoise, coregister and resample your scans, producing visual reports and QC metrics.","doi":"10.25663/brainlife.app.246","__v":6623,"_canedit":true},{"_id":"5eefdb0b78d63f4c2fd37637","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3c2a62f3d3800f127c51"}],"success_rate":54.166666666666664,"users":1,"runtime_mean":97084.23076923077,"runtime_std":90349.81698176845,"requested":24,"examples":1,"groups":2},"projects":[],"admins":["283"],"tags":[],"removed":false,"config":{"output":{"type":"input","file_id":"output","input_id":"fs"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":true,"advanced":false,"_id":"5eefdb0b78d63f70e2d37638","id":"fs","datatype":"58cb22c8e13a50849b25882e"}],"outputs":[{"datatype_tags":["qoala-t"],"output_on_root":false,"archive":true,"_id":"5f8779f8e6432dd82e92ed92","id":"Output_Qoala_T","datatype":"5ed53b69da664506f88e6df9","datatype_tags_pass":null,"files":null}],"github_branch":"master","github":"davhunt/app-qoala-t-model-a","name":"Qoala-T Model A","user_id":"283","contributors":[{"name":"David Hunt","email":"davhunt@iu.edu","_id":"634a3c2a62f3d3800f127c52"}],"create_date":"2020-06-21T22:11:23.410Z","desc":"Predicting scan Qoala-T score by using Braintime model","doi":"10.25663/brainlife.app.386","__v":4573,"_canedit":true},{"_id":"599f2c0a1a12b6002f642c74","name":"Quantitative Statistics of Classified Fiber Tracts","desc":"This will give you the fiber count, mean length, standard deviation of length, total length, and volume of each fiber tract classified by AFQ or WMA.","github":"brainlife/app-classifiedfibertractstats","github_branch":"1.1","config":{"afq_fg":{"type":"input","file_id":"output","input_id":"AFQ"}},"user_id":"43","create_date":"2017-08-24T19:42:02.143Z","removed":false,"_rate":5,"outputs":[{"id":"output","datatype":"599f305ad1f46fec1759f363","datatype_tags":[],"output_on_root":false,"files":null,"archive":true,"_id":"599f2c0a1a12b6002f642c75"}],"inputs":[{"id":"AFQ","datatype":"58f10a90436ee50ffd9063c5","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"599f2c0a1a12b6002f642c76"}],"tags":[],"admins":["16","56","41","146","43","1"],"__v":14288,"contributors":[{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a311762f3d3800f116662"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a311762f3d3800f116663"}],"projects":[],"references":[],"stats":{"stars":0,"requested":5,"users":2,"success_rate":100,"serviceinfo":{"_id":"5d729e1f78356a109788b30d","counts":{"_id":"5e5c688487cac7cb91ab1baa","failed":389,"finished":12137,"removed":14521,"requested":17185,"running":12486,"running_sync":0,"stop_requested":32},"success_rate":96.89445952418968,"users":15,"readme_status":"ok","runtime_mean":1497857.82,"runtime_std":4074154.7970297043,"service":"kitchell/app-classifiedfibertractstats","__v":0},"gitinfo":{"desc":"This will give you the fiber count, mean length, standard deviation of length, total length, and volume of each fiber tract classified by AFQ or WMA.","tags":["analysis"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null}]},"runtime_mean":26105.5,"runtime_std":5268.568330201289,"resources":[],"examples":1,"groups":2},"doi":"10.25663/bl.app.12","deprecated_by":"5cc9c6b44b5e4502275edb4b","_canedit":true},{"_id":"5aac2437f0b5260027e24ae1","name":"RACE-Track | MRTrix3 Anatomical Informed Tractography","desc":"Runs mrtrix3 ACT (Anatomically Constrained Tractography) using either single- or multi-shell diffusion-weighted MRI data. ","citation":null,"github":"brainlife/app-mrtrix3-act","github_branch":"1.4","config":{"bvec":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bval":{"type":"input","file_id":"bvals","input_id":"dwi"},"diff":{"type":"input","file_id":"dwi","input_id":"dwi"},"anat":{"type":"input","file_id":"t1","input_id":"anat"},"tensor_fit":{"optional":true,"default":"","desc":"If multi-shell data is passed, this selects the shell that will be extracted and have a tensor fit performed\n\nIf single-shell data is passed, this is ignored","placeholder":"","type":"string","id":"tensor_fit","pid":0.39541970724428177,"_order":2},"norm":{"default":false,"desc":"perform log-domain normalization of CSD data before tracking (multi-shell data only)","placeholder":"","type":"boolean","id":"norm","pid":0.24734864840034665,"_order":3},"min_length":{"default":"10","desc":"the minimum length a streamline may be","placeholder":"","type":"string","id":"min_length","pid":0.6349942651119325,"_order":4},"max_length":{"default":"200","desc":"the maximum length a streamline may be","placeholder":"","type":"string","id":"max_length","pid":0.32846126416280486,"_order":5},"imaxs":{"default":"","desc":"The lmax(s) or maximum value to fit and create tractography data. If not provided,  the App will find the maximum possible lmax within the data and use that.","placeholder":"","type":"string","id":"imaxs","pid":0.3013318459208867,"_order":6,"optional":true},"ens_lmax":{"default":true,"desc":"perform ensemble tracking on every lmax up to the maximum value passed","placeholder":"","type":"boolean","id":"ens_lmax","pid":0.004250776089096631,"_order":7},"curvs":{"default":"5 10 20 40 80","desc":"the maximum curvature angle streamline can take during tracking","placeholder":"","type":"string","id":"curvs","pid":0.4282261289529081,"_order":8},"num_fibers":{"default":"15000","desc":"the number of streamlines to produce per parameter combination","placeholder":"","type":"string","id":"num_fibers","pid":0.10094898444608336,"_order":9},"do_dtdt":{"default":true,"desc":"perform tensor-based deterministic tractography","placeholder":"","type":"boolean","id":"do_dtdt","pid":0.9853568711397678,"_order":10},"do_dtpb":{"default":false,"desc":"perform tensor-based probabilistic tractography","placeholder":"","type":"boolean","id":"do_dtpb","pid":0.5814919999307471,"_order":11},"do_detr":{"default":true,"desc":"perform deterministic tractography","placeholder":"","type":"boolean","id":"do_detr","pid":0.17004659915421239,"_order":12},"do_prb1":{"default":false,"desc":"perform mrtrix2 probabilistic tractography","placeholder":"","type":"boolean","id":"do_prb1","pid":0.41632173478288625,"_order":13},"do_prb2":{"default":true,"desc":"perform mrtrix3 probabilistic tractography","placeholder":"","type":"boolean","id":"do_prb2","pid":0.9948206840500884,"_order":14},"do_fact":{"id":"do_fact","type":"boolean","placeholder":"","desc":"Perform FACT tracking","default":false,"_order":15,"pid":0.2833593919402324},"fact_dirs":{"id":"fact_dirs","type":"number","placeholder":"3","desc":"The number of directions to perform FACT tracking on.","default":3,"_order":16,"pid":0.6317440381372841,"min":1,"max":5},"fact_fibs":{"id":"fact_fibs","type":"number","placeholder":"","desc":"The number of FACT fibers to track per lmax.","default":0,"_order":17,"pid":0.4633961466944505,"min":0,"max":1000000,"optional":true},"premask":{"id":"premask","type":"boolean","placeholder":"","advanced":true,"desc":"If the input anatomical T1s have already been skull stripped, check this to prevent 5ttgen from cutting off a portion of the brain.  (This sets -premasked option for 5ttgens)","default":false,"_order":18,"pid":0.25459165415005924}},"user_id":"19","create_date":"2018-03-16T20:08:23.804Z","removed":false,"_rate":0,"outputs":[{"id":"tracking","datatype":"5907d922436ee50ffde9c549","datatype_tags":[],"output_on_root":true,"files":null,"archive":true,"_id":"5aac2437f0b5260027e24ae3"},{"id":"tensor","datatype":"5a79df48d071a1753f1d661b","datatype_tags":[],"output_on_root":true,"files":{"tensors":"tensor.nii.gz"},"archive":true,"_id":"5aac2437f0b5260027e24ae2"},{"id":"csd","datatype":"5c536bf0f9109beac46adb45","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":true,"files":null,"archive":true,"_id":"5c536e10405b850032979e46"}],"inputs":[{"id":"dwi","datatype":"58c33c5fe13a50849b25879b","datatype_tags":["preprocessed"],"optional":false,"multi":false,"advanced":false,"_id":"5aac2437f0b5260027e24ae5"},{"id":"anat","datatype":"58c33bcee13a50849b25879a","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5aac2437f0b5260027e24ae4"}],"contributors":[{"name":"Brent McPherson","email":"bcmcpher@gmail.com","_id":"634a325962f3d3800f1174d5"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a325962f3d3800f1174d6"},{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a325962f3d3800f1174d7"},{"name":"Franco Pestilli","email":null,"_id":"634a325962f3d3800f1174d8"},{"name":"Brad Caron","email":null,"_id":"634a325962f3d3800f1174d9"},{"name":"Anibal Sólon","email":"anibalsolon@gmail.com","_id":"634a325962f3d3800f1174da"}],"tags":["tracking","tractography"],"references":[],"admins":["19","16","146"],"projects":[],"__v":14236,"stats":{"stars":0,"requested":16087,"users":51,"success_rate":48.09201623815967,"serviceinfo":{"_id":"5d729e1f78356a109788b299","counts":{"_id":"5e5c68a587cac70559ab1bd1","failed":3479,"finished":10104,"removed":17081,"requested":19150,"running":13580,"running_sync":0,"stop_requested":1002},"success_rate":74.38710152396378,"users":26,"readme_status":"too short","runtime_mean":3527763.1,"runtime_std":2413346.823899846,"service":"brain-life/app-mrtrix3-act","__v":0},"gitinfo":{"desc":"Runs mrtrix3 ACT (Anatomically Constrained Tractography) using either single- or multi-shell diffusion-weighted MRI data. ","tags":["tracking","tractography"],"stats":{"stars":0},"contributors":[{"name":"Brent McPherson","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":23600497.98,"runtime_std":25578287.666498195,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a325862f3d3800f1174d3"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a325862f3d3800f1174d4"}],"examples":5,"groups":103},"doi":"10.25663/bl.app.101","_canedit":true},{"_id":"5cb0c93f454d3c00353fa0d3","stats":{"stars":0,"requested":84,"users":2,"success_rate":70.37037037037037,"serviceinfo":{"_id":"5d729e1e78356a109788b221","counts":{"_id":"5e5c3df087cac7b042ab1404","failed":23,"finished":57,"removed":56,"requested":82,"running":82,"running_sync":0,"stop_requested":2},"success_rate":71.25,"users":1,"readme_status":"no README.md","runtime_mean":140748.50877192983,"runtime_std":183446.30834882264,"service":"giulia-berto/app-plot-roc-curve","__v":0},"gitinfo":{"desc":null,"tags":[],"stats":{"stars":0},"contributors":[{"name":"Giulia Bertò","email":null}]},"runtime_mean":140748.50877192983,"runtime_std":183446.30834882264,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a35a162f3d3800f11a20f"}],"examples":0,"groups":2},"projects":[],"admins":["1","146"],"tags":[],"removed":false,"config":{"measures":{"type":"input","file_id":"csv","input_id":"0"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":true,"advanced":false,"_id":"5cb0c93f454d3c00353fa0d4","id":"0","datatype":"599f305ad1f46fec1759f363","desc":"csv file reporting fdr, tdr and AUC for multi-LAP and multi-NN"}],"outputs":[{"datatype_tags":[],"output_on_root":true,"archive":true,"_id":"5cb0c93f454d3c00353fa0d5","id":"1","datatype":"5967b799b09297d8d831709e","datatype_tags_pass":"0","files":null}],"github_branch":"1.0","github":"giulia-berto/app-plot-roc-curve","name":"ROC curve (deprecated)","user_id":"146","contributors":[{"name":"Giulia Bertò","email":null,"_id":"634a35a162f3d3800f11a210"}],"create_date":"2019-04-12T17:22:07.626Z","desc":null,"doi":"10.25663/brainlife.app.180","__v":8288,"desc_override":"Plot ROC-AUC curve for multi-LAP and multi-NN. Warning: this app can be run ONLY after the app https://doi.org/10.25663/brainlife.app.174.  This App was used specifically for a Replicability Study and has been deprecated.","_canedit":true},{"_id":"5ea9e8fd0efebf12de1984ee","projects":[],"admins":["16"],"tags":[],"removed":false,"stats":{"success_rate":83.41739577972209,"users":25,"runtime_mean":799849.04,"runtime_std":1408516.1455727932,"requested":12365,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3a4762f3d3800f12374d"},{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a3a4762f3d3800f12374e"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3a4762f3d3800f12374f"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"634a3a4762f3d3800f123750"}],"examples":0,"groups":53},"config":{"dtiinit":{"type":"input","file_id":"output","input_id":"dtiinit"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"parc":{"type":"input","file_id":"parc","input_id":"parcellation"},"key":{"type":"input","file_id":"key","input_id":"parcellation"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"prfDir":{"type":"input","file_id":"varea","input_id":"prf"},"parcellationROIs":{"id":"parcellationROIs","type":"string","placeholder":"","advanced":false,"desc":"If a non-freesurfer parcellation is used, enter ROI numbers from key.txt (parcellation) ROIs wanted.\n\nExample: 45,54\n\nROIs will be outputted with following name format to avoid complications with other parcellations and similar ROI numbers: ROI#.nii.gz, with # being the number of the ROI","default":"","_order":2,"pid":0.87240878797892,"optional":true},"subcorticalROIs":{"id":"subcorticalROIs","type":"string","placeholder":"","advanced":false,"desc":"Enter the number of the subcortical ROI (if wanted).\n\nROIs will be outputted with following name format to avoid complications with other parcellations and similar ROI numbers: ROI0#.nii.gz, with # being the number of the ROI. Please note the leading 0.","default":"","_order":3,"pid":0.8219745489461137,"optional":true},"thalamicROIs":{"id":"thalamicROIs","type":"string","placeholder":"","advanced":false,"desc":"If thalamic nuclei segmentation from freesurfer is used, enter the number of the thalamic ROI (if wanted).\n\nPlease refer to this color lut (https://github.com/freesurfer/freesurfer/blob/dev/ThalamicNuclei/compressionLookupTable.txt) and your thalamic segmentation for specific ROI numbers\n\nROIs will be outputted with following name format to avoid complications with other parcellations and similar ROI numbers: ROI00#.nii.gz, with # being the number of the ROI. Please note the leading 00.","default":"","_order":4,"pid":0.9694067188862432,"optional":true},"prfROIs":{"id":"prfROIs","type":"string","placeholder":"","advanced":false,"desc":"If a visual area segmentation from a PRF mapping app is used, enter the number of the visual field ROI (if wanted).\n\nPlease refer to visual area segmentation from the PRF to determine ROI numbers.\n\nROIs will be outputted with following name format to avoid complications with other parcellations and similar ROI numbers: ROI000#.nii.gz, with # being the number of the ROI. Please note the leading 000.","default":"","_order":5,"pid":0.6856091645384299,"optional":true},"freesurferROIs":{"id":"freesurferROIs","type":"string","placeholder":"","advanced":false,"desc":"If ROIs from the freesurfer segmentation is desired, enter the number of the ROI from the freesurfer colorLUT.\n\nROIs will be outputted with following name format to avoid complications with other parcellations and similar ROI numbers: ROI0000#.nii.gz, with # being the number of the ROI. Please note the leading 0000.","default":"","_order":6,"pid":0.23210304079871769,"optional":true},"mergeROIsL":{"id":"mergeROIsL","type":"string","placeholder":"","advanced":false,"desc":"Left hemisphere ROI numbers you would like to merge into a single ROI","default":"","_order":7,"pid":0.8469736931074379,"optional":true},"mergeROIsR":{"id":"mergeROIsR","type":"string","placeholder":"","advanced":false,"desc":"Right hemisphere ROI numbers you would like to merge into a single ROI","default":"","_order":8,"pid":0.49244697283062466,"optional":true},"mergename":{"id":"mergename","type":"string","placeholder":"","advanced":false,"desc":"Name for the ROI that you would like merged. The output will be in the following format: ROI${mergename}.nii.gz","default":"","_order":9,"pid":0.7453144900773119,"optional":true},"parcInflate":{"id":"parcInflate","type":"number","placeholder":"","advanced":false,"desc":"if parcellation ROI inflation into WM is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":null,"_order":10,"pid":0.9969991743107101,"optional":true},"thalamusInflate":{"id":"thalamusInflate","type":"number","placeholder":"","advanced":false,"desc":"if ROI inflation into WM for thalamus segmentation is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":null,"_order":11,"pid":0.9594641571910207,"optional":true},"visInflate":{"id":"visInflate","type":"number","placeholder":"","advanced":false,"desc":"if ROI inflation into WM for visual area segmentation is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":null,"_order":12,"pid":0.2742711662185746,"optional":true},"freesurferInflate":{"id":"freesurferInflate","type":"number","placeholder":"","advanced":false,"desc":"if ROI inflation into WM for freesurfer segmentation is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":null,"_order":13,"pid":0.5891071732152147,"optional":true},"inputparc":{"id":"inputparc","type":"enum","placeholder":"","advanced":false,"desc":"The freesurfer parcellation to use","default":"aparc","_order":14,"pid":0.13626610585769616,"options":[{"desc":"Desikan-Killiany Atlas","label":"aparc","value":"aparc"},{"desc":"Destrieux Atlas","label":"aparc.a2009s","value":"aparc.a2009s"},{"desc":"DKT Atlas","label":"aparc.DKTatlas","value":"aparc.DKTatlas"}]},"whitematter":{"id":"whitematter","type":"boolean","placeholder":"","advanced":false,"desc":"If you want to include the white matter in the inflation, which will limit the amount of inflation into the white matter, select 'true'.  However, selecting 'false' will trim the white matter, which may eliminate some potential ROIs.","default":true,"_order":15,"pid":0.6620525258221301}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5dbb497c8aeeee9e8df34e7a","id":"dtiinit","datatype":"58cb234be13a50849b25882f","desc":"Specify this if you want to use dtiinit preprocessed dwi data. If you specify, this App will use dti/bin/brainMask.nii.gz for brainmask. "},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5dbb497c8aeeee77fef34e79","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e","desc":"If you want thalamic ROIs, make sure to use the output from app-segment-thalamic-nuclei"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5dbb497c8aeeee5680f34e78","id":"parcellation","datatype":"5c1a7489f9109beac4a88a1f","desc":"The path to the parcellation/volume datatype (optional)"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5dbb497c8aeeeef56df34e77","id":"mask","datatype":"5a281aee2c214c9ba83ce620","desc":"Specify this if you want to use your custom brainmask. If neither dtiinit nor brainmask is specified, this App will create brainmask from your dwi input using FSL bet."},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5dbb497c8aeeee7339f34e76","id":"prf","datatype":"5d9d18d8e30ae43bb0612715","desc":"Specify prf input if you want to generate ROIs from the PRF/varea parcellation."}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5dbb497c8aeeeef269f34e7d","id":"parc","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags_pass":null,"files":null,"desc":"Parcellation nifti with all of the ROIs merged"},{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5dbb497c8aeeeeb60bf34e7c","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9","datatype_tags_pass":null,"files":null,"desc":"Directory containing all of the ROIs generated"}],"github_branch":"master","github":"brainlife/app-roiGenerator","name":"ROI Generation (merge) - dtiInit","user_id":"1","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3a4762f3d3800f123751"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a3a4762f3d3800f123752"},{"name":"Franco Pestilli","email":null,"_id":"634a3a4762f3d3800f123753"}],"desc":"Generate a parcellation volume (and roi nifti files split into each label) for specific ROIs, or every ROI, for a parcellation from freesurfer output and/or input parcellation volume. This App can also inflate input parcellation volume toward non-white matter voxels.","__v":4994,"create_date":"2020-04-29T20:52:13.937Z","doi":"10.25663/brainlife.app.334","deprecated_by":"5ec29d1641ba11e054f3edc1","_canedit":true},{"_id":"5da537382b4f67d8f7e67166","stats":{"stars":0,"serviceinfo":{"_id":"5d729e1f78356a109788b2b7","counts":{"_id":"5e5c3e1a87cac77086ab1433","failed":788,"finished":6048,"removed":7078,"requested":7656,"running":6617,"running_sync":0,"stop_requested":49},"success_rate":88.47279110590989,"users":12,"readme_status":"ok","runtime_mean":5580586.29,"runtime_std":23419021.556393724,"service":"brain-life/app-roiGenerator","__v":0},"success_rate":83.41739577972209,"users":25,"runtime_mean":799849.04,"runtime_std":1408516.1455727932,"requested":12365,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a373962f3d3800f11d582"},{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a373962f3d3800f11d583"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a373962f3d3800f11d584"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"634a373962f3d3800f11d585"}],"examples":0,"groups":53},"projects":[],"admins":["16"],"tags":[],"removed":false,"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"dtiinit":{"type":"input","file_id":"output","input_id":"dtiinit"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"parc":{"type":"input","file_id":"parc","input_id":"parcellation"},"key":{"type":"input","file_id":"key","input_id":"parcellation"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"prfDir":{"type":"input","file_id":"varea","input_id":"prf"},"parcellationROIs":{"id":"parcellationROIs","type":"string","placeholder":"","advanced":false,"desc":"If a non-freesurfer parcellation is used, enter ROI numbers from key.txt (parcellation) ROIs wanted.\n\nExample: 45,54\n\nROIs will be outputted with following name format to avoid complications with other parcellations and similar ROI numbers: ROI#.nii.gz, with # being the number of the ROI","default":"","_order":2,"pid":0.4922604790420946,"optional":true},"subcorticalROIs":{"id":"subcorticalROIs","type":"string","placeholder":"","advanced":false,"desc":"Enter the number of the subcortical ROI (if wanted).\n\nROIs will be outputted with following name format to avoid complications with other parcellations and similar ROI numbers: ROI0#.nii.gz, with # being the number of the ROI. Please note the leading 0.","default":"","_order":3,"pid":0.022280538683508988,"optional":true},"thalamicROIs":{"id":"thalamicROIs","type":"string","placeholder":"","advanced":false,"desc":"If thalamic nuclei segmentation from freesurfer is used, enter the number of the thalamic ROI (if wanted).\n\nPlease refer to this color lut (https://github.com/freesurfer/freesurfer/blob/dev/ThalamicNuclei/compressionLookupTable.txt) and your thalamic segmentation for specific ROI numbers\n\nROIs will be outputted with following name format to avoid complications with other parcellations and similar ROI numbers: ROI00#.nii.gz, with # being the number of the ROI. Please note the leading 00.","default":"","_order":4,"pid":0.6921438921718792,"optional":true},"prfROIs":{"id":"prfROIs","type":"string","placeholder":"","advanced":false,"desc":"If a visual area segmentation from a PRF mapping app is used, enter the number of the visual field ROI (if wanted).\n\nPlease refer to visual area segmentation from the PRF to determine ROI numbers.\n\nROIs will be outputted with following name format to avoid complications with other parcellations and similar ROI numbers: ROI000#.nii.gz, with # being the number of the ROI. Please note the leading 000.","default":"","_order":5,"pid":0.2050943970774708,"optional":true},"freesurferROIs":{"id":"freesurferROIs","type":"string","placeholder":"","advanced":false,"desc":"If ROIs from the freesurfer segmentation is desired, enter the number of the ROI from the freesurfer colorLUT.\n\nROIs will be outputted with following name format to avoid complications with other parcellations and similar ROI numbers: ROI0000#.nii.gz, with # being the number of the ROI. Please note the leading 0000.","default":"","_order":6,"pid":0.7895665539254881,"optional":true},"parcInflate":{"id":"parcInflate","type":"number","placeholder":"","advanced":false,"desc":"if parcellation ROI inflation into WM is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":null,"_order":7,"pid":0.11573444446664793,"optional":true,"min":""},"thalamusInflate":{"id":"thalamusInflate","type":"number","placeholder":"","advanced":false,"desc":"if ROI inflation into WM for thalamus segmentation is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":null,"_order":8,"pid":0.8980134960248802,"optional":true,"min":""},"visInflate":{"id":"visInflate","type":"number","placeholder":"","advanced":false,"desc":"if ROI inflation into WM for visual area segmentation is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":null,"_order":9,"pid":0.6113903991656247,"optional":true,"min":""},"freesurferInflate":{"id":"freesurferInflate","type":"number","placeholder":"","advanced":false,"desc":"if ROI inflation into WM for freesurfer segmentation is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":null,"_order":11,"pid":0.6302734428200518,"optional":true},"inputparc":{"id":"inputparc","type":"enum","placeholder":"","advanced":false,"desc":"Freesurfer parcellation","default":"","_order":12,"pid":0.9137737546998328,"options":[{"desc":"Desikan-Killiany Atlas","label":"aparc","value":"aparc"},{"desc":"Destrieux Atlas","label":"aparc.a2009s","value":"aparc.a2009s"},{"desc":"DKT Atlas","label":"aparc.DKTatlas","value":"aparc.DKTatlas"}]},"whitematter":{"id":"whitematter","type":"boolean","placeholder":"","advanced":false,"desc":"If you want to include the white matter in the inflation, which will limit the amount of inflation into the white matter, select 'true'.  However, selecting 'false' will trim the white matter, which may eliminate some potential ROIs.","default":false,"_order":13,"pid":0.5290311350731534}},"inputs":[{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5da537382b4f6746bde6716b","id":"dwi","datatype":"58c33c5fe13a50849b25879b","desc":"If not using dtiinit, must input dwi"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5da537382b4f677166e6716a","id":"dtiinit","datatype":"58cb234be13a50849b25882f","desc":"If not using dwi, must input dtiinit"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5da537382b4f67267ae67169","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e","desc":"If you want thalamic ROIs, make sure to use the output from app-segment-thalamic-nuclei"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5da537382b4f6731f1e67168","id":"parcellation","datatype":"5c1a7489f9109beac4a88a1f","desc":"If you want to use a different atlas not provided by Freesurfer (i.e. hcp-mmp-b), please input a parcellation datatype. Otherwise, just the Freesurfer will suffice"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5da537382b4f673889e67167","id":"mask","datatype":"5a281aee2c214c9ba83ce620","desc":"If you don't want a brainmask generated by FSL bet, please input a brainmask"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5dacd11c5d19163fe4202e94","id":"prf","datatype":"5d9d18d8e30ae43bb0612715","desc":"PRF data (temporary placeholder until datatype is finalized)"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5da537382b4f675df3e6716d","id":"parc","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags_pass":null,"files":null,"desc":"Parcellation nifti with all ROIs"},{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5da537382b4f67ac47e6716c","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9","datatype_tags_pass":null,"files":null,"desc":"Directory containing all ROIs"}],"github_branch":"pre_merge","github":"brainlife/app-roiGenerator","name":"ROI Generation (no merge)","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a373962f3d3800f11d586"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a373962f3d3800f11d587"},{"name":"Franco Pestilli","email":null,"_id":"634a373962f3d3800f11d588"}],"create_date":"2019-10-15T03:04:24.459Z","desc":"Generate a parcellation volume (and roi nifti files split into each label) for specific ROIs, or every ROI, for a parcellation from freesurfer output and/or input parcellation volume. This App can also inflate input parcellation volume toward non-white matter voxels.","doi":"10.25663/brainlife.app.235","__v":6744,"deprecated_by":"5dbb497c8aeeee769af34e75","_canedit":true},{"_id":"5c54d89912cbcc01e1635aeb","stats":{"stars":0,"serviceinfo":{"_id":"5d729e1f78356a109788b2b7","counts":{"_id":"5e5c3ddd87cac71c73ab13ee","failed":788,"finished":6048,"removed":7078,"requested":7656,"running":6617,"running_sync":0,"stop_requested":49},"success_rate":88.47279110590989,"users":12,"readme_status":"ok","runtime_mean":5580586.29,"runtime_std":23419021.556393724,"service":"brain-life/app-roiGenerator","__v":0},"gitinfo":{"desc":"This app will generate nifti files for specific ROIs, or every ROI, for a parcellation (either freesurfer or atlas).","tags":[],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"success_rate":83.41739577972209,"users":25,"runtime_mean":799849.04,"runtime_std":1408516.1455727932,"requested":12365,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a34ed62f3d3800f118ed9"},{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a34ed62f3d3800f118eda"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a34ed62f3d3800f118edb"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"634a34ed62f3d3800f118edc"}],"examples":0,"groups":53},"projects":[],"admins":["135","16"],"tags":[],"removed":false,"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"parc":{"type":"input","file_id":"parc","input_id":"parcellation"},"key":{"type":"input","file_id":"key","input_id":"parcellation"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"ROI":{"id":"ROI","type":"string","placeholder":"","advanced":false,"desc":"Enter ROI numbers from Freesurfer colorLUT (https://surfer.nmr.mgh.harvard.edu/fswiki/FsTutorial/AnatomicalROI/FreeSurferColorLUT) and/or key.txt (parcellation) for the cortical ROIs wanted. This App assumes that label number will not collide between Freesurfer and parcellation key.txt.\n\nExample: 45,54","default":"","_order":3,"pid":0.6294993177020487},"subcort":{"id":"subcort","type":"string","placeholder":"","advanced":false,"desc":"Enter the number of the subcortical ROI (if wanted).\n\nSubcortical ROIs will be outputted with a leading 0 before the number (i.e. ROI012) for subcortical ROI 12. This is in order to avoid repetition in numbers between cortical and subcortical LUTs","default":"","_order":4,"pid":0.7354654799285867,"optional":true},"inflate":{"id":"inflate","type":"number","placeholder":"","desc":"If ROI inflation into WM is wanted, specify the number of inflated voxels desired.","default":0,"_order":6,"pid":0.38280027947363715,"optional":true},"inputparc":{"id":"inputparc","type":"enum","placeholder":"","desc":"Choose which Freesurfer parcellation to use as input","default":"aparc","_order":7,"pid":0.10128697954833754,"options":[{"desc":"Desikan-Killiany Atlas","label":"aparc","value":"aparc"},{"desc":"Destrieux Atlas","label":"aparc.a2009s","value":"aparc.a2009s"},{"desc":"DKT Atlas","label":"aparc.DKTatlas","value":"aparc.DKTatlas"}]},"whitematter":{"id":"whitematter","type":"boolean","placeholder":"","desc":"Leave this off to trim the INSET to exclude voxels in WM, excluding those which overlap an input WM                        skeleton, SKEL (see `-wm_skel', below; to trim off                        CSF, see separate `-csf_skel').  NB: trimming is done                        before volume thresholding the ROIs, so fewer ROIs                        might pass, or some input regions might be split                        apart creating a greater number of regions.","default":false,"_order":8,"pid":0.9029856469586424}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c54d89912cbcc01e1635aef","id":"dwi","datatype":"58c33c5fe13a50849b25879b","desc":"dwi image used to register freesurfer parcellation and white matter mask generated from it, as well as input parcellation volume (optional). "},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c54d89912cbcc01e1635aee","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e","desc":"Freesurfer is used to generate the white matter mask, as well as to generate the output ROI volumes if Freesurfer labels are specified for ROI input. "},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5c54d89912cbcc01e1635aed","id":"parcellation","datatype":"5c1a7489f9109beac4a88a1f","desc":"The parcellation input used to generate the output ROIs. It must contain voxels with corresponding ROI labels to be selected."},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5c54d89912cbcc01e1635aec","id":"mask","datatype":"5a281aee2c214c9ba83ce620","desc":"If specified, it will be used as white matter mask instead of using Freesurfer output. Only used if you are inflating the ROI. "}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5c54d89912cbcc01e1635af2","id":"parc","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags_pass":null,"files":null,"desc":"Parcellation nifti of all ROIs"},{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5c54d89912cbcc01e1635af1","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9","datatype_tags_pass":null,"files":null,"desc":"Copy of the parcellation/volume except each ROIs are split into different nifti files."}],"github_branch":"non_dtiinit","github":"brainlife/app-roiGenerator","name":"ROI Generation (old)","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a34ee62f3d3800f118edd"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a34ee62f3d3800f118ede"},{"name":"Franco Pestilli","email":null,"_id":"634a34ee62f3d3800f118edf"}],"create_date":"2019-02-01T23:39:05.808Z","desc":"Generate a parcellation volume (and roi nifti files split into each label) for specific ROIs, or every ROI, for a parcellation from freesurfer output and/or input parcellation volume. This App can also inflate input parcellation volume toward non-white matter voxels.","doi":"10.25663/brainlife.app.154","__v":8847,"deprecated_by":"5da537382b4f67d8f7e67166","_canedit":true},{"_id":"5d60ccf84cfacf00366c11cc","stats":{"stars":0,"serviceinfo":{"_id":"5d729e1f78356a109788b2b7","counts":{"_id":"5e5c3e1187cac7d75fab1428","failed":788,"finished":6048,"removed":7078,"requested":7656,"running":6617,"running_sync":0,"stop_requested":49},"success_rate":88.47279110590989,"users":12,"readme_status":"ok","runtime_mean":5580586.29,"runtime_std":23419021.556393724,"service":"brain-life/app-roiGenerator","__v":0},"gitinfo":{"desc":"This app will generate nifti files for specific ROIs, or every ROI, for a parcellation (either freesurfer or atlas).","tags":[],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"success_rate":83.41739577972209,"users":25,"runtime_mean":799849.04,"runtime_std":1408516.1455727932,"requested":12365,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a36e462f3d3800f11d171"},{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a36e462f3d3800f11d172"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a36e462f3d3800f11d173"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"634a36e462f3d3800f11d174"}],"examples":0,"groups":53},"projects":[],"admins":["16"],"tags":[],"removed":false,"config":{"t1":{"type":"input","file_id":"t1","input_id":"t1"},"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"parc":{"type":"input","file_id":"parc","input_id":"parcellation"},"key":{"type":"input","file_id":"key","input_id":"parcellation"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"ROI":{"id":"ROI","type":"string","placeholder":"","advanced":false,"desc":"Enter ROI numbers from key.txt (parcellation) or colorLUT (freesurfer) for the cortical ROIs wanted.\n\nExample: 45,54","default":"","_order":2,"pid":0.520970444829586,"optional":true},"subcort":{"id":"subcort","type":"string","placeholder":"","advanced":false,"desc":"Enter the number of the subcortical ROI (if wanted).\n\nSubcortical ROIs will be outputted with a leading 0 before the number (i.e. ROI012) for subcortical ROI 12. This is in order to avoid repetition in numbers between cortical and subcortical LUTs","default":"","_order":3,"pid":0.9351801258158599,"optional":true},"thalamus":{"id":"thalamus","type":"string","placeholder":"","advanced":false,"desc":"Enter the number of the thalamic ROI (if wanted).\n\nPlease refer to this color lut (https://github.com/freesurfer/freesurfer/blob/dev/ThalamicNuclei/compressionLookupTable.txt) and your thalamic segmentation for specific ROI numbers","default":"","_order":4,"pid":0.09523528178536766},"inflate":{"id":"inflate","type":"number","placeholder":"","advanced":false,"desc":"if ROI inflation into WM is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":null,"_order":5,"pid":0.7522251864849063,"optional":true},"thalamusInflate":{"id":"thalamusInflate","type":"number","placeholder":"","advanced":false,"desc":"if ROI inflation into WM for thalamus segmentation is wanted, specify the number of inflated voxels desired\n\nexample: 1","default":null,"_order":6,"pid":0.2170019072900764,"optional":true},"inputparc":{"id":"inputparc","type":"enum","placeholder":"","advanced":false,"desc":"Freesurfer parcellation","default":"aparc","_order":7,"pid":0.1753339599789534,"options":[{"desc":"Desikan-Killiany Atlas","label":"aparc","value":"aparc"},{"desc":"Destrieux Atlas","label":"aparc.a2009s","value":"aparc.a2009s"},{"desc":"DKT Atlas","label":"aparc.DKTatlas","value":"aparc.DKTatlas"}]},"whitematter":{"id":"whitematter","type":"boolean","placeholder":"","advanced":false,"desc":"include white matter roi","default":false,"_order":8,"pid":0.9902613046252646}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d60ccf84cfacf00366c11d1","id":"t1","datatype":"58c33bcee13a50849b25879a","desc":"The path to the anat/t1w datatype"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d60ccf84cfacf00366c11d0","id":"dwi","datatype":"58c33c5fe13a50849b25879b","desc":"The path to the DWI datatype"},{"datatype_tags":["thalamic_nuclei"],"optional":false,"multi":false,"advanced":false,"_id":"5d60ccf84cfacf00366c11cf","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e","desc":"The path to the freesurfer datatype"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5d60ccf84cfacf00366c11ce","id":"parcellation","datatype":"5c1a7489f9109beac4a88a1f","desc":"The path to the parcellation/volume datatype"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5d60ccf84cfacf00366c11cd","id":"mask","datatype":"5a281aee2c214c9ba83ce620","desc":"The path to the mask datatype containing the dwi brainmask"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5d60ccf84cfacf00366c11d3","id":"parc","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags_pass":null,"files":null,"desc":"Parcellation nifti containing all the ROIs"},{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5d60ccf84cfacf00366c11d2","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9","datatype_tags_pass":null,"files":null,"desc":"Directory containing all of the ROIs"}],"github_branch":"subthalamic","github":"brainlife/app-roiGenerator","name":"ROI Generation (thalamic nuclei)","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a36e462f3d3800f11d175"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a36e462f3d3800f11d176"},{"name":"Franco Pestilli","email":null,"_id":"634a36e462f3d3800f11d177"}],"create_date":"2019-08-24T05:36:56.074Z","desc":"Generate a parcellation volume (and roi nifti files split into each label) for specific ROIs, or every ROI, for a parcellation from freesurfer output and/or input parcellation volume. This App can also inflate input parcellation volume toward non-white matter voxels.","doi":"10.25663/brainlife.app.223","__v":7282,"deprecated_by":"5dbb497c8aeeee769af34e75","_canedit":true},{"_id":"5b061a2ad85b030192ff6ab4","doi":"10.25663/bl.app.37","stats":{"stars":0,"requested":12365,"users":25,"success_rate":83.41739577972209,"serviceinfo":{"_id":"5d729e1f78356a109788b2b7","counts":{"_id":"5e5c3da487cac765efab13b5","failed":788,"finished":6048,"removed":7078,"requested":7656,"running":6617,"running_sync":0,"stop_requested":49},"success_rate":88.47279110590989,"users":12,"readme_status":"ok","runtime_mean":5580586.29,"runtime_std":23419021.556393724,"service":"brain-life/app-roiGenerator","__v":0},"gitinfo":{"desc":"This app will generate nifti files for specific ROIs, or every ROI, for a parcellation (either freesurfer or atlas).","tags":[],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":799849.04,"runtime_std":1408516.1455727932,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a32f462f3d3800f117b17"},{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a32f462f3d3800f117b18"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a32f462f3d3800f117b19"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"634a32f462f3d3800f117b1a"}],"examples":0,"groups":53},"name":"ROI Generation (w/ dtiinit)","desc":"Generate a parcellation volume (and roi nifti files split into each label) for specific ROIs, or every ROI, for a parcellation from freesurfer output and/or input parcellation volume. This App can also inflate input parcellation volume toward non-white matter voxels.","citation":null,"github":"brainlife/app-roiGenerator","github_branch":"1.0","config":{"t1":{"type":"input","file_id":"t1","input_id":"t1"},"dtiinit":{"type":"input","file_id":"output","input_id":"dtiinit"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"parc":{"type":"input","file_id":"parc","input_id":"parcellation"},"key":{"type":"input","file_id":"key","input_id":"parcellation"},"ROI":{"type":"string","placeholder":"","desc":"Enter the parcellation numbers for the ROIs wanted to be generated\n\nexample: 45,54","default":"","id":"ROI","pid":0.6669761451969267,"_order":2},"inflate":{"optional":true,"default":null,"desc":"if ROI inflation into WM is wanted, specify the number of inflated voxels desired\n\nexample: 1","placeholder":"","type":"number","id":"inflate","pid":0.7849456168861411,"_order":3}},"user_id":"16","create_date":"2018-05-24T01:49:30.447Z","removed":false,"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5b061a2ad85b030192ff6ab5","id":"parc","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags_pass":null,"files":null,"desc":"Parcellation nifti containing all of the ROIs"},{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5c3e4f914503e500ea9cb105","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9","datatype_tags_pass":null,"files":null,"desc":"Directory containing all of the ROIs"}],"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5b061a2ad85b030192ff6ab9","id":"t1","datatype":"58c33bcee13a50849b25879a","desc":"The path to the anat/t1w datatype"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5b061a2ad85b030192ff6ab8","id":"dtiinit","datatype":"58cb234be13a50849b25882f","desc":"The path to the DTIINIT datatype"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5b061a2ad85b030192ff6ab7","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e","desc":"The path to the freesurfer datatype"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5b061a2ad85b030192ff6ab6","id":"parcellation","datatype":"5c1a7489f9109beac4a88a1f","desc":"The path to the parcellation/volume datatype"}],"contributors":[{"name":"Brad Caron","email":null,"_id":"634a32f462f3d3800f117b1b"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a32f462f3d3800f117b1c"},{"name":"Franco Pestilli","email":null,"_id":"634a32f462f3d3800f117b1d"}],"tags":[],"references":[],"admins":["135","16"],"projects":[],"__v":13259,"deprecated_by":"5ec29d1641ba11e054f3edc1","_canedit":true},{"_id":"5e516420cb80941d63f51b0e","projects":[],"admins":["135","1","41","16"],"tags":["tracking"],"removed":false,"stats":{"stars":0,"requested":82,"users":3,"success_rate":4.411764705882353,"serviceinfo":{"_id":"5d729e1f78356a109788b2eb","counts":{"_id":"5e5c3e3c87cac71f5eab1455","failed":3381,"finished":11383,"removed":28448,"requested":30096,"running":14546,"running_sync":0,"stop_requested":509},"success_rate":77.0997019777838,"users":4,"readme_status":"ok","runtime_mean":5104239.9,"runtime_std":9812760.010720242,"service":"brain-life/app-roi2roitracking","__v":0},"gitinfo":{"desc":"This app will perform ensemble tracking between 2 or more cortical regions of interest (ROIs) from either a freesurfer parcellation or an atlas parcellation. The app will automatically generate ROI niftis in diffusion space for tracking based on inputted ROI numbers. Inputs include: parcellation (freesurfer; atlas optional), dt6 from dtiinit, and ROI pairings. Outputs include a track.tck for each pairing of ROIs, a classification structure, and a fg_classified structure which can then be fed into other apps on the website (example: Clean WMC Output).","tags":["tracking"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null},{"name":"Ilaria Sani","email":"ila.gina@virgilio.it"}]},"runtime_mean":48983551,"runtime_std":10404132.833534982,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a385462f3d3800f11ef27"}],"examples":1,"groups":4},"name":"ROI to ROI Tracking - MRTrix 0.2.12","desc":"This app will perform ensemble tracking between 2 or more cortical regions of interest (ROIs) from either a freesurfer parcellation or an atlas parcellation. The app will automatically generate ROI niftis in diffusion space for tracking based on inputted ROI numbers. Inputs include: parcellation (freesurfer; atlas optional), dt6 from dtiinit, and ROI pairings. Outputs include a track.tck for each pairing of ROIs, a classification structure, and a fg_classified structure which can then be fed into other apps on the website (example: Clean WMC Output).","github":"brainlife/app-roi2roitracking","github_branch":"1.4","config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"rois":{"type":"input","file_id":"rois","input_id":"rois"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"lmax2":{"type":"input","file_id":"lmax2","input_id":"csd"},"lmax4":{"type":"input","file_id":"lmax4","input_id":"csd"},"lmax6":{"type":"input","file_id":"lmax6","input_id":"csd"},"lmax8":{"type":"input","file_id":"lmax8","input_id":"csd"},"lmax10":{"type":"input","file_id":"lmax10","input_id":"csd"},"lmax12":{"type":"input","file_id":"lmax12","input_id":"csd"},"lmax14":{"type":"input","file_id":"lmax14","input_id":"csd"},"response":{"type":"input","file_id":"response","input_id":"csd"},"brainmask":{"type":"input","file_id":"mask","input_id":"brainmask"},"white_matter":{"type":"input","file_id":"mask","input_id":"white_matter"},"max_lmax":{"type":"number","placeholder":"Auto Calculate","desc":"Max numb of params for CSD.\nLeave empty if you know it.","default":null,"optional":true,"id":"max_lmax","pid":0.8773154032661914,"_order":2},"num_repetitions":{"type":"number","placeholder":"","desc":"This allows you to track multiple times the very same tract.","default":1,"min":1,"max":10,"id":"num_repetitions","pid":0.6714770687029763,"_order":3},"roiPair":{"type":"string","placeholder":"","desc":"Space-separated pairing of 2 ROI numbers or ROI names you'd like to track between. For number \"ROI\" will be prefixed to search for the roi file (rois/ROI<num>.nii.gz). If not number, then the name is assumed to be rois/<name>.nii.gz\n\nexample: \n45 54\nL_FEF_sphere_bin L_PIT_sphere_bin","default":"","id":"roiPair","pid":0.9459404616415497,"_order":4,"multiline":true},"maxlength":{"default":200,"desc":"maximum length of each streamline generated","placeholder":"","type":"number","id":"maxlength","pid":0.7118132039713858,"_order":5},"minlength":{"default":10,"desc":"minimum length of each streamline generated","placeholder":"","type":"number","id":"minlength","pid":0.407336970950118,"_order":6},"stepsize":{"default":0.2,"desc":"step size for tracking","placeholder":"","type":"number","id":"stepsize","pid":0.7252258545892574,"_order":7},"max_num":{"default":1000000,"desc":"maximum number of tracts to generate. if empty, mrtrix2 automatically sets to 100 times num_fibers","placeholder":"","type":"number","id":"max_num","pid":0.10398683484859705,"_order":8,"optional":true},"num_fibers":{"default":500000,"desc":"desired number of fibers per tracking output","placeholder":"","type":"number","id":"num_fibers","pid":0.5726660721355232,"_order":9},"curv":{"id":"curv","type":"string","placeholder":"","advanced":false,"desc":"minimum radius of curvature","default":"0.25 0.5 1 2 4","_order":10,"pid":0.32177470361654326},"single_lmax":{"id":"single_lmax","type":"boolean","placeholder":"","advanced":false,"desc":"Using a single (max) lmax instead of tracking with multiple lmax between 2 and max lmax.","default":false,"_order":11,"pid":0.48638531392170736},"multiple_seed":{"id":"multiple_seed","type":"boolean","placeholder":"","advanced":false,"desc":"If you want to use multiple rois for seeding, select true","default":false,"_order":12,"pid":0.985673525620556},"reslice":{"id":"reslice","type":"boolean","placeholder":"","advanced":false,"desc":"reslice the input rois so that dimensions of them will match that of input dwi. ","default":false,"_order":13,"pid":0.007514417743675006},"cutoff":{"id":"cutoff","type":"number","placeholder":"","advanced":false,"desc":"set the FA or FOD amplitude cutoff for terminating tracks.","default":0.1,"_order":14,"pid":0.04322361511301809}},"desc_override":"This app will perform tracking between 2 cortical regions of interest (ROIs) from either a freesurfer parcellation or an atlas parcellation.  Inputs include: parcellation (freesurfer; atlas optional) with ROI niftis (generated from app-roiGeneration), dt6 from dtiinit, and ROI pairings. Outputs include a track.tck for each pairing of ROIs, a classification structure, and a fg_classified structure which can then be fed into other apps on the website (example: Clean WMC Output).","user_id":"16","outputs":[{"datatype_tags":["roi2roi"],"output_on_root":false,"archive":true,"_id":"5b01f6849ae9260026c8ddc7","id":"wmc","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags_pass":null,"files":null,"desc":"The classification structure including a classification.mat structure that contains the streamline indices in the tractogram."},{"datatype_tags":["roi2roi"],"output_on_root":false,"archive":true,"_id":"5b0701e025da6f011fb5b7c1","id":"track","datatype":"5907d922436ee50ffde9c549","datatype_tags_pass":null,"files":null,"desc":"Tractogram (tck) generated"},{"datatype_tags":[],"output_on_root":false,"archive":false,"_id":"5e5833af4a8208e6cb890015","id":"csd","datatype":"5c536bf0f9109beac46adb45","datatype_tags_pass":null,"files":null,"desc":"FOD images generated by mrtrix"}],"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e5164cacb809466c7f51b9a","id":"dwi","datatype":"58c33c5fe13a50849b25879b","desc":"The path to the DWI datatype"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5b01f6849ae9260026c8ddca","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9","desc":"The path to the ROIs datatype"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5b01f6849ae9260026c8ddc9","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e","desc":"aparc+aseg.nii.gz from freesurfer is used to create the white matter mask. You can override this by setting white_matter input, but you still need to input freesurfer as it is used to generate the visualization content (surface overlay)"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5e5164cacb80945434f51b9b","id":"csd","datatype":"5c536bf0f9109beac46adb45","desc":"The path to the csd datatype"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5e5169afcb80944685f51df4","id":"brainmask","datatype":"5a281aee2c214c9ba83ce620","desc":"The path to the mask datatype containing the brainmask of the DWI"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5e581c914a8208267288f7ef","id":"white_matter","datatype":"5a281aee2c214c9ba83ce620","desc":"Specify white matter mask you'd like to use - instead of creating one on the fly from the freesurfer input."}],"contributors":[{"name":"Brad Caron","email":null,"_id":"634a385462f3d3800f11ef28"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a385462f3d3800f11ef29"},{"name":"Franco Pestilli","email":null,"_id":"634a385462f3d3800f11ef2a"},{"name":"Ilaria Sani","email":"ila.gina@virgilio.it","_id":"634a385462f3d3800f11ef2b"}],"__v":5551,"create_date":"2020-02-22T17:25:52.601Z","doi":"10.25663/brainlife.app.279","_canedit":true},{"_id":"5b01f6849ae9260026c8ddc6","doi":"10.25663/bl.app.34","stats":{"stars":0,"requested":82,"users":3,"success_rate":4.411764705882353,"serviceinfo":{"_id":"5d729e1f78356a109788b2eb","counts":{"_id":"5e5c3da287cac78155ab13b3","failed":3381,"finished":11383,"removed":28448,"requested":30096,"running":14546,"running_sync":0,"stop_requested":509},"success_rate":77.0997019777838,"users":4,"readme_status":"ok","runtime_mean":5104239.9,"runtime_std":9812760.010720242,"service":"brain-life/app-roi2roitracking","__v":0},"gitinfo":{"desc":"This app will perform ensemble tracking between 2 or more cortical regions of interest (ROIs) from either a freesurfer parcellation or an atlas parcellation. The app will automatically generate ROI niftis in diffusion space for tracking based on inputted ROI numbers. Inputs include: parcellation (freesurfer; atlas optional), dt6 from dtiinit, and ROI pairings. Outputs include a track.tck for each pairing of ROIs, a classification structure, and a fg_classified structure which can then be fed into other apps on the website (example: Clean WMC Output).","tags":["tracking"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null},{"name":"Ilaria Sani","email":"ila.gina@virgilio.it"}]},"runtime_mean":48983551,"runtime_std":10404132.833534982,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a32e162f3d3800f117b0d"}],"examples":0,"groups":4},"name":"ROI to ROI Tracking - deprecated","desc":"This app will perform ensemble tracking between 2 or more cortical regions of interest (ROIs) from either a freesurfer parcellation or an atlas parcellation. The app will automatically generate ROI niftis in diffusion space for tracking based on inputted ROI numbers. Inputs include: parcellation (freesurfer; atlas optional), dt6 from dtiinit, and ROI pairings. Outputs include a track.tck for each pairing of ROIs, a classification structure, and a fg_classified structure which can then be fed into other apps on the website (example: Clean WMC Output).","citation":null,"github":"brainlife/app-roi2roitracking","github_branch":"1.0","config":{"rois":{"type":"input","file_id":"rois","input_id":"rois"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"dtiinit":{"type":"input","file_id":"output","input_id":"dtiinit"},"max_lmax":{"type":"number","placeholder":"Auto Calculate","desc":"Max numb of params for CSD.\nLeave empty if you know it.","default":null,"optional":true,"id":"max_lmax","pid":0.5125817987432377,"_order":2},"num_repetitions":{"type":"number","placeholder":"","desc":"this allows you to track multiple times the very same tract.","default":1,"min":1,"max":10,"id":"num_repetitions","pid":0.12771372752255106,"_order":3},"roiPair":{"type":"string","placeholder":"","desc":"Space-separated pairing of ROI numbers or ROI names you'd like to track between\n\nNeeds to correspond to ROIs from ROI Generation app, or from locally stored ROIs\n\nexample: 45 54; L_FEF_sphere_bin L_PIT_sphere_bin","default":"","id":"roiPair","pid":0.9231953992849502,"_order":4},"maxlength":{"default":200,"desc":"maximum length of each streamline generated","placeholder":"","type":"number","id":"maxlength","pid":0.6925045836847863,"_order":5},"minlength":{"default":10,"desc":"minimum length of each streamline generated","placeholder":"","type":"number","id":"minlength","pid":0.9146548170675548,"_order":6},"stepsize":{"default":0.2,"desc":"step size for tracking","placeholder":"","type":"number","id":"stepsize","pid":0.011338871682004426,"_order":7},"max_num":{"default":1000000,"desc":"maximum number of tracts to generate","placeholder":"","type":"number","id":"max_num","pid":0.7381536160648712,"_order":8},"num_fibers":{"default":500000,"desc":"desired number of fibers per tracking output","placeholder":"","type":"number","id":"num_fibers","pid":0.3868084472852935,"_order":9}},"desc_override":"This app will perform tracking between 2 cortical regions of interest (ROIs) from either a freesurfer parcellation or an atlas parcellation.  Inputs include: parcellation (freesurfer; atlas optional) with ROI niftis (generated from app-roiGeneration), dt6 from dtiinit, and ROI pairings. Outputs include a track.tck for each pairing of ROIs, a classification structure, and a fg_classified structure which can then be fed into other apps on the website (example: Clean WMC Output).","user_id":"16","create_date":"2018-05-20T22:28:20.022Z","removed":false,"outputs":[{"datatype_tags":["roi2roi"],"output_on_root":true,"archive":true,"_id":"5b01f6849ae9260026c8ddc7","id":"wmc","datatype":"58f10a90436ee50ffd9063c5","datatype_tags_pass":null,"files":null,"desc":"The classification structure  (deprecated) including a classification.mat structure that contains the streamline indices in the tractogram."},{"datatype_tags":["roi2roi"],"output_on_root":true,"archive":true,"_id":"5b0701e025da6f011fb5b7c1","id":"output","datatype":"5907d922436ee50ffde9c549","datatype_tags_pass":null,"files":null,"desc":"Tractogram (tck) generated"}],"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5b01f6849ae9260026c8ddca","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9","desc":"The path to the rois datatype"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5b01f6849ae9260026c8ddc9","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e","desc":"The path to the freesurfer datatype"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5b01f6849ae9260026c8ddc8","id":"dtiinit","datatype":"58cb234be13a50849b25882f","desc":"The path to the DTIINIT datatype"}],"contributors":[{"name":"Brad Caron","email":null,"_id":"634a32e262f3d3800f117b0e"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a32e262f3d3800f117b0f"},{"name":"Franco Pestilli","email":null,"_id":"634a32e262f3d3800f117b10"},{"name":"Ilaria Sani","email":"ila.gina@virgilio.it","_id":"634a32e262f3d3800f117b11"}],"tags":["tracking"],"references":[],"admins":["135","1","41","16"],"projects":[],"__v":13342,"deprecated_by":"5e516420cb80941d63f51b0e","_canedit":true},{"_id":"5ea9d98df1745d5443f84dc6","projects":[],"admins":["135","1","41","16"],"tags":["tracking"],"removed":false,"stats":{"requested":82,"users":3,"success_rate":4.411764705882353,"gitinfo":{"desc":"This app will perform ensemble tracking between 2 or more cortical regions of interest (ROIs) from either a freesurfer parcellation or an atlas parcellation. The app will automatically generate ROI niftis in diffusion space for tracking based on inputted ROI numbers. Inputs include: parcellation (freesurfer; atlas optional), dt6 from dtiinit, and ROI pairings. Outputs include a track.tck for each pairing of ROIs, a classification structure, and a fg_classified structure which can then be fed into other apps on the website (example: Clean WMC Output).","tags":["tracking"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null},{"name":"Ilaria Sani","email":"ila.gina@virgilio.it"}]},"runtime_mean":48983551,"runtime_std":10404132.833534982,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3a3e62f3d3800f123747"}],"examples":0,"groups":4},"name":"ROI to ROI Tracking - with dtiInit","desc":"This app will perform ensemble tracking between 2 or more cortical regions of interest (ROIs) from either a freesurfer parcellation or an atlas parcellation. The app will automatically generate ROI niftis in diffusion space for tracking based on inputted ROI numbers. Inputs include: parcellation (freesurfer; atlas optional), dt6 from dtiinit, and ROI pairings. Outputs include a track.tck for each pairing of ROIs, a classification structure, and a fg_classified structure which can then be fed into other apps on the website (example: Clean WMC Output).","github":"brainlife/app-roi2roitracking","github_branch":"1.4","config":{"dtiinit":{"type":"input","file_id":"output","input_id":"dtiinit"},"rois":{"type":"input","file_id":"rois","input_id":"rois"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"lmax2":{"type":"input","file_id":"lmax2","input_id":"csd"},"lmax4":{"type":"input","file_id":"lmax4","input_id":"csd"},"lmax6":{"type":"input","file_id":"lmax6","input_id":"csd"},"lmax8":{"type":"input","file_id":"lmax8","input_id":"csd"},"lmax10":{"type":"input","file_id":"lmax10","input_id":"csd"},"lmax12":{"type":"input","file_id":"lmax12","input_id":"csd"},"lmax14":{"type":"input","file_id":"lmax14","input_id":"csd"},"response":{"type":"input","file_id":"response","input_id":"csd"},"brainmask":{"type":"input","file_id":"mask","input_id":"brainmask"},"white_matter":{"type":"input","file_id":"mask","input_id":"white_matter"},"max_lmax":{"type":"number","placeholder":"Auto Calculate","desc":"Max numb of params for CSD.\nLeave empty if you know it.","default":null,"optional":true,"id":"max_lmax","pid":0.32644588959377985,"_order":2},"num_repetitions":{"type":"number","placeholder":"","desc":"this allows you to track multiple times the very same tract.","default":1,"min":1,"max":10,"id":"num_repetitions","pid":0.0559719075631806,"_order":3},"roiPair":{"type":"string","placeholder":"","desc":"Space-separated pairing of 2 ROI numbers or ROI names you'd like to track between. For number \"ROI\" will be prefixed to search for the roi file (rois/ROI<num>.nii.gz). If not number, then the name is assumed to be rois/<name>.nii.gz\n\nexample: \n45 54\nL_FEF_sphere_bin L_PIT_sphere_bin","default":"","id":"roiPair","pid":0.7491905549814308,"_order":4,"multiline":true},"maxlength":{"default":200,"desc":"maximum length of each streamline generated","placeholder":"","type":"number","id":"maxlength","pid":0.8722556153418508,"_order":5},"minlength":{"default":10,"desc":"minimum length of each streamline generated","placeholder":"","type":"number","id":"minlength","pid":0.8097858055425049,"_order":6},"stepsize":{"default":0.2,"desc":"step size for tracking","placeholder":"","type":"number","id":"stepsize","pid":0.6392216326898166,"_order":7},"max_num":{"default":1000000,"desc":"maximum number of tracts to generate","placeholder":"","type":"number","id":"max_num","pid":0.9957005465622988,"_order":8},"num_fibers":{"default":500000,"desc":"desired number of fibers per tracking output","placeholder":"","type":"number","id":"num_fibers","pid":0.9614412390566367,"_order":9},"curv":{"id":"curv","type":"string","placeholder":"","advanced":false,"desc":"minimum radius of curvature","default":"0.25 0.5 1 2 4","_order":10,"pid":0.8428966845661958},"single_lmax":{"id":"single_lmax","type":"boolean","placeholder":"","advanced":false,"desc":"Using a single (max) lmax instead of tracking with multiple lmax between 2 and max lmax.","default":false,"_order":11,"pid":0.2164644107746625},"multiple_seed":{"id":"multiple_seed","type":"boolean","placeholder":"","advanced":false,"desc":"If you want to use multiple rois for seeding, select true","default":false,"_order":12,"pid":0.3269077181219917},"reslice":{"id":"reslice","type":"boolean","placeholder":"","advanced":false,"desc":"reslice the input rois so that dimensions of them will match that of input dwi. ","default":false,"_order":13,"pid":0.40387606795105446},"cutoff":{"id":"cutoff","type":"number","placeholder":"","advanced":false,"desc":"set the FA or FOD amplitude cutoff for terminating tracks.","default":0.1,"_order":14,"pid":0.9028012546654387}},"desc_override":"This app will perform tracking between 2 cortical regions of interest (ROIs) from either a freesurfer parcellation or an atlas parcellation.  Inputs include: parcellation (freesurfer; atlas optional) with ROI niftis (generated from app-roiGeneration), dt6 from dtiinit, and ROI pairings. Outputs include a track.tck for each pairing of ROIs, a classification structure, and a fg_classified structure which can then be fed into other apps on the website (example: Clean WMC Output).","user_id":"1","outputs":[{"datatype_tags":["roi2roi"],"output_on_root":false,"archive":true,"_id":"5b01f6849ae9260026c8ddc7","id":"wmc","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags_pass":null,"files":null,"desc":"The classification structure including a classification.mat structure that contains the streamline indices in the tractogram."},{"datatype_tags":["roi2roi"],"output_on_root":false,"archive":true,"_id":"5b0701e025da6f011fb5b7c1","id":"track","datatype":"5907d922436ee50ffde9c549","datatype_tags_pass":null,"files":null,"desc":"Tractogram (tck) generated"},{"datatype_tags":[],"output_on_root":false,"archive":false,"_id":"5e5833af4a8208e6cb890015","id":"csd","datatype":"5c536bf0f9109beac46adb45","datatype_tags_pass":null,"files":null,"desc":"FOD images generated with mrtrix"}],"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5b01f6849ae9260026c8ddc8","id":"dtiinit","datatype":"58cb234be13a50849b25882f","desc":"The path to the DTIINIT datatype"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5b01f6849ae9260026c8ddca","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9","desc":"The path to the rois datatype"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5b01f6849ae9260026c8ddc9","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e","desc":"aparc+aseg.nii.gz from freesurfer is used to create the white matter mask. You can override this by setting white_matter input, but you still need to input freesurfer as it is used to generate the visualization content (surface overlay)"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5e5164cacb80945434f51b9b","id":"csd","datatype":"5c536bf0f9109beac46adb45","desc":"The path to the CSD datatype"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5e5169afcb80944685f51df4","id":"brainmask","datatype":"5a281aee2c214c9ba83ce620","desc":"The path to the mask datatype containing the brainmask of the DWI"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5e581c914a8208267288f7ef","id":"white_matter","datatype":"5a281aee2c214c9ba83ce620","desc":"Specify white matter mask you'd like to use - instead of creating one on the fly from the freesurfer input."}],"contributors":[{"name":"Brad Caron","email":null,"_id":"634a3a3e62f3d3800f123748"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a3a3e62f3d3800f123749"},{"name":"Franco Pestilli","email":null,"_id":"634a3a3e62f3d3800f12374a"},{"name":"Ilaria Sani","email":"ila.gina@virgilio.it","_id":"634a3a3e62f3d3800f12374b"}],"__v":5000,"create_date":"2020-04-29T19:46:21.136Z","doi":"10.25663/brainlife.app.333","deprecated_by":"5e516420cb80941d63f51b0e","_canedit":true},{"_id":"5bbfbbc71f00c80027644894","projects":[],"admins":["41","285","87"],"tags":["diffusion-mri","dipy","segmentation"],"removed":false,"config":{"streamline_files":{"type":"input","file_id":"track","input_id":"track"},"greater_than":{"id":"greater_than","type":"number","placeholder":"","advanced":false,"desc":"Keep streamlines that have a length greater than this value.","default":50,"_order":2,"pid":0.46695786229427516},"less_than":{"id":"less_than","type":"number","placeholder":"","advanced":false,"desc":"Keep streamlines have a length lesser than this value.","default":1000000,"_order":3,"pid":0.9561043356676153},"no_slr":{"id":"no_slr","type":"boolean","placeholder":"","advanced":false,"desc":"","default":false,"_order":4,"pid":0.8464461993303245},"clust_thr":{"id":"clust_thr","type":"number","placeholder":"","advanced":false,"desc":"MDF distance threshold for all streamlines.","default":15,"_order":5,"pid":0.7753347056271991},"reduction_thr":{"id":"reduction_thr","type":"number","placeholder":"","advanced":false,"desc":"Reduce search space by (mm).","default":15,"_order":6,"pid":0.553758689696743},"reduction_distance":{"id":"reduction_distance","type":"enum","placeholder":"","advanced":false,"desc":"Reduction distance type.","default":"mdf","_order":7,"pid":0.7598083148754673,"options":[{"desc":"","label":"Maximum Average Minimum Distance","value":"mam"},{"desc":"","label":"Minimum Average Direct-Flip Distance","value":"mdf"}]},"model_clust_thr":{"id":"model_clust_thr","type":"number","placeholder":"","advanced":false,"desc":"MDF distance threshold for the model bundles.","default":2.5,"_order":8,"pid":0.6601294176846939},"pruning_thr":{"id":"pruning_thr","type":"number","placeholder":"","advanced":false,"desc":"Pruning after matching.","default":8,"_order":9,"pid":0.013682176352461717},"pruning_distance":{"id":"pruning_distance","type":"enum","placeholder":"","advanced":false,"desc":"Pruning distance type.","default":"mdf","_order":10,"pid":0.6759985715343269,"options":[{"desc":"","label":"Maximum Average Minimum Distance","value":"mam"},{"desc":"","label":"Minimum Average Direct-Flip Distance","value":"mdf"}]},"slr_metric":{"id":"slr_metric","type":"enum","placeholder":"","advanced":false,"desc":"","default":"symmetric","_order":11,"pid":0.7207448585185829,"options":[{"desc":"","label":"Asymmetric","value":"asymmetric"},{"desc":"","label":"Diagonal","value":"diagonal"},{"desc":"","label":"Symmetric","value":"symmetric"}]},"slr_transform":{"id":"slr_transform","type":"enum","placeholder":"","advanced":false,"desc":"","default":"similarity","_order":12,"pid":0.20869721513308925,"options":[{"desc":"","label":"Rigid","value":"rigid"},{"desc":"","label":"Scaling","value":"scaling"},{"desc":"","label":"Similarity","value":"similarity"},{"desc":"","label":"Translation","value":"translation"}]},"slr_matrix":{"id":"slr_matrix","type":"enum","placeholder":"","advanced":false,"desc":"","default":"small","_order":13,"pid":0.26633140899070185,"options":[{"desc":"","label":"Nano","value":"nano"},{"desc":"","label":"Tiny","value":"tiny"},{"desc":"","label":"Small","value":"small"},{"desc":"","label":"Medium","value":"medium"},{"desc":"","label":"Large","value":"large"},{"desc":"","label":"Huge","value":"huge"}]},"refine":{"id":"refine","type":"boolean","placeholder":"","advanced":false,"desc":"Enable refine of recognized bundle.","default":false,"_order":14,"pid":0.8885567869204483},"r_reduction_thr":{"id":"r_reduction_thr","type":"number","placeholder":"","advanced":false,"desc":"Refine reduce search space by (mm).","default":12,"_order":15,"pid":0.2719515426014203},"r_pruning_thr":{"id":"r_pruning_thr","type":"number","placeholder":"","advanced":false,"desc":"Refine pruning after matching.","default":6,"_order":16,"pid":0.5757456074983047},"no_r_slr":{"id":"no_r_slr","type":"boolean","placeholder":"","advanced":false,"desc":"Don't enable Refine local Streamline-based Linear Registration.","default":false,"_order":17,"pid":0.7837907217260975}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5bbfbbc71f00c80027644895","id":"track","datatype":"5b956f6cd7b3f1e24e9121ce"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5bbfbbc71f00c80027644896","id":"wmc","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags_pass":null,"files":null},{"datatype_tags":["wm_tracts","tracts_labels"],"output_on_root":false,"archive":true,"_id":"6085cebd89df43b75373b4a6","id":"output","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null}],"github_branch":"1.1.1","github":"dipy/bl_apps_dipy_recobundles","name":"RecoBundles","desc_override":"RecoBundles  - Automatic extraction of brain pathways","user_id":"87","references":[],"contributors":[{"name":"Javier Guaje","email":null,"_id":"634a340e62f3d3800f1184b4"},{"name":"Serge Koudoro","email":null,"_id":"634a340e62f3d3800f1184b5"}],"create_date":"2018-10-11T21:08:23.865Z","desc":"Brainlife wrapper app for dipy_recobundles workflows.","stats":{"stars":0,"requested":801,"users":8,"success_rate":1.6786570743405276,"serviceinfo":{"_id":"5d729e1f78356a109788b2dd","counts":{"_id":"5e5c3dc187cac76fccab13d6","failed":1372,"finished":2816,"removed":5103,"requested":5301,"running":3198,"running_sync":0,"stop_requested":12},"success_rate":67.23973256924546,"users":20,"readme_status":"ok","runtime_mean":5885857.53,"runtime_std":14501545.618587041,"service":"brain-life/app-dipy-workflows","__v":0},"gitinfo":{"desc":"Brainlife wrapper app for Dipy workflows.","tags":["dipy"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Serge Koudoro","email":null},{"name":"Aman Arya","email":"aman.arya524@gmail.com"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":3352681.285714286,"runtime_std":2555161.9765768116,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a340d62f3d3800f1184b3"}],"examples":0,"groups":9},"doi":"10.25663/brainlife.app.113","__v":10044,"_canedit":true},{"_id":"5b0614c6d85b030192ff6aae","doi":"10.25663/bl.app.36","stats":{"stars":0,"requested":78,"users":2,"success_rate":76.47058823529412,"serviceinfo":{"_id":"5d729e1f78356a109788b2db","counts":{"_id":"5e5c3da387cac7ca5eab13b4","failed":16,"finished":52,"removed":52,"requested":78,"running":69,"running_sync":0,"stop_requested":4},"success_rate":76.47058823529412,"users":2,"readme_status":"ok","runtime_mean":8616369.461538462,"runtime_std":5782143.5322341435,"service":"kitchell/app-reconstructLBeigenfunction","__v":0},"gitinfo":{"desc":"This application will reconstruct the surfaces of each 3D model based on the selected number of eigenfunctions.","tags":["analysis"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null}]},"runtime_mean":8616369.461538462,"runtime_std":5782143.5322341435,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a32eb62f3d3800f117b13"}],"examples":0,"groups":2},"name":"Reconstruct Surfaces from LB Eigenfunctions","desc":"This application will reconstruct the surfaces of each 3D model based on the selected number of eigenfunctions.","citation":null,"avatar":null,"github":"kitchell/app-reconstructLBeigenfunction","github_branch":null,"config":{"surfaces":{"type":"input","file_id":"surfaces","input_id":"surfaces"},"single_surf":{"type":"boolean","placeholder":"","desc":"only reconstruct a single surface","default":false,"id":"single_surf","pid":0.8091983752623364,"_order":2},"singlesurf_filename":{"type":"string","placeholder":"full filename of the single surface you want to reconstruct","desc":"Include the full filename of the surface you want to reconstruct. Best practice is to copy it directly from the 3D surfaces app output","default":"","optional":true,"id":"singlesurf_filename","pid":0.4567076956074425,"_order":3},"spectrum_size":{"min":1,"default":50,"desc":"","placeholder":"number of eigenfunctions you want to use in the reconstruction","type":"number","id":"spectrum_size","pid":0.5796400205592416,"_order":4}},"user_id":"43","create_date":"2018-05-24T01:26:30.574Z","removed":false,"outputs":[{"datatype_tags":["reconstructed"],"_id":"5b0614c6d85b030192ff6aaf","id":"images","datatype":"5967b799b09297d8d831709e","datatype_tags_pass":null,"files":null,"output_on_root":true,"archive":true},{"datatype_tags":["lb_reconstructed"],"_id":"5bc662ec44f3980027a7aae3","id":"surfaces","datatype":"59307a08436ee50ffd973278","datatype_tags_pass":null,"files":null,"output_on_root":true,"archive":true}],"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"_id":"5b0614c6d85b030192ff6ab0","id":"surfaces","datatype":"59307a08436ee50ffd973278"}],"contributors":[{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a32eb62f3d3800f117b14"},{"name":null,"email":null,"_id":"634a32eb62f3d3800f117b15"}],"tags":["analysis"],"references":[],"admins":["43"],"projects":[],"__v":13248,"_canedit":true},{"_id":"6130060d584a7684793c3e5f","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a425062f3d3800f12f488"}],"success_rate":92.5233644859813,"users":3,"runtime_mean":48898.41414141414,"runtime_std":30823.490354214686,"requested":111,"examples":0,"groups":4},"projects":[],"admins":["386"],"tags":["afni","brainlife","fmri"],"removed":false,"config":{"bold":{"type":"input","file_id":"bold","input_id":"bold"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"neighborhood":{"id":"neighborhood","type":"enum","placeholder":"","advanced":false,"desc":"","default":"27","_order":2,"pid":0.8011817790461553,"options":[{"desc":"","label":"face-wise neighbors","value":"7"},{"desc":"","label":"face- and edge-wise neighbors","value":"19"},{"desc":"","label":"face-, edge-, and node-wise neighbors","value":"27"}],"optional":true},"fwhm":{"id":"fwhm","type":"number","placeholder":"","advanced":false,"desc":"Smoothing parameter (in mm). Blurs the image until it reaches the FWHM smoothness.","default":0,"_order":3,"pid":0.13691104365890028,"optional":true,"min":0}},"inputs":[{"id":"bold","datatype":"59b685a08e5d38b0b331ddc5","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"6130060d584a766c723c3e60"},{"id":"mask","datatype":"5a281aee2c214c9ba83ce620","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"61391a82584a761eb7420bf5"}],"outputs":[{"id":"reho","datatype":"60f69321b991113f21b4fdf6","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"6130060d584a769c243c3e61"}],"github_branch":"main","github":"anibalsolon/app-reho","name":"Regional Homogeneity (ReHo)","user_id":"386","contributors":[{"name":"Anibal Sólon","email":"anibalsolon@gmail.com","_id":"634a425162f3d3800f12f489"}],"create_date":"2021-09-01T23:00:29.478Z","desc":"BrainLife.io Regional Homogeneity app","__v":1924,"doi":"10.25663/brainlife.app.567","avatar":"data:image/png;base64,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","_canedit":true},{"_id":"59fb2f15c996d0002d47ee1d","name":"Register DWI to T1 using Vistasoft","desc":"This app will register a DWI image to a T1w image and rotate the bvecs. Requires a DWI image (with bvals and bvecs) and an T1w image (either ACPC-aligned or native). Will output an aligned DWI image, the rotated bvecs, and the bvals files.","github":"brainlife/app-vistasoft-registration","github_branch":"1.1","config":{"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"t1":{"type":"input","file_id":"t1","input_id":"t1"},"interpolation":{"id":"interpolation","type":"enum","placeholder":"","desc":"Interpolation method","default":"linear","_order":3,"pid":0.04458293556017945,"options":[{"desc":"","label":"linear","value":"linear"},{"desc":"","label":"trilinear","value":"trilinear"},{"desc":"","label":"spline","value":"spline"}]},"resolution":{"default":"","desc":"pixel dimension to pass to dtiRawResample","placeholder":"use default","type":"string","id":"resolution","pid":0.09838578948930343,"_order":4,"optional":true}},"user_id":"16","create_date":"2017-11-02T14:43:33.703Z","removed":false,"_rate":0,"outputs":[{"datatype_tags":["t1_aligned"],"output_on_root":true,"archive":true,"_id":"59fb2f15c996d0002d47ee1e","id":"output","datatype":"58c33c5fe13a50849b25879b","files":null,"desc":"Aligned DWI with corrected bvectors and bvalues"}],"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"59fb2f15c996d0002d47ee20","id":"dwi","datatype":"58c33c5fe13a50849b25879b","desc":"The path to the DWI datatype"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5aac0d8ff0b5260027e24add","id":"t1","datatype":"58c33bcee13a50849b25879a","desc":"The path to the anat/t1w datatype"}],"tags":["diffusion-preprocessing"],"admins":["16"],"projects":[],"__v":14283,"contributors":[{"name":"Brad Caron","email":null,"_id":"634a317262f3d3800f116717"},{"name":"Franco Pestilli","email":null,"_id":"634a317262f3d3800f116718"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a317262f3d3800f116719"}],"references":[],"stats":{"stars":0,"requested":2770,"users":5,"success_rate":100,"serviceinfo":{"_id":"5d729e1f78356a109788b2ab","counts":{"_id":"5e5c688c87cac76891ab1bb4","failed":19,"finished":118,"removed":169,"requested":199,"running":184,"running_sync":0,"stop_requested":48},"success_rate":86.13138686131386,"users":14,"readme_status":"ok","runtime_mean":3734990.38,"runtime_std":6250171.746329549,"service":"brain-life/app-vistasoft-registration","__v":0},"gitinfo":{"desc":"This app will register a DWI image to a T1w image and rotate the bvecs. Requires a DWI image (with bvals and bvecs) and an T1w image (either ACPC-aligned or native). Will output an aligned DWI image, the rotated bvecs, and the bvals files.","tags":["diffusion-preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":7868558.56,"runtime_std":23236294.625384867,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a317262f3d3800f116716"}],"examples":2,"groups":6},"doi":"10.25663/bl.app.50","_canedit":true},{"_id":"5cd1cc287d889900340f6f0e","stats":{"stars":0,"requested":80,"users":2,"success_rate":100,"serviceinfo":{"_id":"5d729e1e78356a109788b20f","counts":{"_id":"5e5c3dff87cac738f9ab1414","failed":0,"finished":77,"removed":80,"requested":80,"running":77,"running_sync":0,"stop_requested":0},"success_rate":100,"users":2,"readme_status":"too short","runtime_mean":273422.97402597405,"runtime_std":205939.08727147238,"service":"brainlife/app-removeFirstB0","__v":0},"gitinfo":{"desc":null,"tags":[],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null}]},"runtime_mean":273422.97402597405,"runtime_std":205939.08727147238,"resources":[],"examples":0,"groups":1},"projects":[],"admins":["16"],"tags":[],"removed":false,"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"inDWI"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"inDWI"},"bvals":{"type":"input","file_id":"bvals","input_id":"inDWI"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"_id":"5cd1cc287d889900340f6f0f","id":"inDWI","datatype":"58c33c5fe13a50849b25879b"}],"outputs":[{"datatype_tags":["even","missing_first_b0"],"output_on_root":false,"_id":"5cd1cc287d889900340f6f10","id":"outDWI","datatype":"58c33c5fe13a50849b25879b","datatype_tags_pass":"inDWI","files":null,"archive":true}],"github_branch":"master","github":"brainlife/app-removeFirstB0","name":"Remove First B0 (temp)","desc_override":"Temporary app to remove first b0 for Athlete Brain Study Dataset","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a365162f3d3800f11cd32"}],"create_date":"2019-05-07T18:19:20.302Z","desc":null,"doi":"10.25663/brainlife.app.197","__v":8076,"_canedit":true},{"_id":"5ea7c768f1745db773f8041d","stats":{"success_rate":98.23008849557522,"users":4,"runtime_mean":12168229.68,"runtime_std":2668833.2476458354,"requested":119,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3a0662f3d3800f12358e"}],"examples":1,"groups":3},"projects":[],"admins":["285","87"],"tags":["diffusion-mri","diffusion-preprocessing","dipy"],"removed":false,"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"slice_axis":{"id":"slice_axis","type":"number","placeholder":"","advanced":false,"desc":"Data axis corresponding to the number of acquired slices. Default is set to the third axis(2). Could be (0, 1, or 2).","default":2,"_order":2,"pid":0.43917978973161076},"n_points":{"id":"n_points","type":"number","placeholder":"","advanced":false,"desc":"Number of neighbour points to access local TV ","default":3,"_order":3,"pid":0.32850779949132125}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ea7c768f1745d6753f8041e","id":"dwi","datatype":"58c33c5fe13a50849b25879b"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5ea7c768f1745db097f8041f","id":"output","datatype":"58c33c5fe13a50849b25879b","datatype_tags_pass":"dwi","files":null}],"github_branch":"1.1.1","github":"dipy/bl_apps_dipy_gibbs_ringing","name":"Remove Gibbs Ringing from your DWI data","user_id":"87","contributors":[{"name":"Serge Koudoro","email":null,"_id":"634a3a0662f3d3800f12358f"},{"name":"Javier Guaje","email":null,"_id":"634a3a0662f3d3800f123590"}],"create_date":"2020-04-28T06:04:24.331Z","desc":"Brainlife wrapper app for dipy_gibbs_ringing workflows.","doi":"10.25663/brainlife.app.327","__v":4993,"_canedit":true},{"_id":"5c59dc65464fde003639ebb2","stats":{"stars":0,"requested":19423,"users":25,"success_rate":89.79670118910626,"serviceinfo":{"_id":"5d729e1e78356a109788b21f","counts":{"_id":"5e5c3ddf87cac74cbaab13f1","failed":157,"finished":5210,"removed":5514,"requested":5650,"running":5347,"running_sync":0,"stop_requested":66},"success_rate":97.074715856158,"users":6,"readme_status":"too short","runtime_mean":6928469.15,"runtime_std":7026262.31425993,"service":"brainlife/app-removeTractOutliers","__v":0},"gitinfo":{"desc":null,"tags":[],"stats":{"stars":0},"contributors":[{"name":"Daniel Bullock","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":1014928.65,"runtime_std":1719534.8980541779,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a350862f3d3800f118f0b"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a350862f3d3800f118f0c"}],"examples":0,"groups":72},"projects":[],"admins":["56"],"tags":[],"removed":false,"config":{"output":{"type":"input","file_id":"output","input_id":"wmc"},"track":{"type":"input","file_id":"track","input_id":"wbfg"},"centroidSD":{"id":"centroidSD","type":"number","placeholder":"4","desc":"Cut streamlines which are this many standard deviations away from the tract centroid.","default":4,"_order":2,"pid":0.5171120326932015,"min":1},"lengthSD":{"id":"lengthSD","type":"number","placeholder":"4","desc":"Cut streamlines which are this many standard deviations away from the tract average streamline length.","default":4,"_order":3,"pid":0.35169384732099496,"min":1},"maxIter":{"id":"maxIter","type":"number","placeholder":"5","desc":"The maximum number of iterations to compute tract averages and apply a cut.","default":null,"_order":4,"pid":0.39666744875012006,"min":1}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c59dc65464fde003639ebb4","id":"wmc","datatype":"58f10a90436ee50ffd9063c5"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c59dc65464fde003639ebb3","id":"wbfg","datatype":"5907d922436ee50ffde9c549"}],"outputs":[{"datatype_tags":["cleaned"],"output_on_root":true,"archive":true,"_id":"5c59dc65464fde003639ebb5","id":"wmc","datatype":"58f10a90436ee50ffd9063c5","datatype_tags_pass":null,"files":null}],"github_branch":"1.3","github":"brainlife/app-removeTractOutliers","name":"Remove Tract Outliers","user_id":"56","contributors":[{"name":"Daniel Bullock","email":"iisdanbul@gmail.com","_id":"634a350962f3d3800f118f0d"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a350962f3d3800f118f0e"},{"name":"Franco Pestilli","email":null,"_id":"634a350962f3d3800f118f0f"}],"create_date":"2019-02-05T18:56:37.235Z","desc":"This is a brainlife.io wrapper app for mbaComputeFibersOutliers algorithm. It takes an existing tract classification and prune classified fibers that are unlike other fibers within the same tract.","doi":"10.25663/brainlife.app.157","__v":8182,"deprecated_by":"5cc9eca04b5e4502275edba6","_canedit":true},{"_id":"5cc9eca04b5e4502275edba6","projects":[],"admins":["56"],"tags":[],"removed":false,"stats":{"stars":0,"requested":19423,"users":25,"success_rate":89.79670118910626,"serviceinfo":{"_id":"5d729e1e78356a109788b21f","counts":{"_id":"5e5c3dfd87cac77038ab1412","failed":157,"finished":5210,"removed":5514,"requested":5650,"running":5347,"running_sync":0,"stop_requested":66},"success_rate":97.074715856158,"users":6,"readme_status":"too short","runtime_mean":6928469.15,"runtime_std":7026262.31425993,"service":"brainlife/app-removeTractOutliers","__v":0},"gitinfo":{"desc":null,"tags":[],"stats":{"stars":0},"contributors":[{"name":"Daniel Bullock","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":1014928.65,"runtime_std":1719534.8980541779,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a363e62f3d3800f11cd29"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a363e62f3d3800f11cd2a"}],"examples":5,"groups":72},"config":{"classification":{"type":"input","file_id":"classification","input_id":"classification"},"track":{"type":"input","file_id":"track","input_id":"wbfg"},"centroidSD":{"id":"centroidSD","type":"number","placeholder":"4","desc":"Cut streamlines which are this many standard deviations away from the tract centroid.","default":4,"_order":2,"pid":0.25051627566288137,"min":1},"lengthSD":{"id":"lengthSD","type":"number","placeholder":"4","desc":"Cut streamlines which are this many standard deviations away from the tract average streamline length.","default":4,"_order":3,"pid":0.3764060538259526,"min":1},"maxIter":{"id":"maxIter","type":"number","placeholder":"","desc":"The maximum number of iterations to compute tract averages and apply a cut.","default":5,"_order":4,"pid":0.7266181234704523,"min":1}},"inputs":[{"id":"classification","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c59dc65464fde003639ebb4"},{"id":"wbfg","datatype":"5907d922436ee50ffde9c549","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c59dc65464fde003639ebb3"}],"outputs":[{"id":"classification","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags":["cleaned"],"datatype_tags_pass":"classification","output_on_root":false,"files":null,"archive":true,"_id":"5c59dc65464fde003639ebb5"}],"github_branch":"1.4","github":"brainlife/app-removeTractOutliers","name":"Remove Tract Outliers","user_id":"56","contributors":[{"name":"Daniel Bullock","email":"iisdanbul@gmail.com","_id":"634a363f62f3d3800f11cd2b"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a363f62f3d3800f11cd2c"},{"name":"Franco Pestilli","email":null,"_id":"634a363f62f3d3800f11cd2d"}],"desc":"This is a brainlife.io wrapper app for mbaComputeFibersOutliers algorithm. It takes an existing tract classification and prune classified fibers that are unlike other fibers within the same tract.","__v":8124,"create_date":"2019-05-01T18:59:44.993Z","doi":"10.25663/brainlife.app.195","_canedit":true},{"_id":"6065aa66d040080706b09da2","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3fb662f3d3800f12d1cd"}],"success_rate":95.6386292834891,"users":3,"runtime_mean":205693.68,"runtime_std":1284647.7711051689,"requested":321,"examples":0,"groups":3},"projects":[],"admins":["578"],"tags":["preprocessing"],"removed":false,"config":{"bold":{"type":"input","file_id":"bold","input_id":"fmri"},"n_vols":{"id":"n_vols","type":"number","placeholder":"Number of volumes to be removed","advanced":false,"desc":"","default":null,"_order":2,"pid":0.3934774406646999}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"6065aa66d040086bbcb09da3","id":"fmri","datatype":"59b685a08e5d38b0b331ddc5","desc":""}],"outputs":[{"datatype_tags":["first_volumes_removed"],"output_on_root":false,"archive":true,"_id":"6065aa66d04008b562b09da4","id":"out_dir","datatype":"59b685a08e5d38b0b331ddc5","datatype_tags_pass":null,"files":null}],"github_branch":"1.0","github":"amnsbr/app-remove-first-volumes","name":"Remove first volumes of fMRI","user_id":"578","contributors":[{"name":"Amin Saberi","email":"amnsbr@gmail.com","_id":"634a3fb662f3d3800f12d1ce"}],"create_date":"2021-04-01T11:11:34.900Z","desc":"Simple Brainlife app which removes the first volumes of fMRI images","__v":2980,"doi":"10.25663/brainlife.app.495","_canedit":true},{"_id":"6101a824b9911153e8ba5f55","stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a41b362f3d3800f12e693"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a41b362f3d3800f12e694"},{"resource_id":"62e4a2654a710d5a15a6d50d","name":"slurm24","_id":"634a41b362f3d3800f12e695"}],"success_rate":76.42612120442129,"users":15,"runtime_mean":966510.03,"runtime_std":1250650.5328230064,"requested":19020,"examples":4,"groups":42},"projects":[],"admins":["16"],"tags":["postprocessing"],"removed":false,"config":{"cortexmap":{"type":"input","file_id":"cortexmap","input_id":"cortexmap"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"resample_surf":{"id":"resample_surf","type":"enum","placeholder":"","advanced":false,"desc":"This is the standard mesh defining the number of vertices the data will be resampled to.","default":"164k","_order":2,"pid":0.548875180571866,"options":[{"desc":"164k vertices fsaverage","label":"164k","value":"164k"},{"desc":"32k vertices fsaverage","label":"32k","value":"32k"}]}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"6101a824b991113740ba5f56","id":"cortexmap","datatype":"5c58aa5ef9109beac4b52f61"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"6101a824b991112fccba5f57","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e"}],"outputs":[{"datatype_tags":["resampled"],"output_on_root":false,"archive":true,"_id":"6101a824b9911120eaba5f58","id":"cortexmap","datatype":"5c58aa5ef9109beac4b52f61","datatype_tags_pass":"cortexmap","files":null}],"github_branch":"resample-v1.0","github":"brainlife/app-cortex-tissue-mapping","name":"Resample cortexmap data to a standard mesh using Connectome Workbench","desc_override":"This app will take surf and func data from cortexmap datatype and resample to a standard mesh. This will be useful for performing group averaging of surface maps.","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a41b462f3d3800f12e696"},{"name":"Franco Pestilli","email":null,"_id":"634a41b462f3d3800f12e697"}],"create_date":"2021-07-28T18:55:32.736Z","desc":"This app will map volumated measure files (i.e. tensor, NODDI) to the cortical surface following Fukutomi et al (2018; 10.1016/j.neuroimage.2018.02.017) using Connectome Workbench.","__v":2194,"doi":"10.25663/brainlife.app.551","_canedit":true},{"_id":"62100c47c16bfbf27e09a18f","user_id":"16","projects":[],"admins":["16"],"name":"Resample surface data from fsaverage space","github":"brainlife/app-resample-surface-data","github_branch":"app-v1.0-freesurfer-7.1.1-wb-1.5.0","tags":[],"config":{"left":{"type":"input","file_id":"left","input_id":"surfaces"},"right":{"type":"input","file_id":"right","input_id":"surfaces"},"label":{"type":"input","file_id":"label","input_id":"surfaces"},"resamp_space":{"id":"resamp_space","type":"enum","placeholder":"","advanced":true,"desc":"space you would like to resample your data to","default":"fs_LR-deformed_to-fsaverage","_order":2,"pid":0.4386267955610491,"options":[{"desc":"fs_LR-deformed_to-fsaverage","label":"fs_LR-deformed_to-fsaverage","value":"fs_LR-deformed_to-fsaverage"}]},"num_vertices":{"id":"num_vertices","type":"enum","placeholder":"","advanced":false,"desc":"number of vertices to resample to","default":"32k","_order":3,"pid":0.8715839183811901,"options":[{"desc":"32k","label":"32k","value":"32k"},{"desc":"59k","label":"59k","value":"59k"},{"desc":"164k","label":"164k","value":"164k"}]},"surf_space":{"id":"surf_space","type":"enum","placeholder":"","advanced":true,"desc":"","default":"fsaverage5","_order":4,"pid":0.19200421292177294,"options":[{"desc":"fsaverage3","label":"fsaverage3","value":"fsaverage3"},{"desc":"fsaverage4","label":"fsaverage4","value":"fsaverage4"},{"desc":"fsaverage5","label":"fsaverage5","value":"fsaverage5"},{"desc":"fsaverage6","label":"fsaverage6","value":"fsaverage6"},{"desc":"fsaverage7","label":"fsaverage7","value":"fsaverage7"}]}},"inputs":[{"id":"surfaces","datatype":"5f78b377268f76598c29b27a","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"62100c47c16bfbf27e09a190"}],"outputs":[{"id":"func","datatype":"5f78b377268f76598c29b27a","datatype_tags":["resampled"],"datatype_tags_pass":"surfaces","output_on_root":false,"files":null,"archive":true,"_id":"62100c47c16bfbf27e09a191"}],"stats":{"resources":[],"success_rate":93.09859154929578,"users":1,"runtime_mean":33885.04,"runtime_std":8520.661798146903,"requested":714,"examples":1,"groups":2},"removed":false,"contributors":[{"name":"Brad Caron","email":null,"_id":"634a439562f3d3800f1304b9"}],"create_date":"2022-02-18T21:14:47.817Z","desc":null,"__v":821,"doi":"10.25663/brainlife.app.604","_canedit":true},{"_id":"5bdc3c2218c7cd002708d78d","stats":{"stars":0,"requested":1192,"users":3,"success_rate":81.53380423814329,"serviceinfo":{"_id":"5d729e1f78356a109788b27b","counts":{"_id":"5e5c3dc887cac77901ab13dd","failed":174,"finished":616,"removed":801,"requested":928,"running":836,"running_sync":0,"stop_requested":52},"success_rate":77.9746835443038,"users":2,"readme_status":"no README.md","runtime_mean":294682.24,"runtime_std":138262.99233656997,"service":"giulia-berto/app-resample-tck","__v":0},"gitinfo":{"desc":"Code to resample a tck file with a give step size.","tags":[],"stats":{"stars":0},"contributors":[]},"runtime_mean":263805.13,"runtime_std":122656.52682655373,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a345062f3d3800f118abc"}],"examples":0,"groups":5},"projects":[],"admins":["146"],"tags":[],"removed":false,"config":{"track":{"type":"input","file_id":"track","input_id":"0"},"type":{"id":"type","type":"enum","placeholder":"","advanced":false,"desc":"Resampling can be done either by setting the new step size (in mm) or the new number of points. Tell which option you want to use.","default":"","_order":2,"pid":0.857135152617873,"options":[{"desc":"","label":"I want to set the new step size","value":"step_size"},{"desc":"","label":"I want to set the new number of points","value":"nb_points"}]},"new_param":{"id":"new_param","type":"number","placeholder":"","desc":"Set the step size OR the number of points, depending on your choice above","default":null,"_order":3,"pid":0.4350871026428933}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5bdc3c2218c7cd002708d78e","id":"0","datatype":"5907d922436ee50ffde9c549","desc":"tractogram"}],"outputs":[{"datatype_tags":["res"],"output_on_root":false,"archive":true,"_id":"5bdc3c2218c7cd002708d78f","id":"tck","datatype":"5907d922436ee50ffde9c549","datatype_tags_pass":"0","files":null,"desc":"resampled tractogram"}],"name":"Resample tck","github":"giulia-berto/app-resample-tck","user_id":"146","references":[],"contributors":[{"name":"Giulia Bertò","email":null,"_id":"634a345062f3d3800f118abd"}],"create_date":"2018-11-02T11:59:30.127Z","doi":"10.25663/brainlife.app.124","__v":5990,"desc_override":"","desc":"Code to resample a tck file with a give step size or number of points.","github_branch":"1.0","_canedit":true},{"_id":"5ae8dbccf446980028b15e95","doi":"10.25663/bl.app.5","stats":{"stars":0,"requested":1402,"users":5,"success_rate":99.84214680347277,"serviceinfo":{"_id":"5d729e1f78356a109788b2dd","counts":{"_id":"5e5c3d9a87cac7e1a0ab13aa","failed":1372,"finished":2816,"removed":5103,"requested":5301,"running":3198,"running_sync":0,"stop_requested":12},"success_rate":67.23973256924546,"users":20,"readme_status":"ok","runtime_mean":5885857.53,"runtime_std":14501545.618587041,"service":"brain-life/app-dipy-workflows","__v":0},"gitinfo":{"desc":"Brainlife wrapper app for Dipy workflows.","tags":["dipy"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Serge Koudoro","email":null},{"name":"Aman Arya","email":"aman.arya524@gmail.com"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":388510.17,"runtime_std":953346.2336801682,"resources":[],"examples":1,"groups":7},"name":"Reslice","desc":"Brainlife wrapper app for dipy_reslice workflows.","citation":null,"github":"dipy/bl_apps_dipy_reslice","github_branch":"1.1.1","config":{"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"order":{"id":"order","type":"number","placeholder":"","advanced":false,"desc":"Order of interpolation, from 0 to 5.","default":1,"_order":4,"pid":0.06004478682571679,"min":0,"max":5},"mode":{"id":"mode","type":"enum","placeholder":"","advanced":false,"desc":"Points outside the boundaries of the input are filled according to the given mode.","default":"constant","_order":6,"pid":0.3853395781656421,"options":[{"desc":"","label":"Constant","value":"constant"},{"desc":"","label":"Nearest","value":"nearest"},{"desc":"","label":"Reflect","value":"reflect"},{"desc":"","label":"Wrap","value":"wrap"}]},"cval":{"id":"cval","type":"number","placeholder":"","advanced":false,"desc":"The value used for points outside the boundaries of the input if mode='constant'.","default":0,"_order":7,"pid":0.4443448913410024},"new_vox_size":{"default":1,"desc":"New voxel size.","placeholder":"","type":"number","id":"new_vox_size","pid":0.8805458480754931,"_order":8}},"desc_override":"Reslice a dMRI dataset to have isotropic voxel size (dipy_reslice).","user_id":"1","create_date":"2018-05-01T21:27:40.818Z","removed":false,"outputs":[{"datatype_tags":["resliced"],"output_on_root":false,"archive":true,"_id":"5ae8dbccf446980028b15e96","id":"output","datatype":"58c33c5fe13a50849b25879b","datatype_tags_pass":"dwi","files":null}],"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ae8dbccf446980028b15e97","id":"dwi","datatype":"58c33c5fe13a50849b25879b"}],"contributors":[{"name":"Javier Guaje","email":null,"_id":"634a329962f3d3800f117714"},{"name":"Serge Koudoro","email":null,"_id":"634a329962f3d3800f117715"}],"tags":["diffusion-mri","diffusion-preprocessing","dipy"],"references":[],"admins":["41","285","87","1"],"projects":[],"__v":13774,"_canedit":true},{"_id":"633336fcdb978c799193d995","user_id":"16","projects":[],"admins":["16"],"name":"Reslice ROIs to match input DWI","github":"bacaron/app-reslice-rois-dwi","github_branch":"master","desc":null,"tags":[],"contributors":[],"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"sbref":{"type":"input","file_id":"sbref","input_id":"dwi"},"sbref_json":{"type":"input","file_id":"sbref_json","input_id":"dwi"},"rois":{"type":"input","file_id":"rois","input_id":"rois"},"label":{"type":"input","file_id":"label","input_id":"rois"}},"inputs":[{"id":"dwi","datatype":"58c33c5fe13a50849b25879b","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"60a590f422b42a32d96fb318"},{"id":"rois","datatype":"5be9ea0315a8683a39a1ebd9","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"60a590f422b42a4f0c6fb319"}],"outputs":[{"id":"output","datatype":"5be9ea0315a8683a39a1ebd9","datatype_tags":["resliced","dwi"],"datatype_tags_pass":"rois","output_on_root":false,"files":null,"archive":true,"_id":"60a590f422b42a911a6fb31a"}],"stats":{"success_rate":58.2089552238806,"groups":1,"users":2,"runtime_mean":200879.07692307694,"runtime_std":623771.5143825886,"requested":73,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a45e562f3d3800f13127e"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a45e562f3d3800f13127f"}],"examples":1},"removed":false,"__v":1,"create_date":"2022-09-27T17:46:36.432Z","doi":"10.25663/brainlife.app.671","_canedit":true},{"_id":"60a590f422b42ad40d6fb317","stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a40a862f3d3800f12d82a"}],"success_rate":88.48484848484848,"users":2,"runtime_mean":533586.93,"runtime_std":909171.0816872063,"requested":182,"examples":1,"groups":2},"projects":[],"admins":["16"],"tags":[],"removed":false,"config":{"anat":{"type":"input","file_id":"t1","input_id":"anat"},"rois":{"type":"input","file_id":"rois","input_id":"rois"},"label":{"type":"input","file_id":"label","input_id":"rois"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"60a590f422b42a32d96fb318","id":"anat","datatype":"58c33bcee13a50849b25879a"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"60a590f422b42a4f0c6fb319","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9"}],"outputs":[{"datatype_tags":["resliced","anat"],"output_on_root":false,"archive":true,"_id":"60a590f422b42a911a6fb31a","id":"output","datatype":"5be9ea0315a8683a39a1ebd9","datatype_tags_pass":"rois","files":null}],"github_branch":"v1.0","github":"bacaron/app-reslice-roi-t1","name":"Reslice ROIs to match input anatomy","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a40a962f3d3800f12d82b"}],"create_date":"2021-05-19T22:28:04.670Z","desc":null,"__v":2613,"doi":"10.25663/brainlife.app.522","_canedit":true},{"_id":"60e4c42e4cb7040aec068b83","projects":[],"admins":["16"],"tags":[],"removed":false,"stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a414462f3d3800f12e260"}],"success_rate":88.48484848484848,"users":2,"runtime_mean":533586.93,"runtime_std":909171.0816872063,"requested":182,"examples":2,"groups":2},"config":{"anat":{"type":"input","file_id":"t1","input_id":"anat"},"rois":{"type":"input","file_id":"rois","input_id":"rois"},"label":{"type":"input","file_id":"label","input_id":"rois"},"warp":{"type":"input","file_id":"warp","input_id":"affine"},"inverse-warp":{"type":"input","file_id":"inverse-warp","input_id":"affine"},"affine":{"type":"input","file_id":"affine","input_id":"affine"},"inverse":{"id":"inverse","type":"boolean","placeholder":"","advanced":true,"desc":"","default":true,"_order":2,"pid":0.8803597877728695}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"60a590f422b42a32d96fb318","id":"anat","datatype":"58c33bcee13a50849b25879a"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"60a590f422b42a4f0c6fb319","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"60e4c42e4cb704115d068b88","id":"affine","datatype":"5bbfb28071454db2a890fbce"}],"outputs":[{"datatype_tags":["resliced","anat"],"output_on_root":false,"archive":true,"_id":"60a590f422b42a911a6fb31a","id":"output","datatype":"5be9ea0315a8683a39a1ebd9","datatype_tags_pass":"rois","files":null}],"github_branch":"affine-v1.0","github":"bacaron/app-reslice-roi-t1","name":"Reslice ROIs to match input anatomy (with affine)","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a414562f3d3800f12e261"}],"desc":null,"__v":2362,"create_date":"2021-07-06T20:59:26.811Z","doi":"10.25663/brainlife.app.539","_canedit":true},{"_id":"59272453436ee50ffd669a08","user_id":"1","name":"Round b-values / Flip b-vecs for dtiInit","desc":"(soon to be deprecated) This service round the b-values to the nearest 100. It will also flip the b-vecs around one or more chosen axes (please use Test Gradient Flip app to find out which one needs to be flipped). Some apps requires b-values to be round for their algorithms to work properly.","github":"brainlife/app-datanormalize","admins":["16","41","146","43","1"],"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"xflip":{"type":"boolean","default":false,"desc":"X-Flip (often required by Siemens/GE)","id":"xflip","pid":0.5119414629089731,"_order":2},"yflip":{"type":"boolean","default":false,"desc":"Y-Flip","id":"yflip","pid":0.09080818828737902,"_order":3},"zflip":{"type":"boolean","default":false,"desc":"Z-Flip (often required by Philips)","id":"zflip","pid":0.5784313679431679,"_order":4}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"59272495b3cd7c00211dc22d","id":"dwi","datatype":"58c33c5fe13a50849b25879b"}],"outputs":[{"datatype_tags":["normalized"],"output_on_root":true,"archive":true,"_id":"59272495b3cd7c00211dc22e","id":"output","datatype":"58c33c5fe13a50849b25879b","files":null,"datatype_tags_pass":"dwi"}],"__v":14332,"create_date":"2017-05-25T18:38:13.562Z","_rate":5,"tags":["diffusion-preprocessing"],"removed":false,"github_branch":"1.1","contributors":[{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a308562f3d3800f116217"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a308562f3d3800f116218"},{"name":"Franco Pestilli","email":null,"_id":"634a308562f3d3800f116219"}],"projects":[],"references":[],"stats":{"stars":0,"serviceinfo":{"_id":"5d729e1f78356a109788b2f7","counts":{"_id":"5e5c687687cac76eecab1b98","failed":1160,"finished":7195,"removed":8816,"requested":13523,"running":8234,"running_sync":0,"stop_requested":130},"success_rate":86.11609814482347,"users":31,"readme_status":"ok","runtime_mean":457217.38,"runtime_std":627787.970992114,"service":"brain-life/app-datanormalize","__v":0},"gitinfo":{"desc":"(soon to be deprecated) This service round the b-values to the nearest 100. It will also flip the b-vecs around one or more chosen axes (please use Test Gradient Flip app to find out which one needs to be flipped). Some apps requires b-values to be round for their algorithms to work properly.","tags":["diffusion-preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null}]},"success_rate":100,"users":3,"runtime_mean":91656.09090909091,"runtime_std":97905.36430140962,"requested":16,"resources":[],"examples":1,"groups":5},"doi":"10.25663/bl.app.4","desc_override":"","deprecated_by":"592db717b3cd7c00211dc230","_canedit":true},{"_id":"626ab5b3f3858674a2a3f407","user_id":"16","projects":[],"admins":["16"],"name":"Sample streamlines based on labels assignments","github":"brainlife/app-filter-tractograms","github_branch":"v1.0","tags":[],"config":{"track":{"type":"input","file_id":"track","input_id":"track"},"labels":{"type":"input","file_id":"index","input_id":"labels"}},"inputs":[{"id":"track","datatype":"5907d922436ee50ffde9c549","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"626ab5b3f3858674a2a3f408"},{"id":"labels","datatype":"606345ade4a8347b6f337de4","datatype_tags":["binary"],"optional":false,"multi":false,"advanced":false,"_id":"626ab5b3f3858674a2a3f409"}],"outputs":[{"id":"filtered_track","datatype":"5907d922436ee50ffde9c549","datatype_tags":["filtered"],"datatype_tags_pass":"track","output_on_root":false,"files":null,"archive":true,"_id":"626ab5b3f3858674a2a3f40a"}],"stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a441b62f3d3800f130bdc"}],"examples":1,"success_rate":40,"users":1,"groups":1,"runtime_mean":358873.5,"runtime_std":16639.5,"requested":5},"removed":false,"contributors":[{"name":"Brad Caron","email":null,"_id":"634a441c62f3d3800f130bdd"}],"create_date":"2022-04-28T15:41:39.753Z","desc":null,"__v":448,"doi":"10.25663/brainlife.app.619","_canedit":true},{"_id":"61395cfa584a767f674249ec","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a426c62f3d3800f12f53b"}],"examples":0,"users":1,"requested":2,"groups":1},"projects":[],"admins":["386"],"tags":["afni","brainlife","fmri","network"],"removed":false,"config":{"bold":{"type":"input","file_id":"bold","input_id":"bold"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"seed":{"id":"seed","type":"string","placeholder":"MNI coordinates to seed","advanced":false,"desc":"MNI coordinates to seed","default":"0 -54 26","_order":2,"pid":0.6481607779304515},"radius":{"id":"radius","type":"number","placeholder":"Radius in mm","advanced":false,"desc":"Radius from the seed to capture the average time series","default":5,"_order":3,"pid":0.22024279249308854,"min":0,"optional":false},"fwhm":{"id":"fwhm","type":"number","placeholder":"Smoothing FWHM, in mm","advanced":false,"desc":"Smoothing parameter (in mm). Blurs the image until it reaches the FWHM smoothness.","default":0,"_order":4,"pid":0.5877579506396371,"optional":true}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"61395cfa584a7605aa4249ed","id":"bold","datatype":"59b685a08e5d38b0b331ddc5"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"61395cfa584a76578e4249ee","id":"mask","datatype":"5a281aee2c214c9ba83ce620"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"61395cfa584a7622704249ef","id":"corr","datatype":"5edd3b77c5972b8c47b3a2c3","datatype_tags_pass":"bold","files":null}],"github_branch":"main","github":"anibalsolon/app-seed-correlation","name":"Seed-based Correlation","user_id":"386","contributors":[{"name":"Anibal Sólon","email":"anibalsolon@gmail.com","_id":"634a426c62f3d3800f12f53c"}],"create_date":"2021-09-09T01:01:46.200Z","desc":null,"__v":1865,"doi":"10.25663/brainlife.app.571","_canedit":true},{"_id":"5e54514f5b9d90668672d5fc","stats":{"stars":0,"serviceinfo":{"_id":"5e55bbdae86ae82d65712e1e","counts":{"_id":"5e5c3e3e87cac7db63ab1458","failed":33,"finished":609,"removed":1180,"requested":1803,"running":762,"running_sync":0,"stop_requested":98},"success_rate":94.85981308411215,"users":2,"readme_status":"too short","runtime_mean":1641385.46,"runtime_std":6687249.690709428,"service":"brainlife/app-intersect-tract-roi","__v":0},"success_rate":90.91310101455669,"users":5,"runtime_mean":3144216.95,"runtime_std":7326976.712590997,"requested":3443,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a386962f3d3800f11f304"}],"examples":3,"groups":7},"projects":[],"admins":["16"],"tags":[],"removed":false,"config":{"track_path":{"type":"input","file_id":"track","input_id":"track"},"classification_path":{"type":"input","file_id":"classification","input_id":"wmc"},"rois":{"type":"input","file_id":"rois","input_id":"rois"},"reference_anatomy":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"roiNames":{"id":"roiNames","type":"string","placeholder":"","advanced":false,"desc":"names of the rois to intersect. multiple rois can be used at one time to generate a single track, and multiple tracks can be generated at one time. groupings of rois go on a single line, multiple tracks goes on multiple lines. roi names come directly from input roi datatype, and text should match the text inbetween the .nii.gz and ROI entensions and prefixes.\n\nexample:\nfreesurfer-11121 freesurfer-11161\nfreesurfer-parietal_L freesurfer-11121\nfreesurfer_occipital_R","default":"","_order":2,"pid":0.31481397097224906,"multiline":true},"intersect_type":{"id":"intersect_type","type":"string","placeholder":"","advanced":false,"desc":"two types:\n1) \"include\": include streamlines that have endpoints in rois\n2) \"exclude\": include all other streamlines except those that end in rois\n\none type per track. for example, for three tracks:\n\ninclude\nexclude\ninclude","default":"","_order":3,"pid":0.44136795908243265,"multiline":true},"inverse":{"id":"inverse","type":"boolean","placeholder":"","advanced":false,"desc":"If you want the inverse of the operation (i.e. all streamlines that don't end in a roi), set this to true. default = false","default":false,"_order":4,"pid":0.14030337496686407},"endpoints_only":{"id":"endpoints_only","type":"boolean","placeholder":"","advanced":false,"desc":"If you want to only segment based on endpoints, set this to true. else, set to false. default = true","default":true,"_order":5,"pid":0.892463173454981}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e54514f5b9d90739a72d5fd","id":"track","datatype":"5907d922436ee50ffde9c549","desc":"The path to the track/tck datatype"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e54514f5b9d90841a72d5fe","id":"wmc","datatype":"5cc1d64c44947d8aea6b2d8b","desc":"The path to the classification.mat structure from the wmc datatype"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e54514f5b9d90643572d5ff","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9","desc":"The path to the rois datatype"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"60f20845ddc2df358f6727fc","id":"dwi","datatype":"58c33c5fe13a50849b25879b"}],"outputs":[{"datatype_tags":["intersected"],"output_on_root":false,"archive":true,"_id":"60f20845ddc2dfdf946727fd","id":"track","datatype":"5907d922436ee50ffde9c549","datatype_tags_pass":"track","files":null,"desc":""},{"datatype_tags":["intersected"],"output_on_root":false,"archive":true,"_id":"5e54514f5b9d903fe772d600","id":"wmc","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags_pass":"wmc","files":null,"desc":"The classification structure including a classification.mat structure that contains the streamline indices in the whole-brain tractogram."},{"datatype_tags":["intersected"],"output_on_root":false,"archive":true,"_id":"60f20845ddc2df51826727ff","id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":"wmc","files":null}],"github_branch":"v1.1","github":"brainlife/app-intersect-tract-roi","name":"Segment Tracts with ROIs","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a386a62f3d3800f11f305"},{"name":"Jan Kurzawski","email":null,"_id":"634a386a62f3d3800f11f306"},{"name":"Franco Pestilli","email":null,"_id":"634a386a62f3d3800f11f307"}],"create_date":"2020-02-24T22:42:23.805Z","desc":null,"doi":"10.25663/brainlife.app.282","__v":5512,"_canedit":true},{"_id":"610cad1fe1a90d476797cffe","projects":[],"admins":["16"],"tags":[],"removed":false,"stats":{"success_rate":90.91310101455669,"users":5,"runtime_mean":3144216.95,"runtime_std":7326976.712590997,"requested":3443,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a41ea62f3d3800f12f191"}],"examples":1,"groups":7},"config":{"track":{"type":"input","file_id":"track","input_id":"track"},"rois":{"type":"input","file_id":"rois","input_id":"rois"},"reference_anatomy":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"roiNames":{"id":"roiNames","type":"string","placeholder":"","advanced":false,"desc":"names of the rois to intersect. multiple rois can be used at one time to generate a single track, and multiple tracks can be generated at one time. groupings of rois go on a single line, multiple tracks goes on multiple lines. roi names come directly from input roi datatype, and text should match the text inbetween the .nii.gz and ROI entensions and prefixes.\n\nexample:\nfreesurfer-11121 freesurfer-11161\nfreesurfer-parietal_L freesurfer-11121\nfreesurfer_occipital_R","default":"","_order":2,"pid":0.9960000234896191,"multiline":true},"intersect_type":{"id":"intersect_type","type":"string","placeholder":"","advanced":false,"desc":"two types:\n1) \"include\": include streamlines that have endpoints in rois\n2) \"exclude\": include all other streamlines except those that end in rois\n\none type per track. for example, for three tracks:\n\ninclude\nexclude\ninclude","default":"","_order":3,"pid":0.39354487952486494,"multiline":true},"inverse":{"id":"inverse","type":"boolean","placeholder":"","advanced":false,"desc":"If you want the inverse of the operation (i.e. all streamlines that don't end in a roi), set this to true. default = false","default":false,"_order":4,"pid":0.16646208902617665},"endpoints_only":{"id":"endpoints_only","type":"boolean","placeholder":"","advanced":false,"desc":"If you want to only segment based on endpoints, set this to true. else, set to false. default = true","default":true,"_order":5,"pid":0.01568957167724183}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e54514f5b9d90739a72d5fd","id":"track","datatype":"5907d922436ee50ffde9c549","desc":"The path to the track/tck datatype"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e54514f5b9d90643572d5ff","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9","desc":"The path to the rois datatype"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"60f20845ddc2df358f6727fc","id":"dwi","datatype":"58c33c5fe13a50849b25879b"}],"outputs":[{"datatype_tags":["intersected"],"output_on_root":false,"archive":true,"_id":"60f20845ddc2dfdf946727fd","id":"track","datatype":"5907d922436ee50ffde9c549","datatype_tags_pass":"track","files":null,"desc":""},{"datatype_tags":["intersected"],"output_on_root":false,"archive":true,"_id":"5e54514f5b9d903fe772d600","id":"wmc","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags_pass":null,"files":null,"desc":"The classification structure including a classification.mat structure that contains the streamline indices in the whole-brain tractogram."},{"datatype_tags":["intersected"],"output_on_root":false,"archive":true,"_id":"60f20845ddc2df51826727ff","id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null}],"github_branch":"wholebrain-v1.0","github":"brainlife/app-intersect-tract-roi","name":"Segment Wholebrain Tractogram with ROIs","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a41eb62f3d3800f12f192"},{"name":"Jan Kurzawski","email":null,"_id":"634a41eb62f3d3800f12f193"},{"name":"Franco Pestilli","email":null,"_id":"634a41eb62f3d3800f12f194"}],"desc":null,"__v":2128,"create_date":"2021-08-06T03:31:43.528Z","doi":"10.25663/brainlife.app.556","_canedit":true},{"_id":"5d60c7314cfacf00366c11c2","stats":{"stars":0,"serviceinfo":{"_id":"5d729e1e78356a109788b1db","counts":{"_id":"5e5c3e1087cac76e98ab1427","failed":106,"finished":926,"removed":1403,"requested":1479,"running":985,"running_sync":0,"stop_requested":15},"success_rate":89.72868217054264,"users":5,"readme_status":"ok","runtime_mean":1950079.2,"runtime_std":1938600.008409801,"service":"brainlife/app-segment-thalamic-nuclei","__v":0},"gitinfo":{"desc":"This app will segment the thalamus into its multiple components using the developer version of Freesurfer's segmentThalamicNuclei.sh function (http://freesurfer.net/fswiki/ThalamicNuclei). This app takes a Freesurfer segmentation in as an input and generates .mgz files with the appropriate thalamic segmentation inside the Freesurfer directory as an output.","tags":["analysis","anatomy-preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null}]},"success_rate":91.98282032927703,"users":16,"runtime_mean":1315508.23,"runtime_std":1039061.9689246339,"requested":3942,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a36da62f3d3800f11d149"}],"examples":3,"groups":31},"projects":[],"admins":["1","16"],"tags":["analysis","anatomy-preprocessing"],"removed":false,"config":{"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d60c7314cfacf00366c11c3","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e","desc":"The path to the freesurfer datatype"}],"outputs":[{"datatype_tags":["thalamic_nuclei"],"output_on_root":false,"archive":false,"_id":"5d60c7314cfacf00366c11c4","id":"output","datatype":"58cb22c8e13a50849b25882e","datatype_tags_pass":"freesurfer","files":null,"desc":"Output freesurfer datatype including thalamic nuclei segmentation"}],"github_branch":"v1.0","github":"brainlife/app-segment-thalamic-nuclei","name":"Segment thalamic nuclei","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a36db62f3d3800f11d14a"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a36db62f3d3800f11d14b"}],"create_date":"2019-08-24T05:12:17.413Z","desc":"This app will segment the thalamus into its multiple components using the developer version of Freesurfer's segmentThalamicNuclei.sh function (http://freesurfer.net/fswiki/ThalamicNuclei). This app takes a Freesurfer segmentation in as an input and generates .mgz files with the appropriate thalamic segmentation inside the Freesurfer directory as an output.","doi":"10.25663/brainlife.app.222","__v":7263,"_canedit":true},{"_id":"5c3fba22147b69003601ca60","projects":[],"admins":["41","56"],"tags":["white-matter-segmentation"],"removed":false,"stats":{"stars":0,"requested":6256,"users":23,"success_rate":75.81903276131045,"serviceinfo":{"_id":"5d729e1f78356a109788b257","counts":{"_id":"5e5c3dd687cac737a4ab13ec","failed":630,"finished":2538,"removed":2930,"requested":3538,"running":3151,"running_sync":0,"stop_requested":76},"success_rate":80.11363636363636,"users":14,"readme_status":"ok","runtime_mean":4701550.01,"runtime_std":5896154.965123517,"service":"brainlife/app-streamlineCategorySegmentation","__v":0},"gitinfo":{"desc":"anatomy","tags":["anatomy","white-matter-segmentation"],"stats":{"stars":0},"contributors":[{"name":"Franco Pestilli","email":null},{"name":"Daniel Bullock","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Sophia Vinci-Booher","email":null}]},"runtime_mean":8509963.76,"runtime_std":20066628.778182894,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a34da62f3d3800f118e1b"}],"examples":0,"groups":32},"config":{"track":{"type":"input","file_id":"track","input_id":"track"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"inflateITer":{"id":"inflateITer","type":"number","placeholder":"2","desc":"How many iterations of inflation should be run to inflate grey matter into white matter. 2 recommended.  ","default":2,"_order":4,"pid":0.47871968746066007,"min":0}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c0865fff9b4a2002efc1584","id":"track","datatype":"5907d922436ee50ffde9c549","desc":"Whole brain tractography"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c0865fff9b4a2002efc1583","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e"}],"outputs":[{"datatype_tags":["categories"],"output_on_root":true,"archive":true,"_id":"5c094bf8f9b4a2002efc15ca","id":"wmc","datatype":"58f10a90436ee50ffd9063c5","datatype_tags_pass":"track","files":null},{"datatype_tags":["categories"],"output_on_root":false,"archive":true,"_id":"5cc1d8fb4ed9df00317f61bb","id":"classification","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags_pass":"track","files":null}],"name":"Segment tractogram into fiber categories","github":"brainlife/app-streamlineCategorySegmentation","user_id":"56","references":[],"contributors":[{"name":"Daniel Bullock","email":"iisdanbul@gmail.com","_id":"634a34db62f3d3800f118e1c"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a34db62f3d3800f118e1d"},{"name":"Franco Pestilli","email":null,"_id":"634a34db62f3d3800f118e1e"},{"name":"Sophia Vinci-Booher","email":null,"_id":"634a34db62f3d3800f118e1f"},{"name":null,"email":null,"_id":"634a34db62f3d3800f118e20"}],"__v":7337,"desc":"Automatically segment a tractogram into categories (i.e. fronto-parietal tracts, parieto-temporal tracts, etc). THIS APPLICATION IS HIGHLY RECOMMENDED AS A MEANS OF RUNNING AN INITIAL QUALITY ASSURANCE CHECK ON YOUR GENERATED TRACTOGRAPHY OR AS A SANITY CHECK ON PROBLEMATIC SEGMENTATIONS.","create_date":"2019-01-16T23:11:30.869Z","doi":"10.25663/brainlife.app.151","github_branch":"1.3","desc_override":"Segments all streamlines from an input tractogram in to general categories (i.e. fronto-temporal, parieto-occipital etc).","deprecated_by":"5dc9d8ee5017f0bde0519db5","_canedit":true},{"_id":"5dc9d8ee5017f0bde0519db5","projects":[],"admins":["56","1"],"tags":["white-matter-segmentation"],"removed":false,"stats":{"stars":0,"requested":6256,"users":23,"success_rate":75.81903276131045,"serviceinfo":{"_id":"5d729e1f78356a109788b257","counts":{"_id":"5e5c3e2a87cac72549ab143d","failed":630,"finished":2538,"removed":2930,"requested":3538,"running":3151,"running_sync":0,"stop_requested":76},"success_rate":80.11363636363636,"users":14,"readme_status":"ok","runtime_mean":4701550.01,"runtime_std":5896154.965123517,"service":"brainlife/app-streamlineCategorySegmentation","__v":0},"gitinfo":{"desc":"anatomy","tags":["anatomy","white-matter-segmentation"],"stats":{"stars":0},"contributors":[{"name":"Franco Pestilli","email":null},{"name":"Daniel Bullock","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Sophia Vinci-Booher","email":null}]},"runtime_mean":8509963.76,"runtime_std":20066628.778182894,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a379d62f3d3800f11e378"}],"examples":0,"groups":32},"config":{"track":{"type":"input","file_id":"track","input_id":"track"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"inflateITer":{"id":"inflateITer","type":"number","placeholder":"2","desc":"How many iterations of inflation should be run to inflate grey matter into white matter. 2 recommended.  ","default":2,"_order":4,"pid":0.35151144198578943,"min":0}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c0865fff9b4a2002efc1584","id":"track","datatype":"5907d922436ee50ffde9c549","desc":"Whole brain tractography"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c0865fff9b4a2002efc1583","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e"}],"outputs":[{"datatype_tags":["categories"],"output_on_root":false,"archive":true,"_id":"5cc1d8fb4ed9df00317f61bb","id":"classification","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags_pass":"track","files":null}],"name":"Segment tractogram into fiber categories","github":"brainlife/app-streamlineCategorySegmentation","user_id":"1","contributors":[{"name":"Daniel Bullock","email":"iisdanbul@gmail.com","_id":"634a379e62f3d3800f11e379"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a379e62f3d3800f11e37a"},{"name":"Franco Pestilli","email":null,"_id":"634a379e62f3d3800f11e37b"},{"name":"Sophia Vinci-Booher","email":null,"_id":"634a379e62f3d3800f11e37c"},{"name":null,"email":null,"_id":"634a379e62f3d3800f11e37d"}],"__v":6547,"desc":"Automatically segment a tractogram into categories (i.e. fronto-parietal tracts, parieto-temporal tracts, etc). THIS APPLICATION IS HIGHLY RECOMMENDED AS A MEANS OF RUNNING AN INITIAL QUALITY ASSURANCE CHECK ON YOUR GENERATED TRACTOGRAPHY OR AS A SANITY CHECK ON PROBLEMATIC SEGMENTATIONS.","github_branch":"2.0","desc_override":"","create_date":"2019-11-11T21:55:58.655Z","doi":"10.25663/brainlife.app.249","_canedit":true},{"_id":"5f77e8cd268f7638af29a925","stats":{"resources":[],"success_rate":52.75590551181102,"users":2,"runtime_mean":1509383.462686567,"runtime_std":2250036.5602694694,"requested":151,"examples":1,"groups":2},"projects":[],"admins":["16"],"tags":[],"removed":false,"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"tractogram":{"type":"input","file_id":"track","input_id":"tractogram"},"classification":{"type":"input","file_id":"classification","input_id":"classification"},"number_bundles":{"id":"number_bundles","type":"string","placeholder":"","advanced":false,"desc":"","default":"3","_order":2,"pid":0.6714592432551441}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5f77e8cd268f766bdb29a926","id":"dwi","datatype":"58c33c5fe13a50849b25879b","desc":"Source dwi for tractogram. Only used in loading"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5f77e8cd268f76844729a927","id":"tractogram","datatype":"5907d922436ee50ffde9c549"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5f77e8cd268f765d1029a928","id":"classification","datatype":"5cc1d64c44947d8aea6b2d8b"}],"outputs":[{"datatype_tags":["quickbundles"],"output_on_root":false,"archive":true,"_id":"5f77e8cd268f76088e29a929","id":"wmc","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags_pass":"classification","files":null}],"github_branch":"main","github":"brainlife/app-extract-bundles-quickbundles","name":"Segment tracts into multiple bundles using QuickBundles","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3db962f3d3800f12b576"}],"create_date":"2020-10-03T02:58:21.040Z","desc":null,"doi":"10.25663/brainlife.app.438","__v":4150,"_canedit":true},{"_id":"5e82b9eadd840e693ae970be","stats":{"success_rate":0.3797185615367433,"users":16,"runtime_mean":6657990.647058823,"runtime_std":8398729.027456077,"requested":4911,"resources":[],"examples":1,"groups":25},"projects":[],"admins":["16"],"tags":[],"removed":false,"config":{"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"track":{"type":"input","file_id":"track","input_id":"track"},"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"affine":{"id":"affine","type":"boolean","placeholder":"","advanced":false,"desc":"If true, will first align the DWI to the MNI template using an affine registration before computing the non-linear warp. However, if this has already been done, the non-linear warp should work just fine and this can be set to false","default":false,"_order":2,"pid":0.5975314417540152}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e82b9eadd840e1dade970bf","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e","desc":"The path to the top directory of the Freesurfer datatype. This is used for the visualization."},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e82b9eadd840e58d4e970c0","id":"track","datatype":"5907d922436ee50ffde9c549","desc":"The path to the whole-brain tractogram to be segmented."},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e82b9eadd840e83b7e970c1","id":"dwi","datatype":"58c33c5fe13a50849b25879b","desc":"The path to the DWI datatype used to generate the whole-brain tractogram."}],"outputs":[{"datatype_tags":["afq"],"output_on_root":false,"archive":true,"_id":"5e82b9eadd840e0f8ee970c2","id":"wmc","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags_pass":null,"files":null,"desc":"The AFQ classification structure including a classification.mat structure that contains the streamline indices in the whole-brain tractogram."}],"github_branch":"0.4.1","github":"brainlife/app-pyafq-segment","name":"Segment white matter tracts using pyAFQ","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a38dd62f3d3800f11feae"},{"name":"Giulia Bertò","email":null,"_id":"634a38dd62f3d3800f11feaf"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a38dd62f3d3800f11feb0"}],"create_date":"2020-03-31T03:32:58.860Z","desc":null,"doi":"10.25663/brainlife.app.295","__v":5233,"desc_override":"This app will segment a whole-brain tractogram into the 20 whole-brain tracks provided by Automatic Fiber Quantification (AFQ). This app takes a dwi, track/tck, and freesurfer inputs and outputs a white-matter classification (WMC) structure containing the names and streamlines indices of the AFQ tracks.","_canedit":true},{"_id":"628a4e34d0697cf1eae9b915","user_id":"56","projects":[],"admins":["56"],"name":"Segment with ROIs","github":"DanNBullock/app-segment_with_ROIs","desc_override":"Segment a tractogram to return a tract or tracts","tags":[],"config":{"tractogram":{"type":"input","file_id":"track","input_id":"tractogram"},"availableROIs":{"type":"input","file_id":"rois","input_id":"ROIs"},"label":{"type":"input","file_id":"label","input_id":"ROIs"},"tractNames":{"id":"tractNames","type":"string","placeholder":"tract1,tract2,tract3","advanced":false,"desc":"What to name the requested tract(s).  BE SURE TO ENTER MULTIPLE NAMES IF YOU'RE REQUESTING MULTIPLE TRACTS","default":"","_order":2,"pid":0.43014030603446296},"segRequests":{"id":"segRequests","type":"string","placeholder":"endpoint_ROI1 either_end true;exclusion_ROI1 any false;waypoint_ROI1 any true endpoint_ROI2 either_end true;exclusion_ROI2 any false;waypoint_ROI2 any true endpoint_ROI3 either_end true;exclusion_ROI3 any false;waypoint_ROI3 any true","advanced":false,"desc":"The performance of a segmentation is based on the application of some number of segmentation criteria.  Each segmentation criteria is composed of the following:\n\n1.  ROI name:  the name of the specific, desired ROI that is found in the input ROI datatype.\n\n2.  The requested operation, which may be one of the following: \n\n>  \"any\" : any point is within tolerance from ROI. The \"default\" operation.\n>  \"all\" : all points are within tolerance from ROI.\n>  \"either_end\" : either of the end-points is within tolerance from ROI\n>  \"both_end\" : both end points are within tolerance from ROI.\n\n3.  Whether or not the streamlines meeting the operation criteria should be retained or excluded.  True = keep, False = exclude.\n\nYou can perform a single segmentation or multiple segmentations with this app.\n\nTo perform a **single segmentation** (e.g. to obtain one tract), each criterion should be entered on a separate line.  Each component of a criterion should be separated by a space.  As an example:\n\nendpoint_ROI1 either_end true\nexclusion_ROI1 any false\nwaypoint_ROI1 any true\n\nTo perform a **multi segmentation** (e.g. to obtain multiple tracts), each set of criteria (for distinct tracts) should be on separate lines.  Within each line (and thus for each tract) each individual criterion should separated by a semicolon (;).  Each component of a criterion should be separated by a space.  As an example:\n\nendpoint_ROI1 either_end true;exclusion_ROI1 any false;waypoint_ROI1 any true\nendpoint_ROI2 either_end true;exclusion_ROI2 any false;waypoint_ROI2 any true\nendpoint_ROI3 either_end true;exclusion_ROI3 any false;waypoint_ROI3 any true","default":"","_order":3,"pid":0.12142604191446604,"optional":false,"multiline":true}},"inputs":[{"id":"tractogram","datatype":"5907d922436ee50ffde9c549","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"628a4e34d0697cf1eae9b916"},{"id":"ROIs","datatype":"5be9ea0315a8683a39a1ebd9","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"628a4e34d0697cf1eae9b917"}],"outputs":[{"id":"output","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags":["customSeg"],"datatype_tags_pass":"tractogram","output_on_root":false,"files":null,"archive":true,"_id":"628a4e34d0697cf1eae9b918"}],"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a448162f3d3800f130e35"}],"examples":1,"success_rate":37.68115942028986,"users":1,"groups":2,"runtime_mean":7530760.807692308,"runtime_std":2379587.8664086577,"requested":92},"removed":false,"contributors":[{"name":"Daniel Bullock","email":"iisdanbul@gmail.com","_id":"634a448262f3d3800f130e36"}],"create_date":"2022-05-22T14:52:36.759Z","desc":null,"__v":326,"doi":"10.25663/brainlife.app.631","github_branch":"multiSeg","_canedit":true},{"_id":"5a5100c306b9e8003f1ee684","name":"Segmentation with Median Otsu ","desc":"Brainlife wrapper app for dipy_median_otsu workflows.","citation":null,"github":"dipy/bl_apps_dipy_median_otsu","github_branch":"1.1.1","config":{"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"median_radius":{"default":2,"desc":"Radius (in voxels) of the applied median filter.","placeholder":"","type":"number","id":"median_radius","pid":0.5392814339106788,"_order":2},"numpass":{"default":5,"desc":"The number of times to pass of the median filter.","placeholder":"","type":"number","id":"numpass","pid":0.4334777842577828,"_order":3},"autocrop":{"type":"boolean","placeholder":"","desc":"Check this if you'd want to crop using the bounding box defined by the masked data. For example, if diffusion images are of 1x1x1 (mm^3) or higher resolution auto-cropping could reduce their size in memory and speed up some of the analysis.","default":false,"id":"autocrop","pid":0.2233848793388966,"_order":4},"vol_idx":{"id":"vol_idx","type":"string","placeholder":"","advanced":false,"desc":"1D array representing indices of the last dimension of a 4D 'input_volume', i.e., gradients. The input must be provided as \"0 1 2 3 4\".","default":"0","_order":5,"pid":0.01919482141882356},"dilate":{"id":"dilate","type":"string","placeholder":"","advanced":false,"desc":"The number of iterations for binary dilation.","default":"null","_order":6,"pid":0.6015483656204696}},"desc_override":"Brain segmentation with the median_otsu method using DIPY.","user_id":"1","create_date":"2018-01-06T17:00:51.493Z","removed":false,"_rate":0,"outputs":[{"id":"output","datatype":"58c33c5fe13a50849b25879b","datatype_tags":["masked"],"datatype_tags_pass":"dwi","output_on_root":false,"files":null,"archive":true,"_id":"5a510364183f630030d86eb2"},{"id":"secondary","datatype":"5a281aee2c214c9ba83ce620","datatype_tags":["brain","dwi"],"output_on_root":false,"files":null,"archive":true,"_id":"5a510364183f630030d86eb1"}],"inputs":[{"id":"dwi","datatype":"58c33c5fe13a50849b25879b","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5a5100c306b9e8003f1ee685"}],"contributors":[{"name":"Javier Guaje","email":null,"_id":"634a31cc62f3d3800f11693b"},{"name":"Serge Koudoro","email":null,"_id":"634a31cc62f3d3800f11693c"}],"tags":["diffusion-mri","diffusion-preprocessing","dipy"],"references":[],"admins":["41","285","87","1"],"projects":[],"__v":14261,"stats":{"stars":0,"requested":1175,"users":9,"success_rate":95.0965824665676,"serviceinfo":{"_id":"5d729e1f78356a109788b2dd","counts":{"_id":"5e5c689587cac74675ab1bbf","failed":1372,"finished":2816,"removed":5103,"requested":5301,"running":3198,"running_sync":0,"stop_requested":12},"success_rate":67.23973256924546,"users":20,"readme_status":"ok","runtime_mean":5885857.53,"runtime_std":14501545.618587041,"service":"brain-life/app-dipy-workflows","__v":0},"gitinfo":{"desc":"Brainlife wrapper app for Dipy workflows.","tags":["dipy"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Serge Koudoro","email":null},{"name":"Aman Arya","email":"aman.arya524@gmail.com"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":56332.21,"runtime_std":153399.40732286384,"resources":[],"examples":3,"groups":28},"doi":"10.25663/bl.app.70","_canedit":true},{"_id":"5c37b38f836af601cc8587af","stats":{"stars":0,"requested":29,"users":4,"success_rate":44.44444444444444,"serviceinfo":{"_id":"5d729e1f78356a109788b25b","counts":{"_id":"5e5c3dd587cac7564fab13eb","failed":12,"finished":9,"removed":8,"requested":21,"running":20,"running_sync":0,"stop_requested":0},"success_rate":42.857142857142854,"users":1,"readme_status":"ok","runtime_mean":123736.11111111111,"runtime_std":127565.68790796411,"service":"soichih/app-shapesignature","__v":0},"gitinfo":{"desc":" This App takes tract masks and convert them to series of numerical values that chracaterizes each masks.  The numerical values are generated from the flattened output of 3D convolutional layers of the model trained to classify tract names. Output values could be used as a \"shape signature\" and compared against other similar shaped tracts.","tags":[],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":130233.83333333333,"runtime_std":122727.6647621563,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a34d162f3d3800f118e17"},{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"634a34d162f3d3800f118e18"}],"examples":1,"groups":5},"projects":[],"admins":["16","41","146","1"],"tags":[],"removed":false,"config":{"masks":{"type":"input","file_id":"masks","input_id":"masks"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c37b38f836af601cc8587b0","id":"masks","datatype":"592dded1436ee50ffd88f5d0"}],"outputs":[{"datatype_tags":["shape_signature"],"output_on_root":true,"archive":true,"_id":"5c37b38f836af601cc8587b1","id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null}],"github_branch":"1.0","github":"soichih/app-shapesignature","name":"Shape Signature","user_id":"1","references":[],"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a34d262f3d3800f118e19"}],"create_date":"2019-01-10T21:05:19.896Z","desc":" This App takes tract masks and convert them to series of numerical values that chracaterizes each masks.  The numerical values are generated from the flattened output of 3D convolutional layers of the model trained to classify tract names. Output values could be used as a \"shape signature\" and compared against other similar shaped tracts.","doi":"10.25663/brainlife.app.141","__v":9024,"_canedit":true},{"_id":"60b139f022b42a6dc5771dd2","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a40eb62f3d3800f12dccc"}],"success_rate":86.63551401869158,"users":1,"runtime_mean":23190.87,"runtime_std":20948.441733291285,"requested":5368,"examples":2,"groups":9},"projects":[],"admins":["1348"],"tags":["meg"],"removed":false,"config":{"mne":{"type":"input","file_id":"mne","input_id":"raw01"},"t1min":{"id":"t1min","type":"number","placeholder":"","advanced":false,"desc":"In seconds","default":0,"_order":2,"pid":0.7254194477339412},"t1max":{"id":"t1max","type":"string","placeholder":"","advanced":false,"desc":"In seconds","default":"100","_order":3,"pid":0.42114784260021687},"t2min":{"id":"t2min","type":"number","placeholder":"","advanced":false,"desc":"In seconds","default":100,"_order":4,"pid":0.5937861576378629},"t2max":{"id":"t2max","type":"number","placeholder":"","advanced":false,"desc":"In seconds","default":200,"_order":5,"pid":0.8800825996164462}},"inputs":[{"id":"raw01","datatype":"61893398e8be76b34cb9826e","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"60b139f022b42ad000771dd3"}],"outputs":[{"id":"out_dir1","datatype":"6000737faacf9ee51fa691cb","datatype_tags":["split","test"],"datatype_tags_pass":"raw01","output_on_root":false,"files":null,"archive":true,"_id":"60b139f022b42a73ff771dd4"},{"id":"out_dir2","datatype":"6000737faacf9ee51fa691cb","datatype_tags":["split","retest"],"datatype_tags_pass":"raw01","output_on_root":false,"files":null,"archive":true,"_id":"60b139f022b42a5d51771dd5"}],"github_branch":"main","github":"guiomar/app-meg-split-fif","name":"Split MEG file","user_id":"1348","contributors":[{"name":"Julia Guiomar Niso Galán","email":null,"_id":"634a40eb62f3d3800f12dccd"}],"create_date":"2021-05-28T18:44:00.559Z","desc":null,"__v":2603,"doi":"10.25663/brainlife.app.529","_canedit":true},{"_id":"60d08cb5cdfdb50acdff5893","projects":[],"admins":["1348"],"tags":[],"removed":false,"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a412962f3d3800f12e1cb"}],"success_rate":27.083333333333332,"users":2,"runtime_mean":49553.692307692305,"runtime_std":121278.80699153476,"requested":51,"examples":1,"groups":5},"config":{"ds":{"type":"input","file_id":"ds","input_id":"fif file"},"headshape":{"type":"input","file_id":"headshape","input_id":"fif file"},"channels":{"type":"input","file_id":"channels","input_id":"fif file"},"coordsystem":{"type":"input","file_id":"coordsystem","input_id":"fif file"},"events":{"type":"input","file_id":"events","input_id":"fif file"},"events_json":{"type":"input","file_id":"events_json","input_id":"fif file"},"t1min":{"id":"t1min","type":"number","placeholder":"","advanced":false,"desc":"","default":0,"_order":2,"pid":0.3730780566745733},"t1max":{"id":"t1max","type":"string","placeholder":"","advanced":false,"desc":"","default":"","_order":3,"pid":0.2814415379079148},"t2min":{"id":"t2min","type":"number","placeholder":"","advanced":false,"desc":"","default":null,"_order":4,"pid":0.33458976708559374},"t2max":{"id":"t2max","type":"number","placeholder":"","advanced":false,"desc":"","default":null,"_order":5,"pid":0.7580847799905971}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"60b139f022b42ad000771dd3","id":"fif file","datatype":"6000714baacf9e22a6a691c8"}],"outputs":[{"datatype_tags":["split","test"],"output_on_root":false,"archive":false,"_id":"60b139f022b42a73ff771dd4","id":"out_dir1","datatype":"6000737faacf9ee51fa691cb","datatype_tags_pass":null,"files":null},{"datatype_tags":["split","retest"],"output_on_root":false,"archive":true,"_id":"60b139f022b42a5d51771dd5","id":"out_dir2","datatype":"6000737faacf9ee51fa691cb","datatype_tags_pass":null,"files":null}],"github_branch":"main","github":"guiomar/app-meg-split-ctf","name":"Split MEG file [ctf]","user_id":"1348","contributors":[{"name":"Julia Guiomar Niso Galán","email":null,"_id":"634a412962f3d3800f12e1cc"}],"desc":null,"__v":2409,"create_date":"2021-06-21T12:57:25.179Z","doi":"10.25663/brainlife.app.536","_canedit":true},{"_id":"592db717b3cd7c00211dc230","name":"Split Shells","desc":"Split multi-shell diffusion data into a single chosen b value shell while rounding bvals","avatar":"https://static.projects.iq.harvard.edu/files/styles/os_files_medium/public/nac/files/multishell_dmri.png","github":"brainlife/app-splitshells","github_branch":"1.2","config":{"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvals_round":{"id":"bvals_round","type":"number","placeholder":"","desc":"bvals will be rounded up to nearest bvals with this value. For example, 100 means 2401-2499 will be rounded to 2500. ","default":100,"_order":2,"pid":0.2420938640171919,"min":0},"shell":{"default":1000,"type":"integer","id":"shell","pid":0.43170664203152964,"_order":3,"desc":"bval corresponding to the shell you want to extract."},"b0_max":{"id":"b0_max","type":"number","placeholder":"","desc":"Any bvals equal or less than this value will be considered b0.","default":200,"_order":4,"pid":0.7118918771214804,"min":0}},"user_id":"43","create_date":"2017-05-30T18:16:55.217Z","outputs":[{"datatype_tags":["single_shell"],"output_on_root":true,"archive":true,"_id":"592db804b3cd7c00211dc231","id":"output","datatype":"58c33c5fe13a50849b25879b","files":null,"datatype_tags_pass":"dwi","desc":"Single shell dwi data."}],"inputs":[{"datatype_tags":["!single_shell"],"optional":false,"multi":false,"advanced":false,"_id":"592db717b3cd7c00211dc22f","id":"dwi","datatype":"58c33c5fe13a50849b25879b","desc":"Multi-shell dwi data."}],"admins":["16","41","146","43","1"],"__v":14303,"_rate":5,"tags":["diffusion-preprocessing"],"removed":false,"contributors":[{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a308f62f3d3800f11637e"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a308f62f3d3800f11637f"},{"name":"Franco Pestilli","email":null,"_id":"634a308f62f3d3800f116380"}],"projects":[],"references":[],"stats":{"stars":0,"requested":2438,"users":25,"success_rate":91.42131979695432,"serviceinfo":{"_id":"5d729e1e78356a109788b229","counts":{"_id":"5e5c687787cac7de27ab1b99","failed":29,"finished":462,"removed":833,"requested":858,"running":610,"running_sync":0,"stop_requested":121},"success_rate":94.09368635437882,"users":14,"readme_status":"ok","runtime_mean":313953.05,"runtime_std":194584.31356763456,"service":"brainlife/app-splitshells","__v":0},"gitinfo":{"desc":"Split multi-shell diffusion data into a single chosen b value shell while rounding bvals","tags":["diffusion-preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":932332.86,"runtime_std":3664477.719378139,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a308e62f3d3800f11637d"}],"examples":3,"groups":41},"doi":"10.25663/bl.app.17","_canedit":true},{"_id":"5ea9b710f1745d6d4af842f2","stats":{"success_rate":98.45559845559846,"users":4,"runtime_mean":113442.55,"runtime_std":146419.17360041165,"requested":260,"resources":[],"examples":3,"groups":3},"projects":[],"admins":["285","87"],"tags":["diffusion-mri","dipy"],"removed":false,"config":{"static_track":{"type":"input","file_id":"track","input_id":"static_tracks"},"moving_track":{"type":"input","file_id":"track","input_id":"moving_tracks"},"x0":{"id":"x0","type":"enum","placeholder":"","advanced":false,"desc":"Affine, rigid, or similarity transformation model (default affine)","default":"affine","_order":3,"pid":0.8653076071205235,"options":[{"desc":"","label":"Affine","value":"affine"},{"desc":"","label":"Rigid","value":"rigid"},{"desc":"","label":"Similarity","value":"similarity"}]},"rm_small_clusters":{"id":"rm_small_clusters","type":"number","placeholder":"","advanced":false,"desc":"Remove clusters that have less than rm_small_clusters","default":50,"_order":4,"pid":0.5797283484531104},"greater_than":{"id":"greater_than","type":"number","placeholder":"","advanced":false,"desc":"Keep streamlines that have length greater than this value","default":50,"_order":5,"pid":0.1901766190256451},"less_than":{"id":"less_than","type":"number","placeholder":"","advanced":false,"desc":"Keep streamlines have length less than this value","default":250,"_order":6,"pid":0.9635600235450656},"nb_pts":{"id":"nb_pts","type":"number","placeholder":"","advanced":false,"desc":"Number of points for discretizing each streamline","default":20,"_order":7,"pid":0.4242035944995235},"progressive":{"id":"progressive","type":"boolean","placeholder":"","advanced":false,"desc":"","default":true,"_order":8,"pid":0.8772525166288432}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ea9b710f1745d152bf842f3","id":"static_tracks","datatype":"5b956f6cd7b3f1e24e9121ce","desc":" "},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ea9b710f1745d7689f842f4","id":"moving_tracks","datatype":"5b956f6cd7b3f1e24e9121ce"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5ea9b710f1745d3224f842f5","id":"output","datatype":"5b956f6cd7b3f1e24e9121ce","datatype_tags_pass":null,"files":null}],"github_branch":"1.1.1","github":"dipy/bl_apps_dipy_slr","name":"Streamlines Linear Registration (slr)","user_id":"87","contributors":[{"name":"Serge Koudoro","email":null,"_id":"634a3a3562f3d3800f123744"},{"name":"Javier Guaje","email":null,"_id":"634a3a3562f3d3800f123745"}],"create_date":"2020-04-29T17:19:12.298Z","desc":"Brainlife wrapper app for dipy_slr workflows.","doi":"10.25663/brainlife.app.332","__v":4951,"_canedit":true},{"_id":"626840bbf3858674a29fe791","user_id":"16","projects":[],"admins":["16"],"name":"Structural Connectome MRTrix3 (SCMRT)","github":"brainlife/app-sift2-connectome-generation","github_branch":"nosift-input-labels-weights-v1.0","desc":null,"desc_override":"Generate structural connectomes using MRTrix3","tags":[],"contributors":[{"name":"Brad Caron","email":null,"_id":"634a440962f3d3800f130b41"},{"name":"Franco Pestilli","email":null,"_id":"634a440962f3d3800f130b42"}],"config":{"track":{"type":"input","file_id":"track","input_id":"track"},"parc":{"type":"input","file_id":"parc","input_id":"parc"},"key":{"type":"input","file_id":"key","input_id":"parc"},"label":{"type":"input","file_id":"label","input_id":"parc"},"fa":{"type":"input","file_id":"fa","input_id":"tensor"},"md":{"type":"input","file_id":"md","input_id":"tensor"},"rd":{"type":"input","file_id":"rd","input_id":"tensor"},"ad":{"type":"input","file_id":"ad","input_id":"tensor"},"ga":{"type":"input","file_id":"ga","input_id":"tensor"},"ak":{"type":"input","file_id":"ak","input_id":"tensor"},"mk":{"type":"input","file_id":"mk","input_id":"tensor"},"rk":{"type":"input","file_id":"rk","input_id":"tensor"},"ndi":{"type":"input","file_id":"ndi","input_id":"noddi"},"isovf":{"type":"input","file_id":"isovf","input_id":"noddi"},"odi":{"type":"input","file_id":"odi","input_id":"noddi"},"labels":{"type":"input","file_id":"index","input_id":"labels"},"weights":{"type":"input","file_id":"weights","input_id":"weights"},"T1map":{"type":"input","file_id":"T1map","input_id":"qmri"},"T1map_json":{"type":"input","file_id":"T1map_json","input_id":"qmri"},"R1map":{"type":"input","file_id":"R1map","input_id":"qmri"},"R1map_json":{"type":"input","file_id":"R1map_json","input_id":"qmri"},"M0map":{"type":"input","file_id":"M0map","input_id":"qmri"},"M0map_json":{"type":"input","file_id":"M0map_json","input_id":"qmri"},"PD":{"type":"input","file_id":"PD","input_id":"qmri"},"MTV":{"type":"input","file_id":"MTV","input_id":"qmri"},"VIP":{"type":"input","file_id":"VIP","input_id":"qmri"},"SIR":{"type":"input","file_id":"SIR","input_id":"qmri"},"WF":{"type":"input","file_id":"WF","input_id":"qmri"},"myelin_map":{"type":"input","file_id":"map","input_id":"myelin_map"},"assignment_radial_search":{"id":"assignment_radial_search","type":"number","placeholder":"","advanced":true,"desc":"perform a radial search from each streamline endpoint to locate the nearest node. Argument is the maximum radius in mm; if no node is found within this radius, the streamline endpoint is not assigned to any node. Default search distance is 4mm.","default":4,"_order":2,"pid":0.16648079594553855},"assignment_reverse_search":{"id":"assignment_reverse_search","type":"string","placeholder":"","advanced":true,"desc":"traverse from each streamline endpoint inwards along the streamline, in search of the last node traversed by the streamline. Argument is the maximum traversal length in mm (set to 0 to allow search to continue to the streamline midpoint).","default":"","_order":3,"pid":0.7933662654695963,"optional":true},"assignment_forward_search":{"id":"assignment_forward_search","type":"string","placeholder":"","advanced":true,"desc":"project the streamline forwards from the endpoint in search of a parcellation node voxel. Argument is the maximum traversal length in mm.","default":"","_order":4,"pid":0.5318618094965264,"optional":true}},"inputs":[{"id":"track","datatype":"5907d922436ee50ffde9c549","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5f2a1b64beafe9807362b4fe"},{"id":"parc","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5f2a1b64beafe922a562b4ff"},{"id":"tensor","datatype":"5a79df48d071a1753f1d661b","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5f2a1b64beafe93cc462b502"},{"id":"noddi","datatype":"5ed02a620a8ed8e39c482a61","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5f2a1b64beafe91c7c62b503"},{"id":"labels","datatype":"606345ade4a8347b6f337de4","datatype_tags":["binary"],"optional":true,"multi":false,"advanced":false,"_id":"626840bbf3858674a29fe798"},{"id":"weights","datatype":"5dcecaffc4ae284155298383","datatype_tags":["sift2"],"optional":true,"multi":false,"advanced":false,"_id":"626840bbf3858674a29fe799"},{"id":"qmri","datatype":"608ac8b089df43e33c758fa1","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"6268584df3858674a2a076ec"},{"id":"myelin_map","datatype":"5fad54c27e8ecba2c3aa0c24","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"6268584df3858674a2a076ed"}],"outputs":[{"id":"output","datatype":"59c3eae633fc1cf9ead71679","datatype_tags":["networkmatrices"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5f2a1b64beafe9dad262b504"},{"id":"count_out","datatype":"5d34d9f744947d8aea0e0d2f","datatype_tags":["count"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"6111cae8a5a04c3b68f84bda"},{"id":"length_out","datatype":"5d34d9f744947d8aea0e0d2f","datatype_tags":["length"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"6111cae8a5a04c5d13f84bdb"},{"id":"density_out","datatype":"5d34d9f744947d8aea0e0d2f","datatype_tags":["density"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"6111cae8a5a04c5d92f84bdc"},{"id":"denlen_out","datatype":"5d34d9f744947d8aea0e0d2f","datatype_tags":["denlen"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"6111cae8a5a04c4c71f84bdd"},{"id":"assignments","datatype":"606345ade4a8347b6f337de4","datatype_tags":["connectivity_assignments"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"62685813f3858674a2a05bc7"}],"stats":{"success_rate":74.46719160104986,"groups":27,"users":11,"runtime_mean":336572.05,"runtime_std":671455.0292547282,"requested":14312,"resources":[{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a440962f3d3800f130b3f"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a440962f3d3800f130b40"}],"examples":1},"removed":false,"__v":467,"create_date":"2022-04-26T18:58:03.997Z","doi":"10.25663/brainlife.app.617","_canedit":true},{"_id":"6165b253fc8eb97e54faca55","projects":[],"admins":["16"],"tags":[],"removed":false,"stats":{"resources":[{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a42bf62f3d3800f12fa32"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a42bf62f3d3800f12fa33"}],"success_rate":74.46719160104986,"users":11,"runtime_mean":336572.05,"runtime_std":671455.0292547282,"requested":14312,"examples":2,"groups":27},"config":{"track":{"type":"input","file_id":"track","input_id":"track"},"parc":{"type":"input","file_id":"parc","input_id":"parc"},"key":{"type":"input","file_id":"key","input_id":"parc"},"label":{"type":"input","file_id":"label","input_id":"parc"},"lmax2":{"type":"input","file_id":"lmax2","input_id":"csd"},"lmax4":{"type":"input","file_id":"lmax4","input_id":"csd"},"lmax6":{"type":"input","file_id":"lmax6","input_id":"csd"},"lmax8":{"type":"input","file_id":"lmax8","input_id":"csd"},"lmax10":{"type":"input","file_id":"lmax10","input_id":"csd"},"lmax12":{"type":"input","file_id":"lmax12","input_id":"csd"},"lmax14":{"type":"input","file_id":"lmax14","input_id":"csd"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"fa":{"type":"input","file_id":"fa","input_id":"tensor"},"md":{"type":"input","file_id":"md","input_id":"tensor"},"rd":{"type":"input","file_id":"rd","input_id":"tensor"},"ad":{"type":"input","file_id":"ad","input_id":"tensor"},"ga":{"type":"input","file_id":"ga","input_id":"tensor"},"ak":{"type":"input","file_id":"ak","input_id":"tensor"},"mk":{"type":"input","file_id":"mk","input_id":"tensor"},"rk":{"type":"input","file_id":"rk","input_id":"tensor"},"ndi":{"type":"input","file_id":"ndi","input_id":"noddi"},"isovf":{"type":"input","file_id":"isovf","input_id":"noddi"},"odi":{"type":"input","file_id":"odi","input_id":"noddi"},"lmax":{"id":"lmax","type":"number","placeholder":"","advanced":false,"desc":"","default":8,"_order":2,"pid":0.46614147317283183}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5f2a1b64beafe9807362b4fe","id":"track","datatype":"5907d922436ee50ffde9c549"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5f2a1b64beafe922a562b4ff","id":"parc","datatype":"5c1a7489f9109beac4a88a1f"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5f2a1b64beafe903cf62b500","id":"csd","datatype":"5c536bf0f9109beac46adb45"},{"datatype_tags":["5tt_masks"],"optional":false,"multi":false,"advanced":false,"_id":"5f2a1b64beafe910e262b501","id":"mask","datatype":"5a281aee2c214c9ba83ce620"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5f2a1b64beafe93cc462b502","id":"tensor","datatype":"5a79df48d071a1753f1d661b"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5f2a1b64beafe91c7c62b503","id":"noddi","datatype":"5ed02a620a8ed8e39c482a61"}],"outputs":[{"datatype_tags":["networkmatrices"],"output_on_root":false,"archive":true,"_id":"5f2a1b64beafe9dad262b504","id":"output","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null},{"datatype_tags":["count"],"output_on_root":false,"archive":true,"_id":"6111cc2ba5a04c83e7f855e6","id":"count_out","datatype":"5d34d9f744947d8aea0e0d2f","datatype_tags_pass":null,"files":null},{"datatype_tags":["length"],"output_on_root":false,"archive":true,"_id":"6111cc2ba5a04c2dbcf855e7","id":"length_out","datatype":"5d34d9f744947d8aea0e0d2f","datatype_tags_pass":null,"files":null},{"datatype_tags":["density"],"output_on_root":false,"archive":true,"_id":"6111cc2ba5a04c20eff855e8","id":"density_out","datatype":"5d34d9f744947d8aea0e0d2f","datatype_tags_pass":null,"files":null},{"datatype_tags":["denlen_out"],"output_on_root":false,"archive":true,"_id":"6111cc2ba5a04c612df855e9","id":"denlen_out","datatype":"5d34d9f744947d8aea0e0d2f","datatype_tags_pass":null,"files":null},{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"6165b253fc8eb9428afaca64","id":"netneuro","datatype":"58e6e21e6cd4e826de4537ee","datatype_tags_pass":null,"files":null}],"github_branch":"sift2_v1.2_centers_netneuro","github":"brainlife/app-sift2-connectome-generation","name":"Structural Connectome MRTrix3 (SCMRT) (SIFT2)","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a42c062f3d3800f12fa34"},{"name":"Franco Pestilli","email":null,"_id":"634a42c062f3d3800f12fa35"}],"desc":null,"__v":1605,"desc_override":"Generate structural connectomes using MRTrix3 and SIFT2","create_date":"2021-10-12T16:05:39.510Z","doi":"10.25663/brainlife.app.580","_canedit":true},{"_id":"5f2a1b64beafe9cce862b4fd","stats":{"resources":[{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a3c6862f3d3800f128983"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3c6862f3d3800f128984"}],"success_rate":74.46719160104986,"users":11,"runtime_mean":336572.05,"runtime_std":671455.0292547282,"requested":14312,"examples":3,"groups":27},"projects":[],"admins":["16"],"tags":[],"removed":false,"config":{"track":{"type":"input","file_id":"track","input_id":"track"},"parc":{"type":"input","file_id":"parc","input_id":"parc"},"key":{"type":"input","file_id":"key","input_id":"parc"},"label":{"type":"input","file_id":"label","input_id":"parc"},"lmax2":{"type":"input","file_id":"lmax2","input_id":"csd"},"lmax4":{"type":"input","file_id":"lmax4","input_id":"csd"},"lmax6":{"type":"input","file_id":"lmax6","input_id":"csd"},"lmax8":{"type":"input","file_id":"lmax8","input_id":"csd"},"lmax10":{"type":"input","file_id":"lmax10","input_id":"csd"},"lmax12":{"type":"input","file_id":"lmax12","input_id":"csd"},"lmax14":{"type":"input","file_id":"lmax14","input_id":"csd"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"fa":{"type":"input","file_id":"fa","input_id":"tensor"},"md":{"type":"input","file_id":"md","input_id":"tensor"},"rd":{"type":"input","file_id":"rd","input_id":"tensor"},"ad":{"type":"input","file_id":"ad","input_id":"tensor"},"ga":{"type":"input","file_id":"ga","input_id":"tensor"},"ak":{"type":"input","file_id":"ak","input_id":"tensor"},"mk":{"type":"input","file_id":"mk","input_id":"tensor"},"rk":{"type":"input","file_id":"rk","input_id":"tensor"},"ndi":{"type":"input","file_id":"ndi","input_id":"noddi"},"isovf":{"type":"input","file_id":"isovf","input_id":"noddi"},"odi":{"type":"input","file_id":"odi","input_id":"noddi"},"lmax":{"id":"lmax","type":"number","placeholder":"","advanced":false,"desc":"","default":8,"_order":2,"pid":0.46413463443161096}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5f2a1b64beafe9807362b4fe","id":"track","datatype":"5907d922436ee50ffde9c549"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5f2a1b64beafe922a562b4ff","id":"parc","datatype":"5c1a7489f9109beac4a88a1f"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5f2a1b64beafe903cf62b500","id":"csd","datatype":"5c536bf0f9109beac46adb45"},{"datatype_tags":["5tt_masks"],"optional":false,"multi":false,"advanced":false,"_id":"5f2a1b64beafe910e262b501","id":"mask","datatype":"5a281aee2c214c9ba83ce620"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5f2a1b64beafe93cc462b502","id":"tensor","datatype":"5a79df48d071a1753f1d661b"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5f2a1b64beafe91c7c62b503","id":"noddi","datatype":"5ed02a620a8ed8e39c482a61"}],"outputs":[{"datatype_tags":["networkmatrices"],"output_on_root":false,"archive":true,"_id":"5f2a1b64beafe9dad262b504","id":"output","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null},{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"6111cc2ba5a04c83e7f855e6","id":"count_out","datatype":"5d34d9f744947d8aea0e0d2f","datatype_tags_pass":null,"files":null},{"datatype_tags":["length"],"output_on_root":false,"archive":true,"_id":"6111cc2ba5a04c2dbcf855e7","id":"length_out","datatype":"5d34d9f744947d8aea0e0d2f","datatype_tags_pass":null,"files":null},{"datatype_tags":["density"],"output_on_root":false,"archive":true,"_id":"6111cc2ba5a04c20eff855e8","id":"density_out","datatype":"5d34d9f744947d8aea0e0d2f","datatype_tags_pass":null,"files":null},{"datatype_tags":["denlen_out"],"output_on_root":false,"archive":true,"_id":"6111cc2ba5a04c612df855e9","id":"denlen_out","datatype":"5d34d9f744947d8aea0e0d2f","datatype_tags_pass":null,"files":null}],"github_branch":"sift2_v1.1_centers","github":"brainlife/app-sift2-connectome-generation","name":"Structural Connectome MRTrix3 (SCMRT) (SIFT2) - Deprecated","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3c6962f3d3800f128985"},{"name":"Franco Pestilli","email":null,"_id":"634a3c6962f3d3800f128986"}],"create_date":"2020-08-05T02:37:24.381Z","desc":null,"doi":"10.25663/brainlife.app.394","__v":4243,"desc_override":"Generate structural connectomes using MRTrix3 and SIFT2","deprecated_by":"6165b253fc8eb97e54faca55","_canedit":true},{"_id":"5f2ac098beafe9595162c249","projects":[],"admins":["16"],"tags":[],"removed":false,"stats":{"resources":[{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a3c7462f3d3800f128e38"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3c7462f3d3800f128e39"}],"success_rate":74.46719160104986,"users":11,"runtime_mean":336572.05,"runtime_std":671455.0292547282,"requested":14312,"examples":5,"groups":27},"config":{"track":{"type":"input","file_id":"track","input_id":"track"},"parc":{"type":"input","file_id":"parc","input_id":"parc"},"key":{"type":"input","file_id":"key","input_id":"parc"},"label":{"type":"input","file_id":"label","input_id":"parc"},"fa":{"type":"input","file_id":"fa","input_id":"tensor"},"md":{"type":"input","file_id":"md","input_id":"tensor"},"rd":{"type":"input","file_id":"rd","input_id":"tensor"},"ad":{"type":"input","file_id":"ad","input_id":"tensor"},"ga":{"type":"input","file_id":"ga","input_id":"tensor"},"ak":{"type":"input","file_id":"ak","input_id":"tensor"},"mk":{"type":"input","file_id":"mk","input_id":"tensor"},"rk":{"type":"input","file_id":"rk","input_id":"tensor"},"ndi":{"type":"input","file_id":"ndi","input_id":"noddi"},"isovf":{"type":"input","file_id":"isovf","input_id":"noddi"},"odi":{"type":"input","file_id":"odi","input_id":"noddi"}},"inputs":[{"id":"track","datatype":"5907d922436ee50ffde9c549","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5f2a1b64beafe9807362b4fe"},{"id":"parc","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5f2a1b64beafe922a562b4ff"},{"id":"tensor","datatype":"5a79df48d071a1753f1d661b","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5f2a1b64beafe93cc462b502"},{"id":"noddi","datatype":"5ed02a620a8ed8e39c482a61","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5f2a1b64beafe91c7c62b503"}],"outputs":[{"id":"output","datatype":"59c3eae633fc1cf9ead71679","datatype_tags":["networkmatrices"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5f2a1b64beafe9dad262b504"},{"id":"count_out","datatype":"5d34d9f744947d8aea0e0d2f","datatype_tags":["count"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"6111cae8a5a04c3b68f84bda"},{"id":"length_out","datatype":"5d34d9f744947d8aea0e0d2f","datatype_tags":["length"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"6111cae8a5a04c5d13f84bdb"},{"id":"density_out","datatype":"5d34d9f744947d8aea0e0d2f","datatype_tags":["density"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"6111cae8a5a04c5d92f84bdc"},{"id":"denlen_out","datatype":"5d34d9f744947d8aea0e0d2f","datatype_tags":["denlen"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"6111cae8a5a04c4c71f84bdd"},{"id":"netneuro","datatype":"58e6e21e6cd4e826de4537ee","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"62489edf5d8ab5d5f06845f7"}],"github_branch":"nosift2_v1.2_centers_netneuro","github":"brainlife/app-sift2-connectome-generation","name":"Structural Connectome MRTrix3 (SCMRT) - No labels or weights","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3c7562f3d3800f128e3a"},{"name":"Franco Pestilli","email":null,"_id":"634a3c7562f3d3800f128e3b"}],"desc":null,"__v":4236,"desc_override":"Generate structural connectomes using MRTrix3","create_date":"2020-08-05T14:22:16.905Z","doi":"10.25663/brainlife.app.395","_canedit":true},{"_id":"60707088c7f80a837895d048","stats":{"resources":[],"success_rate":25.020275750202757,"users":4,"runtime_mean":17158826.72,"runtime_std":34649099.26803448,"requested":4265,"examples":2,"groups":7},"projects":["5f279259beafe9ac0c628312"],"admins":["19","704"],"tags":[],"removed":false,"config":{"track":{"type":"input","file_id":"track","input_id":"track"},"parc":{"type":"input","file_id":"parc","input_id":"parc"},"key":{"type":"input","file_id":"key","input_id":"parc"},"label":{"type":"input","file_id":"label","input_id":"parc"},"maxDist":{"id":"maxDist","type":"number","placeholder":"","advanced":false,"desc":"The distance (in mm) the streamline endpoints will search for the cortical labels during assignment (only the nearest label is used to determine assignment).","default":2,"_order":2,"pid":0.9887983815241792,"min":0,"max":10},"minStrm":{"id":"minStrm","type":"number","placeholder":"","advanced":false,"desc":"The minimum number of streamlines that must exist in an edge for it to be weighted in the network.","default":0,"_order":3,"pid":0.6700173774165323,"min":0},"clean":{"id":"clean","type":"boolean","placeholder":"","advanced":false,"desc":"Perform outlier removal edge-wise on a streamlines based on the distance from the estimated centroid of the edges' center.","default":false,"_order":4,"pid":0.6983076895942509},"minLength":{"id":"minLength","type":"number","placeholder":"","advanced":true,"desc":"The minimum length in mm for a streamline to be kept as valid during cleaning.","default":20,"_order":5,"pid":0.39201140378742416,"min":1},"maxVars":{"id":"maxVars","type":"number","placeholder":"","advanced":true,"desc":"The maximum units of standard deviation a streamline can deviate from the central tendency before being removed during cleaning.","default":4,"_order":6,"pid":0.23458345679727022,"min":1},"maxLengthStd":{"id":"maxLengthStd","type":"number","placeholder":"","advanced":true,"desc":"The maximum units of standard deviation streamline length can deviate from the central tendency before being removed during cleaning.","default":4,"_order":7,"pid":0.8525014886201152,"min":1},"numNodes":{"id":"numNodes","type":"number","placeholder":"","advanced":true,"desc":"The number of nodes a streamline is resampled to when estimating cleaning cutoffs.","default":100,"_order":8,"pid":0.5204391457852293,"min":3},"maxIter":{"id":"maxIter","type":"number","placeholder":"","advanced":true,"desc":"The number of iterations performed during cleaning to estimate outliers.","default":10,"_order":9,"pid":0.9773072785207605,"min":10}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"60707088c7f80a689e95d049","id":"track","datatype":"5907d922436ee50ffde9c549"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"60707088c7f80a401995d04a","id":"parc","datatype":"5c1a7489f9109beac4a88a1f"}],"outputs":[{"datatype_tags":["count"],"output_on_root":false,"archive":true,"_id":"60707088c7f80a6bb395d04b","id":"conmat-count","datatype":"5d34d9f744947d8aea0e0d2f","datatype_tags_pass":null,"files":null,"desc":"The streamline count connectivity matrix."},{"datatype_tags":["length"],"output_on_root":false,"archive":true,"_id":"60707088c7f80ac7f395d04c","id":"conmat-length","datatype":"5d34d9f744947d8aea0e0d2f","datatype_tags_pass":null,"files":null,"desc":"The streamline length connectivity matrix."},{"datatype_tags":["density"],"output_on_root":false,"archive":true,"_id":"60707088c7f80a172f95d04d","id":"conmat-density","datatype":"5d34d9f744947d8aea0e0d2f","datatype_tags_pass":null,"files":null,"desc":"The streamline density connectivity matrix."},{"datatype_tags":["denlen"],"output_on_root":false,"archive":true,"_id":"60707088c7f80ab25895d04e","id":"conmat-denlen","datatype":"5d34d9f744947d8aea0e0d2f","datatype_tags_pass":null,"files":null,"desc":"The streamline density-length connectivity matrix."},{"datatype_tags":["count"],"output_on_root":false,"archive":true,"_id":"60707088c7f80a410e95d04f","id":"network-count","datatype":"5ed0352de3f453b13b267dae","datatype_tags_pass":null,"files":null,"desc":"The streamline count .json graph."},{"datatype_tags":["length"],"output_on_root":false,"archive":true,"_id":"60707088c7f80a75ec95d050","id":"network-length","datatype":"5ed0352de3f453b13b267dae","datatype_tags_pass":null,"files":null,"desc":"The streamline length .json graph."},{"datatype_tags":["density"],"output_on_root":false,"archive":true,"_id":"60707088c7f80add1a95d051","id":"network-density","datatype":"5ed0352de3f453b13b267dae","datatype_tags_pass":null,"files":null,"desc":"The streamline density .json graph."},{"datatype_tags":["denlen"],"output_on_root":false,"archive":true,"_id":"60707088c7f80affd195d052","id":"network-denlen","datatype":"5ed0352de3f453b13b267dae","datatype_tags_pass":null,"files":null,"desc":"The streamline density-length .json graph."},{"datatype_tags":["matlab"],"output_on_root":false,"archive":true,"_id":"612ea0e2ff3adde3f2e4c422","id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null,"desc":"netw.mat containing the MATLAB structure made during the analysis."}],"github_branch":"master","github":"bcmcpher/app-StructuralCountNetwork","name":"Structural Networks (count)","desc_override":"","user_id":"19","contributors":[{"name":"Brent McPherson","email":"bcmcpher@gmail.com","_id":"634a3fe362f3d3800f12d413"}],"create_date":"2021-04-09T15:19:36.638Z","desc":null,"__v":2938,"doi":"10.25663/brainlife.app.503","_canedit":true},{"_id":"629a6ee47f60950a54cc82f6","user_id":"56","projects":[],"admins":["56"],"name":"Structural connectivity & White Matter Classification (WMC) using DIPY","github":"DanNBullock/app-DIPY-connectome_and_WMC_from_parc","tags":[],"config":{"parc":{"type":"input","file_id":"parc","input_id":"parcellation"},"key":{"type":"input","file_id":"key","input_id":"parcellation"},"label":{"type":"input","file_id":"label","input_id":"parcellation"},"track":{"type":"input","file_id":"track","input_id":"tractogram"},"threshold":{"id":"threshold","type":"number","placeholder":"","advanced":false,"desc":"The threshold to be applied to the connectome generation process.  Numbers less than one will be interpreted as proportion of total input tractogram streamline count, numbers larger than 1 will be interpreted as streamline count.","default":null,"_order":2,"pid":0.22311061865422632,"min":0}},"inputs":[{"id":"parcellation","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"629a6ee47f60950a54cc82f7"},{"id":"tractogram","datatype":"5907d922436ee50ffde9c549","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"629a6ee47f60950a54cc82f8"}],"outputs":[{"id":"wmc","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"629a6f1e7f60950a54cc87ee"},{"id":"connectome","datatype":"5d34d9f744947d8aea0e0d2f","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"629a6f1e7f60950a54cc87ef"}],"stats":{"resources":[],"success_rate":37.5,"users":1,"groups":1,"requested":8,"examples":1,"runtime_mean":56751.333333333336,"runtime_std":4732.627834747015},"removed":false,"contributors":[{"name":"Daniel Bullock","email":"iisdanbul@gmail.com","_id":"634a44d362f3d3800f130eba"}],"create_date":"2022-06-03T20:28:20.976Z","desc":"Generate a structural connectivity matrix and a White Matter Classification structure for a given parcellation and tractogram.","__v":299,"doi":"10.25663/brainlife.app.640","_canedit":true},{"_id":"621e582f5d8ab5d5f01b357c","user_id":"1447","projects":[],"admins":["1447"],"name":"Structural connectivity predictors","github":"FarnazZE/bnbl-brainlife-sc-based-predictors","github_branch":"main","tags":[],"config":{"csv":{"type":"input","file_id":"csv","input_id":"input"},"index":{"type":"input","file_id":"index","input_id":"input"},"label":{"type":"input","file_id":"label","input_id":"input"},"gammavals":{"id":"gammavals","type":"number","placeholder":"gamma value","advanced":false,"desc":"convert edge weight to cost","default":0.5,"_order":2,"pid":0.8667025439340859,"min":"","max":""},"remove nodes":{"id":"remove nodes","type":"enum","placeholder":"","advanced":false,"desc":"remove isolated nodes/ROI (column/rows with all zero values)","default":"","_order":5,"pid":0.19197843571427464,"options":[{"desc":"","label":"","value":"true"},{"desc":"","label":"","value":"false"}]}},"inputs":[{"id":"input","datatype":"5d34d9f744947d8aea0e0d2f","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"621e582f5d8ab5d5f01b357d"}],"outputs":[{"id":"output","desc":"csv files containing predictors for structural connectivity","datatype":"5d34d9f744947d8aea0e0d2f","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"621e582f5d8ab5d5f01b357e"}],"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a43a862f3d3800f1305b2"}],"examples":1,"success_rate":9.649122807017543,"users":1,"runtime_mean":68360.45454545454,"runtime_std":41955.53783658391,"requested":125,"groups":2},"removed":false,"contributors":[{"name":"Farnaz Zamani Esfahlani","email":null,"_id":"634a43a862f3d3800f1305b3"}],"create_date":"2022-03-01T17:30:23.316Z","desc":null,"__v":782,"doi":"10.25663/brainlife.app.606","_canedit":true},{"_id":"5f4bbdb429b3acd6f3f213dc","stats":{"resources":[],"success_rate":98.36808703535812,"users":1,"runtime_mean":64895.36,"runtime_std":170803.39759293554,"requested":1550,"examples":1,"groups":1},"projects":["5941a225f876b000210c11e5"],"admins":["16"],"tags":[],"removed":false,"config":{"freesurferpost":{"type":"input","file_id":"output","input_id":"freesurferpost"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5f4bbdb429b3ac44edf213dd","id":"freesurferpost","datatype":"5e767ddcde643b260e2a8a52"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5f4bbdb429b3ac3b52f213de","id":"warp","datatype":"5bbfb28071454db2a890fbce","datatype_tags_pass":null,"files":null}],"github_branch":"master","github":"brainlife/app-extract-warp-temp","name":"Temp extract warp freesurferpost HCP","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3ca462f3d3800f1298d1"}],"create_date":"2020-08-30T14:54:44.236Z","desc":null,"doi":"10.25663/brainlife.app.402","__v":4153,"_canedit":true},{"_id":"5ed0324ce3f453693e267d1f","stats":{"success_rate":100,"users":1,"runtime_mean":10820097.2,"runtime_std":25115798.30425453,"requested":133,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3b8762f3d3800f126270"}],"examples":0,"groups":3},"projects":[],"admins":["16"],"tags":[],"removed":false,"config":{"dir":{"type":"input","file_id":"dir","input_id":"noddi-deprecated"},"icvf":{"type":"input","file_id":"icvf","input_id":"noddi-deprecated"},"isovf":{"type":"input","file_id":"isovf","input_id":"noddi-deprecated"},"od":{"type":"input","file_id":"od","input_id":"noddi-deprecated"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ed0324ce3f4533bc5267d20","id":"noddi-deprecated","datatype":"5bd77a8615a8683a39440dab"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5ed0324ce3f45315c9267d21","id":"noddi","datatype":"5ed02a620a8ed8e39c482a61","datatype_tags_pass":"noddi-deprecated","files":null}],"github_branch":"master","github":"brainlife/app-convert-noddi-datatypes","name":"Temporary converter app from NODDI-deprecated to NODDI datatype","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3b8862f3d3800f126271"}],"create_date":"2020-05-28T21:51:08.955Z","desc":null,"doi":"10.25663/brainlife.app.368","__v":4746,"_canedit":true},{"_id":"6169c901fc8eb97d1efe09fe","stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a42d162f3d3800f12fae5"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a42d162f3d3800f12fae6"}],"success_rate":99.49250845819236,"users":2,"runtime_mean":24619.7,"runtime_std":14839.001036794898,"requested":6236,"examples":1,"groups":6},"projects":[],"admins":["16"],"tags":[],"removed":false,"config":{"lh_annot":{"type":"input","file_id":"lh_annot","input_id":"parc_deprecated"},"rh_annot":{"type":"input","file_id":"rh_annot","input_id":"parc_deprecated"},"lh_inflated":{"type":"input","file_id":"lh_inflated_surf","input_id":"parc_deprecated"},"rh_inflated":{"type":"input","file_id":"rh_inflated_surf","input_id":"parc_deprecated"},"lh_pial":{"type":"input","file_id":"lh_pial_surf","input_id":"parc_deprecated"},"rh_pial":{"type":"input","file_id":"rh_pial_surf","input_id":"parc_deprecated"},"lh_white":{"type":"input","file_id":"lh_white_surf","input_id":"parc_deprecated"},"rh_white":{"type":"input","file_id":"rh_white_surf","input_id":"parc_deprecated"},"key":{"type":"input","file_id":"key","input_id":"parc_deprecated"},"label":{"type":"input","file_id":"label","input_id":"parc_deprecated"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"6169c901fc8eb9144dfe09ff","id":"parc_deprecated","datatype":"5c478b7bf9109beac4520be6"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"6169c901fc8eb9df46fe0a00","id":"surface_verts","datatype":"5f78b255268f764bdd29b254","datatype_tags_pass":"parc_deprecated","files":null},{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"6169c901fc8eb9346cfe0a01","id":"surface_data","datatype":"5f78b377268f76598c29b27a","datatype_tags_pass":"parc_deprecated","files":null}],"github_branch":"v1.0","github":"brainlife/app-temp-parc-surface-deprecated-converter","name":"Temporary converter of parcellation/surface-deprecated datatypes to surface datatypes","desc_override":"This will convert parcellation/surface-deprecated datatypes to the updated surface datatypes","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a42d262f3d3800f12fae7"}],"create_date":"2021-10-15T18:31:29.707Z","desc":null,"__v":1580,"doi":"10.25663/brainlife.app.582","_canedit":true},{"_id":"5b21753e16fe38002748e5e1","projects":[],"admins":["285","87","1"],"tags":[],"removed":false,"name":"Tensor Mask","desc":"Brainlife wrapper app for dipy_mask workflows.","citation":null,"references":[],"avatar":"https://raw.githubusercontent.com/brain-life/brainlife.github.io/master/images/app-logos/dipy_mask.png","github":"dipy/bl_apps_dipy_mask","github_branch":"1.1.1","config":{"img":{"type":"input","file_id":"fa","input_id":"tensor"},"lb":{"type":"number","placeholder":"","desc":"Lower bound value.","default":0.2,"id":"lb","pid":0.6332895732908475,"_order":2},"ub":{"id":"ub","type":"string","placeholder":"","desc":"Upper bound value","default":"Inf","_order":3,"pid":0.13234064704976278,"optional":true}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5b7f16c3b3e3800027ce9bab","id":"tensor","datatype":"5a79df48d071a1753f1d661b"}],"outputs":[{"datatype_tags":["dwi"],"output_on_root":false,"archive":true,"_id":"5b21753e16fe38002748e5e3","id":"output","datatype":"5a281aee2c214c9ba83ce620","datatype_tags_pass":"tensor","files":null}],"user_id":"61","contributors":[{"name":"Serge Koudoro","email":null,"_id":"634a334862f3d3800f117e47"},{"name":"Javier Guaje","email":null,"_id":"634a334862f3d3800f117e48"}],"create_date":"2018-06-13T19:49:18.543Z","stats":{"stars":0,"requested":133,"users":6,"success_rate":88.88888888888889,"serviceinfo":{"_id":"5d729e1f78356a109788b2dd","counts":{"_id":"5e5c3dae87cac7e68eab13bf","failed":1372,"finished":2816,"removed":5103,"requested":5301,"running":3198,"running_sync":0,"stop_requested":12},"success_rate":67.23973256924546,"users":20,"readme_status":"ok","runtime_mean":5885857.53,"runtime_std":14501545.618587041,"service":"brain-life/app-dipy-workflows","__v":0},"gitinfo":{"desc":"Brainlife wrapper app for Dipy workflows.","tags":["dipy"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Serge Koudoro","email":null},{"name":"Aman Arya","email":"aman.arya524@gmail.com"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":4094572.25,"runtime_std":13283063.972576123,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a334862f3d3800f117e46"}],"examples":1,"groups":4},"doi":"10.25663/bl.app.65","__v":12788,"desc_override":"Generate a mask from FA/GFA","_canedit":true},{"_id":"59c47cdc561b3f002182e673","project":"595d56bb716f2e004969d584","name":"Test App","desc":"updated 3","github":"soichih/app-test","github_branch":"master","config":{"t1":{"type":"input","file_id":"t1","input_id":"input"},"ds":{"type":"input","file_id":"ds","input_id":"ctf"},"headshape":{"type":"input","file_id":"headshape","input_id":"ctf"},"channels":{"type":"input","file_id":"channels","input_id":"ctf"},"coordsystem":{"type":"input","file_id":"coordsystem","input_id":"ctf"},"events":{"type":"input","file_id":"events","input_id":"ctf"},"events_json":{"type":"input","file_id":"events_json","input_id":"ctf"},"num":{"type":"number","placeholder":"test","desc":"hello desc","default":100,"id":"num","pid":0.2591443422742281,"_order":2},"param1":{"default":100,"desc":"optional","placeholder":"Number of time to run alg.","type":"integer","id":"param1","pid":0.2924269896714107,"_order":3,"optional":true},"optional":{"id":"optional","type":"string","placeholder":"","desc":"","default":"test","_order":4,"pid":0.042706490679634834,"optional":true,"multiline":true},"optional_nodefault":{"id":"optional_nodefault","type":"string","placeholder":"","desc":"","default":"","_order":5,"pid":0.537004445351281,"optional":true},"optional_nodefault_num":{"id":"optional_nodefault_num","type":"number","placeholder":"","desc":"","default":null,"_order":6,"pid":0.12225730570900772,"optional":true}},"user_id":"1","create_date":"2017-09-22T03:00:44.283Z","removed":false,"_rate":0,"outputs":[{"datatype_tags":["test"],"output_on_root":false,"archive":true,"_id":"59c47cdc561b3f002182e674","id":"output","datatype":"59c3eae633fc1cf9ead71679","files":null}],"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"59c47cdc561b3f002182e675","id":"input","datatype":"58c33bcee13a50849b25879a","desc":"t1 input"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"6075c60ae8c7641ff4e4bf65","id":"ctf","datatype":"6000714baacf9e22a6a691c8"}],"tags":["test"],"admins":["1"],"__v":14293,"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a313262f3d3800f11667d"}],"projects":["5d64733db29ac960ca2e797f","5a74ccd66ed91402ce400cc6"],"references":[],"stats":{"stars":0,"requested":111,"users":2,"success_rate":74.73684210526315,"serviceinfo":{"_id":"5d729e1f78356a109788b2cb","counts":{"_id":"5e5c688687cac7c561ab1bad","failed":24,"finished":65,"removed":65,"requested":103,"running":90,"running_sync":0,"stop_requested":6},"success_rate":73.03370786516854,"users":2,"readme_status":"too short","runtime_mean":312920.3076923077,"runtime_std":1463192.524602218,"service":"soichih/app-test","__v":0},"gitinfo":{"desc":"updated 3","tags":["test"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":295940.676056338,"runtime_std":1401348.9991926115,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a313262f3d3800f11667b"},{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a313262f3d3800f11667c"}],"examples":0,"groups":7},"doi":"10.25663/bl.app.45","_canedit":true},{"_id":"59779342749315002f268594","name":"Test Gradient Flip for dtiInit processing","desc":"application to test if the gradients (bvecs) need to be flipped","github":"brainlife/app-testgradientflip","github_branch":"master","config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"t1":{"type":"input","file_id":"t1","input_id":"t1"},"phaseEncodeDir":{"type":"enum","placeholder":"","desc":"","default":"2","options":[{"desc":"use the y dimension","label":"y dimension","value":"2"},{"desc":"use the x dimension","label":"x dimension","value":"1"},{"desc":"use the z dimension","label":"z dimension","value":"3"}],"id":"phaseEncodeDir","pid":0.43412009958489506,"_order":2},"rotateBvecsWithCanXform":{"type":"boolean","placeholder":"","desc":"Rotate the bvectors according to the canonical xForm","default":true,"id":"rotateBvecsWithCanXform","pid":0.3248688026819502,"_order":3},"rotateBvecsWithRx":{"type":"boolean","placeholder":"","desc":"Rotate the bvectors according to the prescription","default":true,"id":"rotateBvecsWithRx","pid":0.8630877588796821,"_order":4},"eddyCorrect":{"type":"enum","placeholder":"","desc":"","default":"1","options":[{"desc":"","label":"no eddy current or motion correction","value":"-1"},{"desc":"","label":"do eddy current and motion correction","value":"1"},{"desc":"","label":"only do motion correction","value":"0"}],"id":"eddyCorrect","pid":0.16985245264913296,"_order":5}},"user_id":"43","create_date":"2017-07-25T18:51:46.321Z","removed":false,"_rate":5,"outputs":[{"datatype_tags":["test_gradient_flip"],"output_on_root":true,"archive":true,"_id":"59779342749315002f268595","id":"results","datatype":"59c3eae633fc1cf9ead71679","files":null}],"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"59779342749315002f268596","id":"dwi","datatype":"58c33c5fe13a50849b25879b"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5977bf2f371a14003035aec5","id":"t1","datatype":"58c33bcee13a50849b25879a"}],"tags":[],"admins":["16","41","146","1"],"__v":14289,"contributors":[{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a30fc62f3d3800f116556"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a30fc62f3d3800f116557"}],"projects":[],"references":[],"stats":{"stars":0,"requested":5,"users":2,"success_rate":0,"serviceinfo":{"_id":"5d729e1f78356a109788b331","counts":{"_id":"5e5c688187cac72711ab1ba7","failed":138,"finished":417,"removed":538,"requested":742,"running":539,"running_sync":0,"stop_requested":34},"success_rate":75.13513513513513,"users":20,"readme_status":"ok","runtime_mean":30679977.67,"runtime_std":26631234.265194666,"service":"kitchell/app-testgradientflip","__v":0},"gitinfo":{"desc":"This application will provide a recommendation on which axis you should flip the bvecs of your data, if it is necessary. It will perform fiber tracking using 4 different gradient flip options (no flip, x flip, y flip, and z flip) and report the most likely flip needed for your data. The flip recommendation is made based on the flip direction with the highest number of long fibers.","tags":["quality-check"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Steven O'Riley","email":null}]},"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a30fc62f3d3800f116554"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a30fc62f3d3800f116555"}],"examples":0,"groups":2},"doi":"10.25663/bl.app.18","_canedit":true},{"_id":"5fa46d70e138ec6b634ea36b","stats":{"resources":[],"success_rate":60,"users":4,"runtime_mean":69566,"runtime_std":41820.37049891675,"requested":5,"examples":1,"groups":4},"projects":[],"admins":["412","41","1103"],"tags":[],"removed":false,"config":{"t1":{"type":"input","file_id":"t1","input_id":"anat01"},"outres":{"id":"outres","type":"string","placeholder":"","advanced":false,"desc":"This is the resolution in mm of the voxels of the NIFTI-1 file that this App will output","default":"1,1,1","_order":2,"pid":0.8249731138041076}},"inputs":[{"datatype_tags":["acpc_aligned"],"optional":false,"multi":false,"advanced":false,"_id":"5fa46d70e138ec09724ea36c","id":"anat01","datatype":"58c33bcee13a50849b25879a","desc":"This is a simple T1w NIFTI-1 file that the app needs to load to resample"}],"outputs":[{"datatype_tags":["acpc_aligned"],"output_on_root":false,"archive":true,"_id":"5fa46d70e138ec7c694ea36d","id":"out_res","datatype":"58c33bcee13a50849b25879a","datatype_tags_pass":null,"files":null,"desc":"THis is a resampled T1w File compatible with a anat/t1w datatype"}],"github_branch":"master","github":"brainlife/app-template-python","name":"Test Python Template for Class","desc_override":"This App should be deleted. It used as an example for the class. The happy uses the code available at https://github.com/brainlife/app-template-python. The code is simple, it loads a t1w.nii.gz (which in brainlife.io is called neuro/anat) and resamples the file at the wanted resolution","user_id":"41","contributors":[{"name":"Franco Pestilli","email":null,"_id":"634a3dfc62f3d3800f12b9c0"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a3dfc62f3d3800f12b9c1"}],"create_date":"2020-11-05T21:24:00.384Z","desc":"This is a template for a python-based brainlife.io/app","doi":"10.25663/brainlife.app.445","__v":3961,"_canedit":true},{"_id":"5eded100c5972bf65db3e2f9","stats":{"success_rate":76.47058823529412,"users":2,"runtime_mean":205788.96153846153,"runtime_std":104120.76255722737,"requested":35,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3baf62f3d3800f1267d6"}],"examples":0,"groups":4},"projects":[],"admins":["239"],"tags":[],"removed":false,"config":{"timeseries":{"type":"input","file_id":"timeseries","input_id":"time series"},"key":{"type":"input","file_id":"key","input_id":"time series"},"label":{"type":"input","file_id":"label","input_id":"time series"},"discard":{"id":"discard","type":"number","placeholder":"","advanced":false,"desc":"","default":0,"_order":2,"pid":0.7292539673083236,"min":0,"optional":true},"similaritymeas":{"id":"similaritymeas","type":"enum","placeholder":"","advanced":true,"desc":"","default":"correlation","_order":3,"pid":0.484714879174877,"options":[{"desc":"","label":"correlation","value":"correlation"},{"desc":"","label":"partial correlation","value":"partialcorrelation"},{"desc":"","label":"covariance","value":"covariance"}],"optional":true}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5eded100c5972ba091b3e2fa","id":"time series","datatype":"5ed834cdda66453cde8edfb7"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5eded100c5972b209cb3e2fb","id":"cm","datatype":"5d34d9f744947d8aea0e0d2f","datatype_tags_pass":null,"files":null}],"github_branch":"master","github":"brainlife/app-time-series-2-network","name":"Time Series to Network","user_id":"239","contributors":[{"name":"Josh Faskowitz","email":null,"_id":"634a3bb062f3d3800f1267d7"}],"create_date":"2020-06-09T00:00:00.052Z","desc":"convert an NxT time series to an NxN functional connectivity matrix","doi":"10.25663/brainlife.app.372","__v":4670,"avatar":"https://upload.wikimedia.org/wikipedia/commons/thumb/a/aa/Brain_anatomy_medical_head_skull_digital_3_d_x_ray_xray_psychedelic_3720x2631.jpg/320px-Brain_anatomy_medical_head_skull_digital_3_d_x_ray_xray_psychedelic_3720x2631.jpg","_canedit":true},{"_id":"60b961b10ad40d58e1ca7fe7","stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a410862f3d3800f12e161"}],"success_rate":76.72583826429981,"users":8,"runtime_mean":111164.64,"runtime_std":415556.9320141711,"requested":3769,"examples":5,"groups":13},"projects":[],"admins":["704"],"tags":["network"],"removed":false,"config":{"tsv":{"type":"input","file_id":"tsv","input_id":"timeseries"},"json":{"type":"input","file_id":"json","input_id":"timeseries"},"method":{"id":"method","type":"enum","placeholder":"","advanced":false,"desc":"Measure of similarity used to create the connectivity matrix.\n\n[1] G. Varoquaux et al. “Detection of brain functional-connectivity difference in post-stroke patients using group-level covariance modeling, MICCAI 2010.","default":"correlation","_order":2,"pid":0.3656963852095658,"options":[{"desc":"Use Pearson correlation","label":"Correlation","value":"correlation"},{"desc":"Use covariance similarity","label":"Covariance","value":"covariance"},{"desc":"Use partial correlation","label":"Partial correlation","value":"partial correlation"},{"desc":"Use tangent space covariance [1]","label":"Tangent space covariance","value":"tangent"},{"desc":"Use precision-based approach","label":"Precision","value":"precision"}]}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"60b961b10ad40d47eeca7fe8","id":"timeseries","datatype":"604a4553ebfe4559de3af944","desc":"Input time series used to construct the connectivity matrices."}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"60b961b10ad40d7c5aca7fe9","id":"output","datatype":"5ed0352de3f453b13b267dae","datatype_tags_pass":"timeseries","files":null,"desc":"Network generated from the connectivity matrix"}],"github_branch":"0.2","github":"filipinascimento/bl-timeseries2network","name":"Time series to network","avatar":"https://raw.githubusercontent.com/filipinascimento/bl-timeseries2network/master/Media/Icon.png","user_id":"704","contributors":[{"name":"Filipi Nascimento Silva","email":"filipinascimento@gmail.com","_id":"634a410962f3d3800f12e162"}],"create_date":"2021-06-03T23:11:45.467Z","desc":"Calculates a similarity matrix (such as correlation, covariance, etc) from time series and convert it to a network datatype (JGFZ) so it can be used in the network pipeline.","__v":2542,"doi":"10.25663/brainlife.app.532","_canedit":true},{"_id":"629fb60a7f60950a54d5e63b","user_id":"56","projects":[],"admins":["56"],"name":"Tissue-specific SNR (and other tissue-specific metrics)","github":"DanNBullock/app-SNR_Report","github_branch":"master","tags":[],"config":{"t1":{"type":"input","file_id":"t1","input_id":"t1"},"diff":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvec":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bval":{"type":"input","file_id":"bvals","input_id":"dwi"},"sbref":{"type":"input","file_id":"sbref","input_id":"dwi"},"sbref_json":{"type":"input","file_id":"sbref_json","input_id":"dwi"}},"inputs":[{"id":"t1","datatype":"58c33bcee13a50849b25879a","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"629fb60a7f60950a54d5e63c"},{"id":"dwi","datatype":"58c33c5fe13a50849b25879b","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"629fb60a7f60950a54d5e63d"}],"outputs":[{"id":"output","desc":"An SNR (and other metric report) with tissue & b-shell specific measurements.","datatype":"60ca4f058b8b7238324295d3","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"629fb60a7f60950a54d5e63e"}],"stats":{"resources":[],"examples":0},"removed":false,"contributors":[{"name":"Daniel Bullock","email":"iisdanbul@gmail.com","_id":"634a44ee62f3d3800f130ee0"}],"create_date":"2022-06-07T20:33:14.025Z","desc":null,"__v":298,"doi":"10.25663/brainlife.app.643","_canedit":true},{"_id":"5db234008aeeee3329f25d9c","stats":{"stars":0,"serviceinfo":{"_id":"5db23fa5e9b0ce3ab491f8d0","counts":{"_id":"5e5c3e1d87cac7e98cab1436","failed":225,"finished":2666,"removed":3085,"requested":3306,"running":2880,"running_sync":0,"stop_requested":10},"users":5,"readme_status":"ok","service":"brainlife/app-mrtrix3-5tt","__v":0,"runtime_mean":15688516.39,"runtime_std":41278139.97729138,"success_rate":92.21722587340021},"success_rate":74.28925404277517,"users":38,"runtime_mean":1027189.36,"runtime_std":591145.3048517178,"requested":20770,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a375662f3d3800f11dc37"}],"examples":5,"groups":81},"projects":[],"admins":["16","19"],"tags":[],"removed":false,"config":{"anat":{"type":"input","file_id":"t1","input_id":"anat"},"premask":{"id":"premask","type":"boolean","placeholder":"","advanced":false,"desc":"If the T1 has been skull-stripped before this step, set this to \"true\". Otherwise you risk losing significant portions of the brain. Else, leave as false","default":false,"_order":2,"pid":0.9117378604079076}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5db234008aeeee008af25d9d","id":"anat","datatype":"58c33bcee13a50849b25879a","desc":"The path to the anat/t1w datatype"}],"outputs":[{"datatype_tags":["5tt","anat","5tt_masks"],"output_on_root":false,"archive":true,"_id":"5db234008aeeeeadbcf25d9e","id":"mask","datatype":"5a281aee2c214c9ba83ce620","datatype_tags_pass":null,"files":null,"desc":"5 tissue type probability image"}],"github_branch":"binarize-v1.0","github":"brainlife/app-mrtrix3-5tt","name":"Tissue-type segmentation","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a375762f3d3800f11dc38"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a375762f3d3800f11dc39"}],"create_date":"2019-10-24T23:30:08.038Z","desc":"This app will generate a 5-tissue type mask (5tt) from a T1 anatomical image using mrtrix3's 5ttgen. This code was adapted from app-mrtrix3-act (https://brainlife.io/app/5aac2437f0b5260027e24ae1), written by Brent McPherson (bcmcpher@iu.edu).","doi":"10.25663/brainlife.app.239","__v":6653,"_canedit":true},{"_id":"6068bf10c7f80a3c109411b0","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3fd162f3d3800f12d2f5"}],"success_rate":94.98553519768564,"users":3,"runtime_mean":708059.29,"runtime_std":169074.69081570397,"requested":1359,"examples":0,"groups":5},"projects":[],"admins":["56"],"tags":[],"removed":false,"config":{"t1":{"type":"input","file_id":"t1","input_id":"t1"},"tractogram":{"type":"input","file_id":"track","input_id":"tractome"},"WMC":{"type":"input","file_id":"classification","input_id":"classification"},"tracts":{"type":"input","file_id":"tracts","input_id":"classification"},"surfaces":{"type":"input","file_id":"surfaces","input_id":"classification"},"voxelResize":{"id":"voxelResize","type":"number","placeholder":"","advanced":false,"desc":"the voxel resize parameter.  0 or [] results in no resizing.  Input value indicates the desired isometric voxel size of the output.  WARNING:  given that the node sampling rate is ~ 1mm, resizing of less than 1mm can result in masks with many holes.  Recommend use of smoothing to combat this.","default":1,"_order":2,"pid":0.33875456628520495,"min":0.1,"max":10},"threshold":{"id":"threshold","type":"number","placeholder":"","advanced":false,"desc":" The minimum number of streamlines (nodes, in practice) required in a voxel needed to prevent the value from being thresheld to 0.  This is applied AFTER the voxel resize but BEFORE any smoothing is applied.","default":0,"_order":3,"pid":0.2706762510359231,"min":0},"smoothParam":{"id":"smoothParam","type":"number","placeholder":"","advanced":false,"desc":"the smoothing kernel (necessarily odd, corresponding to diameter +1) to be applied to the mask.  Currently implemented as gaussian.","default":1,"_order":4,"pid":0.9747286934658583,"min":0},"normalizeBool":{"id":"normalizeBool","type":"boolean","placeholder":"","advanced":false,"desc":"Whether or not to apply normalization.  This will occur at the last step.  Will divide by highest density such that values range from 0 to 1.","default":false,"_order":5,"pid":0.4194147398562065}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"6068bf10c7f80a86e49411b1","id":"t1","datatype":"58c33bcee13a50849b25879a","desc":"A reference T1 from which will provide the reference space that the density mask will be created in."},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"6068bf10c7f80a78829411b2","id":"tractome","datatype":"5907d922436ee50ffde9c549","desc":"The source tractome that the WMC data object is associated with"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"6068bf10c7f80a343c9411b3","id":"classification","datatype":"5cc1d64c44947d8aea6b2d8b"}],"outputs":[{"datatype_tags":["density"],"output_on_root":false,"archive":true,"_id":"6111735ba5a04ce806f7c962","id":"masks","datatype":"592dded1436ee50ffd88f5d0","datatype_tags_pass":null,"files":null,"desc":"NIfTI density masks for each of the structures listed in the input WMC object."}],"github":"brainlife/app-tractDensityMasks","name":"Track Density Masks","user_id":"56","contributors":[{"name":"Daniel Bullock","email":"iisdanbul@gmail.com","_id":"634a3fd162f3d3800f12d2f6"}],"create_date":"2021-04-03T19:16:32.075Z","desc":"This app creates a streamline density mask (NIfTI format) for each structure labeled in a classification structure.  This provides information about the volumetric density of streamline models of tracts.","__v":2972,"avatar":"https://raw.githubusercontent.com/brainlife/app-tractDensityMasks/master/yifof.gif","doi":"10.25663/brainlife.app.498","_canedit":true},{"_id":"5ddb7138936ca3c660c58a46","stats":{"stars":0,"serviceinfo":{"_id":"5ddc70174e1eed32f44698e0","counts":{"_id":"5e5c3e2c87cac75f96ab1440","failed":39,"finished":166,"removed":904,"requested":1005,"running":289,"running_sync":0,"stop_requested":108},"success_rate":80.97560975609757,"users":1,"readme_status":"too short","service":"brainlife/app-contrack-optic-radiation","__v":0,"runtime_mean":4833658.12,"runtime_std":12226682.928288473},"success_rate":73.77398720682304,"users":3,"runtime_mean":25563004.18,"runtime_std":18189546.80106385,"requested":1685,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a37b962f3d3800f11e462"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a37b962f3d3800f11e463"}],"examples":1,"groups":5},"projects":[],"admins":["16","1"],"tags":[],"removed":false,"config":{"dtiinit":{"type":"input","file_id":"output","input_id":"dtiinit"},"t1":{"type":"input","file_id":"t1","input_id":"t1"},"rois":{"type":"input","file_id":"rois","input_id":"rois"},"eccentricity":{"type":"input","file_id":"eccentricity","input_id":"prf"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"nSamples":{"id":"nSamples","type":"number","placeholder":"","advanced":false,"desc":"Number of streamlines desired. NOTE: This may not be final total as tracking is performed without anatomical constraints (i.e. csf exclusion)","default":50000,"_order":2,"pid":0.573288784643298},"maxNodes":{"id":"maxNodes","type":"number","placeholder":"","advanced":false,"desc":"maximum number of nodes","default":240,"_order":3,"pid":0.04278827998243451},"minNodes":{"id":"minNodes","type":"number","placeholder":"","advanced":false,"desc":"minimum number of nodes","default":100,"_order":4,"pid":0.6629444819432456},"stepSize":{"id":"stepSize","type":"number","placeholder":"","advanced":false,"desc":"step size","default":1,"_order":5,"pid":0.23426732926901894},"lgn":{"id":"lgn","type":"string","placeholder":"","advanced":false,"desc":"number of LGN (008109 - left hemisphere; 008209 - right hemisphere)","default":"lgn","_order":6,"pid":0.18972294771852827},"v1":{"id":"v1","type":"string","placeholder":"","advanced":false,"desc":"number of v1 roi","default":"v1","_order":7,"pid":0.7873772259890887},"minDegree":{"id":"minDegree","type":"string","placeholder":"","advanced":false,"desc":"Minimum degrees to use for eccentricity classification","default":"0 15 30","_order":8,"pid":0.6722861502447087},"maxDegree":{"id":"maxDegree","type":"string","placeholder":"","advanced":false,"desc":"Minimum degrees to use for eccentricity classification","default":"3 30 90","_order":9,"pid":0.7900080314411426},"contrackThreshold":{"id":"contrackThreshold","type":"number","placeholder":"","advanced":true,"desc":"","default":5000,"_order":10,"pid":0.1301250841935676},"inflate_lgn":{"id":"inflate_lgn","type":"number","placeholder":"","advanced":false,"desc":"","default":1,"_order":11,"pid":0.6365758130523799},"inflate_v1":{"id":"inflate_v1","type":"number","placeholder":"","advanced":false,"desc":"","default":1,"_order":12,"pid":0.3971715812844814},"minDistanceClean":{"id":"minDistanceClean","type":"number","placeholder":"","advanced":true,"desc":"","default":0.85,"_order":13,"pid":0.752564157454591}},"inputs":[{"id":"dtiinit","datatype":"58cb234be13a50849b25882f","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ddb7138936ca38219c58a4c"},{"id":"t1","datatype":"58c33bcee13a50849b25879a","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ddb7138936ca3f6a7c58a4b"},{"id":"rois","datatype":"5be9ea0315a8683a39a1ebd9","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ddb7138936ca38156c58a4a"},{"id":"prf","datatype":"5d9d18d8e30ae43bb0612715","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ddb7138936ca300d8c58a49"},{"id":"mask","desc":"5-tissue type mask to extract csf","datatype":"5a281aee2c214c9ba83ce620","datatype_tags":["5tt_masks"],"optional":true,"multi":false,"advanced":false,"_id":"5ddb7138936ca3490ec58a48"},{"id":"freesurfer","datatype":"58cb22c8e13a50849b25882e","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ddb7138936ca3fd9ec58a47"}],"outputs":[{"id":"track","datatype":"5907d922436ee50ffde9c549","datatype_tags":["optic_radiation"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5ddb7138936ca3c95bc58a4e"},{"id":"wmc","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags":["optic_radiation"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5ddb7138936ca3d363c58a4d"}],"github_branch":"v1.1","github":"brainlife/app-contrack-optic-radiation","name":"Track The Human Optic RAdiation (THORA): Contrack - Eccentricity","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a37ba62f3d3800f11e464"}],"create_date":"2019-11-25T06:14:16.589Z","desc":null,"doi":"10.25663/brainlife.app.252","__v":6572,"_canedit":true},{"_id":"5ddce502936ca3bec8c5b4b7","stats":{"stars":0,"serviceinfo":{"_id":"5ddc70174e1eed32f44698e0","counts":{"_id":"5e5c3e2e87cac7e448ab1442","failed":39,"finished":166,"removed":904,"requested":1005,"running":289,"running_sync":0,"stop_requested":108},"success_rate":80.97560975609757,"users":1,"readme_status":"too short","service":"brainlife/app-contrack-optic-radiation","__v":0,"runtime_mean":4833658.12,"runtime_std":12226682.928288473},"users":3,"requested":152,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a37cd62f3d3800f11e56b"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a37cd62f3d3800f11e56c"}],"examples":0,"groups":4,"success_rate":65.21739130434783,"runtime_mean":20861874.9,"runtime_std":9739200.687745852},"projects":[],"admins":["16"],"tags":[],"removed":false,"config":{"dtiinit":{"type":"input","file_id":"output","input_id":"dtiinit"},"t1":{"type":"input","file_id":"t1","input_id":"t1"},"rois":{"type":"input","file_id":"rois","input_id":"rois"},"eccentricity":{"type":"input","file_id":"eccentricity","input_id":"prf"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"nSamples":{"id":"nSamples","type":"number","placeholder":"","advanced":false,"desc":"Number of streamlines desired. NOTE: This may not be final total as tracking is performed without anatomical constraints (i.e. csf exclusion)","default":50000,"_order":2,"pid":0.4998407447885568},"maxNodes":{"id":"maxNodes","type":"number","placeholder":"","advanced":false,"desc":"maximum number of nodes","default":240,"_order":3,"pid":0.7191410363879452},"minNodes":{"id":"minNodes","type":"number","placeholder":"","advanced":false,"desc":"minimum number of nodes","default":100,"_order":4,"pid":0.1548468964798202},"stepSize":{"id":"stepSize","type":"number","placeholder":"","advanced":false,"desc":"step size","default":1,"_order":5,"pid":0.6842433975269911},"contrackThreshold":{"id":"contrackThreshold","type":"number","placeholder":"","advanced":false,"desc":"","default":5000,"_order":6,"pid":0.35241770178814236},"lgn":{"id":"lgn","type":"string","placeholder":"","advanced":false,"desc":"","default":"lgn","_order":7,"pid":0.8151681428350853},"v1":{"id":"v1","type":"string","placeholder":"","advanced":false,"desc":"","default":"v1","_order":8,"pid":0.3768899203763497},"minDegree":{"id":"minDegree","type":"string","placeholder":"","advanced":false,"desc":"","default":"0 15 30","_order":9,"pid":0.5535653407214289},"maxDegree":{"id":"maxDegree","type":"string","placeholder":"","advanced":false,"desc":"","default":"3 30 90","_order":10,"pid":0.2561005649896939},"inflate_lgn":{"id":"inflate_lgn","type":"number","placeholder":"","advanced":false,"desc":"","default":1,"_order":11,"pid":0.035169993192136095},"inflate_v1":{"id":"inflate_v1","type":"number","placeholder":"","advanced":false,"desc":"","default":1,"_order":12,"pid":0.042168034643804586},"minDistanceClean":{"id":"minDistanceClean","type":"number","placeholder":"","advanced":true,"desc":"","default":0.87,"_order":13,"pid":0.2828068459484643}},"inputs":[{"id":"dtiinit","datatype":"58cb234be13a50849b25882f","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ddce502936ca38c4bc5b4bd"},{"id":"t1","datatype":"58c33bcee13a50849b25879a","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ddce502936ca30580c5b4bc"},{"id":"rois","desc":"must include thalamic rois 008109 and 008209 derived from app-segment-thalamic-nuclei","datatype":"5be9ea0315a8683a39a1ebd9","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ddce502936ca3a209c5b4bb"},{"id":"prf","datatype":"5d9d18d8e30ae43bb0612715","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ddce502936ca3a41ec5b4ba"},{"id":"mask","datatype":"5a281aee2c214c9ba83ce620","datatype_tags":["5tt_masks"],"optional":true,"multi":false,"advanced":false,"_id":"5ddce502936ca30c5cc5b4b9"},{"id":"freesurfer","datatype":"58cb22c8e13a50849b25882e","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ddce502936ca3fd3ac5b4b8"}],"outputs":[{"id":"track","datatype":"5907d922436ee50ffde9c549","datatype_tags":["optic_radiation","tracking_eccentricity"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5ddce502936ca32d72c5b4bf"},{"id":"wmc","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags":["optic_radiation","tracking_eccentricity"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5ddce502936ca358abc5b4be"}],"github_branch":"tracking-eccentricity-or-v1.1","github":"brainlife/app-contrack-visual-white-matter","name":"Track The Human Optic RAdiation (THORA): Contrack - Tracking Eccentricity","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a37cd62f3d3800f11e56d"}],"create_date":"2019-11-26T08:40:34.227Z","desc":null,"doi":"10.25663/brainlife.app.254","__v":6551,"_canedit":true},{"_id":"5d9632fdf6484a44c06a87db","stats":{"stars":0,"serviceinfo":{"_id":"5d729e1e78356a109788b1e3","counts":{"_id":"5e5c3e1987cac7be13ab1431","failed":112,"finished":147,"removed":309,"requested":392,"running":302,"running_sync":0,"stop_requested":65},"success_rate":56.75675675675676,"users":7,"readme_status":"ok","runtime_mean":18540062.42,"runtime_std":10967451.73775354,"service":"brainlife/app-trekker-roi-tracking","__v":0},"success_rate":44.38652766639935,"users":14,"runtime_mean":9394121.4,"runtime_std":8236894.053758132,"requested":3594,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a372762f3d3800f11d57a"}],"examples":1,"groups":24},"projects":["59cbd18ff32356076a887fe4","5d2fb9756c03750a8a525343","628c14c3d0697cf1eaec72c9","5dceb267c4ae281d2c297b92"],"admins":["16"],"tags":["diffusion-mri","mri","tracking","tractography","vision"],"removed":false,"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"lmax2":{"type":"input","file_id":"lmax2","input_id":"csd"},"lmax4":{"type":"input","file_id":"lmax4","input_id":"csd"},"lmax6":{"type":"input","file_id":"lmax6","input_id":"csd"},"lmax8":{"type":"input","file_id":"lmax8","input_id":"csd"},"lmax10":{"type":"input","file_id":"lmax10","input_id":"csd"},"lmax12":{"type":"input","file_id":"lmax12","input_id":"csd"},"lmax14":{"type":"input","file_id":"lmax14","input_id":"csd"},"rois":{"type":"input","file_id":"rois","input_id":"rois"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"brainmask":{"type":"input","file_id":"mask","input_id":"brainmask"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"min_length":{"id":"min_length","type":"number","placeholder":"","advanced":false,"desc":"min length of streamlines","default":10,"_order":2,"pid":0.6253201235381532},"max_length":{"id":"max_length","type":"number","placeholder":"","advanced":false,"desc":"max length of streamlines","default":200,"_order":3,"pid":0.7942462462799132},"lmax":{"id":"lmax","type":"number","placeholder":"","advanced":false,"desc":"max lmax","default":8,"_order":4,"pid":0.6905890490595618},"lgn":{"id":"lgn","type":"string","placeholder":"","advanced":false,"desc":"Enter the names of the lgn ROIs that can be found in the rois input datatype. For example, if tracking both the left and right hemisphere ORs, and the lgn roi names are lh.lgn and rh.lgn, enter \"lh.lgn rh.lgn\". Please see roi datatype for exact name of each.\n\nNote: if ROI name includes \"ROI\" prefix, do not need to include that in the ROI name","default":"","_order":5,"pid":0.5881728757478956},"v1":{"id":"v1","type":"string","placeholder":"","advanced":false,"desc":"Enter the names of the v1 ROIs that can be found in the rois input datatype. For example, if tracking both the left and right hemisphere ORs, and the v1 roi names are lh.v1 and rh.v1, enter \"lh.v1 rh.v1\". Please see roi datatype for exact name of each.\n\nEccentricity-binned ROIs of the v1 must be included in the rois input datatype following the subsequent naming format: <roi-name>.Ecc<minDegree>to<maxDegree>.nii.gz. Example: lh.v1.Ecc0to5.nii.gz\n\nNote: if ROI name includes \"ROI\" prefix, do not need to include that in the ROI name","default":"","_order":11,"pid":0.13297292527205573},"exclusion":{"id":"exclusion","type":"string","placeholder":"","advanced":false,"desc":"Enter the names of the exclusion ROIs that can be found in the rois input datatype. For example, if tracking both the left and right hemisphere ORs, and the lgn roi names are lh.exclusion and rh.exclusion, enter \"lh.exclusion rh.exclusion\". Please see roi datatype for exact name of each. Note: if ROI name includes \"ROI\" prefix, do not need to include that in the ROI name\n\nThese exclusion can be any grouping of ROIs that you DO NOT want streamlines to cross. For example, opposite hemisphere white matter, cerebellar white matter, hippocampus are good exclusions for the OR. \n\nIf you do not want to use exclusion ROIs, leave blank","default":"","_order":13,"pid":0.06833476587514342,"optional":true},"count":{"id":"count","type":"number","placeholder":"","advanced":false,"desc":"total number of streamlines","default":500,"_order":14,"pid":0.17113846009325961},"stepsize":{"id":"stepsize","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":18,"pid":0.9189165073865705},"min_degree":{"id":"min_degree","type":"string","placeholder":"","advanced":false,"desc":"","default":"0 15 30","_order":20,"pid":0.13842256111996465},"max_degree":{"id":"max_degree","type":"string","placeholder":"","advanced":false,"desc":"","default":"3 30 90","_order":21,"pid":0.3161488677902833},"curvatures":{"id":"curvatures","type":"string","placeholder":"","advanced":true,"desc":"minimum radius of curvature","default":"default","_order":22,"pid":0.7754366463895345},"probelength":{"id":"probelength","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":23,"pid":0.3363452627839909},"probecount":{"id":"probecount","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":24,"pid":0.7414221575645275},"proberadius":{"id":"proberadius","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":25,"pid":0.3491120358765186},"probequality":{"id":"probequality","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":26,"pid":0.6938776103844329},"maxsampling":{"id":"maxsampling","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":27,"pid":0.4498520945072283},"maxtrials":{"id":"maxtrials","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":28,"pid":0.09378238640380199},"minfodamp":{"id":"minfodamp","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":29,"pid":0.7715552378962459},"bestAtInit":{"id":"bestAtInit","type":"boolean","placeholder":"","advanced":true,"desc":"","default":false,"_order":31,"pid":0.5916394555703708},"single_lmax":{"id":"single_lmax","type":"boolean","placeholder":"","advanced":true,"desc":"","default":true,"_order":32,"pid":0.26156486089239706}},"inputs":[{"id":"dwi","datatype":"58c33c5fe13a50849b25879b","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d9632fdf6484a16376a87e1"},{"id":"csd","datatype":"5c536bf0f9109beac46adb45","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d9632fdf6484a7e636a87df"},{"id":"rois","datatype":"5be9ea0315a8683a39a1ebd9","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d9632fdf6484ae53a6a87de"},{"id":"mask","datatype":"5a281aee2c214c9ba83ce620","datatype_tags":["5tt_masks"],"optional":false,"multi":false,"advanced":false,"_id":"5d9632fdf6484a00aa6a87dd"},{"id":"brainmask","datatype":"5a281aee2c214c9ba83ce620","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5d9632fdf6484ab04e6a87dc"},{"id":"freesurfer","datatype":"58cb22c8e13a50849b25882e","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5dd80a3f936ca33e0dc56fe7"}],"outputs":[{"id":"track","datatype":"5907d922436ee50ffde9c549","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5d9632fdf6484abc006a87e7"},{"id":"brainmask","datatype":"5a281aee2c214c9ba83ce620","datatype_tags":["brain_mask"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":false,"_id":"5d9632fdf6484a43206a87e4"},{"id":"wmc","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags":["optic_radiation"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5d9632fdf6484a5fbc6a87e3"},{"id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags":["or_derivatives"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5eabb9ec0efebff94f19e745"}],"github_branch":"optic-radiation-eccentricity-v1.3","github":"brainlife/app-trekker-roi-tracking","name":"Track The Human Optic RAdiation (THORA): Trekker - Eccentricity","desc_override":"This app uses [Trekker](https://dmritrekker.github.io) to Track the Human Optic Radiation.","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a372762f3d3800f11d57b"},{"name":"Franco Pestilli","email":null,"_id":"634a372762f3d3800f11d57c"}],"create_date":"2019-10-03T17:42:21.650Z","desc":"Brainlife App (wrapper) for dMRI based fiber tracking between ROIs using parallel transport tractography","doi":"10.25663/brainlife.app.233","__v":6845,"_canedit":true},{"_id":"5f4f12ce42c172341e648573","projects":["59cbd18ff32356076a887fe4","5d2fb9756c03750a8a525343","5dceb267c4ae281d2c297b92"],"admins":["16"],"tags":["diffusion-mri","mri","tracking","tractography","vision"],"removed":false,"stats":{"success_rate":44.38652766639935,"users":14,"runtime_mean":9394121.4,"runtime_std":8236894.053758132,"requested":3594,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3cbf62f3d3800f1298e2"}],"examples":0,"groups":24},"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"lmax2":{"type":"input","file_id":"lmax2","input_id":"csd"},"lmax4":{"type":"input","file_id":"lmax4","input_id":"csd"},"lmax6":{"type":"input","file_id":"lmax6","input_id":"csd"},"lmax8":{"type":"input","file_id":"lmax8","input_id":"csd"},"lmax10":{"type":"input","file_id":"lmax10","input_id":"csd"},"lmax12":{"type":"input","file_id":"lmax12","input_id":"csd"},"lmax14":{"type":"input","file_id":"lmax14","input_id":"csd"},"rois":{"type":"input","file_id":"rois","input_id":"rois"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"brainmask":{"type":"input","file_id":"mask","input_id":"brainmask"},"min_length":{"id":"min_length","type":"number","placeholder":"","advanced":false,"desc":"min length of streamlines","default":10,"_order":2,"pid":0.562871825949137},"max_length":{"id":"max_length","type":"number","placeholder":"","advanced":false,"desc":"max length of streamlines","default":200,"_order":3,"pid":0.12926794996243784},"lmax":{"id":"lmax","type":"number","placeholder":"","advanced":false,"desc":"max lmax","default":8,"_order":4,"pid":0.39986131681323833},"lgn":{"id":"lgn","type":"string","placeholder":"","advanced":false,"desc":"Enter the names of the lgn ROIs that can be found in the rois input datatype. For example, if tracking both the left and right hemisphere ORs, and the lgn roi names are lh.lgn and rh.lgn, enter \"lh.lgn rh.lgn\". Please see roi datatype for exact name of each.\n\nNote: if ROI name includes \"ROI\" prefix, do not need to include that in the ROI name","default":"","_order":5,"pid":0.6045365173054049},"v2":{"id":"v2","type":"string","placeholder":"","advanced":false,"desc":"Enter the names of the v2 ROIs that can be found in the rois input datatype. For example, if tracking both the left and right hemisphere ORs, and the v2 roi names are lh.v2 and rh.v2, enter \"lh.v2 rh.v2\". Please see roi datatype for exact name of each.\n\nEccentricity-binned ROIs of the v2 must be included in the rois input datatype following the subsequent naming format: <roi-name>.Ecc<minDegree>to<maxDegree>.nii.gz. Example: lh.v2.Ecc0to5.nii.gz\n\nNote: if ROI name includes \"ROI\" prefix, do not need to include that in the ROI name","default":"","_order":11,"pid":0.47862381026926526},"exclusion":{"id":"exclusion","type":"string","placeholder":"","advanced":false,"desc":"\n\nEnter the names of the exclusion ROIs that can be found in the rois input datatype. For example, if tracking both the left and right hemisphere ORs, and the lgn roi names are lh.exclusion and rh.exclusion, enter \"lh.exclusion rh.exclusion\". Please see roi datatype for exact name of each. Note: if ROI name includes \"ROI\" prefix, do not need to include that in the ROI name\n\nThese exclusion can be any grouping of ROIs that you DO NOT want streamlines to cross. For example, opposite hemisphere white matter, cerebellar white matter, hippocampus are good exclusions for the OR. \n\nIf you do not want to use exclusion ROIs, leave blank","default":"","_order":13,"pid":0.9731558679582031,"optional":true},"count":{"id":"count","type":"number","placeholder":"","advanced":false,"desc":"total number of streamlines","default":500,"_order":14,"pid":0.5213234456361764},"stepsize":{"id":"stepsize","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":18,"pid":0.5483354255743635},"min_degree":{"id":"min_degree","type":"string","placeholder":"","advanced":false,"desc":"","default":"0 15 30","_order":20,"pid":0.0284686155564291},"max_degree":{"id":"max_degree","type":"string","placeholder":"","advanced":false,"desc":"","default":"3 30 90","_order":21,"pid":0.7368601819991205},"curvatures":{"id":"curvatures","type":"string","placeholder":"","advanced":true,"desc":"minimum radius of curvature","default":"default","_order":22,"pid":0.022977917474881426},"probelength":{"id":"probelength","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":23,"pid":0.40574262971833286},"probecount":{"id":"probecount","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":24,"pid":0.9778298849348697},"proberadius":{"id":"proberadius","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":25,"pid":0.6007117052899991},"probequality":{"id":"probequality","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":26,"pid":0.8583538197673564},"maxsampling":{"id":"maxsampling","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":27,"pid":0.2091465555125509},"maxtrials":{"id":"maxtrials","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":28,"pid":0.11910711987372768},"minfodamp":{"id":"minfodamp","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":29,"pid":0.1100020668789099},"bestAtInit":{"id":"bestAtInit","type":"boolean","placeholder":"","advanced":true,"desc":"","default":false,"_order":31,"pid":0.39932958988108},"single_lmax":{"id":"single_lmax","type":"boolean","placeholder":"","advanced":true,"desc":"","default":true,"_order":32,"pid":0.3704406194272136}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d9632fdf6484a16376a87e1","id":"dwi","datatype":"58c33c5fe13a50849b25879b"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d9632fdf6484a7e636a87df","id":"csd","datatype":"5c536bf0f9109beac46adb45"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d9632fdf6484ae53a6a87de","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9"},{"datatype_tags":["5tt_masks"],"optional":false,"multi":false,"advanced":false,"_id":"5d9632fdf6484a00aa6a87dd","id":"mask","datatype":"5a281aee2c214c9ba83ce620"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5d9632fdf6484ab04e6a87dc","id":"brainmask","datatype":"5a281aee2c214c9ba83ce620"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5d9632fdf6484abc006a87e7","id":"track","datatype":"5907d922436ee50ffde9c549","datatype_tags_pass":null,"files":null},{"datatype_tags":["brain_mask"],"output_on_root":false,"archive":false,"_id":"5d9632fdf6484a43206a87e4","id":"brainmask","datatype":"5a281aee2c214c9ba83ce620","datatype_tags_pass":null,"files":null},{"datatype_tags":["optic_radiation"],"output_on_root":false,"archive":true,"_id":"5d9632fdf6484a5fbc6a87e3","id":"wmc","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags_pass":null,"files":null},{"datatype_tags":["or_derivatives"],"output_on_root":false,"archive":true,"_id":"5eabb9ec0efebff94f19e745","id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null}],"github_branch":"optic-radiation-eccentricity-v2-v1.0","github":"brainlife/app-trekker-roi-tracking","name":"Track The Human Optic RAdiation (THORA): Trekker - Eccentricity (V2)","desc_override":"This app uses [Trekker](https://dmritrekker.github.io) to Track the Human Optic Radiation.","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3cc062f3d3800f1298e3"},{"name":"Franco Pestilli","email":null,"_id":"634a3cc062f3d3800f1298e4"}],"desc":"Brainlife App (wrapper) for dMRI based fiber tracking between ROIs using parallel transport tractography","__v":4155,"create_date":"2020-09-02T03:34:38.429Z","doi":"10.25663/brainlife.app.405","deprecated_by":"5d9632fdf6484a44c06a87db","_canedit":true},{"_id":"5ee1cf9bc5972b084cb44de8","projects":["59cbd18ff32356076a887fe4","5d2fb9756c03750a8a525343","5dceb267c4ae281d2c297b92"],"admins":["16"],"tags":["diffusion-mri","mri","tracking","tractography","vision"],"removed":false,"stats":{"success_rate":44.38652766639935,"users":14,"runtime_mean":9394121.4,"runtime_std":8236894.053758132,"requested":3594,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3bc162f3d3800f126821"}],"examples":0,"groups":24},"config":{"prfSurfacesDir":{"type":"input","file_id":"prf_surfaces","input_id":"prf"},"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"t1":{"type":"input","file_id":"t1","input_id":"anat"},"lmax2":{"type":"input","file_id":"lmax2","input_id":"csd"},"lmax4":{"type":"input","file_id":"lmax4","input_id":"csd"},"lmax6":{"type":"input","file_id":"lmax6","input_id":"csd"},"lmax8":{"type":"input","file_id":"lmax8","input_id":"csd"},"lmax10":{"type":"input","file_id":"lmax10","input_id":"csd"},"lmax12":{"type":"input","file_id":"lmax12","input_id":"csd"},"lmax14":{"type":"input","file_id":"lmax14","input_id":"csd"},"rois":{"type":"input","file_id":"rois","input_id":"rois"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"brainmask":{"type":"input","file_id":"mask","input_id":"brainmask"},"dtiinit":{"type":"input","file_id":"output","input_id":"dtiinit"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"min_length":{"id":"min_length","type":"number","placeholder":"","advanced":false,"desc":"min length of streamlines","default":10,"_order":2,"pid":0.3665969591173335},"max_length":{"id":"max_length","type":"number","placeholder":"","advanced":false,"desc":"max length of streamlines","default":200,"_order":3,"pid":0.3427599657419629},"maxlmax":{"id":"maxlmax","type":"number","placeholder":"","advanced":false,"desc":"max lmax","default":8,"_order":4,"pid":0.8051004132673472},"seed_roi":{"id":"seed_roi","type":"string","placeholder":"","advanced":false,"desc":"ROI for LGN\nFor left optic radiation: 008109; for right optic radiation: 008209","default":"","_order":5,"pid":0.9448043594510143},"count":{"id":"count","type":"number","placeholder":"","advanced":false,"desc":"total number of streamlines","default":500,"_order":7,"pid":0.12693227814998465},"probelength":{"id":"probelength","type":"number","placeholder":"","advanced":false,"desc":"Length of the probe. Pick 1/4 of the smallest of the FOD(input dwi) voxel dimensions. For whole-brain tractography, use 1.0","default":0.25,"_order":9,"pid":0.37561496418531215},"stepsize":{"id":"stepsize","type":"string","placeholder":"","advanced":false,"desc":"","default":"0.05","_order":11,"pid":0.21161132607613453},"maxtrials":{"id":"maxtrials","type":"number","placeholder":"","advanced":false,"desc":"Sets the maximum number of attempts to generate streamline from the seed point. Default=1000000.","default":1000000,"_order":12,"pid":0.9783511964805587},"probecount":{"id":"probecount","type":"number","placeholder":"","advanced":false,"desc":"Determines the number of lines outside the cylinder. Default: 1, i.e: by default, the radius of the cylinder (probeRadius) is zero and only a single line is used to model a cylinder.","default":1,"_order":13,"pid":0.38016756486444314},"probequality":{"id":"probequality","type":"number","placeholder":"","advanced":false,"desc":"This parameter sets the number of segments to split the cylinder along the length of the probe. The larger the value is, the slower the computation gets. Default=4.","default":4,"_order":14,"pid":0.44335960347938186},"maxsampling":{"id":"maxsampling","type":"number","placeholder":"","advanced":false,"desc":"This option limits the number of samples that can be tested for rejection sampling during propagation. Default=10000.","default":10000,"_order":15,"pid":0.30294971045212726},"minfodamp":{"id":"minfodamp","type":"number","placeholder":"","advanced":false,"desc":"","default":0.01,"_order":16,"pid":0.21375251315201216},"MinDegree":{"id":"MinDegree","type":"string","placeholder":"","advanced":false,"desc":"","default":"0 15 30","_order":18,"pid":0.6073932500007897},"MaxDegree":{"id":"MaxDegree","type":"string","placeholder":"","advanced":false,"desc":"","default":"3 30 90","_order":19,"pid":0.0835541154482966},"curv":{"id":"curv","type":"string","placeholder":"","advanced":false,"desc":"minimum radius of curvature","default":"0.25","_order":20,"pid":0.5053324770432086},"names":{"id":"names","type":"string","placeholder":"","advanced":false,"desc":"names for final tracks in classification structure","default":"","_order":21,"pid":0.2622233438886423}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d9632fdf6484a652b6a87e2","id":"prf","datatype":"5d9d18d8e30ae43bb0612715"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5d9632fdf6484a16376a87e1","id":"dwi","datatype":"58c33c5fe13a50849b25879b"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d9632fdf6484a64516a87e0","id":"anat","datatype":"58c33bcee13a50849b25879a"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d9632fdf6484a7e636a87df","id":"csd","datatype":"5c536bf0f9109beac46adb45"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d9632fdf6484ae53a6a87de","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9"},{"datatype_tags":["5tt_masks"],"optional":true,"multi":false,"advanced":false,"_id":"5d9632fdf6484a00aa6a87dd","id":"mask","datatype":"5a281aee2c214c9ba83ce620"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5d9632fdf6484ab04e6a87dc","id":"brainmask","datatype":"5a281aee2c214c9ba83ce620"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5dcebdc3c4ae2807dc297eaf","id":"dtiinit","datatype":"58cb234be13a50849b25882f"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5dd80a3f936ca33e0dc56fe7","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5d9632fdf6484abc006a87e7","id":"track","datatype":"5907d922436ee50ffde9c549","datatype_tags_pass":null,"files":null},{"datatype_tags":["5tt_masks"],"output_on_root":false,"archive":false,"_id":"5d9632fdf6484aee7b6a87e5","id":"mask","datatype":"5a281aee2c214c9ba83ce620","datatype_tags_pass":null,"files":null},{"datatype_tags":["brain_mask"],"output_on_root":false,"archive":false,"_id":"5d9632fdf6484a43206a87e4","id":"brainmask","datatype":"5a281aee2c214c9ba83ce620","datatype_tags_pass":null,"files":null},{"datatype_tags":["optic_radiation"],"output_on_root":false,"archive":true,"_id":"5d9632fdf6484a5fbc6a87e3","id":"wmc","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags_pass":null,"files":null},{"datatype_tags":["or_derivatives"],"output_on_root":false,"archive":true,"_id":"5eabb9ec0efebff94f19e745","id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null}],"github_branch":"optic-radiation-eccentricity-exclusion","github":"brainlife/app-trekker-roi-tracking","name":"Track The Human Optic RAdiation (THORA): Trekker - Eccentricity - DEPRECATED","desc_override":"This app uses [Trekker](https://dmritrekker.github.io) to Track the Human Optic Radiation.","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3bc262f3d3800f126822"},{"name":"Franco Pestilli","email":null,"_id":"634a3bc262f3d3800f126823"}],"desc":"Brainlife App (wrapper) for dMRI based fiber tracking between ROIs using parallel transport tractography","__v":4657,"create_date":"2020-06-11T06:30:51.820Z","doi":"10.25663/brainlife.app.375","deprecated_by":"5d9632fdf6484a44c06a87db","_canedit":true},{"_id":"5ddcab89936ca37544c5adf3","stats":{"stars":0,"serviceinfo":{"_id":"5d729e1f78356a109788b2eb","counts":{"_id":"5e5c3e2d87cac73cfaab1441","failed":3381,"finished":11383,"removed":28448,"requested":30096,"running":14546,"running_sync":0,"stop_requested":509},"success_rate":77.0997019777838,"users":4,"readme_status":"ok","runtime_mean":5104239.9,"runtime_std":9812760.010720242,"service":"brain-life/app-roi2roitracking","__v":0},"success_rate":4.411764705882353,"users":3,"runtime_mean":48983551,"runtime_std":10404132.833534982,"requested":82,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a37c262f3d3800f11e466"}],"examples":0,"groups":4},"projects":["5dceb267c4ae281d2c297b92"],"admins":["16"],"tags":["tracking"],"removed":false,"config":{"eccentricity":{"type":"input","file_id":"eccentricity","input_id":"prf"},"varea":{"type":"input","file_id":"varea","input_id":"prf"},"dtiinit":{"type":"input","file_id":"output","input_id":"dtiinit"},"t1":{"type":"input","file_id":"t1","input_id":"anat"},"lmax2":{"type":"input","file_id":"lmax2","input_id":"csd"},"lmax4":{"type":"input","file_id":"lmax4","input_id":"csd"},"lmax6":{"type":"input","file_id":"lmax6","input_id":"csd"},"lmax8":{"type":"input","file_id":"lmax8","input_id":"csd"},"lmax10":{"type":"input","file_id":"lmax10","input_id":"csd"},"lmax12":{"type":"input","file_id":"lmax12","input_id":"csd"},"lmax14":{"type":"input","file_id":"lmax14","input_id":"csd"},"response":{"type":"input","file_id":"response","input_id":"csd"},"rois":{"type":"input","file_id":"rois","input_id":"rois"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"brainmask":{"type":"input","file_id":"mask","input_id":"brainmask"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"minlength":{"id":"minlength","type":"number","placeholder":"","advanced":false,"desc":"min length of streamlines","default":10,"_order":2,"pid":0.7423607497088134},"maxlength":{"id":"maxlength","type":"number","placeholder":"","advanced":false,"desc":"max length of streamlines","default":200,"_order":3,"pid":0.8040067482213027},"max_lmax":{"id":"max_lmax","type":"number","placeholder":"","advanced":false,"desc":"maximum spherical harmonic for csd. If empty, this will automatically be calculated based on number of directions in dwi data.","default":8,"_order":4,"pid":0.9139403822773506,"optional":true},"seed_roi":{"id":"seed_roi","type":"string","placeholder":"","advanced":false,"desc":"ROI for LGN\nFor left optic radiation: 008109; for right optic radiation: 008209","default":"","_order":5,"pid":0.5187288080049279},"num_fibers":{"id":"num_fibers","type":"number","placeholder":"","advanced":false,"desc":"number of streamlines for each lmax csd","default":null,"_order":6,"pid":0.7876534036459439},"max_num":{"id":"max_num","type":"number","placeholder":"","advanced":false,"desc":"maximum number of attempts per seed location. If 0, app will run until desired number of streamlines per lmax csd. Usually set to 100x the number of desired streamlines","default":0,"_order":7,"pid":0.24494355351719155},"stepsize":{"id":"stepsize","type":"number","placeholder":"","advanced":false,"desc":"step size","default":null,"_order":8,"pid":0.6572138514173429},"minfodamp":{"id":"minfodamp","type":"number","placeholder":"","advanced":false,"desc":"","default":0.01,"_order":9,"pid":0.10791832821898706},"num_repetitions":{"id":"num_repetitions","type":"number","placeholder":"","advanced":false,"desc":"number of repetitions per lmax csd desired","default":1,"_order":10,"pid":0.9164494690550444},"term_roi":{"id":"term_roi","type":"string","placeholder":"","advanced":false,"desc":"termination ROI (v1)","default":"0001","_order":11,"pid":0.4483367819242121},"MinDegree":{"id":"MinDegree","type":"string","placeholder":"","advanced":false,"desc":"","default":"0 15 30","_order":12,"pid":0.5363015015921038},"MaxDegree":{"id":"MaxDegree","type":"string","placeholder":"","advanced":false,"desc":"","default":"3 30 90","_order":13,"pid":0.5433294105366864}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ddcab89936ca326d9c5adfb","id":"prf","datatype":"5d9d18d8e30ae43bb0612715"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ddcab89936ca304c5c5adfa","id":"dtiinit","datatype":"58cb234be13a50849b25882f"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ddcab89936ca38fdac5adf9","id":"anat","datatype":"58c33bcee13a50849b25879a"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5ddcab89936ca3bd23c5adf8","id":"csd","datatype":"5c536bf0f9109beac46adb45","desc":"Will be computed internally if not inputted"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ddcab89936ca346c7c5adf7","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9"},{"datatype_tags":["5tt_masks"],"optional":true,"multi":false,"advanced":false,"_id":"5ddcab89936ca308c5c5adf6","id":"mask","datatype":"5a281aee2c214c9ba83ce620"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5ddcab89936ca36b1ac5adf5","id":"brainmask","datatype":"5a281aee2c214c9ba83ce620"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ddcab89936ca330c3c5adf4","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5ddcab89936ca3a3c7c5adfd","id":"track","datatype":"5907d922436ee50ffde9c549","datatype_tags_pass":null,"files":null},{"datatype_tags":["optic_radiation"],"output_on_root":false,"archive":true,"_id":"5ddcab89936ca36472c5adfc","id":"wmc","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags_pass":null,"files":null},{"datatype_tags":["single_shell"],"output_on_root":false,"archive":false,"_id":"5ddcaba2936ca358acc5aeb2","id":"csd","datatype":"5c536bf0f9109beac46adb45","datatype_tags_pass":null,"files":null}],"github_branch":"optic_radiation_eccentricity","github":"brainlife/app-roi2roitracking","name":"Track The Human Optic RAdiation (THORA): mrtrix2 - Eccentricity","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a37c362f3d3800f11e467"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a37c362f3d3800f11e468"},{"name":"Franco Pestilli","email":null,"_id":"634a37c362f3d3800f11e469"},{"name":"Ilaria Sani","email":"ila.gina@virgilio.it","_id":"634a37c362f3d3800f11e46a"}],"create_date":"2019-11-26T04:35:21.568Z","desc":"This app will perform ensemble tracking between 2 or more cortical regions of interest (ROIs) from either a freesurfer parcellation or an atlas parcellation. The app will automatically generate ROI niftis in diffusion space for tracking based on inputted ROI numbers. Inputs include: parcellation (freesurfer; atlas optional), dt6 from dtiinit, and ROI pairings. Outputs include a track.tck for each pairing of ROIs, a classification structure, and a fg_classified structure which can then be fed into other apps on the website (example: Clean WMC Output).","doi":"10.25663/brainlife.app.253","__v":6565,"_canedit":true},{"_id":"62a7b499ab3e66978061e46c","user_id":"16","projects":[],"admins":["16"],"name":"Track Visual White Matter Tracks by Visual Field Eccentricty: Contrack","github":"brainlife/app-contrack-visual-white-matter","github_branch":"tracking-eccentricity-v1.1","desc":null,"tags":[],"contributors":[{"name":"Brad Caron","email":null,"_id":"634a451262f3d3800f130f75"}],"config":{"dtiinit":{"type":"input","file_id":"output","input_id":"dtiinit"},"t1":{"type":"input","file_id":"t1","input_id":"t1"},"rois":{"type":"input","file_id":"rois","input_id":"rois"},"eccentricity":{"type":"input","file_id":"eccentricity","input_id":"prf"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"nSamples":{"id":"nSamples","type":"number","placeholder":"","advanced":false,"desc":"Number of streamlines desired. NOTE: This may not be final total as tracking is performed without anatomical constraints (i.e. csf exclusion)","default":50000,"_order":2,"pid":0.038141528110552936},"maxNodes":{"id":"maxNodes","type":"number","placeholder":"","advanced":false,"desc":"maximum number of nodes","default":240,"_order":3,"pid":0.7796934246079735},"minNodes":{"id":"minNodes","type":"number","placeholder":"","advanced":false,"desc":"minimum number of nodes","default":100,"_order":4,"pid":0.9241819560731103},"stepSize":{"id":"stepSize","type":"number","placeholder":"","advanced":false,"desc":"step size","default":1,"_order":5,"pid":0.6518536566791152},"contrackThreshold":{"id":"contrackThreshold","type":"number","placeholder":"","advanced":false,"desc":"","default":5000,"_order":6,"pid":0.879827352292317},"start_roi":{"id":"start_roi","type":"string","placeholder":"","advanced":false,"desc":"names of seed ROIs for each tract (separated by spaces) you want to track.\n\nTo use this to track by eccentricity, make sure to include the appropriate naming for that specific eccentricity-binned ROI. For example, if you wanted to track lh v1 to rh v1 binned by eccentricity values 7 to 15, and the name of the lh roi is \"ROI.lh.v1.Ecc7to15.nii.gz\", start_roi == \"lh.v1.Ecc7to15\"","default":"","_order":7,"pid":0.44244621333100964},"term_roi":{"id":"term_roi","type":"string","placeholder":"","advanced":false,"desc":"names of termination ROIs for each tract (separated by spaces) you want to track.\n\nTo use this to track by eccentricity, make sure to include the appropriate naming for that specific eccentricity-binned ROI. For example, if you wanted to track lh v1 to rh v1 binned by eccentricity values 7 to 15, and the name of the rh roi is \"ROI.rh.v1.Ecc7to15.nii.gz\", term_roi == \"rh.v1.Ecc7to15\"","default":"","_order":8,"pid":0.7994090283672252},"inflate_start_roi":{"id":"inflate_start_roi","type":"number","placeholder":"","advanced":false,"desc":"","default":1,"_order":11,"pid":0.5824553647790441},"inflate_term_roi":{"id":"inflate_term_roi","type":"number","placeholder":"","advanced":false,"desc":"","default":1,"_order":12,"pid":0.3240490240049906},"minDistanceClean":{"id":"minDistanceClean","type":"number","placeholder":"","advanced":true,"desc":"","default":0.87,"_order":13,"pid":0.49699517728039955},"exclusion_roi":{"id":"exclusion_roi","type":"string","placeholder":"","advanced":false,"desc":"names of exclusion ROIs for each tract (separated by spaces) you want to track.","default":"","_order":14,"pid":0.9425013671700461}},"inputs":[{"id":"dtiinit","datatype":"58cb234be13a50849b25882f","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ddce502936ca38c4bc5b4bd"},{"id":"t1","datatype":"58c33bcee13a50849b25879a","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ddce502936ca30580c5b4bc"},{"id":"rois","desc":"must include thalamic rois 008109 and 008209 derived from app-segment-thalamic-nuclei","datatype":"5be9ea0315a8683a39a1ebd9","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ddce502936ca3a209c5b4bb"},{"id":"prf","datatype":"5d9d18d8e30ae43bb0612715","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ddce502936ca3a41ec5b4ba"},{"id":"mask","datatype":"5a281aee2c214c9ba83ce620","datatype_tags":["5tt_masks"],"optional":true,"multi":false,"advanced":false,"_id":"5ddce502936ca30c5cc5b4b9"},{"id":"freesurfer","datatype":"58cb22c8e13a50849b25882e","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ddce502936ca3fd3ac5b4b8"}],"outputs":[{"id":"track","datatype":"5907d922436ee50ffde9c549","datatype_tags":["tracking_eccentricity","visual_white_matter"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5ddce502936ca32d72c5b4bf"},{"id":"wmc","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags":["tracking_eccentricity","visual_white_matter"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5ddce502936ca358abc5b4be"}],"stats":{"groups":4,"users":3,"requested":152,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a451262f3d3800f130f73"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a451262f3d3800f130f74"}],"examples":1,"success_rate":65.21739130434783,"runtime_mean":20861874.9,"runtime_std":9739200.687745852},"removed":false,"__v":269,"create_date":"2022-06-13T22:05:13.432Z","doi":"10.25663/brainlife.app.647","_canedit":true},{"_id":"5d65964c39867291e349624a","stats":{"stars":0,"serviceinfo":{"_id":"5d729e1e78356a109788b1e3","counts":{"_id":"5e5c3e1387cac7bdc0ab142a","failed":112,"finished":147,"removed":309,"requested":392,"running":302,"running_sync":0,"stop_requested":65},"success_rate":56.75675675675676,"users":7,"readme_status":"ok","runtime_mean":18540062.42,"runtime_std":10967451.73775354,"service":"brainlife/app-trekker-roi-tracking","__v":0},"gitinfo":{"desc":"Brainlife App (wrapper) for dMRI based fiber tracking between ROIs using parallel transport tractography","tags":["diffusion-mri","mri","tracking","tractography","vision"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"success_rate":44.38652766639935,"users":14,"runtime_mean":9394121.4,"runtime_std":8236894.053758132,"requested":3594,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a36ee62f3d3800f11d315"}],"examples":2,"groups":24},"projects":[],"admins":["16","185","41","1"],"tags":["diffusion-mri","mri","tracking","tractography","vision"],"removed":false,"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"lmax2":{"type":"input","file_id":"lmax2","input_id":"csd"},"lmax4":{"type":"input","file_id":"lmax4","input_id":"csd"},"lmax6":{"type":"input","file_id":"lmax6","input_id":"csd"},"lmax8":{"type":"input","file_id":"lmax8","input_id":"csd"},"lmax10":{"type":"input","file_id":"lmax10","input_id":"csd"},"lmax12":{"type":"input","file_id":"lmax12","input_id":"csd"},"lmax14":{"type":"input","file_id":"lmax14","input_id":"csd"},"rois":{"type":"input","file_id":"rois","input_id":"rois"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"brainmask":{"type":"input","file_id":"mask","input_id":"brainmask"},"min_length":{"id":"min_length","type":"number","placeholder":"","advanced":false,"desc":"min length of streamlines","default":10,"_order":2,"pid":0.7231051861078817},"max_length":{"id":"max_length","type":"number","placeholder":"","advanced":false,"desc":"max length of streamlines","default":200,"_order":3,"pid":0.5425539488543174},"lmax":{"id":"lmax","type":"number","placeholder":"","advanced":false,"desc":"lmax","default":8,"_order":4,"pid":0.09460200919139528},"lgn":{"id":"lgn","type":"string","placeholder":"","advanced":false,"desc":"Enter the names of the lgn ROIs that can be found in the rois input datatype. For example, if tracking both the left and right hemisphere ORs, and the lgn roi names are lh.lgn and rh.lgn, enter \"lh.lgn rh.lgn\". Please see roi datatype for exact name of each.\n\nNote: if ROI name includes \"ROI\" prefix, do not need to include that in the ROI name","default":"","_order":5,"pid":0.8263235396493616},"v1":{"id":"v1","type":"string","placeholder":"","advanced":false,"desc":"Enter the names of the v1 ROIs that can be found in the rois input datatype. For example, if tracking both the left and right hemisphere ORs, and the v1 roi names are lh.v1 and rh.v1, enter \"lh.v1 rh.v1\". Please see roi datatype for exact name of each.\n\nNote: if ROI name includes \"ROI\" prefix, do not need to include that in the ROI name","default":"","_order":6,"pid":0.4175792491737018},"exclusion":{"id":"exclusion","type":"string","placeholder":"","advanced":false,"desc":"Enter the names of the exclusion ROIs that can be found in the rois input datatype. For example, if tracking both the left and right hemisphere ORs, and the lgn roi names are lh.exclusion and rh.exclusion, enter \"lh.exclusion rh.exclusion\". Please see roi datatype for exact name of each. Note: if ROI name includes \"ROI\" prefix, do not need to include that in the ROI name\n\nThese exclusion can be any grouping of ROIs that you DO NOT want streamlines to cross. For example, opposite hemisphere white matter, cerebellar white matter, hippocampus are good exclusions for the OR. \n\nIf you do not want to use exclusion ROIs, leave blank","default":"","_order":7,"pid":0.7151758738219871,"optional":true,"multiline":true},"count":{"id":"count","type":"number","placeholder":"","advanced":false,"desc":"total number of streamlines","default":500,"_order":9,"pid":0.5738622318521114},"curvatures":{"id":"curvatures","type":"string","placeholder":"","advanced":true,"desc":"minimum radius of curvature. If left as 'default', trekker will automatically determine best curvature. Otherwise, enter value of radius of curvature (i.e 0.5)","default":"default","_order":14,"pid":0.042386434573259635},"stepsize":{"id":"stepsize","type":"string","placeholder":"","advanced":true,"desc":"step size. If left as 'default', trekker will automatically determine best step size. Otherwise, enter value of step size (i.e 0.5)","default":"default","_order":15,"pid":0.3247437230663712},"single_lmax":{"id":"single_lmax","type":"boolean","placeholder":"","advanced":false,"desc":"if want to run on only one lmax, set to true. to ensemble, set to false","default":true,"_order":18,"pid":0.22044591679282544},"minfodamp":{"id":"minfodamp","type":"string","placeholder":"","advanced":true,"desc":"minimum FOD amplitude. If left as 'default', trekker will automatically determine best FOD amplitude. Otherwise, enter value of FOD amplitude (i.e 0.5)","default":"default","_order":19,"pid":0.7319152132035736},"maxsampling":{"id":"maxsampling","type":"string","placeholder":"","advanced":true,"desc":"max sampling per seed. If left as 'default', trekker will automatically determine best number of max sampling per seed. Otherwise, enter value here (100000)","default":"default","_order":20,"pid":0.6778987863716035},"maxtrials":{"id":"maxtrials","type":"string","placeholder":"","advanced":true,"desc":"max trials. If left as 'default', trekker will automatically determine best number of max trials. Otherwise, enter value here (100000)","default":"default","_order":21,"pid":0.2575056959174309},"probecount":{"id":"probecount","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":22,"pid":0.9736493924288181},"probelength":{"id":"probelength","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":23,"pid":0.24791854986183548},"proberadius":{"id":"proberadius","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":24,"pid":0.03190085948930954},"probequality":{"id":"probequality","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":25,"pid":0.0795867606118994,"optional":false},"bestAtInit":{"id":"bestAtInit","type":"boolean","placeholder":"","advanced":true,"desc":"","default":false,"_order":26,"pid":0.9528012199437101}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d65964c398672b124496250","id":"dwi","datatype":"58c33c5fe13a50849b25879b"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d65964c398672b57f49624e","id":"csd","datatype":"5c536bf0f9109beac46adb45"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d65964c3986725b9b49624d","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9"},{"datatype_tags":["5tt_masks"],"optional":false,"multi":false,"advanced":false,"_id":"5d65964c3986722b1e49624c","id":"mask","datatype":"5a281aee2c214c9ba83ce620","desc":"5-tissue type mask (needed for csd fitting)"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5d65964c398672012849624b","id":"brainmask","datatype":"5a281aee2c214c9ba83ce620","desc":"whole-brain mask"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5d65964c3986726908496255","id":"track","datatype":"5907d922436ee50ffde9c549","datatype_tags_pass":null,"files":null},{"datatype_tags":["brain_mask"],"output_on_root":false,"archive":false,"_id":"5d65964c398672dec1496252","id":"brainmask","datatype":"5a281aee2c214c9ba83ce620","datatype_tags_pass":null,"files":null},{"datatype_tags":["optic_radiation"],"output_on_root":false,"archive":true,"_id":"5d65964c39867210f4496251","id":"wmc","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags_pass":null,"files":null}],"github_branch":"optic-radiation-v1.2","github":"brainlife/app-trekker-roi-tracking","name":"Track the Human Optic RAdiation (THORA) - Trekker","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a36ef62f3d3800f11d316"},{"name":"Franco Pestilli","email":null,"_id":"634a36ef62f3d3800f11d317"}],"create_date":"2019-08-27T20:45:00.120Z","desc":"Brainlife App (wrapper) for dMRI based fiber tracking between ROIs using parallel transport tractography","doi":"10.25663/brainlife.app.226","__v":7301,"desc_override":"This app uses [Trekker](https://dmritrekker.github.io) to Track the Human Optic Radiation.","avatar":"https://raw.githubusercontent.com/brainlife/app-trekker-roi-tracking/optic_radiation/left_or.jpg","_canedit":true},{"_id":"5f4f103f42c172427b64837d","projects":[],"admins":["16","185","41","1"],"tags":["diffusion-mri","mri","tracking","tractography","vision"],"removed":false,"stats":{"gitinfo":{"desc":"Brainlife App (wrapper) for dMRI based fiber tracking between ROIs using parallel transport tractography","tags":["diffusion-mri","mri","tracking","tractography","vision"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"success_rate":44.38652766639935,"users":14,"runtime_mean":9394121.4,"runtime_std":8236894.053758132,"requested":3594,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3cb662f3d3800f1298de"}],"examples":0,"groups":24},"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"lmax2":{"type":"input","file_id":"lmax2","input_id":"csd"},"lmax4":{"type":"input","file_id":"lmax4","input_id":"csd"},"lmax6":{"type":"input","file_id":"lmax6","input_id":"csd"},"lmax8":{"type":"input","file_id":"lmax8","input_id":"csd"},"lmax10":{"type":"input","file_id":"lmax10","input_id":"csd"},"lmax12":{"type":"input","file_id":"lmax12","input_id":"csd"},"lmax14":{"type":"input","file_id":"lmax14","input_id":"csd"},"rois":{"type":"input","file_id":"rois","input_id":"rois"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"brainmask":{"type":"input","file_id":"mask","input_id":"brainmask"},"min_length":{"id":"min_length","type":"number","placeholder":"","advanced":false,"desc":"min length of streamlines","default":10,"_order":2,"pid":0.0092464685318987},"max_length":{"id":"max_length","type":"number","placeholder":"","advanced":false,"desc":"max length of streamlines","default":200,"_order":3,"pid":0.7944813645293021},"lmax":{"id":"lmax","type":"number","placeholder":"","advanced":false,"desc":"lmax","default":8,"_order":4,"pid":0.86692703739449},"lgn":{"id":"lgn","type":"string","placeholder":"","advanced":false,"desc":"Enter the names of the lgn ROIs that can be found in the rois input datatype. For example, if tracking both the left and right hemisphere ORs, and the lgn roi names are lh.lgn and rh.lgn, enter \"lh.lgn rh.lgn\". Please see roi datatype for exact name of each.\n\nNote: if ROI name includes \"ROI\" prefix, do not need to include that in the ROI name","default":"","_order":5,"pid":0.7484383178314393},"v2":{"id":"v2","type":"string","placeholder":"","advanced":false,"desc":"Enter the names of the v2 ROIs that can be found in the rois input datatype. For example, if tracking both the left and right hemisphere ORs, and the v2 roi names are lh.v2 and rh.v2, enter \"lh.v2 rh.v2\". Please see roi datatype for exact name of each.\n\nNote: if ROI name includes \"ROI\" prefix, do not need to include that in the ROI name","default":"","_order":6,"pid":0.3832076789960752},"exclusion":{"id":"exclusion","type":"string","placeholder":"","advanced":false,"desc":"Enter the names of the exclusion ROIs that can be found in the rois input datatype. For example, if tracking both the left and right hemisphere ORs, and the lgn roi names are lh.exclusion and rh.exclusion, enter \"lh.exclusion rh.exclusion\". Please see roi datatype for exact name of each. Note: if ROI name includes \"ROI\" prefix, do not need to include that in the ROI name\n\nThese exclusion can be any grouping of ROIs that you DO NOT want streamlines to cross. For example, opposite hemisphere white matter, cerebellar white matter, hippocampus are good exclusions for the OR. \n\nIf you do not want to use exclusion ROIs, leave blank","default":"","_order":7,"pid":0.7355926492307623,"optional":true,"multiline":true},"count":{"id":"count","type":"number","placeholder":"","advanced":false,"desc":"total number of streamlines","default":500,"_order":9,"pid":0.5500708010644457},"curvatures":{"id":"curvatures","type":"string","placeholder":"","advanced":true,"desc":"minimum radius of curvature. If left as 'default', trekker will automatically determine best curvature. Otherwise, enter value of radius of curvature (i.e 0.5)","default":"default","_order":14,"pid":0.4552020151581537},"stepsize":{"id":"stepsize","type":"string","placeholder":"","advanced":true,"desc":"step size. If left as 'default', trekker will automatically determine best step size. Otherwise, enter value of step size (i.e 0.5)","default":"default","_order":15,"pid":0.49924618359281014},"single_lmax":{"id":"single_lmax","type":"boolean","placeholder":"","advanced":false,"desc":"if want to run on only one lmax, set to true. to ensemble, set to false","default":true,"_order":18,"pid":0.22183122651663},"minfodamp":{"id":"minfodamp","type":"string","placeholder":"","advanced":true,"desc":"minimum FOD amplitude. If left as 'default', trekker will automatically determine best FOD amplitude. Otherwise, enter value of FOD amplitude (i.e 0.5)","default":"default","_order":19,"pid":0.75436729476749},"maxsampling":{"id":"maxsampling","type":"string","placeholder":"","advanced":true,"desc":"max sampling per seed. If left as 'default', trekker will automatically determine best number of max sampling per seed. Otherwise, enter value here (100000)","default":"default","_order":20,"pid":0.6132164472590309},"maxtrials":{"id":"maxtrials","type":"string","placeholder":"","advanced":true,"desc":"max trials. If left as 'default', trekker will automatically determine best number of max trials. Otherwise, enter value here (100000)","default":"default","_order":21,"pid":0.8991644064853572},"probecount":{"id":"probecount","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":22,"pid":0.47234809503345976},"probelength":{"id":"probelength","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":23,"pid":0.7753059085195042},"proberadius":{"id":"proberadius","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":24,"pid":0.8299960395879473},"probequality":{"id":"probequality","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":25,"pid":0.7381486515362925,"optional":false},"bestAtInit":{"id":"bestAtInit","type":"boolean","placeholder":"","advanced":true,"desc":"","default":false,"_order":26,"pid":0.8503477206641499}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d65964c398672b124496250","id":"dwi","datatype":"58c33c5fe13a50849b25879b"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d65964c398672b57f49624e","id":"csd","datatype":"5c536bf0f9109beac46adb45"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d65964c3986725b9b49624d","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9"},{"datatype_tags":["5tt_masks"],"optional":false,"multi":false,"advanced":false,"_id":"5d65964c3986722b1e49624c","id":"mask","datatype":"5a281aee2c214c9ba83ce620","desc":"5-tissue type mask (needed for csd fitting)"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5d65964c398672012849624b","id":"brainmask","datatype":"5a281aee2c214c9ba83ce620","desc":"whole-brain mask"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5d65964c3986726908496255","id":"track","datatype":"5907d922436ee50ffde9c549","datatype_tags_pass":null,"files":null},{"datatype_tags":["brain_mask"],"output_on_root":false,"archive":false,"_id":"5d65964c398672dec1496252","id":"brainmask","datatype":"5a281aee2c214c9ba83ce620","datatype_tags_pass":null,"files":null},{"datatype_tags":["optic_radiation"],"output_on_root":false,"archive":true,"_id":"5d65964c39867210f4496251","id":"wmc","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags_pass":null,"files":null}],"github_branch":"optic-radiation-v2-v1.0","github":"brainlife/app-trekker-roi-tracking","name":"Track the Human Optic RAdiation (THORA) - Trekker (V2)","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3cb762f3d3800f1298df"},{"name":"Franco Pestilli","email":null,"_id":"634a3cb762f3d3800f1298e0"}],"desc":"Brainlife App (wrapper) for dMRI based fiber tracking between ROIs using parallel transport tractography","__v":4156,"desc_override":"This app uses [Trekker](https://dmritrekker.github.io) to Track the Human Optic Radiation.","avatar":"https://raw.githubusercontent.com/brainlife/app-trekker-roi-tracking/optic_radiation/left_or.jpg","create_date":"2020-09-02T03:23:43.849Z","doi":"10.25663/brainlife.app.404","deprecated_by":"5d65964c39867291e349624a","_canedit":true},{"_id":"5ec842e71f44640ff49e8db1","projects":[],"admins":["16","185","41","1"],"tags":["diffusion-mri","mri","tracking","tractography","vision"],"removed":false,"stats":{"gitinfo":{"desc":"Brainlife App (wrapper) for dMRI based fiber tracking between ROIs using parallel transport tractography","tags":["diffusion-mri","mri","tracking","tractography","vision"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"success_rate":44.38652766639935,"users":14,"runtime_mean":9394121.4,"runtime_std":8236894.053758132,"requested":3594,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3ae362f3d3800f1247a7"}],"examples":0,"groups":24},"config":{"dtiinit":{"type":"input","file_id":"output","input_id":"dtiinit"},"lmax2":{"type":"input","file_id":"lmax2","input_id":"csd"},"lmax4":{"type":"input","file_id":"lmax4","input_id":"csd"},"lmax6":{"type":"input","file_id":"lmax6","input_id":"csd"},"lmax8":{"type":"input","file_id":"lmax8","input_id":"csd"},"lmax10":{"type":"input","file_id":"lmax10","input_id":"csd"},"lmax12":{"type":"input","file_id":"lmax12","input_id":"csd"},"lmax14":{"type":"input","file_id":"lmax14","input_id":"csd"},"rois":{"type":"input","file_id":"rois","input_id":"rois"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"brainmask":{"type":"input","file_id":"mask","input_id":"brainmask"},"min_length":{"id":"min_length","type":"number","placeholder":"","advanced":false,"desc":"min length of streamlines","default":10,"_order":2,"pid":0.9923175084458589},"max_length":{"id":"max_length","type":"number","placeholder":"","advanced":false,"desc":"max length of streamlines","default":200,"_order":3,"pid":0.7860414907857436},"lmax":{"id":"lmax","type":"number","placeholder":"","advanced":false,"desc":"lmax","default":8,"_order":4,"pid":0.16421247889827373},"roiPair":{"id":"roiPair","type":"string","placeholder":"","advanced":false,"desc":"This field is here for whether or not you want to track both hemispheres or one hemisphere at a time. If just one hemisphere is desired, enter the exact ROI number or name from the rois datatype for the lgn of choice (example: '008109'). If both are desired, enter both separated by a space (example: '008109 008209'). Please see ROI datatype for exact name of each.","default":"","_order":5,"pid":0.6646213871845734},"v1":{"id":"v1","type":"string","placeholder":"","advanced":false,"desc":"this field is the exact ROI name or number from the ROI datatype for the V1. Example: '0001'. Please see ROI datatype for exact name of each.","default":"","_order":6,"pid":0.5328489580533535},"exclusion":{"id":"exclusion","type":"string","placeholder":"","advanced":false,"desc":"this field is the exact ROI name or number from the ROI datatype for the V1. Example: 'exclusion_L'. If bother hemispheres are being tracked, enter the name separated by a space for each exclusion 'exclusion_R'. Please see ROI datatype for exact name of each.\n\nThese exclusion can be any grouping of ROIs that you DO NOT want streamlines to cross. For example, opposite hemisphere white matter, cerebellar white matter, hippocampus are good exclusions for the OR. \n\nIf you do not want to use exclusion ROIs, leave blank","default":"","_order":7,"pid":0.7489888211453086,"optional":true,"multiline":true},"count":{"id":"count","type":"number","placeholder":"","advanced":false,"desc":"total number of streamlines","default":500,"_order":9,"pid":0.1637892863863244},"probelength":{"id":"probelength","type":"number","placeholder":"","advanced":true,"desc":"Trekker: probe length\nDefault = 0.25","default":0.25,"_order":10,"pid":0.7005205326835864},"probequality":{"id":"probequality","type":"number","placeholder":"","advanced":true,"desc":"Trekker: Probe quality\nDefault = 4","default":4,"_order":11,"pid":0.6491110607005444},"proberadius":{"id":"proberadius","type":"number","placeholder":"","advanced":true,"desc":"Trekker: probe radius\nDefault =0","default":0,"_order":12,"pid":0.29308764566431544},"probecount":{"id":"probecount","type":"number","placeholder":"","advanced":true,"desc":"Trekker: probe count\nDefault = 1","default":1,"_order":13,"pid":0.5551779731390276},"curvatures":{"id":"curvatures","type":"string","placeholder":"","advanced":false,"desc":"minimum radius of curvature","default":"0.5","_order":14,"pid":0.9669600961155898},"stepsize":{"id":"stepsize","type":"string","placeholder":"","advanced":false,"desc":"step size","default":"0.05","_order":15,"pid":0.06555442949052259},"maxtrials":{"id":"maxtrials","type":"number","placeholder":"","advanced":false,"desc":"maximum number of trials","default":1000000,"_order":16,"pid":0.8871738931033597},"maxsampling":{"id":"maxsampling","type":"number","placeholder":"","advanced":false,"desc":"max sampling per seed","default":10000,"_order":17,"pid":0.9740718652197351},"single_lmax":{"id":"single_lmax","type":"boolean","placeholder":"","advanced":false,"desc":"if want to run on only one lmax, set to true. to ensemble, set to false","default":true,"_order":18,"pid":0.5923839276209015},"minfodamp":{"id":"minfodamp","type":"string","placeholder":"","advanced":false,"desc":"minimum FOD amplitude","default":"0.025","_order":19,"pid":0.5963470890723934}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ec842e71f4464d2589e8db6","id":"dtiinit","datatype":"58cb234be13a50849b25882f"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d65964c398672b57f49624e","id":"csd","datatype":"5c536bf0f9109beac46adb45"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d65964c3986725b9b49624d","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9"},{"datatype_tags":["5tt_masks"],"optional":false,"multi":false,"advanced":false,"_id":"5d65964c3986722b1e49624c","id":"mask","datatype":"5a281aee2c214c9ba83ce620","desc":"5-tissue type mask (needed for csd fitting)"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5d65964c398672012849624b","id":"brainmask","datatype":"5a281aee2c214c9ba83ce620","desc":"whole-brain mask"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5d65964c3986726908496255","id":"track","datatype":"5907d922436ee50ffde9c549","datatype_tags_pass":null,"files":null},{"datatype_tags":["brain_mask"],"output_on_root":false,"archive":false,"_id":"5d65964c398672dec1496252","id":"brainmask","datatype":"5a281aee2c214c9ba83ce620","datatype_tags_pass":null,"files":null},{"datatype_tags":["optic_radiation"],"output_on_root":false,"archive":true,"_id":"5d65964c39867210f4496251","id":"wmc","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags_pass":null,"files":null}],"github_branch":"optic-tract-true-v1.0","github":"brainlife/app-trekker-roi-tracking","name":"Track the Human Optic RAdiation (THORA) - Trekker (dtiinit) -v1.0","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3ae462f3d3800f1247a8"},{"name":"Franco Pestilli","email":null,"_id":"634a3ae462f3d3800f1247a9"}],"desc":"Brainlife App (wrapper) for dMRI based fiber tracking between ROIs using parallel transport tractography","__v":4815,"desc_override":"This app uses [Trekker](https://dmritrekker.github.io) to Track the Human Optic Radiation.","avatar":"https://raw.githubusercontent.com/brainlife/app-trekker-roi-tracking/optic_radiation/left_or.jpg","create_date":"2020-05-22T21:23:51.283Z","doi":"10.25663/brainlife.app.351","deprecated_by":"5ecca4321f4464c6279ede27","_canedit":true},{"_id":"5ecc88fa1f44648d649ece57","projects":[],"admins":["16","185","41","1"],"tags":["diffusion-mri","mri","tracking","tractography","vision"],"removed":false,"stats":{"gitinfo":{"desc":"Brainlife App (wrapper) for dMRI based fiber tracking between ROIs using parallel transport tractography","tags":["diffusion-mri","mri","tracking","tractography","vision"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"success_rate":44.38652766639935,"users":14,"runtime_mean":9394121.4,"runtime_std":8236894.053758132,"requested":3594,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3aff62f3d3800f124887"}],"examples":0,"groups":24},"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"lmax2":{"type":"input","file_id":"lmax2","input_id":"csd"},"lmax4":{"type":"input","file_id":"lmax4","input_id":"csd"},"lmax6":{"type":"input","file_id":"lmax6","input_id":"csd"},"lmax8":{"type":"input","file_id":"lmax8","input_id":"csd"},"lmax10":{"type":"input","file_id":"lmax10","input_id":"csd"},"lmax12":{"type":"input","file_id":"lmax12","input_id":"csd"},"lmax14":{"type":"input","file_id":"lmax14","input_id":"csd"},"rois":{"type":"input","file_id":"rois","input_id":"rois"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"brainmask":{"type":"input","file_id":"mask","input_id":"brainmask"},"min_length":{"id":"min_length","type":"number","placeholder":"","advanced":false,"desc":"min length of streamlines","default":10,"_order":2,"pid":0.7801899252756255},"max_length":{"id":"max_length","type":"number","placeholder":"","advanced":false,"desc":"max length of streamlines","default":200,"_order":3,"pid":0.4197554941705648},"lmax":{"id":"lmax","type":"number","placeholder":"","advanced":false,"desc":"lmax","default":8,"_order":4,"pid":0.9114191856298},"roiPair":{"id":"roiPair","type":"string","placeholder":"","advanced":false,"desc":"This field is here for whether or not you want to track both hemispheres or one hemisphere at a time. If just one hemisphere is desired, enter the exact ROI number or name from the rois datatype for the lgn of choice (example: '008109'). If both are desired, enter both separated by a space (example: '008109 008209'). Please see ROI datatype for exact name of each.","default":"","_order":5,"pid":0.8399957815098247},"v1":{"id":"v1","type":"string","placeholder":"","advanced":false,"desc":"this field is the exact ROI name or number from the ROI datatype for the V1. Example: '0001'. Please see ROI datatype for exact name of each.","default":"","_order":6,"pid":0.38868681986758347},"exclusion":{"id":"exclusion","type":"string","placeholder":"","advanced":false,"desc":"this field is the exact ROI name or number from the ROI datatype for the V1. Example: 'exclusion_L'. If bother hemispheres are being tracked, enter the name separated by a space for each exclusion 'exclusion_R'. Please see ROI datatype for exact name of each.\n\nThese exclusion can be any grouping of ROIs that you DO NOT want streamlines to cross. For example, opposite hemisphere white matter, cerebellar white matter, hippocampus are good exclusions for the OR. \n\nIf you do not want to use exclusion ROIs, leave blank","default":"","_order":7,"pid":0.5124687215874255,"optional":true,"multiline":true},"count":{"id":"count","type":"number","placeholder":"","advanced":false,"desc":"total number of streamlines","default":500,"_order":9,"pid":0.6080401516977101},"probelength":{"id":"probelength","type":"number","placeholder":"","advanced":true,"desc":"Trekker: probe length\nDefault = 0.25","default":0.25,"_order":10,"pid":0.4908386940336713},"probequality":{"id":"probequality","type":"number","placeholder":"","advanced":true,"desc":"Trekker: Probe quality\nDefault = 4","default":4,"_order":11,"pid":0.4814421670464959},"proberadius":{"id":"proberadius","type":"number","placeholder":"","advanced":true,"desc":"Trekker: probe radius\nDefault =0","default":0,"_order":12,"pid":0.6593409396350862},"probecount":{"id":"probecount","type":"number","placeholder":"","advanced":true,"desc":"Trekker: probe count\nDefault = 1","default":1,"_order":13,"pid":0.12758123286058032},"curvatures":{"id":"curvatures","type":"string","placeholder":"","advanced":false,"desc":"minimum radius of curvature","default":"0.5","_order":14,"pid":0.9750881725860578},"stepsize":{"id":"stepsize","type":"string","placeholder":"","advanced":false,"desc":"step size","default":"0.05","_order":15,"pid":0.1010842029181882},"maxtrials":{"id":"maxtrials","type":"number","placeholder":"","advanced":false,"desc":"maximum number of trials","default":1000000,"_order":16,"pid":0.42085904430652676},"maxsampling":{"id":"maxsampling","type":"number","placeholder":"","advanced":false,"desc":"max sampling per seed","default":10000,"_order":17,"pid":0.3883122285871785},"single_lmax":{"id":"single_lmax","type":"boolean","placeholder":"","advanced":false,"desc":"if want to run on only one lmax, set to true. to ensemble, set to false","default":true,"_order":18,"pid":0.35054556345923427},"minfodamp":{"id":"minfodamp","type":"string","placeholder":"","advanced":false,"desc":"minimum FOD amplitude","default":"0.025","_order":19,"pid":0.8291700997239397}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d65964c398672b124496250","id":"dwi","datatype":"58c33c5fe13a50849b25879b"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d65964c398672b57f49624e","id":"csd","datatype":"5c536bf0f9109beac46adb45"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d65964c3986725b9b49624d","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9"},{"datatype_tags":["5tt_masks"],"optional":false,"multi":false,"advanced":false,"_id":"5d65964c3986722b1e49624c","id":"mask","datatype":"5a281aee2c214c9ba83ce620","desc":"5-tissue type mask (needed for csd fitting)"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5d65964c398672012849624b","id":"brainmask","datatype":"5a281aee2c214c9ba83ce620","desc":"whole-brain mask"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5d65964c3986726908496255","id":"track","datatype":"5907d922436ee50ffde9c549","datatype_tags_pass":null,"files":null},{"datatype_tags":["brain_mask"],"output_on_root":false,"archive":false,"_id":"5d65964c398672dec1496252","id":"brainmask","datatype":"5a281aee2c214c9ba83ce620","datatype_tags_pass":null,"files":null},{"datatype_tags":["optic_radiation"],"output_on_root":false,"archive":true,"_id":"5d65964c39867210f4496251","id":"wmc","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags_pass":null,"files":null}],"github_branch":"optic-radiation-v1.0","github":"brainlife/app-trekker-roi-tracking","name":"Track the Human Optic RAdiation (THORA) - Trekker - V1.0","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3aff62f3d3800f124888"},{"name":"Franco Pestilli","email":null,"_id":"634a3aff62f3d3800f124889"}],"desc":"Brainlife App (wrapper) for dMRI based fiber tracking between ROIs using parallel transport tractography","__v":4788,"desc_override":"This app uses [Trekker](https://dmritrekker.github.io) to Track the Human Optic Radiation.","avatar":"https://raw.githubusercontent.com/brainlife/app-trekker-roi-tracking/optic_radiation/left_or.jpg","create_date":"2020-05-26T03:11:54.042Z","doi":"10.25663/brainlife.app.354","deprecated_by":"5d65964c39867291e349624a","_canedit":true},{"_id":"5ec584961f44640f6b9e2658","projects":[],"admins":["16"],"tags":["tracking"],"removed":false,"stats":{"success_rate":52.65700483091788,"users":8,"runtime_mean":6096105.52,"runtime_std":7555933.599048861,"requested":12206,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3abe62f3d3800f1245c5"}],"examples":2,"groups":17},"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"response":{"type":"input","file_id":"response","input_id":"csd"},"lmax2":{"type":"input","file_id":"lmax2","input_id":"csd"},"lmax4":{"type":"input","file_id":"lmax4","input_id":"csd"},"lmax6":{"type":"input","file_id":"lmax6","input_id":"csd"},"lmax8":{"type":"input","file_id":"lmax8","input_id":"csd"},"lmax10":{"type":"input","file_id":"lmax10","input_id":"csd"},"lmax12":{"type":"input","file_id":"lmax12","input_id":"csd"},"lmax14":{"type":"input","file_id":"lmax14","input_id":"csd"},"rois":{"type":"input","file_id":"rois","input_id":"rois"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"brainmask":{"type":"input","file_id":"mask","input_id":"brainmask"},"wm_mask":{"type":"input","file_id":"mask","input_id":"wm_mask"},"min_length":{"id":"min_length","type":"number","placeholder":"","advanced":false,"desc":"The minimum allowable streamline length to be generated (number)\nexample: 10","default":10,"_order":2,"pid":0.656519684930384},"max_length":{"id":"max_length","type":"number","placeholder":"","advanced":false,"desc":"The maximum allowable streamline length to be generated (number)\nexample: 10","default":200,"_order":3,"pid":0.00986668134039248},"lmax":{"id":"lmax","type":"number","placeholder":"","advanced":false,"desc":"The maxmium spherical harmonic order (lmax) to use. If left empty, this will be identified automatically. (number)","default":8,"_order":4,"pid":0.9589779823599118,"optional":true},"minfodamp":{"id":"minfodamp","type":"string","placeholder":"","advanced":false,"desc":"The minimum FOD amplitude to use as a cutoff (mrtrix3 flag -cutoff) (number)\nex: 0.025","default":"0.025","_order":9,"pid":0.8279625345242767},"roiPair":{"id":"roiPair","type":"string","placeholder":"","advanced":false,"desc":"this field is here in order to allow for the option for only tracking one hemisphere or both hemispheres. If you want to track one hemisphere, enter the exact name of the LGN roi you want to track from (example: '008109'). If both hemispheres are desired, enter both LGN ROI numbers (example: '008109 008209'). Please see your ROI datatype for the exact ROI numbers/names.","default":"","_order":10,"pid":0.8205860466887858,"multiline":true},"stepsize":{"id":"stepsize","type":"string","placeholder":"","advanced":false,"desc":"Step size to use for tracking (number)\nex: 0.25","default":"0.25","_order":10,"pid":0.6755074907065546},"count":{"id":"count","type":"number","placeholder":"","advanced":false,"desc":"total number of streamlines","default":500,"_order":14,"pid":0.027528265139409758},"v1":{"id":"v1","type":"string","placeholder":"","advanced":false,"desc":"this is the exact ROI number/name of the V1 from your ROIs datatype that you would like to track to. Example: '0001'. Please see your ROI datatype for the exact ROI numbers/names.","default":"","_order":14,"pid":0.023974713339910192},"exclusion":{"id":"exclusion","type":"string","placeholder":"","advanced":false,"desc":"these are the names of the exclusion ROIs you would like to use. Follows the same format as roiPair field. For example, if you want to track in both hemispheres, you could enter \"exclusion_L exclusion_R\". \n\nPlease look at your ROIs datatype for the exact name of your exclusion ROI.\n\nIf you do not want to include exclusion ROIs, leave this empty","default":"","_order":18,"pid":0.3315823125398114,"optional":true,"multiline":true},"maxtrials":{"id":"maxtrials","type":"number","placeholder":"","advanced":false,"desc":"Sets the maximum number of attempts to generate streamline from the seed point. Default=1000000.","default":1000000,"_order":18,"pid":0.3507631238985556},"curvatures":{"id":"curvatures","type":"string","placeholder":"","advanced":false,"desc":"maximum angle of curvature (in degrees). can be multiple (i.e. ensemble) or one value. default: 45","default":"45","_order":20,"pid":0.35507361209434785},"single_lmax":{"id":"single_lmax","type":"boolean","placeholder":"","advanced":false,"desc":"Determines whether single lmax (true) or ensemble lmax (false) will be performed","default":true,"_order":23,"pid":0.9090083719644069},"multiple_seed":{"id":"multiple_seed","type":"boolean","placeholder":"","advanced":false,"desc":"If true, this will set the seeds of tractography to be present in both the seeding and termination ROIs. This will also set the tracking to be bidirectional.","default":false,"_order":26,"pid":0.5651604100073384},"act":{"id":"act","type":"boolean","placeholder":"","advanced":false,"desc":"If true, this will use the anatomically constrained tractography framework for tracking. This will include backtracking. \n\nIf false, the white matter mask will be used as a tracking mask. The ROIs will be added to the white matter mask. If the ROIs haven't been resliced to diffusion space, set reslice to true in order to get this to work.","default":true,"_order":27,"pid":0.10852150797054616}},"inputs":[{"id":"dwi","desc":"This is the path's to the DWI image and it's associated bvals and bvecs.","datatype":"58c33c5fe13a50849b25879b","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5db737fe8aeeee68c6f2dc12"},{"id":"csd","desc":"This is the path to the constrained spherical deconvolution (CSD) outputs, including all lmax csd images generated and the response.txt file.","datatype":"5c536bf0f9109beac46adb45","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5db737fe8aeeee0b74f2dc11"},{"id":"rois","desc":"This is the path to the rois directory including both the ROIs listed in the 'roiPair' config","datatype":"5be9ea0315a8683a39a1ebd9","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5db737fe8aeeeea727f2dc10"},{"id":"mask","desc":"This is the path to the five tissue type brain image generated from mrtrix3's 5ttgen function. ","datatype":"5a281aee2c214c9ba83ce620","datatype_tags":["5tt_masks"],"optional":false,"multi":false,"advanced":false,"_id":"5db737fe8aeeee4e46f2dc0f"},{"id":"brainmask","desc":"This is the path to the brain mask of the DWI image. This is optional. If left empty, app will generate brainmask automatically.","datatype":"5a281aee2c214c9ba83ce620","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5db737fe8aeeeedb0af2dc0e"},{"id":"wm_mask","desc":"This is the path to the precomputed white matter mask. if left empty, one will be generated automatically","datatype":"5a281aee2c214c9ba83ce620","datatype_tags":["white_matter"],"optional":true,"multi":false,"advanced":false,"_id":"5eb99fdae8e7ac1a978a9fe2"}],"outputs":[{"id":"track","desc":"This is the output tractogram containing all of the tracks generated","datatype":"5907d922436ee50ffde9c549","datatype_tags":["roi_mrtrix3_ifod2"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5db737fe8aeeee8147f2dc15"},{"id":"wmc","desc":"This is the classification structure that refers to the generated tractogram","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags":["roi_mrtrix3_ifod2"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5db737fe8aeeee899bf2dc13"},{"id":"brainmask","desc":"This is the brainmask output. If input was used, this is just a copy and doesn't need to be archived.","datatype":"5a281aee2c214c9ba83ce620","datatype_tags":["brain_mask"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":false,"_id":"5db737fe8aeeeee32ff2dc14"}],"github_branch":"thora-v1.0","github":"brainlife/app-mrtrix3-roi2roi-tracking","name":"Track the Human Optic RAdiation (THORA) - mrtrix3 iFOD2 (dwi)","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3abf62f3d3800f1245c6"}],"desc":null,"__v":4830,"desc_override":"This app will generate optic radiations using MrTrix3's iFOD2 algorithm with the capability of using the Anatomically Constrained (ACT) framework","create_date":"2020-05-20T19:27:18.258Z","doi":"10.25663/brainlife.app.347","_canedit":true},{"_id":"5ec584b51f446416ca9e26fe","projects":[],"admins":["16"],"tags":["tracking"],"removed":false,"stats":{"success_rate":52.65700483091788,"users":8,"runtime_mean":6096105.52,"runtime_std":7555933.599048861,"requested":12206,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3ac762f3d3800f1245c8"}],"examples":0,"groups":17},"config":{"dtiinit":{"type":"input","file_id":"output","input_id":"dtiinit"},"response":{"type":"input","file_id":"response","input_id":"csd"},"lmax2":{"type":"input","file_id":"lmax2","input_id":"csd"},"lmax4":{"type":"input","file_id":"lmax4","input_id":"csd"},"lmax6":{"type":"input","file_id":"lmax6","input_id":"csd"},"lmax8":{"type":"input","file_id":"lmax8","input_id":"csd"},"lmax10":{"type":"input","file_id":"lmax10","input_id":"csd"},"lmax12":{"type":"input","file_id":"lmax12","input_id":"csd"},"lmax14":{"type":"input","file_id":"lmax14","input_id":"csd"},"rois":{"type":"input","file_id":"rois","input_id":"rois"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"brainmask":{"type":"input","file_id":"mask","input_id":"brainmask"},"wm_mask":{"type":"input","file_id":"mask","input_id":"wm_mask"},"min_length":{"id":"min_length","type":"number","placeholder":"","advanced":false,"desc":"The minimum allowable streamline length to be generated (number)\nexample: 10","default":10,"_order":2,"pid":0.1313131937406291},"max_length":{"id":"max_length","type":"number","placeholder":"","advanced":false,"desc":"The maximum allowable streamline length to be generated (number)\nexample: 10","default":200,"_order":3,"pid":0.8026779553609571},"lmax":{"id":"lmax","type":"number","placeholder":"","advanced":false,"desc":"The maxmium spherical harmonic order (lmax) to use. If left empty, this will be identified automatically. (number)","default":8,"_order":4,"pid":0.03925751472207528,"optional":true},"minfodamp":{"id":"minfodamp","type":"string","placeholder":"","advanced":false,"desc":"The minimum FOD amplitude to use as a cutoff (mrtrix3 flag -cutoff) (number)\nex: 0.025","default":"0.025","_order":9,"pid":0.23769175804355958},"roiPair":{"id":"roiPair","type":"string","placeholder":"","advanced":false,"desc":"this field is here in order to allow for the option for only tracking one hemisphere or both hemispheres. If you want to track one hemisphere, enter the exact name of the LGN roi you want to track from (example: '008109'). If both hemispheres are desired, enter both LGN ROI numbers (example: '008109 008209'). Please see your ROI datatype for the exact ROI numbers/names.","default":"","_order":10,"pid":0.20852044925220992,"multiline":true},"stepsize":{"id":"stepsize","type":"string","placeholder":"","advanced":false,"desc":"Step size to use for tracking (number)\nex: 0.25","default":"0.25","_order":10,"pid":0.27615409363268184},"v1":{"id":"v1","type":"string","placeholder":"","advanced":false,"desc":"this is the exact ROI number/name of the V1 from your ROIs datatype that you would like to track to. Example: '0001'. Please see your ROI datatype for the exact ROI numbers/names.","default":"","_order":14,"pid":0.9560893210908472},"count":{"id":"count","type":"number","placeholder":"","advanced":false,"desc":"total number of streamlines","default":500,"_order":16,"pid":0.47004141113575093},"exclusion":{"id":"exclusion","type":"string","placeholder":"","advanced":false,"desc":"these are the names of the exclusion ROIs you would like to use. Follows the same format as roiPair field. For example, if you want to track in both hemispheres, you could enter \"exclusion_L exclusion_R\". \n\nPlease look at your ROIs datatype for the exact name of your exclusion ROI.\n\nIf you do not want to include exclusion ROIs, leave this empty","default":"","_order":16,"pid":0.6596254601582505,"optional":true,"multiline":true},"maxtrials":{"id":"maxtrials","type":"number","placeholder":"","advanced":false,"desc":"Sets the maximum number of attempts to generate streamline from the seed point. Default=1000000.","default":1000000,"_order":18,"pid":0.545145792434258},"curvatures":{"id":"curvatures","type":"string","placeholder":"","advanced":false,"desc":"maximum angle of curvature (in degrees). can be multiple (i.e. ensemble) or one value. default: 45","default":"45","_order":20,"pid":0.4202919715357183},"single_lmax":{"id":"single_lmax","type":"boolean","placeholder":"","advanced":false,"desc":"Determines whether single lmax (true) or ensemble lmax (false) will be performed","default":true,"_order":23,"pid":0.9039319788544986},"multiple_seed":{"id":"multiple_seed","type":"boolean","placeholder":"","advanced":false,"desc":"If true, this will set the seeds of tractography to be present in both the seeding and termination ROIs. This will also set the tracking to be bidirectional.","default":false,"_order":26,"pid":0.4169798969799152},"act":{"id":"act","type":"boolean","placeholder":"","advanced":false,"desc":"If true, this will use the anatomically constrained tractography framework for tracking. This will include backtracking. \n\nIf false, the white matter mask will be used as a tracking mask. The ROIs will be added to the white matter mask. If the ROIs haven't been resliced to diffusion space, set reslice to true in order to get this to work.","default":true,"_order":27,"pid":0.9466190931903056}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ec584b51f44648bc49e26ff","id":"dtiinit","datatype":"58cb234be13a50849b25882f"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5db737fe8aeeee0b74f2dc11","id":"csd","datatype":"5c536bf0f9109beac46adb45","desc":"This is the path to the constrained spherical deconvolution (CSD) outputs, including all lmax csd images generated and the response.txt file."},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5db737fe8aeeeea727f2dc10","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9","desc":"This is the path to the rois directory including both the ROIs listed in the 'roiPair' config"},{"datatype_tags":["5tt_masks"],"optional":false,"multi":false,"advanced":false,"_id":"5db737fe8aeeee4e46f2dc0f","id":"mask","datatype":"5a281aee2c214c9ba83ce620","desc":"This is the path to the five tissue type brain image generated from mrtrix3's 5ttgen function. "},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5db737fe8aeeeedb0af2dc0e","id":"brainmask","datatype":"5a281aee2c214c9ba83ce620","desc":"This is the path to the brain mask of the DWI image. This is optional. If left empty, app will generate brainmask automatically."},{"datatype_tags":["white_matter"],"optional":true,"multi":false,"advanced":false,"_id":"5eb99fdae8e7ac1a978a9fe2","id":"wm_mask","datatype":"5a281aee2c214c9ba83ce620","desc":"This is the path to the precomputed white matter mask. if left empty, one will be generated automatically"}],"outputs":[{"datatype_tags":["roi_mrtrix3_ifod2"],"output_on_root":false,"archive":true,"_id":"5db737fe8aeeee8147f2dc15","id":"track","datatype":"5907d922436ee50ffde9c549","datatype_tags_pass":null,"files":null,"desc":"This is the output tractogram containing all of the tracks generated"},{"datatype_tags":["roi_mrtrix3_ifod2"],"output_on_root":false,"archive":true,"_id":"5db737fe8aeeee899bf2dc13","id":"wmc","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags_pass":null,"files":null,"desc":"This is the classification structure that refers to the generated tractogram"},{"datatype_tags":["brain_mask"],"output_on_root":false,"archive":false,"_id":"5db737fe8aeeeee32ff2dc14","id":"brainmask","datatype":"5a281aee2c214c9ba83ce620","datatype_tags_pass":null,"files":null,"desc":"This is the brainmask output. If input was used, this is just a copy and doesn't need to be archived."}],"github_branch":"thora-v1.0","github":"brainlife/app-mrtrix3-roi2roi-tracking","name":"Track the Human Optic RAdiation - mrtrix3 iFOD2 (dtiinit)","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3ac862f3d3800f1245c9"}],"desc":null,"__v":4828,"desc_override":"This app will generate optic radiations using MrTrix3's iFOD2 algorithm with the capability of using the Anatomically Constrained (ACT) framework","create_date":"2020-05-20T19:27:49.280Z","doi":"10.25663/brainlife.app.348","deprecated_by":"5ec584961f44640f6b9e2658","_canedit":true},{"_id":"5ecca2f11f446435999ed9f9","projects":[],"admins":["16","185","41","1"],"tags":["diffusion-mri","mri","tracking","tractography","vision"],"removed":false,"stats":{"gitinfo":{"desc":"Brainlife App (wrapper) for dMRI based fiber tracking between ROIs using parallel transport tractography","tags":["diffusion-mri","mri","tracking","tractography","vision"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"success_rate":44.38652766639935,"users":14,"runtime_mean":9394121.4,"runtime_std":8236894.053758132,"requested":3594,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3b1c62f3d3800f124b11"}],"examples":0,"groups":24},"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"lmax2":{"type":"input","file_id":"lmax2","input_id":"csd"},"lmax4":{"type":"input","file_id":"lmax4","input_id":"csd"},"lmax6":{"type":"input","file_id":"lmax6","input_id":"csd"},"lmax8":{"type":"input","file_id":"lmax8","input_id":"csd"},"lmax10":{"type":"input","file_id":"lmax10","input_id":"csd"},"lmax12":{"type":"input","file_id":"lmax12","input_id":"csd"},"lmax14":{"type":"input","file_id":"lmax14","input_id":"csd"},"rois":{"type":"input","file_id":"rois","input_id":"rois"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"brainmask":{"type":"input","file_id":"mask","input_id":"brainmask"},"min_length":{"id":"min_length","type":"number","placeholder":"","advanced":false,"desc":"min length of streamlines","default":10,"_order":2,"pid":0.5977008176239038},"max_length":{"id":"max_length","type":"number","placeholder":"","advanced":false,"desc":"max length of streamlines","default":200,"_order":3,"pid":0.6188947996082532},"lmax":{"id":"lmax","type":"number","placeholder":"","advanced":false,"desc":"lmax","default":8,"_order":4,"pid":0.45257418822243856},"roiPair":{"id":"roiPair","type":"string","placeholder":"","advanced":false,"desc":"This field is here for whether or not you want to track both hemispheres or one hemisphere at a time. If just one hemisphere is desired, enter the exact ROI number or name from the rois datatype for the lgn of choice (example: '008109'). If both are desired, enter both separated by a space (example: '008109 008209'). Please see ROI datatype for exact name of each.","default":"","_order":5,"pid":0.7013955555064169},"oc":{"id":"oc","type":"string","placeholder":"","advanced":false,"desc":"this field is the exact ROI name or number from the ROI datatype for the optic chiasm. Example: '085'. Please see ROI datatype for exact name of each.","default":"","_order":6,"pid":0.14974747877743932},"count":{"id":"count","type":"number","placeholder":"","advanced":false,"desc":"total number of streamlines","default":500,"_order":9,"pid":0.09022957215065164},"curvatures":{"id":"curvatures","type":"string","placeholder":"","advanced":true,"desc":"minimum radius of curvature","default":"default","_order":14,"pid":0.3269118531551858},"stepsize":{"id":"stepsize","type":"string","placeholder":"","advanced":true,"desc":"step size","default":"default","_order":15,"pid":0.4551238045895323},"single_lmax":{"id":"single_lmax","type":"boolean","placeholder":"","advanced":false,"desc":"if want to run on only one lmax, set to true. to ensemble, set to false","default":true,"_order":18,"pid":0.8083435193930977},"minfodamp":{"id":"minfodamp","type":"string","placeholder":"","advanced":true,"desc":"minimum FOD amplitude","default":"default","_order":19,"pid":0.172916720696773},"probecount":{"id":"probecount","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":20,"pid":0.94308806386395},"proberadius":{"id":"proberadius","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":21,"pid":0.8182500658199794},"probequality":{"id":"probequality","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":22,"pid":0.3678734890309767},"probelength":{"id":"probelength","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":23,"pid":0.8829976829443318},"bestAtInit":{"id":"bestAtInit","type":"boolean","placeholder":"","advanced":true,"desc":"","default":false,"_order":24,"pid":0.9107858338571377},"maxsampling":{"id":"maxsampling","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":25,"pid":0.3329042634510655},"maxtrials":{"id":"maxtrials","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":26,"pid":0.36079929783134745}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d65964c398672b124496250","id":"dwi","datatype":"58c33c5fe13a50849b25879b"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d65964c398672b57f49624e","id":"csd","datatype":"5c536bf0f9109beac46adb45"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d65964c3986725b9b49624d","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9"},{"datatype_tags":["5tt_masks"],"optional":false,"multi":false,"advanced":false,"_id":"5d65964c3986722b1e49624c","id":"mask","datatype":"5a281aee2c214c9ba83ce620","desc":"5-tissue type mask (needed for csd fitting)"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5d65964c398672012849624b","id":"brainmask","datatype":"5a281aee2c214c9ba83ce620","desc":"whole-brain mask"}],"outputs":[{"datatype_tags":["optic_tract","trekker"],"output_on_root":false,"archive":true,"_id":"5d65964c3986726908496255","id":"track","datatype":"5907d922436ee50ffde9c549","datatype_tags_pass":null,"files":null},{"datatype_tags":["brain_mask"],"output_on_root":false,"archive":false,"_id":"5d65964c398672dec1496252","id":"brainmask","datatype":"5a281aee2c214c9ba83ce620","datatype_tags_pass":null,"files":null},{"datatype_tags":["optic_tract","trekker"],"output_on_root":false,"archive":true,"_id":"5d65964c39867210f4496251","id":"wmc","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags_pass":null,"files":null},{"datatype_tags":["optic_tract_derivatives"],"output_on_root":false,"archive":true,"_id":"5eccaa291f4464a22e9ee3c8","id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null}],"github_branch":"optic-tract-true-v1.2","github":"brainlife/app-trekker-roi-tracking","name":"Track the Human Optic TRAct (THOTRA) - Trekker","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3b1c62f3d3800f124b12"},{"name":"Franco Pestilli","email":null,"_id":"634a3b1c62f3d3800f124b13"}],"desc":"Brainlife App (wrapper) for dMRI based fiber tracking between ROIs using parallel transport tractography","__v":4787,"desc_override":"This app uses [Trekker](https://dmritrekker.github.io) to Track the Human Optic Tract.","avatar":"https://raw.githubusercontent.com/brainlife/app-trekker-roi-tracking/optic_radiation/left_or.jpg","create_date":"2020-05-26T05:02:41.605Z","doi":"10.25663/brainlife.app.357","_canedit":true},{"_id":"5ecca4a01f4464207d9edf84","projects":[],"admins":["16","185","41","1"],"tags":["diffusion-mri","mri","tracking","tractography","vision"],"removed":false,"stats":{"gitinfo":{"desc":"Brainlife App (wrapper) for dMRI based fiber tracking between ROIs using parallel transport tractography","tags":["diffusion-mri","mri","tracking","tractography","vision"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"success_rate":44.38652766639935,"users":14,"runtime_mean":9394121.4,"runtime_std":8236894.053758132,"requested":3594,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3b2e62f3d3800f124b19"}],"examples":0,"groups":24},"config":{"dtiinit":{"type":"input","file_id":"output","input_id":"dtiinit"},"lmax2":{"type":"input","file_id":"lmax2","input_id":"csd"},"lmax4":{"type":"input","file_id":"lmax4","input_id":"csd"},"lmax6":{"type":"input","file_id":"lmax6","input_id":"csd"},"lmax8":{"type":"input","file_id":"lmax8","input_id":"csd"},"lmax10":{"type":"input","file_id":"lmax10","input_id":"csd"},"lmax12":{"type":"input","file_id":"lmax12","input_id":"csd"},"lmax14":{"type":"input","file_id":"lmax14","input_id":"csd"},"rois":{"type":"input","file_id":"rois","input_id":"rois"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"brainmask":{"type":"input","file_id":"mask","input_id":"brainmask"},"min_length":{"id":"min_length","type":"number","placeholder":"","advanced":false,"desc":"min length of streamlines","default":10,"_order":2,"pid":0.4640533370251614},"max_length":{"id":"max_length","type":"number","placeholder":"","advanced":false,"desc":"max length of streamlines","default":200,"_order":3,"pid":0.7426754764009673},"lmax":{"id":"lmax","type":"number","placeholder":"","advanced":false,"desc":"lmax","default":8,"_order":4,"pid":0.9198790954808369},"roiPair":{"id":"roiPair","type":"string","placeholder":"","advanced":false,"desc":"This field is here for whether or not you want to track both hemispheres or one hemisphere at a time. If just one hemisphere is desired, enter the exact ROI number or name from the rois datatype for the lgn of choice (example: '008109'). If both are desired, enter both separated by a space (example: '008109 008209'). Please see ROI datatype for exact name of each.","default":"","_order":5,"pid":0.24253325697699046},"oc":{"id":"oc","type":"string","placeholder":"","advanced":false,"desc":"this field is the exact ROI name or number from the ROI datatype for the optic chiasm. Example: '085'. Please see ROI datatype for exact name of each.","default":"","_order":6,"pid":0.6890827887915156},"count":{"id":"count","type":"number","placeholder":"","advanced":false,"desc":"total number of streamlines","default":500,"_order":9,"pid":0.6335277764004936},"curvatures":{"id":"curvatures","type":"string","placeholder":"","advanced":true,"desc":"minimum radius of curvature","default":"default","_order":14,"pid":0.8150496198473156},"stepsize":{"id":"stepsize","type":"string","placeholder":"","advanced":true,"desc":"step size","default":"default","_order":15,"pid":0.298800855394751},"single_lmax":{"id":"single_lmax","type":"boolean","placeholder":"","advanced":false,"desc":"if want to run on only one lmax, set to true. to ensemble, set to false","default":true,"_order":18,"pid":0.7604208432204242},"minfodamp":{"id":"minfodamp","type":"string","placeholder":"","advanced":true,"desc":"minimum FOD amplitude","default":"default","_order":19,"pid":0.7662498898252841},"probecount":{"id":"probecount","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":20,"pid":0.6685620162841237},"proberadius":{"id":"proberadius","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":21,"pid":0.08339899514891091},"probequality":{"id":"probequality","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":22,"pid":0.21341580565325202},"probelength":{"id":"probelength","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":23,"pid":0.02179529072549502},"bestAtInit":{"id":"bestAtInit","type":"boolean","placeholder":"","advanced":true,"desc":"","default":false,"_order":24,"pid":0.3584995758441356},"maxsampling":{"id":"maxsampling","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":25,"pid":0.9479690403622312},"maxtrials":{"id":"maxtrials","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":26,"pid":0.8239886144147586}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ecca4a01f446406f99edf85","id":"dtiinit","datatype":"58cb234be13a50849b25882f"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d65964c398672b57f49624e","id":"csd","datatype":"5c536bf0f9109beac46adb45"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d65964c3986725b9b49624d","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9"},{"datatype_tags":["5tt_masks"],"optional":false,"multi":false,"advanced":false,"_id":"5d65964c3986722b1e49624c","id":"mask","datatype":"5a281aee2c214c9ba83ce620","desc":"5-tissue type mask (needed for csd fitting)"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5d65964c398672012849624b","id":"brainmask","datatype":"5a281aee2c214c9ba83ce620","desc":"whole-brain mask"}],"outputs":[{"datatype_tags":["optic_tract","trekker"],"output_on_root":false,"archive":true,"_id":"5d65964c3986726908496255","id":"track","datatype":"5907d922436ee50ffde9c549","datatype_tags_pass":null,"files":null},{"datatype_tags":["brain_mask"],"output_on_root":false,"archive":false,"_id":"5d65964c398672dec1496252","id":"brainmask","datatype":"5a281aee2c214c9ba83ce620","datatype_tags_pass":null,"files":null},{"datatype_tags":["optic_tract","trekker"],"output_on_root":false,"archive":true,"_id":"5d65964c39867210f4496251","id":"wmc","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags_pass":null,"files":null},{"datatype_tags":["optic_tract_derivatives"],"output_on_root":false,"archive":true,"_id":"5eccac451f4464767f9ee46d","id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null}],"github_branch":"optic-tract-v1.1","github":"brainlife/app-trekker-roi-tracking","name":"Track the Human Optic TRAct (THOTRA) - Trekker (dtiinit)","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3b2e62f3d3800f124b1a"},{"name":"Franco Pestilli","email":null,"_id":"634a3b2e62f3d3800f124b1b"}],"desc":"Brainlife App (wrapper) for dMRI based fiber tracking between ROIs using parallel transport tractography","__v":4786,"desc_override":"This app uses [Trekker](https://dmritrekker.github.io) to Track the Human Optic Tract.","avatar":"https://raw.githubusercontent.com/brainlife/app-trekker-roi-tracking/optic_radiation/left_or.jpg","create_date":"2020-05-26T05:09:52.986Z","doi":"10.25663/brainlife.app.360","deprecated_by":"5ecca2f11f446435999ed9f9","_canedit":true},{"_id":"5ecc63491f446406c39ecbfd","projects":[],"admins":["16","185","41","1"],"tags":["diffusion-mri","mri","tracking","tractography","vision"],"removed":false,"stats":{"gitinfo":{"desc":"Brainlife App (wrapper) for dMRI based fiber tracking between ROIs using parallel transport tractography","tags":["diffusion-mri","mri","tracking","tractography","vision"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"success_rate":44.38652766639935,"users":14,"runtime_mean":9394121.4,"runtime_std":8236894.053758132,"requested":3594,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3af662f3d3800f124883"}],"examples":0,"groups":24},"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"lmax2":{"type":"input","file_id":"lmax2","input_id":"csd"},"lmax4":{"type":"input","file_id":"lmax4","input_id":"csd"},"lmax6":{"type":"input","file_id":"lmax6","input_id":"csd"},"lmax8":{"type":"input","file_id":"lmax8","input_id":"csd"},"lmax10":{"type":"input","file_id":"lmax10","input_id":"csd"},"lmax12":{"type":"input","file_id":"lmax12","input_id":"csd"},"lmax14":{"type":"input","file_id":"lmax14","input_id":"csd"},"rois":{"type":"input","file_id":"rois","input_id":"rois"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"brainmask":{"type":"input","file_id":"mask","input_id":"brainmask"},"min_length":{"id":"min_length","type":"number","placeholder":"","advanced":false,"desc":"min length of streamlines","default":10,"_order":2,"pid":0.4272871044115185},"max_length":{"id":"max_length","type":"number","placeholder":"","advanced":false,"desc":"max length of streamlines","default":200,"_order":3,"pid":0.7583168936074467},"lmax":{"id":"lmax","type":"number","placeholder":"","advanced":false,"desc":"lmax","default":8,"_order":4,"pid":0.12055286095600093},"roiPair":{"id":"roiPair","type":"string","placeholder":"","advanced":false,"desc":"This field is here for whether or not you want to track both hemispheres or one hemisphere at a time. If just one hemisphere is desired, enter the exact ROI number or name from the rois datatype for the lgn of choice (example: '008109'). If both are desired, enter both separated by a space (example: '008109 008209'). Please see ROI datatype for exact name of each.","default":"","_order":5,"pid":0.6890814810072468},"oc":{"id":"oc","type":"string","placeholder":"","advanced":false,"desc":"this field is the exact ROI name or number from the ROI datatype for the optic chiasm. Example: '085'. Please see ROI datatype for exact name of each.","default":"","_order":6,"pid":0.4310582582305307},"count":{"id":"count","type":"number","placeholder":"","advanced":false,"desc":"total number of streamlines","default":500,"_order":9,"pid":0.2834902511327715},"probelength":{"id":"probelength","type":"number","placeholder":"","advanced":true,"desc":"Trekker: probe length\nDefault = 0.25","default":0.25,"_order":10,"pid":0.6341723820988308},"probequality":{"id":"probequality","type":"number","placeholder":"","advanced":true,"desc":"Trekker: Probe quality\nDefault = 4","default":4,"_order":11,"pid":0.3500674605997889},"proberadius":{"id":"proberadius","type":"number","placeholder":"","advanced":true,"desc":"Trekker: probe radius\nDefault =0","default":0,"_order":12,"pid":0.2700380975844672},"probecount":{"id":"probecount","type":"number","placeholder":"","advanced":true,"desc":"Trekker: probe count\nDefault = 1","default":1,"_order":13,"pid":0.5138111855887744},"curvatures":{"id":"curvatures","type":"string","placeholder":"","advanced":false,"desc":"minimum radius of curvature","default":"0.5","_order":14,"pid":0.4057398594284538},"stepsize":{"id":"stepsize","type":"string","placeholder":"","advanced":false,"desc":"step size","default":"0.05","_order":15,"pid":0.5428578176933496},"maxtrials":{"id":"maxtrials","type":"number","placeholder":"","advanced":false,"desc":"maximum number of trials","default":1000000,"_order":16,"pid":0.37787420190943655},"maxsampling":{"id":"maxsampling","type":"number","placeholder":"","advanced":false,"desc":"max sampling per seed","default":10000,"_order":17,"pid":0.5900515901322194},"single_lmax":{"id":"single_lmax","type":"boolean","placeholder":"","advanced":false,"desc":"if want to run on only one lmax, set to true. to ensemble, set to false","default":true,"_order":18,"pid":0.596412710436601},"minfodamp":{"id":"minfodamp","type":"string","placeholder":"","advanced":false,"desc":"minimum FOD amplitude","default":"0.025","_order":19,"pid":0.908897984333749}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d65964c398672b124496250","id":"dwi","datatype":"58c33c5fe13a50849b25879b"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d65964c398672b57f49624e","id":"csd","datatype":"5c536bf0f9109beac46adb45"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d65964c3986725b9b49624d","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9"},{"datatype_tags":["5tt_masks"],"optional":false,"multi":false,"advanced":false,"_id":"5d65964c3986722b1e49624c","id":"mask","datatype":"5a281aee2c214c9ba83ce620","desc":"5-tissue type mask (needed for csd fitting)"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5d65964c398672012849624b","id":"brainmask","datatype":"5a281aee2c214c9ba83ce620","desc":"whole-brain mask"}],"outputs":[{"datatype_tags":["optic_tract","trekker"],"output_on_root":false,"archive":true,"_id":"5d65964c3986726908496255","id":"track","datatype":"5907d922436ee50ffde9c549","datatype_tags_pass":null,"files":null},{"datatype_tags":["brain_mask"],"output_on_root":false,"archive":false,"_id":"5d65964c398672dec1496252","id":"brainmask","datatype":"5a281aee2c214c9ba83ce620","datatype_tags_pass":null,"files":null},{"datatype_tags":["optic_tract","trekker"],"output_on_root":false,"archive":true,"_id":"5d65964c39867210f4496251","id":"wmc","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags_pass":null,"files":null}],"github_branch":"optic-tract-true-v1.0","github":"brainlife/app-trekker-roi-tracking","name":"Track the Human Optic TRAct (THOTRA) - Trekker - v1.0","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3af662f3d3800f124884"},{"name":"Franco Pestilli","email":null,"_id":"634a3af662f3d3800f124885"}],"desc":"Brainlife App (wrapper) for dMRI based fiber tracking between ROIs using parallel transport tractography","__v":4791,"desc_override":"This app uses [Trekker](https://dmritrekker.github.io) to Track the Human Optic Tract.","avatar":"https://raw.githubusercontent.com/brainlife/app-trekker-roi-tracking/optic_radiation/left_or.jpg","create_date":"2020-05-26T00:31:05.984Z","doi":"10.25663/brainlife.app.353","deprecated_by":"5ecca2f11f446435999ed9f9","_canedit":true},{"_id":"5f51279442c17258f764c7ee","projects":[],"admins":["16"],"tags":["tracking"],"removed":false,"stats":{"success_rate":52.65700483091788,"users":8,"runtime_mean":6096105.52,"runtime_std":7555933.599048861,"requested":12206,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3cd262f3d3800f129911"}],"examples":1,"groups":17},"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"response":{"type":"input","file_id":"response","input_id":"csd"},"lmax2":{"type":"input","file_id":"lmax2","input_id":"csd"},"lmax4":{"type":"input","file_id":"lmax4","input_id":"csd"},"lmax6":{"type":"input","file_id":"lmax6","input_id":"csd"},"lmax8":{"type":"input","file_id":"lmax8","input_id":"csd"},"lmax10":{"type":"input","file_id":"lmax10","input_id":"csd"},"lmax12":{"type":"input","file_id":"lmax12","input_id":"csd"},"lmax14":{"type":"input","file_id":"lmax14","input_id":"csd"},"rois":{"type":"input","file_id":"rois","input_id":"rois"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"brainmask":{"type":"input","file_id":"mask","input_id":"brainmask"},"wm_mask":{"type":"input","file_id":"mask","input_id":"wm_mask"},"min_length":{"id":"min_length","type":"number","placeholder":"","advanced":false,"desc":"The minimum allowable streamline length to be generated (number)\nexample: 10","default":10,"_order":2,"pid":0.18490660966685923},"max_length":{"id":"max_length","type":"number","placeholder":"","advanced":false,"desc":"The maximum allowable streamline length to be generated (number)\nexample: 10","default":200,"_order":3,"pid":0.45342437145637415},"lmax":{"id":"lmax","type":"number","placeholder":"","advanced":false,"desc":"The maxmium spherical harmonic order (lmax) to use. If left empty, this will be identified automatically. (number)","default":8,"_order":4,"pid":0.8931389748494813,"optional":true},"minfodamp":{"id":"minfodamp","type":"string","placeholder":"","advanced":false,"desc":"The minimum FOD amplitude to use as a cutoff (mrtrix3 flag -cutoff) (number)\nex: 0.025","default":"0.025","_order":9,"pid":0.7185278121731342},"roiPair":{"id":"roiPair","type":"string","placeholder":"","advanced":false,"desc":"this field is here in order to allow for the option for only tracking one hemisphere or both hemispheres. If you want to track one hemisphere, enter the exact name of the LGN roi you want to track from (example: '008109'). If both hemispheres are desired, enter both LGN ROI numbers (example: '008109 008209'). Please see your ROI datatype for the exact ROI numbers/names.","default":"","_order":10,"pid":0.044861513469935055,"multiline":true},"stepsize":{"id":"stepsize","type":"string","placeholder":"","advanced":false,"desc":"Step size to use for tracking (number)\nex: 0.25","default":"0.25","_order":10,"pid":0.10187939240378885},"count":{"id":"count","type":"number","placeholder":"","advanced":false,"desc":"total number of streamlines","default":500,"_order":14,"pid":0.12088507684936856},"oc":{"id":"oc","type":"string","placeholder":"","advanced":false,"desc":"this is the exact ROI number/name of the optic chiasm from your ROIs datatype that you would like to track to. Example: '085'. Please see your ROI datatype for the exact ROI numbers/names.","default":"","_order":14,"pid":0.5639062529461285},"maxtrials":{"id":"maxtrials","type":"number","placeholder":"","advanced":false,"desc":"Sets the maximum number of attempts to generate streamline from the seed point. Default=1000000.","default":1000000,"_order":18,"pid":0.4474709015981846},"curvatures":{"id":"curvatures","type":"string","placeholder":"","advanced":false,"desc":"maximum angle of curvature (in degrees). can be multiple (i.e. ensemble) or one value. default: 45","default":"15","_order":20,"pid":0.0400389909062262},"single_lmax":{"id":"single_lmax","type":"boolean","placeholder":"","advanced":false,"desc":"Determines whether single lmax (true) or ensemble lmax (false) will be performed","default":true,"_order":23,"pid":0.6221191771064882},"multiple_seed":{"id":"multiple_seed","type":"boolean","placeholder":"","advanced":false,"desc":"If true, this will set the seeds of tractography to be present in both the seeding and termination ROIs. This will also set the tracking to be bidirectional.","default":false,"_order":26,"pid":0.39301955042249737},"act":{"id":"act","type":"boolean","placeholder":"","advanced":false,"desc":"If true, this will use the anatomically constrained tractography framework for tracking. This will include backtracking. \n\nIf false, the white matter mask will be used as a tracking mask. The ROIs will be added to the white matter mask. If the ROIs haven't been resliced to diffusion space, set reslice to true in order to get this to work.","default":true,"_order":27,"pid":0.9952526116235547},"tracking_type":{"id":"tracking_type","type":"enum","placeholder":"","advanced":false,"desc":"","default":"","_order":28,"pid":0.7487684665157608,"options":[{"desc":"IFOD2 probabilistic tracking","label":"ifod2","value":"ifod2"},{"desc":"SD_STREAM deterministic tracking","label":"deterministic","value":"deterministic"}]}},"inputs":[{"id":"dwi","desc":"This is the path's to the DWI image and it's associated bvals and bvecs.","datatype":"58c33c5fe13a50849b25879b","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5db737fe8aeeee68c6f2dc12"},{"id":"csd","desc":"This is the path to the constrained spherical deconvolution (CSD) outputs, including all lmax csd images generated and the response.txt file.","datatype":"5c536bf0f9109beac46adb45","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5db737fe8aeeee0b74f2dc11"},{"id":"rois","desc":"This is the path to the rois directory including both the ROIs listed in the 'roiPair' config","datatype":"5be9ea0315a8683a39a1ebd9","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5db737fe8aeeeea727f2dc10"},{"id":"mask","desc":"This is the path to the five tissue type brain image generated from mrtrix3's 5ttgen function. ","datatype":"5a281aee2c214c9ba83ce620","datatype_tags":["5tt_masks"],"optional":false,"multi":false,"advanced":false,"_id":"5db737fe8aeeee4e46f2dc0f"},{"id":"brainmask","desc":"This is the path to the brain mask of the DWI image. This is optional. If left empty, app will generate brainmask automatically.","datatype":"5a281aee2c214c9ba83ce620","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5db737fe8aeeeedb0af2dc0e"},{"id":"wm_mask","desc":"This is the path to the precomputed white matter mask. if left empty, one will be generated automatically","datatype":"5a281aee2c214c9ba83ce620","datatype_tags":["white_matter"],"optional":true,"multi":false,"advanced":false,"_id":"5eb99fdae8e7ac1a978a9fe2"}],"outputs":[{"id":"track","desc":"This is the output tractogram containing all of the tracks generated","datatype":"5907d922436ee50ffde9c549","datatype_tags":["roi_mrtrix3_ifod2"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5db737fe8aeeee8147f2dc15"},{"id":"wmc","desc":"This is the classification structure that refers to the generated tractogram","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags":["roi_mrtrix3_ifod2"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5db737fe8aeeee899bf2dc13"},{"id":"brainmask","desc":"This is the brainmask output. If input was used, this is just a copy and doesn't need to be archived.","datatype":"5a281aee2c214c9ba83ce620","datatype_tags":["brain_mask"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":false,"_id":"5db737fe8aeeeee32ff2dc14"}],"github_branch":"optic-tract-v1.1","github":"brainlife/app-mrtrix3-roi2roi-tracking","name":"Track the Human Optic TRAct (THOTRA) - mrtrix3 (dwi)","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3cd262f3d3800f129912"}],"desc":null,"__v":4152,"desc_override":"This app will generate optic tracts using MrTrix3 with the capability of using the Anatomically Constrained (ACT) framework","create_date":"2020-09-03T17:27:48.302Z","doi":"10.25663/brainlife.app.407","_canedit":true},{"_id":"5f5126cf42c172061a64c5c0","projects":[],"admins":["16"],"tags":["tracking"],"removed":false,"stats":{"success_rate":52.65700483091788,"users":8,"runtime_mean":6096105.52,"runtime_std":7555933.599048861,"requested":12206,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3cc962f3d3800f1298e6"}],"examples":0,"groups":17},"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"response":{"type":"input","file_id":"response","input_id":"csd"},"lmax2":{"type":"input","file_id":"lmax2","input_id":"csd"},"lmax4":{"type":"input","file_id":"lmax4","input_id":"csd"},"lmax6":{"type":"input","file_id":"lmax6","input_id":"csd"},"lmax8":{"type":"input","file_id":"lmax8","input_id":"csd"},"lmax10":{"type":"input","file_id":"lmax10","input_id":"csd"},"lmax12":{"type":"input","file_id":"lmax12","input_id":"csd"},"lmax14":{"type":"input","file_id":"lmax14","input_id":"csd"},"rois":{"type":"input","file_id":"rois","input_id":"rois"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"brainmask":{"type":"input","file_id":"mask","input_id":"brainmask"},"wm_mask":{"type":"input","file_id":"mask","input_id":"wm_mask"},"min_length":{"id":"min_length","type":"number","placeholder":"","advanced":false,"desc":"The minimum allowable streamline length to be generated (number)\nexample: 10","default":10,"_order":2,"pid":0.5514246579009701},"max_length":{"id":"max_length","type":"number","placeholder":"","advanced":false,"desc":"The maximum allowable streamline length to be generated (number)\nexample: 10","default":200,"_order":3,"pid":0.08067281726929587},"lmax":{"id":"lmax","type":"number","placeholder":"","advanced":false,"desc":"The maxmium spherical harmonic order (lmax) to use. If left empty, this will be identified automatically. (number)","default":8,"_order":4,"pid":0.15743657283266854,"optional":true},"minfodamp":{"id":"minfodamp","type":"string","placeholder":"","advanced":false,"desc":"The minimum FOD amplitude to use as a cutoff (mrtrix3 flag -cutoff) (number)\nex: 0.025","default":"0.025","_order":9,"pid":0.8845074020868529},"roiPair":{"id":"roiPair","type":"string","placeholder":"","advanced":false,"desc":"this field is here in order to allow for the option for only tracking one hemisphere or both hemispheres. If you want to track one hemisphere, enter the exact name of the LGN roi you want to track from (example: '008109'). If both hemispheres are desired, enter both LGN ROI numbers (example: '008109 008209'). Please see your ROI datatype for the exact ROI numbers/names.","default":"","_order":10,"pid":0.9423294344396078,"multiline":true},"stepsize":{"id":"stepsize","type":"string","placeholder":"","advanced":false,"desc":"Step size to use for tracking (number)\nex: 0.25","default":"0.25","_order":10,"pid":0.1569672683503156},"count":{"id":"count","type":"number","placeholder":"","advanced":false,"desc":"total number of streamlines","default":500,"_order":14,"pid":0.9343761373308976},"oc":{"id":"oc","type":"string","placeholder":"","advanced":false,"desc":"this is the exact ROI number/name of the optic chiasm from your ROIs datatype that you would like to track to. Example: '085'. Please see your ROI datatype for the exact ROI numbers/names.","default":"","_order":14,"pid":0.24195097614496874},"maxtrials":{"id":"maxtrials","type":"number","placeholder":"","advanced":false,"desc":"Sets the maximum number of attempts to generate streamline from the seed point. Default=1000000.","default":1000000,"_order":18,"pid":0.9711952406852369},"curvatures":{"id":"curvatures","type":"string","placeholder":"","advanced":false,"desc":"maximum angle of curvature (in degrees). can be multiple (i.e. ensemble) or one value. default: 45","default":"15","_order":20,"pid":0.9797165307058877},"single_lmax":{"id":"single_lmax","type":"boolean","placeholder":"","advanced":false,"desc":"Determines whether single lmax (true) or ensemble lmax (false) will be performed","default":true,"_order":23,"pid":0.8347766212484171},"multiple_seed":{"id":"multiple_seed","type":"boolean","placeholder":"","advanced":false,"desc":"If true, this will set the seeds of tractography to be present in both the seeding and termination ROIs. This will also set the tracking to be bidirectional.","default":false,"_order":26,"pid":0.22159446393042836},"act":{"id":"act","type":"boolean","placeholder":"","advanced":false,"desc":"If true, this will use the anatomically constrained tractography framework for tracking. This will include backtracking. \n\nIf false, the white matter mask will be used as a tracking mask. The ROIs will be added to the white matter mask. If the ROIs haven't been resliced to diffusion space, set reslice to true in order to get this to work.","default":true,"_order":27,"pid":0.914207700175119}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5db737fe8aeeee68c6f2dc12","id":"dwi","datatype":"58c33c5fe13a50849b25879b","desc":"This is the path's to the DWI image and it's associated bvals and bvecs."},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5db737fe8aeeee0b74f2dc11","id":"csd","datatype":"5c536bf0f9109beac46adb45","desc":"This is the path to the constrained spherical deconvolution (CSD) outputs, including all lmax csd images generated and the response.txt file."},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5db737fe8aeeeea727f2dc10","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9","desc":"This is the path to the rois directory including both the ROIs listed in the 'roiPair' config"},{"datatype_tags":["5tt_masks"],"optional":false,"multi":false,"advanced":false,"_id":"5db737fe8aeeee4e46f2dc0f","id":"mask","datatype":"5a281aee2c214c9ba83ce620","desc":"This is the path to the five tissue type brain image generated from mrtrix3's 5ttgen function. "},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5db737fe8aeeeedb0af2dc0e","id":"brainmask","datatype":"5a281aee2c214c9ba83ce620","desc":"This is the path to the brain mask of the DWI image. This is optional. If left empty, app will generate brainmask automatically."},{"datatype_tags":["white_matter"],"optional":true,"multi":false,"advanced":false,"_id":"5eb99fdae8e7ac1a978a9fe2","id":"wm_mask","datatype":"5a281aee2c214c9ba83ce620","desc":"This is the path to the precomputed white matter mask. if left empty, one will be generated automatically"}],"outputs":[{"datatype_tags":["roi_mrtrix3_ifod2"],"output_on_root":false,"archive":true,"_id":"5db737fe8aeeee8147f2dc15","id":"track","datatype":"5907d922436ee50ffde9c549","datatype_tags_pass":null,"files":null,"desc":"This is the output tractogram containing all of the tracks generated"},{"datatype_tags":["roi_mrtrix3_ifod2"],"output_on_root":false,"archive":true,"_id":"5db737fe8aeeee899bf2dc13","id":"wmc","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags_pass":null,"files":null,"desc":"This is the classification structure that refers to the generated tractogram"},{"datatype_tags":["brain_mask"],"output_on_root":false,"archive":false,"_id":"5db737fe8aeeeee32ff2dc14","id":"brainmask","datatype":"5a281aee2c214c9ba83ce620","datatype_tags_pass":null,"files":null,"desc":"This is the brainmask output. If input was used, this is just a copy and doesn't need to be archived."}],"github_branch":"optic-tract-v1.0","github":"brainlife/app-mrtrix3-roi2roi-tracking","name":"Track the Human Optic TRAct (THOTRA) - mrtrix3 IFOD2 (dwi)","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3cc962f3d3800f1298e7"}],"desc":null,"__v":4154,"desc_override":"This app will generate optic tracts using MrTrix3's IFOD2 with the capability of using the Anatomically Constrained (ACT) framework","create_date":"2020-09-03T17:24:31.303Z","doi":"10.25663/brainlife.app.406","deprecated_by":"5f51279442c17258f764c7ee","_canedit":true},{"_id":"5ecc12711f4464fbe69ec07f","projects":[],"admins":["16"],"tags":["tracking"],"removed":false,"stats":{"success_rate":52.65700483091788,"users":8,"runtime_mean":6096105.52,"runtime_std":7555933.599048861,"requested":12206,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3aed62f3d3800f124880"}],"examples":0,"groups":17},"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"response":{"type":"input","file_id":"response","input_id":"csd"},"lmax2":{"type":"input","file_id":"lmax2","input_id":"csd"},"lmax4":{"type":"input","file_id":"lmax4","input_id":"csd"},"lmax6":{"type":"input","file_id":"lmax6","input_id":"csd"},"lmax8":{"type":"input","file_id":"lmax8","input_id":"csd"},"lmax10":{"type":"input","file_id":"lmax10","input_id":"csd"},"lmax12":{"type":"input","file_id":"lmax12","input_id":"csd"},"lmax14":{"type":"input","file_id":"lmax14","input_id":"csd"},"rois":{"type":"input","file_id":"rois","input_id":"rois"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"brainmask":{"type":"input","file_id":"mask","input_id":"brainmask"},"wm_mask":{"type":"input","file_id":"mask","input_id":"wm_mask"},"min_length":{"id":"min_length","type":"number","placeholder":"","advanced":false,"desc":"The minimum allowable streamline length to be generated (number)\nexample: 10","default":10,"_order":2,"pid":0.7463596641066159},"max_length":{"id":"max_length","type":"number","placeholder":"","advanced":false,"desc":"The maximum allowable streamline length to be generated (number)\nexample: 10","default":200,"_order":3,"pid":0.4616679820751606},"lmax":{"id":"lmax","type":"number","placeholder":"","advanced":false,"desc":"The maxmium spherical harmonic order (lmax) to use. If left empty, this will be identified automatically. (number)","default":8,"_order":4,"pid":0.7858673334418194,"optional":true},"minfodamp":{"id":"minfodamp","type":"string","placeholder":"","advanced":false,"desc":"The minimum FOD amplitude to use as a cutoff (mrtrix3 flag -cutoff) (number)\nex: 0.025","default":"0.025","_order":9,"pid":0.7157815733160988},"stepsize":{"id":"stepsize","type":"string","placeholder":"","advanced":false,"desc":"Step size to use for tracking (number)\nex: 0.25","default":"0.25","_order":10,"pid":0.3934709948391675},"roiPair":{"id":"roiPair","type":"string","placeholder":"","advanced":false,"desc":"this field is here in order to allow for the option for only tracking one hemisphere or both hemispheres. If you want to track one hemisphere, enter the exact name of the LGN roi you want to track from (example: '008109'). If both hemispheres are desired, enter both LGN ROI numbers (example: '008109 008209'). Please see your ROI datatype for the exact ROI numbers/names.","default":"","_order":10,"pid":0.23789313573300097,"multiline":true},"oc":{"id":"oc","type":"string","placeholder":"","advanced":false,"desc":"this is the exact ROI number/name of the optic chiasm from your ROIs datatype that you would like to track to. Example: '085'. Please see your ROI datatype for the exact ROI numbers/names.","default":"","_order":14,"pid":0.4820809081496651},"count":{"id":"count","type":"number","placeholder":"","advanced":false,"desc":"total number of streamlines","default":500,"_order":14,"pid":0.8615850828589968},"maxtrials":{"id":"maxtrials","type":"number","placeholder":"","advanced":false,"desc":"Sets the maximum number of attempts to generate streamline from the seed point. Default=1000000.","default":1000000,"_order":18,"pid":0.28392862497759586},"curvatures":{"id":"curvatures","type":"string","placeholder":"","advanced":false,"desc":"maximum angle of curvature (in degrees). can be multiple (i.e. ensemble) or one value. default: 45","default":"15","_order":20,"pid":0.6006494360083037},"single_lmax":{"id":"single_lmax","type":"boolean","placeholder":"","advanced":false,"desc":"Determines whether single lmax (true) or ensemble lmax (false) will be performed","default":true,"_order":23,"pid":0.282890152653118},"multiple_seed":{"id":"multiple_seed","type":"boolean","placeholder":"","advanced":false,"desc":"If true, this will set the seeds of tractography to be present in both the seeding and termination ROIs. This will also set the tracking to be bidirectional.","default":false,"_order":26,"pid":0.782795918076634},"act":{"id":"act","type":"boolean","placeholder":"","advanced":false,"desc":"If true, this will use the anatomically constrained tractography framework for tracking. This will include backtracking. \n\nIf false, the white matter mask will be used as a tracking mask. The ROIs will be added to the white matter mask. If the ROIs haven't been resliced to diffusion space, set reslice to true in order to get this to work.","default":true,"_order":27,"pid":0.3269282373366633}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5db737fe8aeeee68c6f2dc12","id":"dwi","datatype":"58c33c5fe13a50849b25879b","desc":"This is the path's to the DWI image and it's associated bvals and bvecs."},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5db737fe8aeeee0b74f2dc11","id":"csd","datatype":"5c536bf0f9109beac46adb45","desc":"This is the path to the constrained spherical deconvolution (CSD) outputs, including all lmax csd images generated and the response.txt file."},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5db737fe8aeeeea727f2dc10","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9","desc":"This is the path to the rois directory including both the ROIs listed in the 'roiPair' config"},{"datatype_tags":["5tt_masks"],"optional":false,"multi":false,"advanced":false,"_id":"5db737fe8aeeee4e46f2dc0f","id":"mask","datatype":"5a281aee2c214c9ba83ce620","desc":"This is the path to the five tissue type brain image generated from mrtrix3's 5ttgen function. "},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5db737fe8aeeeedb0af2dc0e","id":"brainmask","datatype":"5a281aee2c214c9ba83ce620","desc":"This is the path to the brain mask of the DWI image. This is optional. If left empty, app will generate brainmask automatically."},{"datatype_tags":["white_matter"],"optional":true,"multi":false,"advanced":false,"_id":"5eb99fdae8e7ac1a978a9fe2","id":"wm_mask","datatype":"5a281aee2c214c9ba83ce620","desc":"This is the path to the precomputed white matter mask. if left empty, one will be generated automatically"}],"outputs":[{"datatype_tags":["roi_mrtrix3_ifod2"],"output_on_root":false,"archive":true,"_id":"5db737fe8aeeee8147f2dc15","id":"track","datatype":"5907d922436ee50ffde9c549","datatype_tags_pass":null,"files":null,"desc":"This is the output tractogram containing all of the tracks generated"},{"datatype_tags":["roi_mrtrix3_ifod2"],"output_on_root":false,"archive":true,"_id":"5db737fe8aeeee899bf2dc13","id":"wmc","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags_pass":null,"files":null,"desc":"This is the classification structure that refers to the generated tractogram"},{"datatype_tags":["brain_mask"],"output_on_root":false,"archive":false,"_id":"5db737fe8aeeeee32ff2dc14","id":"brainmask","datatype":"5a281aee2c214c9ba83ce620","datatype_tags_pass":null,"files":null,"desc":"This is the brainmask output. If input was used, this is just a copy and doesn't need to be archived."}],"github_branch":"optic-tract-v1.0","github":"brainlife/app-mrtrix3-roi2roi-tracking","name":"Track the Human Optic TRAct (THOTRA) - mrtrix3 iFOD2 (dwi)","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3aed62f3d3800f124881"}],"desc":null,"__v":4790,"desc_override":"This app will generate optic tracts using MrTrix3's iFOD2 algorithm with the capability of using the Anatomically Constrained (ACT) framework","create_date":"2020-05-25T18:46:09.612Z","doi":"10.25663/brainlife.app.352","_canedit":true},{"_id":"628a45c0d0697cf1eae9a3fe","user_id":"56","projects":[],"admins":["56"],"name":"Track the aLIC","github":"DanNBullock/app-track_aLIC","desc_override":"Track the anterior limb of the internal capsule with streamline tractography using MRTRIX3","tags":[],"config":{"diff":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvec":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bval":{"type":"input","file_id":"bvals","input_id":"dwi"},"sbref":{"type":"input","file_id":"sbref","input_id":"dwi"},"sbref_json":{"type":"input","file_id":"sbref_json","input_id":"dwi"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"anat":{"type":"input","file_id":"t1","input_id":"anat"},"tensor_fit":{"id":"tensor_fit","type":"number","placeholder":"","advanced":false,"desc":"If multi-shell data is passed, this selects the shell that will be extracted and have a tensor fit performed If single-shell data is passed, this is ignored","default":1,"_order":2,"pid":0.6905724340772676},"norm":{"id":"norm","type":"boolean","placeholder":"","advanced":false,"desc":"perform log-domain normalization of CSD data before tracking (multi-shell data only)","default":false,"_order":3,"pid":0.18896852899259176},"min_length":{"id":"min_length","type":"number","placeholder":"","advanced":false,"desc":"the minimum length a streamline may be","default":10,"_order":4,"pid":0.166617591891425},"max_length":{"id":"max_length","type":"number","placeholder":"","advanced":false,"desc":"the maximum length a streamline may be","default":250,"_order":5,"pid":0.2072949632239136},"ens_lmax":{"id":"ens_lmax","type":"boolean","placeholder":"","advanced":false,"desc":"perform ensemble tracking on every lmax up to the maximum value passed","default":true,"_order":7,"pid":0.5607445911641802},"curvs":{"id":"curvs","type":"string","placeholder":"","advanced":false,"desc":"the maximum curvature angle streamline can take during tracking","default":"5 10 20 40 80","_order":8,"pid":0.6202039887872413},"num_fibers":{"id":"num_fibers","type":"number","placeholder":"","advanced":false,"desc":"the number of streamlines to produce per parameter combination","default":2500,"_order":9,"pid":0.28730491957251547},"do_dtdt":{"id":"do_dtdt","type":"boolean","placeholder":"","advanced":false,"desc":"perform tensor-based deterministic tractography","default":false,"_order":10,"pid":0.0002412606386661409},"do_dtpb":{"id":"do_dtpb","type":"boolean","placeholder":"","advanced":false,"desc":"perform tensor-based probabilistic tractography\n\n","default":false,"_order":11,"pid":0.3231036789763373},"do_detr":{"id":"do_detr","type":"boolean","placeholder":"","advanced":false,"desc":"perform deterministic tractography","default":false,"_order":12,"pid":0.39342787398842005},"do_prb1":{"id":"do_prb1","type":"boolean","placeholder":"","advanced":false,"desc":"perform mrtrix2 probabilistic tractography","default":false,"_order":13,"pid":0.2665756280749436},"do_prb2":{"id":"do_prb2","type":"boolean","placeholder":"","advanced":false,"desc":"perform mrtrix3 probabilistic tractography","default":true,"_order":14,"pid":0.7460042976086916},"do_fact":{"id":"do_fact","type":"boolean","placeholder":"","advanced":false,"desc":"Perform FACT tracking","default":false,"_order":15,"pid":0.020171642270536028},"fact_dirs":{"id":"fact_dirs","type":"number","placeholder":"","advanced":false,"desc":"The number of directions to perform FACT tracking on.","default":3,"_order":16,"pid":0.3843474209845581},"fact_fibs":{"id":"fact_fibs","type":"number","placeholder":"","advanced":false,"desc":"The number of FACT fibers to track per lmax.","default":0,"_order":17,"pid":0.29896201741500494},"premask":{"id":"premask","type":"boolean","placeholder":"","advanced":false,"desc":"If the input anatomical T1s have already been skull stripped, check this to prevent 5ttgen from cutting off a portion of the brain. (This sets -premasked option for 5ttgens)","default":false,"_order":18,"pid":0.6602090038053599},"step":{"id":"step","type":"number","placeholder":"","advanced":false,"desc":"Streamline internode distance","default":0.5,"_order":19,"pid":0.5224593133682833},"imaxs":{"id":"imaxs","type":"number","placeholder":"The lmax(s) or maximum value to fit and create tractography data. If not provided, the App will find the maximum possible lmax within the data and use that.","advanced":false,"desc":"","default":8,"_order":21,"pid":0.8413850049719702}},"inputs":[{"id":"dwi","datatype":"58c33c5fe13a50849b25879b","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"628a45c0d0697cf1eae9a3ff"},{"id":"freesurfer","datatype":"58cb22c8e13a50849b25882e","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"628a45c0d0697cf1eae9a400"},{"id":"anat","datatype":"58c33bcee13a50849b25879a","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"628a464fd0697cf1eae9aac1"}],"outputs":[{"id":"output","datatype":"5907d922436ee50ffde9c549","datatype_tags":["aLIC"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"628a45c0d0697cf1eae9a401"},{"id":"wmc","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags":["aLIC"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"628e732fd0697cf1eaf1ec42"}],"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a447862f3d3800f130e20"}],"examples":1,"success_rate":15,"users":1,"groups":1,"runtime_mean":15746674.333333334,"runtime_std":10084352.783872988,"requested":27},"removed":false,"contributors":[{"name":"Daniel Bullock","email":"iisdanbul@gmail.com","_id":"634a447962f3d3800f130e21"}],"create_date":"2022-05-22T14:16:32.742Z","desc":"Containerized app for tracking the anterior limb of the internal capsule (in humans)","__v":333,"doi":"10.25663/brainlife.app.630","_canedit":true},{"_id":"5f5a8c510c8f95df586610fd","projects":[],"admins":["16","185","41","1"],"tags":["diffusion-mri","mri","tracking","tractography","vision"],"removed":false,"stats":{"gitinfo":{"desc":"Brainlife App (wrapper) for dMRI based fiber tracking between ROIs using parallel transport tractography","tags":["diffusion-mri","mri","tracking","tractography","vision"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"success_rate":44.38652766639935,"users":14,"runtime_mean":9394121.4,"runtime_std":8236894.053758132,"requested":3594,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3d1662f3d3800f12a061"}],"examples":0,"groups":24},"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"lmax2":{"type":"input","file_id":"lmax2","input_id":"csd"},"lmax4":{"type":"input","file_id":"lmax4","input_id":"csd"},"lmax6":{"type":"input","file_id":"lmax6","input_id":"csd"},"lmax8":{"type":"input","file_id":"lmax8","input_id":"csd"},"lmax10":{"type":"input","file_id":"lmax10","input_id":"csd"},"lmax12":{"type":"input","file_id":"lmax12","input_id":"csd"},"lmax14":{"type":"input","file_id":"lmax14","input_id":"csd"},"rois":{"type":"input","file_id":"rois","input_id":"rois"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"brainmask":{"type":"input","file_id":"mask","input_id":"brainmask"},"min_length":{"id":"min_length","type":"number","placeholder":"","advanced":false,"desc":"min length of streamlines","default":10,"_order":2,"pid":0.578649895289485},"max_length":{"id":"max_length","type":"number","placeholder":"","advanced":false,"desc":"max length of streamlines","default":200,"_order":3,"pid":0.12986213357081033},"lmax":{"id":"lmax","type":"number","placeholder":"","advanced":false,"desc":"lmax","default":8,"_order":4,"pid":0.9555374688980247},"visualROI":{"id":"visualROI","type":"string","placeholder":"","advanced":false,"desc":"This is the exact name (following ROI prefix) of the visual ROI the user wants to use as the visual termination ROIs. The name comes from the ROI input directory. Example: 'varea'","default":"","_order":5,"pid":0.3083644636502376},"exclusion":{"id":"exclusion","type":"string","placeholder":"","advanced":false,"desc":"this field is the exact ROI name or number from the ROI datatype for the exclusion ROIs. Example: 'exclusion_L'. If bother hemispheres are being tracked, enter the name separated by a space for each exclusion 'exclusion_R'. Please see ROI datatype for exact name of each.\n\nThese exclusion can be any grouping of ROIs that you DO NOT want streamlines to cross. For example, opposite hemisphere white matter, cerebellar white matter, hippocampus are good exclusions for the OR. \n\nIf you do not want to use exclusion ROIs, leave blank","default":"","_order":7,"pid":0.7640482755197437,"optional":true,"multiline":true},"count":{"id":"count","type":"number","placeholder":"","advanced":false,"desc":"total number of streamlines","default":50000,"_order":9,"pid":0.6403603770427047},"curvatures":{"id":"curvatures","type":"string","placeholder":"","advanced":true,"desc":"minimum radius of curvature. If left as 'default', trekker will automatically determine best curvature. Otherwise, enter value of radius of curvature (i.e 0.5)","default":"default","_order":14,"pid":0.6987149950811249},"stepsize":{"id":"stepsize","type":"string","placeholder":"","advanced":true,"desc":"step size. If left as 'default', trekker will automatically determine best step size. Otherwise, enter value of step size (i.e 0.5)","default":"default","_order":15,"pid":0.006262363364440304},"single_lmax":{"id":"single_lmax","type":"boolean","placeholder":"","advanced":false,"desc":"if want to run on only one lmax, set to true. to ensemble, set to false","default":true,"_order":18,"pid":0.5398657589401572},"minfodamp":{"id":"minfodamp","type":"string","placeholder":"","advanced":true,"desc":"minimum FOD amplitude. If left as 'default', trekker will automatically determine best FOD amplitude. Otherwise, enter value of FOD amplitude (i.e 0.5)","default":"default","_order":19,"pid":0.4207393974558844},"maxsampling":{"id":"maxsampling","type":"string","placeholder":"","advanced":true,"desc":"max sampling per seed. If left as 'default', trekker will automatically determine best number of max sampling per seed. Otherwise, enter value here (100000)","default":"default","_order":20,"pid":0.5145814876211408},"maxtrials":{"id":"maxtrials","type":"string","placeholder":"","advanced":true,"desc":"max trials. If left as 'default', trekker will automatically determine best number of max trials. Otherwise, enter value here (100000)","default":"default","_order":21,"pid":0.6896171982020545},"probecount":{"id":"probecount","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":22,"pid":0.9705742352066999},"probelength":{"id":"probelength","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":23,"pid":0.14553754671325492},"proberadius":{"id":"proberadius","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":24,"pid":0.12212821955809505},"probequality":{"id":"probequality","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":25,"pid":0.46640840796441374,"optional":false},"bestAtInit":{"id":"bestAtInit","type":"boolean","placeholder":"","advanced":true,"desc":"","default":false,"_order":26,"pid":0.1777050818116208},"reslice":{"id":"reslice","type":"boolean","placeholder":"","advanced":false,"desc":"","default":false,"_order":27,"pid":0.8517186045983753},"min_degree":{"id":"min_degree","type":"string","placeholder":"","advanced":false,"desc":"Minimum eccentricity degrees","default":"0 15 30","_order":28,"pid":0.2708394164836774,"readonly":false},"max_degree":{"id":"max_degree","type":"string","placeholder":"","advanced":false,"desc":"Minimum eccentricity degrees","default":"3 30 90","_order":29,"pid":0.14224871769993297},"both_endpoints":{"id":"both_endpoints","type":"boolean","placeholder":"","advanced":false,"desc":"If it is desired that both sets of endpoints end in the visual ROIs, set true. otherwise, set false. Note: tracking will take considerably longer if true","default":false,"_order":30,"pid":0.7937359409655032},"mergeExclusion":{"id":"mergeExclusion","type":"boolean","placeholder":"","advanced":false,"desc":"","default":false,"_order":31,"pid":0.4078901443629426}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d65964c398672b124496250","id":"dwi","datatype":"58c33c5fe13a50849b25879b"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d65964c398672b57f49624e","id":"csd","datatype":"5c536bf0f9109beac46adb45"},{"datatype_tags":["eccentricity"],"optional":false,"multi":false,"advanced":false,"_id":"5d65964c3986725b9b49624d","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9","desc":"Requires eccentricity rois to already have been generated. See https://brainlife.io/app/5f52cc4b42c17250a7651b63"},{"datatype_tags":["5tt_masks"],"optional":false,"multi":false,"advanced":false,"_id":"5d65964c3986722b1e49624c","id":"mask","datatype":"5a281aee2c214c9ba83ce620","desc":"5-tissue type mask (needed for csd fitting)"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5d65964c398672012849624b","id":"brainmask","datatype":"5a281aee2c214c9ba83ce620","desc":"whole-brain mask"}],"outputs":[{"datatype_tags":["roi_trekker","tracking_eccentricity"],"output_on_root":false,"archive":true,"_id":"5d65964c3986726908496255","id":"track","datatype":"5907d922436ee50ffde9c549","datatype_tags_pass":null,"files":null},{"datatype_tags":["dwi"],"output_on_root":false,"archive":false,"_id":"5d65964c398672dec1496252","id":"brainmask","datatype":"5a281aee2c214c9ba83ce620","datatype_tags_pass":null,"files":null},{"datatype_tags":["roi_trekker","tracking_eccentricity"],"output_on_root":false,"archive":true,"_id":"5d65964c39867210f4496251","id":"wmc","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags_pass":null,"files":null},{"datatype_tags":["roi_tracking_derivatives","tracking_eccentricity"],"output_on_root":false,"archive":true,"_id":"5ee1d523c5972bd387b45562","id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null}],"github_branch":"master-app-eccentricity-visualroi-v1.0","github":"brainlife/app-trekker-roi-tracking","name":"Tracking the Visual White Matter (TVWM) (Trekker) - Eccentricity","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3d1762f3d3800f12a062"},{"name":"Franco Pestilli","email":null,"_id":"634a3d1762f3d3800f12a063"}],"desc":"Brainlife App (wrapper) for dMRI based fiber tracking between ROIs using parallel transport tractography","__v":4154,"desc_override":"This app uses [Trekker](https://dmritrekker.github.io) to track between multiple ROIs.","avatar":"","create_date":"2020-09-10T20:28:01.893Z","doi":"10.25663/brainlife.app.418","_canedit":true},{"_id":"5ea7dcbbf1745d2293f80794","projects":[],"admins":["285","87","1"],"tags":["diffusion-mri","dipy","tracking","tractography"],"removed":false,"name":"Tracking using Closest Peaks algorithm","desc":"Brainlife wrapper app for dipy_track workflows.","avatar":"https://raw.githubusercontent.com/brain-life/brainlife.github.io/master/images/app-logos/dipy_track_det.png","github":"dipy/bl_apps_dipy_track","github_branch":"1.1.1","config":{"peaks":{"type":"input","file_id":"peaks","input_id":"pam_files"},"stopping_files":{"type":"input","file_id":"fa","input_id":"stopping_files"},"md":{"type":"input","file_id":"md","input_id":"stopping_files"},"rd":{"type":"input","file_id":"rd","input_id":"stopping_files"},"ad":{"type":"input","file_id":"ad","input_id":"stopping_files"},"seeding_files":{"type":"input","file_id":"mask","input_id":"seeding_files"},"tracking_method":{"type":"string","placeholder":"","desc":"","default":"closestpeaks","readonly":true,"id":"tracking_method","pid":0.7126320232198851,"_order":2},"use_binary_mask":{"type":"boolean","placeholder":"","desc":"If True, uses a binary stopping criterion. If the provided `stopping_files` are not binary, `stopping_thr` will be used to binarize the images.","default":false,"id":"use_binary_mask","pid":0.8394905246269544,"_order":3},"stopping_thr":{"type":"number","placeholder":"0.25","desc":"Threshold applied to stopping volume's data to identify where\ntracking has to stop (default 0.25).","default":0.25,"id":"stopping_thr","pid":0.8521081579748773,"_order":4},"seed_density":{"type":"number","placeholder":"1","desc":"Number of seeds per dimension inside voxel (default 1).\nFor example, seed_density of 2 means 8 regularly distributed points\nin the voxel. And seed density of 1 means 1 point at the center\nof the voxel.","default":1,"id":"seed_density","pid":0.8848043153092315,"_order":5},"step_size":{"id":"step_size","type":"number","placeholder":"","advanced":false,"desc":"Step size used for tracking (default 0.5mm)","default":0.5,"_order":6,"pid":0.6003360365390733},"pmf_threshold":{"id":"pmf_threshold","type":"number","placeholder":"","advanced":false,"desc":"Threshold for ODF functions","default":0.1,"_order":7,"pid":0.7109342788911088},"max_angle":{"id":"max_angle","type":"number","placeholder":"","advanced":false,"desc":"Maximum angle between streamline segments (range [0, 90]","default":30,"_order":8,"pid":0.14322936953054977}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5b21774b16fe38002748e5f2","id":"pam_files","datatype":"59494478fa1d2e5a1ffd23b4","desc":"Path to the peaks and metrics files."},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5b21774b16fe38002748e5f1","id":"stopping_files","datatype":"5a79df48d071a1753f1d661b","desc":"Path of FA or other images used for stopping criteria for tracking."},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5b21774b16fe38002748e5f0","id":"seeding_files","datatype":"5a281aee2c214c9ba83ce620","desc":"A binary image showing where we need to seed for tracking."}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5b21774b16fe38002748e5f3","id":"output","datatype":"5b956f6cd7b3f1e24e9121ce","datatype_tags_pass":null,"files":{"track":"tractogram.trk"}}],"desc_override":"Closest Peaks tracking using a peaks and metrics (PAM) (dipy_track)","user_id":"87","contributors":[{"name":"Serge Koudoro","email":null,"_id":"634a3a2c62f3d3800f1236e4"},{"name":"Javier Guaje","email":null,"_id":"634a3a2c62f3d3800f1236e5"}],"stats":{"requested":849,"users":12,"success_rate":96.84343434343434,"gitinfo":{"desc":"Brainlife wrapper app for Dipy workflows.","tags":["dipy"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Serge Koudoro","email":null},{"name":"Aman Arya","email":"aman.arya524@gmail.com"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":3502445.35,"runtime_std":4220463.651326779,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3a2b62f3d3800f1236e3"}],"examples":0,"groups":14},"__v":4988,"create_date":"2020-04-28T07:35:23.482Z","doi":"10.25663/brainlife.app.331","_canedit":true},{"_id":"5b21774b16fe38002748e5ef","projects":[],"admins":["285","87","1"],"tags":["diffusion-mri","dipy","tracking","tractography"],"removed":false,"name":"Tracking using Deterministic algorithm","desc":"Brainlife wrapper app for dipy_track workflows.","citation":null,"references":[],"avatar":"https://raw.githubusercontent.com/brain-life/brainlife.github.io/master/images/app-logos/dipy_track_det.png","github":"dipy/bl_apps_dipy_track","github_branch":"1.1.1","config":{"peaks":{"type":"input","file_id":"peaks","input_id":"pam_files"},"stopping_files":{"type":"input","file_id":"fa","input_id":"stopping_files"},"md":{"type":"input","file_id":"md","input_id":"stopping_files"},"rd":{"type":"input","file_id":"rd","input_id":"stopping_files"},"ad":{"type":"input","file_id":"ad","input_id":"stopping_files"},"seeding_files":{"type":"input","file_id":"mask","input_id":"seeding_files"},"tracking_method":{"type":"string","placeholder":"","desc":"","default":"deterministic","readonly":true,"id":"tracking_method","pid":0.6286308024557734,"_order":2},"use_binary_mask":{"type":"boolean","placeholder":"","desc":"If True, uses a binary stopping criterion. If the provided `stopping_files` are not binary, `stopping_thr` will be used to binarize the images.","default":false,"id":"use_binary_mask","pid":0.5086666926203343,"_order":3},"stopping_thr":{"type":"number","placeholder":"0.25","desc":"Threshold applied to stopping volume's data to identify where\ntracking has to stop (default 0.25).","default":0.25,"id":"stopping_thr","pid":0.5193399534978402,"_order":4},"seed_density":{"type":"number","placeholder":"1","desc":"Number of seeds per dimension inside voxel (default 1).\nFor example, seed_density of 2 means 8 regularly distributed points\nin the voxel. And seed density of 1 means 1 point at the center\nof the voxel.","default":1,"id":"seed_density","pid":0.47820703613490956,"_order":5},"step_size":{"id":"step_size","type":"number","placeholder":"","advanced":false,"desc":"Step size used for tracking (default 0.5mm)","default":0.5,"_order":6,"pid":0.7008405081979336},"pmf_threshold":{"id":"pmf_threshold","type":"number","placeholder":"","advanced":false,"desc":"Threshold for ODF functions","default":0.1,"_order":7,"pid":0.7731307692416678},"max_angle":{"id":"max_angle","type":"number","placeholder":"","advanced":false,"desc":"Maximum angle between streamline segments (range [0, 90]","default":30,"_order":8,"pid":0.08575336795633448}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5b21774b16fe38002748e5f2","id":"pam_files","datatype":"59494478fa1d2e5a1ffd23b4","desc":"Path to the peaks and metrics files."},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5b21774b16fe38002748e5f1","id":"stopping_files","datatype":"5a79df48d071a1753f1d661b","desc":"Path of FA or other images used for stopping criteria for tracking."},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5b21774b16fe38002748e5f0","id":"seeding_files","datatype":"5a281aee2c214c9ba83ce620","desc":"A binary image showing where we need to seed for tracking."}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5b21774b16fe38002748e5f3","id":"output","datatype":"5b956f6cd7b3f1e24e9121ce","datatype_tags_pass":null,"files":{"track":"tractogram.trk"}}],"desc_override":"Deterministic tracking using a peaks and metrics (PAM) (dipy_track)","user_id":"61","contributors":[{"name":"Serge Koudoro","email":null,"_id":"634a335262f3d3800f117ea7"},{"name":"Javier Guaje","email":null,"_id":"634a335262f3d3800f117ea8"}],"create_date":"2018-06-13T19:58:03.928Z","stats":{"stars":0,"requested":849,"users":12,"success_rate":96.84343434343434,"serviceinfo":{"_id":"5d729e1f78356a109788b2dd","counts":{"_id":"5e5c3daf87cac794d5ab13c0","failed":1372,"finished":2816,"removed":5103,"requested":5301,"running":3198,"running_sync":0,"stop_requested":12},"success_rate":67.23973256924546,"users":20,"readme_status":"ok","runtime_mean":5885857.53,"runtime_std":14501545.618587041,"service":"brain-life/app-dipy-workflows","__v":0},"gitinfo":{"desc":"Brainlife wrapper app for Dipy workflows.","tags":["dipy"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Serge Koudoro","email":null},{"name":"Aman Arya","email":"aman.arya524@gmail.com"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":3502445.35,"runtime_std":4220463.651326779,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a335162f3d3800f117ea6"}],"examples":0,"groups":14},"doi":"10.25663/bl.app.66","__v":12737,"_canedit":true},{"_id":"5ea7dc4ef1745d4963f80739","projects":[],"admins":["285","87","1"],"tags":["diffusion-mri","dipy","tracking","tractography"],"removed":false,"name":"Tracking using EuDX algorithm","desc":"Brainlife wrapper app for dipy_track workflows.","avatar":"https://raw.githubusercontent.com/brain-life/brainlife.github.io/master/images/app-logos/dipy_track_det.png","github":"dipy/bl_apps_dipy_track","github_branch":"1.1.1","config":{"peaks":{"type":"input","file_id":"peaks","input_id":"pam_files"},"stopping_files":{"type":"input","file_id":"fa","input_id":"stopping_files"},"md":{"type":"input","file_id":"md","input_id":"stopping_files"},"rd":{"type":"input","file_id":"rd","input_id":"stopping_files"},"ad":{"type":"input","file_id":"ad","input_id":"stopping_files"},"seeding_files":{"type":"input","file_id":"mask","input_id":"seeding_files"},"tracking_method":{"type":"string","placeholder":"","desc":"","default":"eudx","readonly":true,"id":"tracking_method","pid":0.3733282924898691,"_order":2,"optional":false},"use_binary_mask":{"type":"boolean","placeholder":"","desc":"If True, uses a binary stopping criterion. If the provided `stopping_files` are not binary, `stopping_thr` will be used to binarize the images.","default":false,"id":"use_binary_mask","pid":0.39670963853814545,"_order":3},"stopping_thr":{"type":"number","placeholder":"0.25","desc":"Threshold applied to stopping volume's data to identify where\ntracking has to stop (default 0.25).","default":0.25,"id":"stopping_thr","pid":0.5432266530014196,"_order":4},"seed_density":{"type":"number","placeholder":"1","desc":"Number of seeds per dimension inside voxel (default 1).\nFor example, seed_density of 2 means 8 regularly distributed points\nin the voxel. And seed density of 1 means 1 point at the center\nof the voxel.","default":1,"id":"seed_density","pid":0.2943957596425608,"_order":5},"step_size":{"id":"step_size","type":"number","placeholder":"","advanced":false,"desc":"Step size used for tracking (default 0.5mm)","default":0.5,"_order":6,"pid":0.2308759790792092},"pmf_threshold":{"id":"pmf_threshold","type":"number","placeholder":"","advanced":false,"desc":"Threshold for ODF functions","default":0.1,"_order":7,"pid":0.07888618607420517},"max_angle":{"id":"max_angle","type":"number","placeholder":"","advanced":false,"desc":"Maximum angle between streamline segments (range [0, 90]","default":30,"_order":8,"pid":0.5660084187086931}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5b21774b16fe38002748e5f2","id":"pam_files","datatype":"59494478fa1d2e5a1ffd23b4","desc":"Path to the peaks and metrics files."},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5b21774b16fe38002748e5f1","id":"stopping_files","datatype":"5a79df48d071a1753f1d661b","desc":"Path of FA or other images used for stopping criteria for tracking."},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5b21774b16fe38002748e5f0","id":"seeding_files","datatype":"5a281aee2c214c9ba83ce620","desc":"A binary image showing where we need to seed for tracking."}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5b21774b16fe38002748e5f3","id":"output","datatype":"5b956f6cd7b3f1e24e9121ce","datatype_tags_pass":null,"files":{"track":"tractogram.trk"}}],"desc_override":"EuDX tracking using a peaks and metrics (PAM) (dipy_track)","user_id":"87","contributors":[{"name":"Serge Koudoro","email":null,"_id":"634a3a2362f3d3800f1236e0"},{"name":"Javier Guaje","email":null,"_id":"634a3a2362f3d3800f1236e1"}],"stats":{"requested":849,"users":12,"success_rate":96.84343434343434,"gitinfo":{"desc":"Brainlife wrapper app for Dipy workflows.","tags":["dipy"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Serge Koudoro","email":null},{"name":"Aman Arya","email":"aman.arya524@gmail.com"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":3502445.35,"runtime_std":4220463.651326779,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3a2262f3d3800f1236df"}],"examples":1,"groups":14},"__v":4987,"create_date":"2020-04-28T07:33:34.696Z","doi":"10.25663/brainlife.app.330","_canedit":true},{"_id":"5ea7d53bf1745d82a5f80509","stats":{"resources":[],"examples":0},"projects":[],"admins":["285","87"],"tags":["diffusion-mri","dipy","tracking","tractography"],"removed":false,"config":{"peaks":{"type":"input","file_id":"peaks","input_id":"peaks"},"wm":{"type":"input","file_id":"mask","input_id":"wm"},"gm":{"type":"input","file_id":"mask","input_id":"gm"},"csf":{"type":"input","file_id":"mask","input_id":"csf"},"seeds":{"type":"input","file_id":"mask","input_id":"seeds"},"step_size":{"id":"step_size","type":"number","placeholder":"","advanced":false,"desc":"Step size used for tracking (default 0.2mm).","default":0.2,"_order":2,"pid":0.8872443869764657},"seed_density":{"id":"seed_density","type":"number","placeholder":"","advanced":false,"desc":"Number of seeds per dimension inside voxel (default 1). For example, seed_density of 2 means 8 regularly distributed points in the voxel.","default":1,"_order":3,"pid":0.718616474773816},"pmf_threshold":{"id":"pmf_threshold","type":"number","placeholder":"","advanced":false,"desc":"Threshold for ODF functions (default 0.1).","default":0.1,"_order":4,"pid":0.5489139372093106},"max_angle":{"id":"max_angle","type":"number","placeholder":"","advanced":false,"desc":"Maximum angle between streamline segments (range [0, 90], default 20).","default":20,"_order":5,"pid":0.05394224810227555},"pft_back":{"id":"pft_back","type":"number","placeholder":"","advanced":false,"desc":"Distance in mm to back track before starting the particle filtering tractography (default 2mm). The total particle filtering tractography distance is equal to back_tracking_dist + front_tracking_dist.","default":2,"_order":6,"pid":0.4913112254365575},"pft_front":{"id":"pft_front","type":"number","placeholder":"","advanced":false,"desc":"Distance in mm to run the particle filtering tractography after the back track distance (default 1mm). The total particle filtering tractography distance is equal to back_tracking_dist + front_tracking_dist.","default":1,"_order":7,"pid":0.5495424857029254},"pft_count":{"id":"pft_count","type":"number","placeholder":"","advanced":false,"desc":"Number of particles to use in the particle filter (default 15).","default":15,"_order":8,"pid":0.7259532551691481}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ea7d53bf1745d2983f8050a","id":"peaks","datatype":"59494478fa1d2e5a1ffd23b4"},{"datatype_tags":["white_matter","dwi"],"optional":false,"multi":false,"advanced":false,"_id":"5ea7d53bf1745d07dbf8050b","id":"wm","datatype":"5a281aee2c214c9ba83ce620"},{"datatype_tags":["gray_matter","dwi"],"optional":false,"multi":false,"advanced":false,"_id":"5ea7d53bf1745d0140f8050c","id":"gm","datatype":"5a281aee2c214c9ba83ce620"},{"datatype_tags":["csf","dwi"],"optional":false,"multi":false,"advanced":false,"_id":"5ea7d53bf1745d7f29f8050d","id":"csf","datatype":"5a281aee2c214c9ba83ce620"},{"datatype_tags":["dwi"],"optional":false,"multi":false,"advanced":false,"_id":"5ea7d53bf1745d40caf8050e","id":"seeds","datatype":"5a281aee2c214c9ba83ce620"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5ea7d53bf1745d5013f8050f","id":"output","datatype":"5b956f6cd7b3f1e24e9121ce","datatype_tags_pass":null,"files":null}],"github_branch":"1.1.1","github":"dipy/bl_apps_dipy_track_pft","name":"Tracking using Particle Filtering (PFT)","user_id":"87","contributors":[{"name":"Javier Guaje","email":null,"_id":"634a3a0f62f3d3800f123592"},{"name":"Serge Koudoro","email":null,"_id":"634a3a0f62f3d3800f123593"}],"create_date":"2020-04-28T07:03:23.608Z","desc":"Brainlife wrapper app for dipy_track_pft workflows.","doi":"10.25663/brainlife.app.328","__v":4652,"_canedit":true},{"_id":"5ea7dbebf1745d70baf80678","projects":[],"admins":["285","87","1"],"tags":["diffusion-mri","dipy","tracking","tractography"],"removed":false,"name":"Tracking using Probabilistic algorithm","desc":"Brainlife wrapper app for dipy_track workflows.","avatar":"https://raw.githubusercontent.com/brain-life/brainlife.github.io/master/images/app-logos/dipy_track_det.png","github":"dipy/bl_apps_dipy_track","github_branch":"1.1.1","config":{"peaks":{"type":"input","file_id":"peaks","input_id":"pam_files"},"stopping_files":{"type":"input","file_id":"fa","input_id":"stopping_files"},"md":{"type":"input","file_id":"md","input_id":"stopping_files"},"rd":{"type":"input","file_id":"rd","input_id":"stopping_files"},"ad":{"type":"input","file_id":"ad","input_id":"stopping_files"},"seeding_files":{"type":"input","file_id":"mask","input_id":"seeding_files"},"tracking_method":{"type":"string","placeholder":"","desc":"","default":"probabilistic","readonly":true,"id":"tracking_method","pid":0.2083563978335088,"_order":2},"use_binary_mask":{"type":"boolean","placeholder":"","desc":"If True, uses a binary stopping criterion. If the provided `stopping_files` are not binary, `stopping_thr` will be used to binarize the images.","default":false,"id":"use_binary_mask","pid":0.9664113437069559,"_order":3},"stopping_thr":{"type":"number","placeholder":"0.25","desc":"Threshold applied to stopping volume's data to identify where\ntracking has to stop (default 0.25).","default":0.25,"id":"stopping_thr","pid":0.8638528855930556,"_order":4},"seed_density":{"type":"number","placeholder":"1","desc":"Number of seeds per dimension inside voxel (default 1).\nFor example, seed_density of 2 means 8 regularly distributed points\nin the voxel. And seed density of 1 means 1 point at the center\nof the voxel.","default":1,"id":"seed_density","pid":0.7796930297812168,"_order":5},"step_size":{"id":"step_size","type":"number","placeholder":"","advanced":false,"desc":"Step size used for tracking (default 0.5mm)","default":0.5,"_order":6,"pid":0.8289705388164921},"pmf_threshold":{"id":"pmf_threshold","type":"number","placeholder":"","advanced":false,"desc":"Threshold for ODF functions","default":0.1,"_order":7,"pid":0.785561074639676},"max_angle":{"id":"max_angle","type":"number","placeholder":"","advanced":false,"desc":"Maximum angle between streamline segments (range [0, 90]","default":30,"_order":8,"pid":0.12823334242789564}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5b21774b16fe38002748e5f2","id":"pam_files","datatype":"59494478fa1d2e5a1ffd23b4","desc":"Path to the peaks and metrics files."},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5b21774b16fe38002748e5f1","id":"stopping_files","datatype":"5a79df48d071a1753f1d661b","desc":"Path of FA or other images used for stopping criteria for tracking."},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5b21774b16fe38002748e5f0","id":"seeding_files","datatype":"5a281aee2c214c9ba83ce620","desc":"A binary image showing where we need to seed for tracking."}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5b21774b16fe38002748e5f3","id":"output","datatype":"5b956f6cd7b3f1e24e9121ce","datatype_tags_pass":null,"files":{"track":"tractogram.trk"}}],"desc_override":"Probabilistic tracking using a peaks and metrics (PAM) (dipy_track)","user_id":"87","contributors":[{"name":"Serge Koudoro","email":null,"_id":"634a3a1962f3d3800f123660"},{"name":"Javier Guaje","email":null,"_id":"634a3a1962f3d3800f123661"}],"stats":{"requested":849,"users":12,"success_rate":96.84343434343434,"gitinfo":{"desc":"Brainlife wrapper app for Dipy workflows.","tags":["dipy"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Serge Koudoro","email":null},{"name":"Aman Arya","email":"aman.arya524@gmail.com"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":3502445.35,"runtime_std":4220463.651326779,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3a1962f3d3800f12365f"}],"examples":2,"groups":14},"__v":4987,"create_date":"2020-04-28T07:31:55.782Z","doi":"10.25663/brainlife.app.448","_canedit":true},{"_id":"59ca5c03c27f5b0770add9cf","project":null,"name":"Tract Analysis Profiles","desc":"Create plots of diffusion metrics (i.e. FA, MD, RD, AD) for each of the segmented tracts from AFQ, known as Tract Profiles. Obtains streamline positions from segmented tracts and plots the metrics of interest along \"nodes\" of the tract, allowing for comparison of individual subject tracts. Requires the dt6 output from dtiinit and a white matter classification output from AFQ or WMA","github":"brainlife/app-tractanalysisprofiles","github_branch":"1.4","config":{"fa":{"type":"input","file_id":"fa","input_id":"tensor"},"md":{"type":"input","file_id":"md","input_id":"tensor"},"rd":{"type":"input","file_id":"rd","input_id":"tensor"},"ad":{"type":"input","file_id":"ad","input_id":"tensor"},"afq":{"type":"input","file_id":"output","input_id":"afq"},"icvf":{"type":"input","file_id":"icvf","input_id":"noddi"},"isovf":{"type":"input","file_id":"isovf","input_id":"noddi"},"od":{"type":"input","file_id":"od","input_id":"noddi"},"fiberbased":{"type":"boolean","placeholder":"","desc":"to create profiles using a non-weighted, fiber-based method: \"true\"","default":false,"id":"fiberbased","pid":0.877341597580674,"_order":2},"numnodes":{"default":200,"desc":"Number of nodes for each tract profile","placeholder":"","type":"integer","id":"numnodes","pid":0.868422562237184,"_order":10}},"user_id":"43","create_date":"2017-09-26T13:54:11.760Z","removed":false,"_rate":0,"outputs":[{"datatype_tags":["tract_profiles"],"output_on_root":true,"archive":true,"_id":"59ca5c03c27f5b0770add9d0","id":"images","datatype":"5967b799b09297d8d831709e","files":null,"desc":"Directory of tract profile images for each tract and measure"},{"datatype_tags":[],"output_on_root":true,"archive":true,"_id":"59d5259d4941900037274515","id":"profiles","datatype":"5965467cb09297d8d81bdbcd","files":null,"desc":"Directory of tract profile csvs for each tract and measure"}],"inputs":[{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"59ca5c03c27f5b0770add9d2","id":"tensor","datatype":"5a79df48d071a1753f1d661b","desc":"The path to the tensor datatype files (optional). If not included, must include NODDI (deprecated) datatype"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"59ca5c03c27f5b0770add9d1","id":"afq","datatype":"58f10a90436ee50ffd9063c5","desc":"Path to the wmc (deprecated) classification structure"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5b092b3f41711001e958b400","id":"noddi","datatype":"5bd77a8615a8683a39440dab","desc":"The path to the NODDI (deprecated) datatype files"}],"tags":["analysis"],"admins":["16"],"__v":14304,"projects":[],"contributors":[{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a313c62f3d3800f116698"},{"name":"Brad Caron","email":null,"_id":"634a313c62f3d3800f116699"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a313c62f3d3800f11669a"},{"name":"Franco Pestilli","email":null,"_id":"634a313c62f3d3800f11669b"},{"name":"Sophia Vinci-Booher","email":null,"_id":"634a313c62f3d3800f11669c"}],"references":[],"stats":{"stars":1,"requested":16297,"users":36,"success_rate":77.95080117354999,"serviceinfo":{"_id":"5d729e1f78356a109788b2e3","counts":{"_id":"5e5c688787cac70f33ab1bae","failed":3076,"finished":18694,"removed":24434,"requested":28274,"running":21318,"running_sync":0,"stop_requested":275},"success_rate":85.8704639412035,"users":28,"readme_status":"ok","runtime_mean":387280.16,"runtime_std":1523501.9629271352,"service":"brain-life/app-tractanalysisprofiles","__v":0},"gitinfo":{"desc":"Create plots of diffusion metrics (i.e. FA, MD, RD, AD) for each of the segmented tracts from AFQ, known as Tract Profiles. Obtains streamline positions from segmented tracts and plots the metrics of interest along \"nodes\" of the tract, allowing for comparison of individual subject tracts. Requires the dt6 output from dtiinit and a white matter classification output from AFQ or WMA","tags":["analysis"],"stats":{"stars":1},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Brad Caron","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":552322.51,"runtime_std":409252.69635279116,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a313b62f3d3800f116696"},{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a313b62f3d3800f116697"}],"examples":1,"groups":79},"doi":"10.25663/bl.app.43","desc_override":"This app has been deprecated. It will only work with wmc_deprecated datatype.","deprecated_by":"5cc210ce4ed9df00317f61cf","_canedit":true},{"_id":"5ed02b780a8ed88a57482c92","projects":[],"admins":["16"],"tags":["analysis"],"removed":false,"stats":{"requested":16297,"users":36,"success_rate":77.95080117354999,"gitinfo":{"desc":"Create plots of diffusion metrics (i.e. FA, MD, RD, AD) for each of the segmented tracts from AFQ, known as Tract Profiles. Obtains streamline positions from segmented tracts and plots the metrics of interest along \"nodes\" of the tract, allowing for comparison of individual subject tracts. Requires the dt6 output from dtiinit and a white matter classification output from AFQ or WMA","tags":["analysis"],"stats":{"stars":1},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Brad Caron","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":552322.51,"runtime_std":409252.69635279116,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3b4262f3d3800f1259b7"},{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a3b4262f3d3800f1259b8"}],"examples":5,"groups":79},"config":{"fa":{"type":"input","file_id":"fa","input_id":"tensor"},"md":{"type":"input","file_id":"md","input_id":"tensor"},"rd":{"type":"input","file_id":"rd","input_id":"tensor"},"ad":{"type":"input","file_id":"ad","input_id":"tensor"},"ga":{"type":"input","file_id":"ga","input_id":"tensor"},"ak":{"type":"input","file_id":"ak","input_id":"tensor"},"mk":{"type":"input","file_id":"mk","input_id":"tensor"},"rk":{"type":"input","file_id":"rk","input_id":"tensor"},"afq":{"type":"input","file_id":"classification","input_id":"afq"},"dir":{"type":"input","file_id":"dir","input_id":"noddi"},"ndi":{"type":"input","file_id":"ndi","input_id":"noddi"},"isovf":{"type":"input","file_id":"isovf","input_id":"noddi"},"odi":{"type":"input","file_id":"odi","input_id":"noddi"},"myelin":{"type":"input","file_id":"map","input_id":"myelin"},"tck":{"type":"input","file_id":"track","input_id":"tck"},"T1":{"type":"input","file_id":"T1map","input_id":"qmri"},"T1_json":{"type":"input","file_id":"T1map_json","input_id":"qmri"},"R1":{"type":"input","file_id":"R1map","input_id":"qmri"},"R1_json":{"type":"input","file_id":"R1map_json","input_id":"qmri"},"M0":{"type":"input","file_id":"M0map","input_id":"qmri"},"M0_json":{"type":"input","file_id":"M0map_json","input_id":"qmri"},"PD":{"type":"input","file_id":"PD","input_id":"qmri"},"MTV":{"type":"input","file_id":"MTV","input_id":"qmri"},"VIP":{"type":"input","file_id":"VIP","input_id":"qmri"},"SIR":{"type":"input","file_id":"SIR","input_id":"qmri"},"WF":{"type":"input","file_id":"WF","input_id":"qmri"},"fiberbased":{"id":"fiberbased","type":"boolean","placeholder":"","desc":"to create profiles using a non-weighted, fiber-based method: \"true\"","default":false,"_order":2,"pid":0.22519795588319924,"advanced":true},"numnodes":{"id":"numnodes","type":"number","placeholder":"","desc":"Number of nodes for tract profiles","default":200,"_order":3,"pid":0.24641732151837958}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5cc210ce4ed9df00317f61d2","id":"tensor","datatype":"5a79df48d071a1753f1d661b","desc":"The path to the tensor datatype files"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5cc210ce4ed9df00317f61d1","id":"afq","datatype":"5cc1d64c44947d8aea6b2d8b","desc":"The path to the wmc classification datatype"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5cc210ce4ed9df00317f61d0","id":"noddi","datatype":"5ed02a620a8ed8e39c482a61","desc":"The path to the NODDI datatype files (optional)"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"60a6ab8222b42a7f5b6ffb0d","id":"myelin","datatype":"5fad54c27e8ecba2c3aa0c24"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5cc210f84ed9df00317f61d9","id":"tck","datatype":"5907d922436ee50ffde9c549","desc":"The path to the tractogram corresponding to the wmc structure"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"6115d123a5a04c2498f9eecf","id":"qmri","datatype":"608ac8b089df43e33c758fa1"}],"outputs":[{"datatype_tags":["tract_profiles"],"output_on_root":true,"archive":true,"_id":"5cc210ce4ed9df00317f61d4","id":"images","datatype":"5967b799b09297d8d831709e","datatype_tags_pass":null,"files":null,"desc":"Directory of tract profile images for each tract and measure"},{"datatype_tags":["profiles"],"output_on_root":false,"archive":true,"_id":"5f37374feb93bf187e60efaa","id":"tractmeasures","datatype":"599f305ad1f46fec1759f363","datatype_tags_pass":null,"files":null,"desc":"CSV containing all tracts and measures"}],"github_branch":"1.13","github":"brainlife/app-tractanalysisprofiles","name":"Tract Analysis Profiles","user_id":"16","contributors":[{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a3b4362f3d3800f1259b9"},{"name":"Brad Caron","email":null,"_id":"634a3b4362f3d3800f1259ba"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a3b4362f3d3800f1259bb"},{"name":"Franco Pestilli","email":null,"_id":"634a3b4362f3d3800f1259bc"},{"name":"Sophia Vinci-Booher","email":null,"_id":"634a3b4362f3d3800f1259bd"}],"desc":"Create plots of diffusion metrics (i.e. FA, MD, RD, AD) for each of the segmented tracts from AFQ, known as Tract Profiles. Obtains streamline positions from segmented tracts and plots the metrics of interest along \"nodes\" of the tract, allowing for comparison of individual subject tracts. Requires the dt6 output from dtiinit and a white matter classification output from AFQ or WMA","__v":4761,"create_date":"2020-05-28T21:22:00.532Z","doi":"10.25663/brainlife.app.361","_canedit":true},{"_id":"5ed02bb20a8ed87a11482d81","projects":[],"admins":["16"],"tags":["analysis"],"removed":false,"stats":{"requested":16297,"users":36,"success_rate":77.95080117354999,"gitinfo":{"desc":"Create plots of diffusion metrics (i.e. FA, MD, RD, AD) for each of the segmented tracts from AFQ, known as Tract Profiles. Obtains streamline positions from segmented tracts and plots the metrics of interest along \"nodes\" of the tract, allowing for comparison of individual subject tracts. Requires the dt6 output from dtiinit and a white matter classification output from AFQ or WMA","tags":["analysis"],"stats":{"stars":1},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Brad Caron","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":552322.51,"runtime_std":409252.69635279116,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3b4c62f3d3800f1259f0"},{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a3b4c62f3d3800f1259f1"}],"examples":1,"groups":79},"config":{"afq":{"type":"input","file_id":"classification","input_id":"afq"},"dir":{"type":"input","file_id":"dir","input_id":"noddi"},"ndi":{"type":"input","file_id":"ndi","input_id":"noddi"},"isovf":{"type":"input","file_id":"isovf","input_id":"noddi"},"odi":{"type":"input","file_id":"odi","input_id":"noddi"},"tck":{"type":"input","file_id":"track","input_id":"tck"},"fiberbased":{"id":"fiberbased","type":"boolean","placeholder":"","desc":"to create profiles using a non-weighted, fiber-based method: \"true\"","default":false,"_order":2,"pid":0.808975807839466,"advanced":true},"numnodes":{"id":"numnodes","type":"number","placeholder":"","desc":"Number of nodes for the tract profiles","default":200,"_order":3,"pid":0.44395957569782496}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5cc210ce4ed9df00317f61d1","id":"afq","datatype":"5cc1d64c44947d8aea6b2d8b","desc":"The path to the wmc classification structure"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5cc210ce4ed9df00317f61d0","id":"noddi","datatype":"5ed02a620a8ed8e39c482a61","desc":"The path to the NODDI datatype files"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5cc210f84ed9df00317f61d9","id":"tck","datatype":"5907d922436ee50ffde9c549","desc":"The tractogram (tck) corresponding to the wmc structure"}],"outputs":[{"datatype_tags":["tract_profiles"],"output_on_root":true,"archive":true,"_id":"5cc210ce4ed9df00317f61d4","id":"images","datatype":"5967b799b09297d8d831709e","datatype_tags_pass":null,"files":null,"desc":"Directory of tract profile images for each tract and measure"},{"datatype_tags":["profiles"],"output_on_root":false,"archive":true,"_id":"5f373778eb93bf471660f02d","id":"tractmeasures","datatype":"599f305ad1f46fec1759f363","datatype_tags_pass":null,"files":null,"desc":"CSV with all tracts and measures"}],"github_branch":"1.13","github":"brainlife/app-tractanalysisprofiles","name":"Tract Analysis Profiles (NODDI)","user_id":"16","contributors":[{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a3b4c62f3d3800f1259f2"},{"name":"Brad Caron","email":null,"_id":"634a3b4c62f3d3800f1259f3"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a3b4c62f3d3800f1259f4"},{"name":"Franco Pestilli","email":null,"_id":"634a3b4c62f3d3800f1259f5"},{"name":"Sophia Vinci-Booher","email":null,"_id":"634a3b4c62f3d3800f1259f6"}],"desc":"Create plots of diffusion metrics (i.e. FA, MD, RD, AD) for each of the segmented tracts from AFQ, known as Tract Profiles. Obtains streamline positions from segmented tracts and plots the metrics of interest along \"nodes\" of the tract, allowing for comparison of individual subject tracts. Requires the dt6 output from dtiinit and a white matter classification output from AFQ or WMA","__v":4769,"create_date":"2020-05-28T21:22:58.634Z","doi":"10.25663/brainlife.app.362","_canedit":true},{"_id":"5ec2f40841ba111ec4f421f7","projects":[],"admins":["16"],"tags":["analysis"],"removed":false,"stats":{"requested":16297,"users":36,"success_rate":77.95080117354999,"gitinfo":{"desc":"Create plots of diffusion metrics (i.e. FA, MD, RD, AD) for each of the segmented tracts from AFQ, known as Tract Profiles. Obtains streamline positions from segmented tracts and plots the metrics of interest along \"nodes\" of the tract, allowing for comparison of individual subject tracts. Requires the dt6 output from dtiinit and a white matter classification output from AFQ or WMA","tags":["analysis"],"stats":{"stars":1},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Brad Caron","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":552322.51,"runtime_std":409252.69635279116,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3aa562f3d3800f123df2"},{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a3aa562f3d3800f123df3"}],"examples":0,"groups":79},"config":{"afq":{"type":"input","file_id":"classification","input_id":"afq"},"icvf":{"type":"input","file_id":"icvf","input_id":"noddi"},"isovf":{"type":"input","file_id":"isovf","input_id":"noddi"},"od":{"type":"input","file_id":"od","input_id":"noddi"},"tck":{"type":"input","file_id":"track","input_id":"tck"},"fiberbased":{"id":"fiberbased","type":"boolean","placeholder":"","desc":"to create profiles using a non-weighted, fiber-based method: \"true\"","default":false,"_order":2,"pid":0.7458356524450971,"advanced":true},"numnodes":{"id":"numnodes","type":"number","placeholder":"","desc":"","default":200,"_order":3,"pid":0.2397856184684779}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5cc210ce4ed9df00317f61d1","id":"afq","datatype":"5cc1d64c44947d8aea6b2d8b"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5cc210ce4ed9df00317f61d0","id":"noddi","datatype":"5bd77a8615a8683a39440dab"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5cc210f84ed9df00317f61d9","id":"tck","datatype":"5907d922436ee50ffde9c549"}],"outputs":[{"datatype_tags":["tract_profiles"],"output_on_root":true,"archive":true,"_id":"5cc210ce4ed9df00317f61d4","id":"images","datatype":"5967b799b09297d8d831709e","datatype_tags_pass":null,"files":null},{"datatype_tags":[],"output_on_root":true,"archive":true,"_id":"5cc210ce4ed9df00317f61d3","id":"profiles","datatype":"5965467cb09297d8d81bdbcd","datatype_tags_pass":null,"files":null}],"github_branch":"1.6","github":"brainlife/app-tractanalysisprofiles","name":"Tract Analysis Profiles (NODDI) - Deprecated","user_id":"16","contributors":[{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a3aa662f3d3800f123df4"},{"name":"Brad Caron","email":null,"_id":"634a3aa662f3d3800f123df5"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a3aa662f3d3800f123df6"},{"name":"Franco Pestilli","email":null,"_id":"634a3aa662f3d3800f123df7"},{"name":"Sophia Vinci-Booher","email":null,"_id":"634a3aa662f3d3800f123df8"}],"desc":"Create plots of diffusion metrics (i.e. FA, MD, RD, AD) for each of the segmented tracts from AFQ, known as Tract Profiles. Obtains streamline positions from segmented tracts and plots the metrics of interest along \"nodes\" of the tract, allowing for comparison of individual subject tracts. Requires the dt6 output from dtiinit and a white matter classification output from AFQ or WMA","__v":4844,"create_date":"2020-05-18T20:46:00.692Z","doi":"10.25663/brainlife.app.345","deprecated_by":"5ed02bb20a8ed87a11482d81","_canedit":true},{"_id":"5cc210ce4ed9df00317f61cf","stats":{"stars":1,"requested":16297,"users":36,"success_rate":77.95080117354999,"serviceinfo":{"_id":"5d729e1f78356a109788b2e3","counts":{"_id":"5e5c3df287cac714b6ab1408","failed":2993,"finished":18141,"removed":24430,"requested":27631,"running":20684,"running_sync":0,"stop_requested":275},"success_rate":85.83798618340114,"users":28,"readme_status":"ok","runtime_mean":254811.88,"runtime_std":243210.8932301463,"service":"brain-life/app-tractanalysisprofiles","__v":0},"gitinfo":{"desc":"Create plots of diffusion metrics (i.e. FA, MD, RD, AD) for each of the segmented tracts from AFQ, known as Tract Profiles. Obtains streamline positions from segmented tracts and plots the metrics of interest along \"nodes\" of the tract, allowing for comparison of individual subject tracts. Requires the dt6 output from dtiinit and a white matter classification output from AFQ or WMA","tags":["analysis"],"stats":{"stars":1},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Brad Caron","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":552322.51,"runtime_std":409252.69635279116,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a35c662f3d3800f11a416"},{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a35c662f3d3800f11a417"}],"examples":2,"groups":79},"projects":[],"admins":["16"],"tags":["analysis"],"removed":false,"config":{"fa":{"type":"input","file_id":"fa","input_id":"tensor"},"md":{"type":"input","file_id":"md","input_id":"tensor"},"rd":{"type":"input","file_id":"rd","input_id":"tensor"},"ad":{"type":"input","file_id":"ad","input_id":"tensor"},"afq":{"type":"input","file_id":"classification","input_id":"afq"},"icvf":{"type":"input","file_id":"icvf","input_id":"noddi"},"isovf":{"type":"input","file_id":"isovf","input_id":"noddi"},"od":{"type":"input","file_id":"od","input_id":"noddi"},"tck":{"type":"input","file_id":"track","input_id":"tck"},"fiberbased":{"id":"fiberbased","type":"boolean","placeholder":"","desc":"to create profiles using a non-weighted, fiber-based method: \"true\"","default":false,"_order":2,"pid":0.31022053227433477,"advanced":true},"numnodes":{"id":"numnodes","type":"number","placeholder":"","desc":"","default":200,"_order":3,"pid":0.10267248155303732}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5cc210ce4ed9df00317f61d2","id":"tensor","datatype":"5a79df48d071a1753f1d661b"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5cc210ce4ed9df00317f61d1","id":"afq","datatype":"5cc1d64c44947d8aea6b2d8b"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5cc210ce4ed9df00317f61d0","id":"noddi","datatype":"5bd77a8615a8683a39440dab"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5cc210f84ed9df00317f61d9","id":"tck","datatype":"5907d922436ee50ffde9c549"}],"outputs":[{"datatype_tags":["tract_profiles"],"output_on_root":true,"archive":true,"_id":"5cc210ce4ed9df00317f61d4","id":"images","datatype":"5967b799b09297d8d831709e","datatype_tags_pass":null,"files":null},{"datatype_tags":[],"output_on_root":true,"archive":true,"_id":"5cc210ce4ed9df00317f61d3","id":"profiles","datatype":"5965467cb09297d8d81bdbcd","datatype_tags_pass":null,"files":null}],"github_branch":"1.6","github":"brainlife/app-tractanalysisprofiles","name":"Tract Analysis Profiles - Deprecated","user_id":"16","contributors":[{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a35c662f3d3800f11a418"},{"name":"Brad Caron","email":null,"_id":"634a35c662f3d3800f11a419"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a35c662f3d3800f11a41a"},{"name":"Franco Pestilli","email":null,"_id":"634a35c662f3d3800f11a41b"},{"name":"Sophia Vinci-Booher","email":null,"_id":"634a35c662f3d3800f11a41c"}],"create_date":"2019-04-25T19:55:58.436Z","desc":"Create plots of diffusion metrics (i.e. FA, MD, RD, AD) for each of the segmented tracts from AFQ, known as Tract Profiles. Obtains streamline positions from segmented tracts and plots the metrics of interest along \"nodes\" of the tract, allowing for comparison of individual subject tracts. Requires the dt6 output from dtiinit and a white matter classification output from AFQ or WMA","doi":"10.25663/brainlife.app.185","__v":8167,"deprecated_by":"5ed02b780a8ed88a57482c92","_canedit":true},{"_id":"6023450fab40ca71564cb1e6","projects":[],"admins":["16"],"tags":["analysis"],"removed":false,"stats":{"requested":16297,"users":36,"success_rate":77.95080117354999,"gitinfo":{"desc":"Create plots of diffusion metrics (i.e. FA, MD, RD, AD) for each of the segmented tracts from AFQ, known as Tract Profiles. Obtains streamline positions from segmented tracts and plots the metrics of interest along \"nodes\" of the tract, allowing for comparison of individual subject tracts. Requires the dt6 output from dtiinit and a white matter classification output from AFQ or WMA","tags":["analysis"],"stats":{"stars":1},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Brad Caron","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":552322.51,"runtime_std":409252.69635279116,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3ef362f3d3800f12c6fc"},{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a3ef362f3d3800f12c6fd"}],"examples":1,"groups":79},"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"classification":{"type":"input","file_id":"classification","input_id":"classification"},"track":{"type":"input","file_id":"track","input_id":"track"},"fa":{"type":"input","file_id":"fa","input_id":"tensor"},"md":{"type":"input","file_id":"md","input_id":"tensor"},"rd":{"type":"input","file_id":"rd","input_id":"tensor"},"ad":{"type":"input","file_id":"ad","input_id":"tensor"},"ga":{"type":"input","file_id":"ga","input_id":"tensor"},"ak":{"type":"input","file_id":"ak","input_id":"tensor"},"mk":{"type":"input","file_id":"mk","input_id":"tensor"},"rk":{"type":"input","file_id":"rk","input_id":"tensor"},"dir":{"type":"input","file_id":"dir","input_id":"noddi"},"ndi":{"type":"input","file_id":"ndi","input_id":"noddi"},"isovf":{"type":"input","file_id":"isovf","input_id":"noddi"},"odi":{"type":"input","file_id":"odi","input_id":"noddi"},"myelin":{"type":"input","file_id":"map","input_id":"myelin"},"T1":{"type":"input","file_id":"T1map","input_id":"qmri"},"T1_json":{"type":"input","file_id":"T1map_json","input_id":"qmri"},"R1":{"type":"input","file_id":"R1map","input_id":"qmri"},"R1_json":{"type":"input","file_id":"R1map_json","input_id":"qmri"},"M0":{"type":"input","file_id":"M0map","input_id":"qmri"},"M0_json":{"type":"input","file_id":"M0map_json","input_id":"qmri"},"PD":{"type":"input","file_id":"PD","input_id":"qmri"},"MTV":{"type":"input","file_id":"MTV","input_id":"qmri"},"VIP":{"type":"input","file_id":"VIP","input_id":"qmri"},"SIR":{"type":"input","file_id":"SIR","input_id":"qmri"},"WF":{"type":"input","file_id":"WF","input_id":"qmri"},"num_nodes":{"id":"num_nodes","type":"number","placeholder":"","desc":"Number of nodes for tract profiles","default":200,"_order":3,"pid":0.2760173736413306}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"6023453aab40ca19d04cb30c","id":"dwi","datatype":"58c33c5fe13a50849b25879b","desc":"The path to the reference dwi for the tractography. Used for the affine header"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5cc210ce4ed9df00317f61d1","id":"classification","datatype":"5cc1d64c44947d8aea6b2d8b","desc":"The path to the wmc classification datatype"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5cc210f84ed9df00317f61d9","id":"track","datatype":"5907d922436ee50ffde9c549","desc":"The path to the tractogram corresponding to the wmc structure"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5cc210ce4ed9df00317f61d2","id":"tensor","datatype":"5a79df48d071a1753f1d661b","desc":"The path to the tensor datatype files"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5cc210ce4ed9df00317f61d0","id":"noddi","datatype":"5ed02a620a8ed8e39c482a61","desc":"The path to the NODDI datatype files (optional)"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"6115f0e5a5a04c761bf9ffb2","id":"myelin","datatype":"5fad54c27e8ecba2c3aa0c24"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"6115f0e5a5a04c8188f9ffb3","id":"qmri","datatype":"608ac8b089df43e33c758fa1"}],"outputs":[{"datatype_tags":["tract_profiles"],"output_on_root":true,"archive":true,"_id":"5cc210ce4ed9df00317f61d4","id":"images","datatype":"5967b799b09297d8d831709e","datatype_tags_pass":null,"files":null,"desc":"Directory of tract profile images for each tract and measure"},{"datatype_tags":[],"output_on_root":true,"archive":true,"_id":"5cc210ce4ed9df00317f61d3","id":"profiles","datatype":"5965467cb09297d8d81bdbcd","datatype_tags_pass":null,"files":null,"desc":"Directory of tract profile csvs for each tract and measure"},{"datatype_tags":["profiles"],"output_on_root":false,"archive":true,"_id":"5f37374feb93bf187e60efaa","id":"tractmeasures","datatype":"599f305ad1f46fec1759f363","datatype_tags_pass":null,"files":null,"desc":"CSV containing all tracts and measures"}],"github_branch":"dipy-1.0","github":"brainlife/app-tractanalysisprofiles","name":"Tract Analysis Profiles - Dipy","user_id":"16","contributors":[{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a3ef462f3d3800f12c6fe"},{"name":"Brad Caron","email":null,"_id":"634a3ef462f3d3800f12c6ff"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a3ef462f3d3800f12c700"},{"name":"Franco Pestilli","email":null,"_id":"634a3ef462f3d3800f12c701"},{"name":"Sophia Vinci-Booher","email":null,"_id":"634a3ef462f3d3800f12c702"}],"desc":"Create plots of diffusion metrics (i.e. FA, MD, RD, AD) for each of the segmented tracts from AFQ, known as Tract Profiles. Obtains streamline positions from segmented tracts and plots the metrics of interest along \"nodes\" of the tract, allowing for comparison of individual subject tracts. Requires the dt6 output from dtiinit and a white matter classification output from AFQ or WMA","__v":3322,"create_date":"2021-02-10T02:29:35.419Z","doi":"10.25663/brainlife.app.474","_canedit":true},{"_id":"60a6a8f922b42a89506ff897","projects":[],"admins":["16"],"tags":["analysis"],"removed":false,"stats":{"requested":16297,"users":36,"success_rate":77.95080117354999,"gitinfo":{"desc":"Create plots of diffusion metrics (i.e. FA, MD, RD, AD) for each of the segmented tracts from AFQ, known as Tract Profiles. Obtains streamline positions from segmented tracts and plots the metrics of interest along \"nodes\" of the tract, allowing for comparison of individual subject tracts. Requires the dt6 output from dtiinit and a white matter classification output from AFQ or WMA","tags":["analysis"],"stats":{"stars":1},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Brad Caron","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":552322.51,"runtime_std":409252.69635279116,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a40b162f3d3800f12d82d"},{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a40b162f3d3800f12d82e"}],"examples":0,"groups":79},"config":{"myelin":{"type":"input","file_id":"map","input_id":"myelin"},"afq":{"type":"input","file_id":"classification","input_id":"afq"},"tck":{"type":"input","file_id":"track","input_id":"tck"},"fiberbased":{"id":"fiberbased","type":"boolean","placeholder":"","desc":"to create profiles using a non-weighted, fiber-based method: \"true\"","default":false,"_order":2,"pid":0.351683116085419,"advanced":true},"numnodes":{"id":"numnodes","type":"number","placeholder":"","desc":"Number of nodes for tract profiles","default":200,"_order":3,"pid":0.3559507225552534}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"60a6a8f922b42a25cf6ff89b","id":"myelin","datatype":"5fad54c27e8ecba2c3aa0c24","desc":"The path to the myelin-map datatype"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5cc210ce4ed9df00317f61d1","id":"afq","datatype":"5cc1d64c44947d8aea6b2d8b","desc":"The path to the wmc classification datatype"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5cc210f84ed9df00317f61d9","id":"tck","datatype":"5907d922436ee50ffde9c549","desc":"The path to the tractogram corresponding to the wmc structure"}],"outputs":[{"datatype_tags":["tract_profiles"],"output_on_root":true,"archive":true,"_id":"5cc210ce4ed9df00317f61d4","id":"images","datatype":"5967b799b09297d8d831709e","datatype_tags_pass":null,"files":null,"desc":"Directory of tract profile images for each tract and measure"},{"datatype_tags":["profiles"],"output_on_root":false,"archive":true,"_id":"5f37374feb93bf187e60efaa","id":"tractmeasures","datatype":"599f305ad1f46fec1759f363","datatype_tags_pass":null,"files":null,"desc":"CSV containing all tracts and measures"}],"github_branch":"1.13","github":"brainlife/app-tractanalysisprofiles","name":"Tract Analysis Profiles - Myelin mapping","user_id":"16","contributors":[{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a40b262f3d3800f12d82f"},{"name":"Brad Caron","email":null,"_id":"634a40b262f3d3800f12d830"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a40b262f3d3800f12d831"},{"name":"Franco Pestilli","email":null,"_id":"634a40b262f3d3800f12d832"},{"name":"Sophia Vinci-Booher","email":null,"_id":"634a40b262f3d3800f12d833"}],"desc":"Create plots of diffusion metrics (i.e. FA, MD, RD, AD) for each of the segmented tracts from AFQ, known as Tract Profiles. Obtains streamline positions from segmented tracts and plots the metrics of interest along \"nodes\" of the tract, allowing for comparison of individual subject tracts. Requires the dt6 output from dtiinit and a white matter classification output from AFQ or WMA","__v":2612,"create_date":"2021-05-20T18:22:49.062Z","doi":"10.25663/brainlife.app.523","_canedit":true},{"_id":"5b74603859b6e90027009974","projects":[],"admins":["16","41","146","1"],"tags":["analysis"],"removed":false,"config":{"outputs":{"type":"input","file_id":"profiles","input_id":"profiles"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":true,"advanced":false,"_id":"5b74603859b6e90027009975","id":"profiles","datatype":"5965467cb09297d8d81bdbcd"}],"outputs":[],"name":"Tract Profile Aggregator","avatar":"https://brainlife.io/images/app-logos/app-tractprofile-agg.png","github":"brainlife/app-tractprofiles-agg","user_id":"1","references":[],"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a339062f3d3800f118008"}],"create_date":"2018-08-15T17:17:44.634Z","desc":"Tract Profile Output Aggregator","stats":{"stars":0,"requested":14,"users":4,"success_rate":64.28571428571429,"serviceinfo":{"_id":"5d729e1e78356a109788b1f9","counts":{"_id":"5e5c3db587cac72491ab13c8","failed":4,"finished":8,"removed":7,"requested":12,"running":11,"running_sync":0,"stop_requested":0},"success_rate":66.66666666666666,"users":2,"readme_status":"empty","runtime_mean":1992114.875,"runtime_std":4353723.755432568,"service":"brainlife/app-tractprofiles-agg","__v":0},"gitinfo":{"desc":"Tract Profile Output Aggregator","tags":["analysis"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":1802518.4444444445,"runtime_std":4139611.5541793993,"resources":[],"examples":1,"groups":3},"doi":"10.25663/bl.app.90","__v":11322,"github_branch":"master","_canedit":true},{"_id":"59638eb91b382a00216a99f5","name":"Tract Profiles","desc":"This app takes in tracking data from the White Matter Segmentation app well as the nifti files of the user and gives tract profiles for each tracking file in a json format.","github":"brainlife/app-tract-profile","config":{"data_file":{"type":"input","input_id":"data_file","file_id":"dwi"},"data_bvec":{"type":"input","input_id":"data_file","file_id":"bvecs"},"data_bval":{"type":"input","input_id":"data_file","file_id":"bvals"},"tck_data":{"type":"input","input_id":"tck_data","file_id":"track"}},"user_id":"61","create_date":"2017-07-10T14:27:05.150Z","removed":false,"_rate":0,"outputs":[{"datatype_tags":[],"output_on_root":true,"archive":true,"_id":"5966536824c73600332f21f7","id":"track","datatype":"5965467cb09297d8d81bdbcd","files":null}],"inputs":[{"datatype_tags":["!single_shell","7t"],"optional":false,"multi":false,"advanced":false,"_id":"596391881b382a00216a99f9","id":"data_file","datatype":"58c33c5fe13a50849b25879b"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"596391881b382a00216a99f8","id":"tck_data","datatype":"5907d922436ee50ffde9c549"}],"tags":["tracking"],"admins":["61","16","41","146","1"],"__v":14298,"contributors":[{"name":"Aman Arya","email":"aman.arya524@gmail.com","_id":"634a30d862f3d3800f116522"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a30d862f3d3800f116523"}],"projects":["5a74ccd66ed91402ce400cc6"],"references":[],"stats":{"stars":0,"requested":16,"users":3,"success_rate":0,"serviceinfo":{"_id":"5d729e1f78356a109788b327","counts":{"_id":"5e5c687e87cac79f8cab1ba3","failed":13,"finished":0,"removed":13,"requested":16,"running":11,"running_sync":0,"stop_requested":1},"success_rate":0,"users":3,"readme_status":"too short","service":"brain-life/app-tract-profile","__v":0},"gitinfo":{"desc":"This app takes in tracking data from the White Matter Segmentation app well as the nifti files of the user and gives tract profiles for each tracking file in a json format.","tags":["tracking"],"stats":{"stars":0},"contributors":[{"name":"Aman Arya","email":"aman.arya524@gmail.com"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":null,"runtime_std":null,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a30d862f3d3800f116521"}],"examples":0},"doi":"10.25663/bl.app.86","_canedit":true},{"_id":"5b82d7f4e2f4f800275e020f","projects":[],"admins":["16","41","146","240","43","1"],"tags":["analysis","white-matter-segmentation"],"removed":false,"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"t1":{"type":"input","file_id":"t1","input_id":"t1"},"preprocess":{"id":"preprocess","type":"boolean","placeholder":"","desc":"Run preprocessing step to align the input image to MNI. The input image must have the same \"orientation\" as the Human Connectome Project data (MNI space) (LEFT must be on the same side as LEFT of the HCP data). If the image orientation and the gradient orientation of your data is the same as in examples/Diffusion.nii.gz you are fine. Otherwise you should rigidly register your image to MNI space (the brains do not have to be perfectly aligned but must have the same LEFT/RIGHT orientation).","default":false,"_order":2,"pid":0.3267627175607364},"csd":{"id":"csd","type":"enum","placeholder":"","desc":"Choose the type of constrained spherical deconvolution (CSD) to run. If you have a registered T1 and multi-shell data, you can choose csd_msmt_5tt, otherwise choose the default. ","default":"csd","_order":3,"pid":0.14686376639448406,"options":[{"desc":"standard CSD","label":"csd","value":"csd"},{"desc":"multi-tissue constrained spherical deconvolution (CSD) of multi-shell data ","label":"csd_msmt_5tt","value":"csd_msmt_5tt"}]}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5b82d7f4e2f4f800275e0210","id":"dwi","datatype":"58c33c5fe13a50849b25879b"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5bbbbad5fcb14c00272a37d0","id":"t1","datatype":"58c33bcee13a50849b25879a"}],"outputs":[{"datatype_tags":["tract_segmentations"],"output_on_root":true,"archive":true,"_id":"5b82d7f4e2f4f800275e0211","id":"output","datatype":"592dded1436ee50ffd88f5d0","datatype_tags_pass":null,"files":{"masks":"tractseg_output/bundle_segmentations"}},{"datatype_tags":["tractseg"],"output_on_root":true,"archive":true,"_id":"5bb3917019fdb40027307f7f","id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":{"output":"tractseg_output"}},{"datatype_tags":["tractseg"],"output_on_root":true,"archive":true,"_id":"5bbd3da9fcb14c00272a437b","id":"wmc","datatype":"58f10a90436ee50ffd9063c5","datatype_tags_pass":null,"files":{"output":"output.mat","fibercounts":"output_fibercounts.txt","tracts":"tracts/"}},{"datatype_tags":["ending_segmentations"],"output_on_root":true,"archive":true,"_id":"5bbe2075fcb14c00272a4397","id":"endingmasks","datatype":"592dded1436ee50ffd88f5d0","datatype_tags_pass":null,"files":{"masks":"tractseg_output/endings_segmentations"}}],"name":"TractSeg","github":"brainlife/app-tractseg","user_id":"1","references":[],"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a33bd62f3d3800f11802b"},{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a33bd62f3d3800f11802c"},{"name":"Giulia Bertò","email":null,"_id":"634a33bd62f3d3800f11802d"},{"name":"Franco Pestilli","email":null,"_id":"634a33bd62f3d3800f11802e"}],"create_date":"2018-08-26T16:40:20.035Z","desc":"Brainlife App for MIC-DKFZ/TractSeg. A tool for fast and accurate white matter bundle segmentation from Diffusion MRI using pretrained pytorch ML model.","stats":{"stars":0,"requested":16806,"users":72,"success_rate":69.09415363698164,"serviceinfo":{"_id":"5d729e1f78356a109788b297","counts":{"_id":"5e5c3db887cac71751ab13cd","failed":1970,"finished":3685,"removed":5706,"requested":6806,"running":5581,"running_sync":0,"stop_requested":277},"success_rate":65.16357206012378,"users":38,"readme_status":"ok","runtime_mean":7740929.19,"runtime_std":13531350.077703223,"service":"brainlife/app-tractseg","__v":0},"gitinfo":{"desc":"Brainlife App for MIC-DKFZ/TractSeg. A tool for fast and accurate white matter bundle segmentation from Diffusion MRI using pretrained pytorch ML model.","tags":["analysis"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Lindsey Kitchell","email":null},{"name":"Franco Pestilli","email":null}]},"runtime_mean":3819627.59,"runtime_std":2440719.0370542537,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a33bc62f3d3800f118028"},{"resource_id":"5ffc99da0df8ff7fc740c95a","name":"Bridges2 @ PSC (GPU-Shared)","_id":"634a33bc62f3d3800f118029"},{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"634a33bc62f3d3800f11802a"}],"examples":0,"groups":94},"doi":"10.25663/bl.app.95","__v":11102,"avatar":"https://raw.githubusercontent.com/brainlife/app-tractseg/master/logo.png","github_branch":"1.7.3","deprecated_by":"5cc3ccf94ed9df00317f6203","_canedit":true},{"_id":"5cc3ccf94ed9df00317f6203","projects":[],"admins":["16","41","146","1"],"tags":["analysis","white-matter-segmentation"],"removed":false,"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"t1":{"type":"input","file_id":"t1","input_id":"t1"},"preprocess":{"id":"preprocess","type":"boolean","placeholder":"","desc":"(this feature is temporarily disabled - as it generates peak.nii.gz in incorrect size for step 2,3,4).","default":false,"_order":2,"pid":0.4449464119517057,"readonly":true,"advanced":true},"csd":{"id":"csd","type":"enum","placeholder":"","desc":"Choose the type of constrained spherical deconvolution (CSD) to run. To use csd_msmt,   multi-shell data is required. To use csd_msmt_5tt,  multi-shell data and a registered T1 are required.","default":"csd","_order":3,"pid":0.6595682448952926,"options":[{"desc":"standard CSD","label":"csd","value":"csd"},{"desc":"multi-tissue constrained spherical deconvolution (CSD) of multi-shell data ","label":"csd_msmt","value":"csd_msmt"},{"desc":"multi-tissue constrained spherical deconvolution (CSD) of multi-shell data and 5TT ","label":"csd_msmt_5tt","value":"csd_msmt_5tt"}]},"nr_fibers":{"id":"nr_fibers","type":"number","placeholder":"","advanced":false,"desc":"Number of fibers to create for each bundle (default: 2000).","default":2000,"_order":4,"pid":0.6694862299374014},"strides":{"id":"strides","type":"string","placeholder":"","advanced":true,"desc":"Specify the strides of the output peaks.nii.gz as a comma-separated list of (signed) integers.","default":"","_order":5,"pid":0.5312833930142833,"optional":true},"bundles":{"id":"bundles","type":"string","placeholder":"","advanced":false,"desc":"Comma separated list (without spaces) of bundles you want to track.  Leave empty if you want to track all. For the list of possible bundles, please refer to https://github.com/MIC-DKFZ/TractSeg.","default":"","_order":6,"pid":0.679645401739392,"optional":true}},"inputs":[{"id":"dwi","desc":"Input dwi image for TractSeg. TractSeg will generate CSD peaks from this dwi before running TOM tracking, and Tractography. The input dwi image must have the same \"orientation\" as the Human Connectome Project data (MNI space) (LEFT must be on the same side as LEFT of the HCP data). ","datatype":"58c33c5fe13a50849b25879b","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5b82d7f4e2f4f800275e0210"},{"id":"t1","desc":"T1w image. Required when using csd_type=csd_msmt_5tt. The T1 image should be in the same space as the dwi image. ","datatype":"58c33bcee13a50849b25879a","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"6320ba54c173fce46c4c4d8a"}],"outputs":[{"id":"tck","datatype":"5907d922436ee50ffde9c549","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5cc3ccf94ed9df00317f6206"},{"id":"wmc","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags":["tractseg"],"datatype_tags_pass":null,"output_on_root":false,"files":{"output":"output.mat","fibercounts":"output_fibercounts.txt","tracts":"tracts/"},"archive":true,"_id":"5bbd3da9fcb14c00272a437b"},{"id":"output","datatype":"592dded1436ee50ffd88f5d0","datatype_tags":["tract_segmentations"],"datatype_tags_pass":null,"output_on_root":false,"files":{"masks":"tractseg_output/bundle_segmentations"},"archive":true,"_id":"5b82d7f4e2f4f800275e0211"},{"id":"endingmasks","datatype":"592dded1436ee50ffd88f5d0","datatype_tags":["ending_segmentations"],"datatype_tags_pass":null,"output_on_root":false,"files":{"masks":"tractseg_output/endings_segmentations"},"archive":true,"_id":"5bbe2075fcb14c00272a4397"},{"id":"tractseg_output","datatype":"630d072219b13f0a0ee3cd15","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":false,"_id":"630d09b319b13f0a0ee3cefa"}],"name":"TractSeg","github":"brainlife/app-tractseg","user_id":"1","contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a35d162f3d3800f11a5e6"},{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a35d162f3d3800f11a5e7"},{"name":"Giulia Bertò","email":null,"_id":"634a35d162f3d3800f11a5e8"},{"name":"Franco Pestilli","email":null,"_id":"634a35d162f3d3800f11a5e9"}],"desc":"Brainlife App for MIC-DKFZ/TractSeg. A tool for fast and accurate white matter bundle segmentation from Diffusion MRI using pretrained pytorch ML model.","stats":{"stars":0,"requested":16806,"users":72,"success_rate":69.09415363698164,"serviceinfo":{"_id":"5d729e1f78356a109788b297","counts":{"_id":"5e5c3df487cac70ffdab1409","failed":1970,"finished":3685,"removed":5706,"requested":6806,"running":5581,"running_sync":0,"stop_requested":277},"success_rate":65.16357206012378,"users":38,"readme_status":"ok","runtime_mean":7740929.19,"runtime_std":13531350.077703223,"service":"brainlife/app-tractseg","__v":0},"gitinfo":{"desc":"Brainlife App for MIC-DKFZ/TractSeg. A tool for fast and accurate white matter bundle segmentation from Diffusion MRI using pretrained pytorch ML model.","tags":["analysis"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Lindsey Kitchell","email":null},{"name":"Franco Pestilli","email":null}]},"runtime_mean":3819627.59,"runtime_std":2440719.0370542537,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a35d062f3d3800f11a5e3"},{"resource_id":"5ffc99da0df8ff7fc740c95a","name":"Bridges2 @ PSC (GPU-Shared)","_id":"634a35d062f3d3800f11a5e4"},{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"634a35d062f3d3800f11a5e5"}],"examples":5,"groups":94},"__v":8177,"avatar":"https://raw.githubusercontent.com/brainlife/app-tractseg/master/logo.png","github_branch":"2.2","create_date":"2019-04-27T03:31:05.108Z","doi":"10.25663/brainlife.app.186","_canedit":true},{"_id":"5cf00ab9059f7a0036ff3848","projects":[],"admins":["446","45","146"],"tags":[],"removed":false,"stats":{"stars":0,"requested":687,"users":3,"success_rate":77.83687943262412,"serviceinfo":{"_id":"5d729e1e78356a109788b1f5","counts":{"_id":"5e5c3e0387cac7d5a9ab141a","failed":123,"finished":333,"removed":418,"requested":577,"running":517,"running_sync":0,"stop_requested":84},"success_rate":73.02631578947368,"users":3,"readme_status":"no README.md","runtime_mean":102083.93,"runtime_std":68121.49101498806,"service":"FBK-NILab/TractSeg-BrainLife","__v":0},"gitinfo":{"desc":"Automatic White Matter Bundle Segmentation","tags":[],"stats":{"stars":0},"contributors":[{"name":"Jakob Wasserthal","email":null},{"name":null,"email":null},{"name":"Pietro Astolfi","email":"pietroastolfi92@gmail.com"},{"name":"Matthias Greiner","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":248676.14,"runtime_std":140231.90157371605,"resources":[],"examples":1,"groups":3},"config":{"peaks":{"type":"input","file_id":"peaks","input_id":"0"},"npz":{"type":"input","file_id":"npz","input_id":"1"},"hparam":{"type":"input","file_id":"hparam","input_id":"1"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5cf00841059f7a0036ff3841","id":"0","datatype":"5c9276dc44947d8aea7d6454","desc":"peaks"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5cf00841059f7a0036ff3840","id":"1","datatype":"5ced859744947d8aeaa4add7","desc":"pretrained weights of TractSeg"}],"outputs":[{"datatype_tags":["tract_segmentations"],"output_on_root":false,"archive":true,"_id":"5cf00ab9059f7a0036ff384c","id":"output","datatype":"592dded1436ee50ffd88f5d0","datatype_tags_pass":null,"files":null,"desc":"Bundle segmentation"}],"github_branch":"brainlife-app","github":"FBK-NILab/TractSeg-BrainLife","name":"TractSeg test","user_id":"146","contributors":[{"name":"Jakob Wasserthal","email":null,"_id":"634a367662f3d3800f11ce69"},{"name":"Pietro Astolfi","email":"pietroastolfi92@gmail.com","_id":"634a367662f3d3800f11ce6a"},{"name":"Matthias Greiner","email":null,"_id":"634a367662f3d3800f11ce6b"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a367662f3d3800f11ce6c"}],"desc":"Automatic White Matter Bundle Segmentation","__v":7901,"create_date":"2019-05-30T16:54:17.360Z","doi":"10.25663/brainlife.app.205","_canedit":true},{"_id":"5cf00841059f7a0036ff383f","stats":{"stars":0,"requested":687,"users":3,"success_rate":77.83687943262412,"serviceinfo":{"_id":"5d729e1e78356a109788b1f5","counts":{"_id":"5e5c3e0287cac7447eab1419","failed":123,"finished":333,"removed":418,"requested":577,"running":517,"running_sync":0,"stop_requested":84},"success_rate":73.02631578947368,"users":3,"readme_status":"no README.md","runtime_mean":102083.93,"runtime_std":68121.49101498806,"service":"FBK-NILab/TractSeg-BrainLife","__v":0},"gitinfo":{"desc":"Automatic White Matter Bundle Segmentation","tags":[],"stats":{"stars":0},"contributors":[{"name":"Jakob Wasserthal","email":null},{"name":null,"email":null},{"name":"Pietro Astolfi","email":"pietroastolfi92@gmail.com"},{"name":"Matthias Greiner","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":248676.14,"runtime_std":140231.90157371605,"resources":[],"examples":0,"groups":3},"projects":[],"admins":["446","45","146"],"tags":[],"removed":false,"config":{"peaks":{"type":"input","file_id":"peaks","input_id":"0"},"masks":{"type":"input","file_id":"masks","input_id":"1"},"perc_val":{"id":"perc_val","type":"number","placeholder":"","desc":"percentage of validation subjects (between 0 and 1)","default":0.2,"_order":2,"pid":0.12141895670138037,"min":0,"max":1},"num_epochs":{"id":"num_epochs","type":"number","placeholder":"","desc":"number of epochs","default":100,"_order":3,"pid":0.3495250838390638,"max":1000,"min":1},"data_augmentation":{"id":"data_augmentation","type":"boolean","placeholder":"","desc":"","default":true,"_order":4,"pid":0.9812817263196905}},"inputs":[{"datatype_tags":[],"optional":false,"multi":true,"advanced":false,"_id":"5cf00841059f7a0036ff3841","id":"0","datatype":"5c9276dc44947d8aea7d6454","desc":"peaks"},{"datatype_tags":["tract_segmentations"],"optional":false,"multi":true,"advanced":false,"_id":"5cf00841059f7a0036ff3840","id":"1","datatype":"592dded1436ee50ffd88f5d0","desc":"ground truth tractmasks"}],"outputs":[{"datatype_tags":["tractseg"],"output_on_root":false,"archive":true,"_id":"5cf00841059f7a0036ff3842","id":"weights","datatype":"5ced859744947d8aeaa4add7","datatype_tags_pass":null,"files":null,"desc":"pretrained weights of TractSeg"},{"datatype_tags":["tractseg"],"output_on_root":false,"archive":true,"_id":"5d303ac66c03750a8a525363","id":"images","datatype":"5967b799b09297d8d831709e","datatype_tags_pass":null,"files":null,"desc":"training metrics"}],"github_branch":"brainlife-app","github":"FBK-NILab/TractSeg-BrainLife","name":"TractSeg training","user_id":"146","contributors":[{"name":"Jakob Wasserthal","email":null,"_id":"634a366c62f3d3800f11cdb0"},{"name":"Pietro Astolfi","email":"pietroastolfi92@gmail.com","_id":"634a366c62f3d3800f11cdb1"},{"name":"Matthias Greiner","email":null,"_id":"634a366c62f3d3800f11cdb2"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a366c62f3d3800f11cdb3"}],"create_date":"2019-05-30T16:43:45.226Z","desc":"Automatic White Matter Bundle Segmentation","doi":"10.25663/brainlife.app.204","__v":7903,"_canedit":true},{"_id":"5f035c35c67a0de2212abf6a","stats":{"resources":[{"resource_id":"5ffc99da0df8ff7fc740c95a","name":"Bridges2 @ PSC (GPU-Shared)","_id":"634a3c5062f3d3800f12801e"}],"success_rate":20.51282051282051,"users":4,"runtime_mean":1056881.25,"runtime_std":2503036.458852465,"requested":44,"examples":0,"groups":5},"projects":[],"admins":["45","446"],"tags":[],"removed":false,"config":{"trk":{"type":"input","file_id":"track","input_id":"1"},"t1":{"type":"input","file_id":"t1","input_id":"2"},"fa":{"type":"input","file_id":"fa","input_id":"3"},"fast_warp":{"id":"fast_warp","type":"boolean","placeholder":"","advanced":false,"desc":"This parameter determine the speed of the non linear registration to standard MNI. When set to true it triggers a fast (few mins) but decent non-linear warp computation (search antsRegistrationSynQuick.sh for details). When set to false it triggers a slower (~30mins) but refined non linear registration.","default":true,"_order":2,"pid":0.7839439029839512}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5f035c35c67a0d34622abf6b","id":"1","datatype":"5b956f6cd7b3f1e24e9121ce","desc":"Input tractogram in trk format."},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5f035c35c67a0d9c482abf6c","id":"2","datatype":"58c33bcee13a50849b25879a","desc":"T1w in dwi space. This argument is not required if tractogram is already in the MNI space."},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5fadcf0b7e8ecb7576aa2fed","id":"3","datatype":"5a79df48d071a1753f1d661b","desc":"FA image of the subject. This argument is not required if tractogram is already in the MNI space."}],"outputs":[{"datatype_tags":["clean"],"output_on_root":false,"archive":true,"_id":"5f035c35c67a0d80202abf6d","id":"output","datatype":"5b956f6cd7b3f1e24e9121ce","datatype_tags_pass":"1","files":null,"desc":"A tractogram where artifactual streamlines has been filtered out. The output is in .trk format."},{"datatype_tags":["plausible_streamlines_indexes"],"output_on_root":false,"archive":true,"_id":"5f035c35c67a0dce702abf6e","id":"output/plausible_idxs","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null,"desc":"Txt file containing the indexes of anatomically plausible streamline with respect to the input tractogram. "},{"datatype_tags":["non_plausible_streamlines_indexes"],"output_on_root":false,"archive":true,"_id":"5f035c35c67a0d7b842abf6f","id":"output/non_plausible_idxs","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null,"desc":"Txt file containing the indexes of anatomically non-plausible streamline with respect to the input tractogram. "}],"github_branch":"brainlife-app","github":"FBK-NILab/tractogram_filtering","name":"Tractogram Filtering","desc_override":"Filtering out of artifactual streamlines from a tractogram with a geometric deep learning model","user_id":"446","contributors":[{"name":"Paolo Avesani","email":null,"_id":"634a3c5162f3d3800f12801f"}],"create_date":"2020-07-06T17:15:33.931Z","desc":"Filtering out of artifactual streamlines from a tractogram with a geometric deep learning model","doi":"10.25663/brainlife.app.390","__v":4459,"_canedit":true},{"_id":"611aa462a5a04c4672fb671b","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a423562f3d3800f12f42d"}],"success_rate":41.66666666666667,"users":3,"requested":13,"examples":0,"groups":3,"runtime_mean":1428172.6,"runtime_std":1725032.193155432},"projects":[],"admins":["56"],"tags":[],"removed":false,"config":{"tractogram":{"type":"input","file_id":"track","input_id":"tractogram"},"classification":{"type":"input","file_id":"classification","input_id":"classification"},"tracts":{"type":"input","file_id":"tracts","input_id":"classification"},"surfaces":{"type":"input","file_id":"surfaces","input_id":"classification"},"streamThresh":{"id":"streamThresh","type":"number","placeholder":"","advanced":false,"desc":"The minimum streamlines (and thus an **integer**) needed in a quickBundles cluster in order to survive the culling process.","default":5,"_order":2,"pid":0.9617148578431578,"min":1,"max":1000},"qbThreshes":{"id":"qbThreshes","type":"string","placeholder":"","advanced":true,"desc":"quickbundles thresholds for application of [dipy.segment.bundles.qbx_and_merge](https://dipy.org/documentation/1.1.1./reference/dipy.segment/#qbx-and-merge)","default":"32,16,8,3","_order":3,"pid":0.45074840620106116}},"inputs":[{"id":"tractogram","desc":"A whole brain tractogram that is to be subjected to a cull of extraneous or otherwise spurious streamlines","datatype":"5907d922436ee50ffde9c549","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"611aa462a5a04c132cfb671c"},{"id":"classification","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"62a7d6aeab3e6697806200df"}],"outputs":[{"id":"tck_survived","desc":"The output tractogram which has had some number of spurious or extraneous streamlines removed.","datatype":"5907d922436ee50ffde9c549","datatype_tags":["filtered"],"datatype_tags_pass":"tractogram","output_on_root":false,"files":null,"archive":true,"_id":"611aa462a5a04c07d2fb671d"},{"id":"wmc_survived","desc":"A WMC corresponding to the surviving streamlines.   Identities passed through if WMC input provided, otherwise ignore.","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags":["filtered"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"62a7d6aeab3e6697806200e1"},{"id":"tck_culled","desc":"A tractogram containing the streamlines that were culled","datatype":"5907d922436ee50ffde9c549","datatype_tags":["culled"],"datatype_tags_pass":"tractogram","output_on_root":false,"files":null,"archive":false,"_id":"611aa789a5a04cf33efb6b54"},{"id":"wmc_culled","desc":"A WMC corresponding to the culled streamlines.   Identities passed through if WMC input provided, otherwise ignore.","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags":["culled"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"62a7d6aeab3e6697806200e3"}],"github":"DanNBullock/app-filterViaQuickbundles","name":"Tractogram cleaning with DIPY's quickBundles","user_id":"56","contributors":[{"name":"Brad Caron","email":null,"_id":"634a423662f3d3800f12f42e"},{"name":"Daniel Bullock","email":"iisdanbul@gmail.com","_id":"634a423662f3d3800f12f42f"}],"create_date":"2021-08-16T17:46:10.804Z","desc":null,"__v":2050,"doi":"10.25663/brainlife.app.564","github_branch":"main","_canedit":true},{"_id":"5c350f24836af601cc858601","stats":{"stars":0,"requested":39290,"users":30,"success_rate":80.92287800016163,"serviceinfo":{"_id":"5d729e1f78356a109788b24f","counts":{"_id":"5e5c3dd487cac7e9c4ab13e9","failed":5766,"finished":9082,"removed":13663,"requested":16042,"running":10542,"running_sync":0,"stop_requested":343},"success_rate":61.166487068965516,"users":12,"readme_status":"ok","runtime_mean":8166187.08,"runtime_std":16929923.436678406,"service":"brainlife/app-tractographyQualityCheck","__v":0},"gitinfo":{"desc":"A quality check application for tractography, segmentatations, and LiFE structures","tags":[],"stats":{"stars":0},"contributors":[{"name":"Daniel Bullock","email":null},{"name":"Franco Pestilli","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":860623.65,"runtime_std":1148769.5499679937,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a34bf62f3d3800f118d1b"},{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a34bf62f3d3800f118d1c"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a34bf62f3d3800f118d1d"}],"examples":0,"groups":69},"projects":[],"admins":["56"],"tags":[],"removed":false,"config":{"track":{"type":"input","file_id":"track","input_id":"wbfg"},"fe":{"type":"input","file_id":"fe","input_id":"fe"},"output":{"type":"input","file_id":"output","input_id":"classification"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c350f24836af601cc858604","id":"wbfg","datatype":"5907d922436ee50ffde9c549","desc":"Whole brain tractography.  A tractome which covers the entire white matter."},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5c350f24836af601cc858603","id":"fe","datatype":"58d15eaee13a50849b258844","desc":"A LiFE structure corresponding to the whole brain tractography entered as a track/tck."},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5c350f24836af601cc858602","id":"classification","datatype":"58f10a90436ee50ffd9063c5","desc":"A white matter classification structure which corresponds to the input whole brain tractography entered as a track/tck."}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5c350f24836af601cc858606","id":"image","datatype":"5cb7711c44947d8aea8cb4f4","datatype_tags_pass":"classification","files":{"image":"tractomeStatPlot.epsc"}},{"datatype_tags":["tract_measures","tractography_quantification"],"output_on_root":false,"archive":true,"_id":"5c350f24836af601cc858605","id":"tractmeasures","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":"classification","files":{"output":"."}},{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5c5cc3235204830032204ccf","id":"resultsSummary","datatype":"599f305ad1f46fec1759f363","datatype_tags_pass":"classification","files":null}],"github_branch":"master","github":"brainlife/app-tractographyQualityCheck","name":"Tractography quality check","user_id":"56","references":[],"contributors":[{"name":"Daniel Bullock","email":"iisdanbul@gmail.com","_id":"634a34bf62f3d3800f118d1e"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a34bf62f3d3800f118d1f"},{"name":"Brad Caron","email":null,"_id":"634a34bf62f3d3800f118d20"},{"name":"Franco Pestilli","email":null,"_id":"634a34bf62f3d3800f118d21"}],"create_date":"2019-01-08T20:59:16.039Z","desc":"Compute many statistics from your input tractogram and any (optionally input) associated classification structure.  These statistics can be used to facilitate quality assurance on your tractography and segmentation, or as part of subject/group level quantative analysis for a research project. See the output section of README.MD for more details.","doi":"10.25663/brainlife.app.139","__v":8247,"deprecated_by":"5cc9c6b44b5e4502275edb4b","_canedit":true},{"_id":"5cc9c6b44b5e4502275edb4b","projects":[],"admins":["16","41","146","1"],"tags":[],"removed":false,"stats":{"stars":0,"serviceinfo":{"_id":"5d729e1f78356a109788b24f","counts":{"_id":"5e5c3df787cac742c9ab140c","failed":5766,"finished":9082,"removed":13663,"requested":16042,"running":10542,"running_sync":0,"stop_requested":343},"success_rate":61.166487068965516,"users":12,"readme_status":"ok","runtime_mean":8166187.08,"runtime_std":16929923.436678406,"service":"brainlife/app-tractographyQualityCheck","__v":0},"gitinfo":{"desc":"A quality check application for tractography, segmentatations, and LiFE structures","tags":[],"stats":{"stars":0},"contributors":[{"name":"Daniel Bullock","email":null},{"name":"Franco Pestilli","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"success_rate":80.92287800016163,"users":30,"runtime_mean":860623.65,"runtime_std":1148769.5499679937,"requested":39290,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a35fc62f3d3800f11bd20"},{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a35fc62f3d3800f11bd21"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a35fc62f3d3800f11bd22"}],"examples":5,"groups":69},"config":{"track":{"type":"input","file_id":"track","input_id":"wbfg"},"classification":{"type":"input","file_id":"classification","input_id":"classification"},"tracts":{"type":"input","file_id":"tracts","input_id":"classification"}},"inputs":[{"id":"wbfg","desc":"Whole brain tractography.  A tractome which covers the entire white matter.","datatype":"5907d922436ee50ffde9c549","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c350f24836af601cc858604"},{"id":"classification","desc":"A white matter classification structure which corresponds to the input whole brain tractography entered as a track/tck.","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c350f24836af601cc858602"}],"outputs":[{"id":"image","datatype":"5cb7711c44947d8aea8cb4f4","datatype_tags":[],"datatype_tags_pass":"classification","output_on_root":false,"files":{"image":"tractomeStatPlot.epsc"},"archive":true,"_id":"5c350f24836af601cc858606"},{"id":"tractmeasures","datatype":"59c3eae633fc1cf9ead71679","datatype_tags":["tractography_quantification","tract_measures"],"datatype_tags_pass":"classification","output_on_root":false,"files":{"output":"."},"archive":true,"_id":"5c350f24836af601cc858605"},{"id":"resultsSummary","datatype":"599f305ad1f46fec1759f363","datatype_tags":["macro"],"datatype_tags_pass":"classification","output_on_root":false,"files":null,"archive":false,"_id":"5c5cc3235204830032204ccf"}],"github_branch":"1.4","github":"brainlife/app-tractographyQualityCheck","name":"Tractography quality check","user_id":"56","contributors":[{"name":"Daniel Bullock","email":"iisdanbul@gmail.com","_id":"634a35fc62f3d3800f11bd23"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a35fc62f3d3800f11bd24"},{"name":"Brad Caron","email":null,"_id":"634a35fc62f3d3800f11bd25"},{"name":"Franco Pestilli","email":null,"_id":"634a35fc62f3d3800f11bd26"}],"desc":"Compute many statistics from your input tractogram and any (optionally input) associated classification structure.  These statistics can be used to facilitate quality assurance on your tractography and segmentation, or as part of subject/group level quantative analysis for a research project. See the output section of README.MD for more details.","__v":8116,"create_date":"2019-05-01T16:17:56.953Z","doi":"10.25663/brainlife.app.189","desc_override":"A quality check application for tractography, and segmentatations.  For the whole brain tractogram, provides a number of statistics associated with average streamline characteristics (i.e. count, volume occupied, avg length, length distribution).  Does the same for the positively weighted streamlines of an FE structure if input.  If a classification structure is input, provides a number of macrostructural statistics like stream count, volume, avg length, whole brain count/volume proportion, etc).","_canedit":true},{"_id":"5e837461dd840e2ef3e988ee","projects":["5d64733db29ac960ca2e797f"],"admins":["16","41","146","1"],"tags":[],"removed":false,"stats":{"gitinfo":{"desc":"A quality check application for tractography, segmentatations, and LiFE structures","tags":[],"stats":{"stars":0},"contributors":[{"name":"Daniel Bullock","email":null},{"name":"Franco Pestilli","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"success_rate":80.92287800016163,"users":30,"runtime_mean":860623.65,"runtime_std":1148769.5499679937,"requested":39290,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a38e662f3d3800f11feb2"},{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a38e662f3d3800f11feb3"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a38e662f3d3800f11feb4"}],"examples":0,"groups":69},"config":{"fe":{"type":"input","file_id":"fe","input_id":"fe"},"classification":{"type":"input","file_id":"classification","input_id":"classification"},"tracts":{"type":"input","file_id":"tracts","input_id":"classification"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c350f24836af601cc858603","id":"fe","datatype":"58d15eaee13a50849b258844","desc":"A LiFE structure corresponding to the whole brain tractography entered as a track/tck."},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5c350f24836af601cc858602","id":"classification","datatype":"5cc1d64c44947d8aea6b2d8b","desc":"A white matter classification structure which corresponds to the input whole brain tractography entered as a track/tck."}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5c350f24836af601cc858606","id":"image","datatype":"5cb7711c44947d8aea8cb4f4","datatype_tags_pass":"classification","files":{"image":"tractomeStatPlot.epsc"}},{"datatype_tags":["tractography_quantification","tract_measures"],"output_on_root":false,"archive":true,"_id":"5c350f24836af601cc858605","id":"tractmeasures","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":"classification","files":{"output":"."}},{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5c5cc3235204830032204ccf","id":"resultsSummary","datatype":"599f305ad1f46fec1759f363","datatype_tags_pass":"classification","files":null}],"github_branch":"1.2","github":"brainlife/app-tractographyQualityCheck","name":"Tractography quality check - with LiFE (BROKEN?)","user_id":"1","contributors":[{"name":"Daniel Bullock","email":"iisdanbul@gmail.com","_id":"634a38e662f3d3800f11feb5"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a38e662f3d3800f11feb6"},{"name":"Brad Caron","email":null,"_id":"634a38e662f3d3800f11feb7"},{"name":"Franco Pestilli","email":null,"_id":"634a38e662f3d3800f11feb8"}],"desc":"Compute many statistics from your input tractogram and any (optionally input) associated classification structure.  These statistics can be used to facilitate quality assurance on your tractography and segmentation, or as part of subject/group level quantative analysis for a research project. See the output section of README.MD for more details.","__v":5231,"desc_override":"A quality check application for tractography, segmentatations, with LiFE structures.  For the whole brain tractogram, provides a number of statistics associated with average streamline characteristics (i.e. count, volume occupied, avg length, length distribution).  Does the same for the positively weighted streamlines of an FE structure if input.  If a classification structure is input, provides a number of macrostructural statistics like stream count, volume, avg length, whole brain count/volume proportion, etc).","create_date":"2020-03-31T16:48:33.098Z","doi":"10.25663/brainlife.app.296","_canedit":true},{"_id":"5ecc9bfe1f446412299ed644","projects":[],"admins":["1","41","185","19","16"],"tags":[],"removed":false,"stats":{"gitinfo":{"desc":"Brainlife App (wrapper) for dMRI based fiber tracking using parallel transport tractography https://dmritrekker.github.io","tags":[],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null}]},"success_rate":62.396694214876035,"users":11,"runtime_mean":37618051.82,"runtime_std":23629358.40570497,"requested":341,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3b1262f3d3800f124b0c"}],"examples":1,"groups":12},"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"lmax2":{"type":"input","file_id":"lmax2","input_id":"csd"},"lmax4":{"type":"input","file_id":"lmax4","input_id":"csd"},"lmax6":{"type":"input","file_id":"lmax6","input_id":"csd"},"lmax8":{"type":"input","file_id":"lmax8","input_id":"csd"},"lmax10":{"type":"input","file_id":"lmax10","input_id":"csd"},"lmax12":{"type":"input","file_id":"lmax12","input_id":"csd"},"lmax14":{"type":"input","file_id":"lmax14","input_id":"csd"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"min_length":{"id":"min_length","type":"number","placeholder":"","desc":"min length of streamlines","default":10,"_order":2,"pid":0.2347468384397533},"max_length":{"id":"max_length","type":"number","placeholder":"","desc":"max length of streamlines","default":200,"_order":3,"pid":0.8529474393257837},"lmax":{"id":"lmax","type":"number","placeholder":"","desc":"lmax","default":8,"_order":4,"pid":0.4882791762887786},"count":{"id":"count","type":"number","placeholder":"","desc":"total number of streamlines","default":50000,"_order":5,"pid":0.4809453327806541},"minfodamp":{"id":"minfodamp","type":"string","placeholder":"","advanced":true,"desc":"This is the minimum FOD amplitude. If multiple values are requested, please input as space separated list (example: 0.25 0.5). ","default":"default","_order":6,"pid":0.8712596711306646},"curvatures":{"id":"curvatures","type":"string","placeholder":"","advanced":true,"desc":"Minimum radius of curvature. If multiple values are requested, please input as space separated list (example: 0.25 0.5). ","default":"default","_order":7,"pid":0.5468890853614594},"stepsize":{"id":"stepsize","type":"string","placeholder":"","advanced":true,"desc":"Step size. If multiple values are requested, please input as space separated list (example: 0.25 0.5). ","default":"default","_order":8,"pid":0.06623020954143577},"single_lmax":{"id":"single_lmax","type":"boolean","placeholder":"","advanced":false,"desc":"if only wanting to run on one lmax, set true. else, leave false","default":false,"_order":13,"pid":0.764179631757671},"probelength":{"id":"probelength","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":14,"pid":0.3781036974946712},"probecount":{"id":"probecount","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":15,"pid":0.08353694809350354},"probequality":{"id":"probequality","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":16,"pid":0.44482326715297527},"proberadius":{"id":"proberadius","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":17,"pid":0.8354686132446023},"maxsampling":{"id":"maxsampling","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":18,"pid":0.07318815147040536},"maxtrials":{"id":"maxtrials","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":19,"pid":0.7530601059950162},"bestAtInit":{"id":"bestAtInit","type":"boolean","placeholder":"","advanced":true,"desc":"","default":false,"_order":20,"pid":0.9368986178524641}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ecca5431f44647fae9ee046","id":"dwi","datatype":"58c33c5fe13a50849b25879b"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d6231b24cfacf00366c12c5","id":"csd","datatype":"5c536bf0f9109beac46adb45"},{"datatype_tags":["5tt_masks"],"optional":false,"multi":false,"advanced":false,"_id":"5d6251e14cfacf00366c131f","id":"mask","datatype":"5a281aee2c214c9ba83ce620","desc":"5 tissue type mask"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5d2eada46c03750a8a5252d0","id":"track","datatype":"5907d922436ee50ffde9c549","datatype_tags_pass":null,"files":null},{"datatype_tags":["5tt_masks"],"output_on_root":false,"archive":false,"_id":"5d6244744cfacf00366c130f","id":"mask","datatype":"5a281aee2c214c9ba83ce620","datatype_tags_pass":null,"files":null}],"github_branch":"v.1.2","github":"brainlife/app-trekker","name":"Trekker","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3b1362f3d3800f124b0d"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a3b1362f3d3800f124b0e"},{"name":"Franco Pestilli","email":null,"_id":"634a3b1362f3d3800f124b0f"}],"desc":"Brainlife App (wrapper) for dMRI based fiber tracking using parallel transport tractography https://dmritrekker.github.io","__v":4789,"create_date":"2020-05-26T04:33:02.139Z","doi":"10.25663/brainlife.app.356","_canedit":true},{"_id":"60073190af402b2d814853e0","projects":["5ffc884d2ba0fba7a7e89132","5f6cc0816bbee389b59a1819"],"admins":["1","41","185","19","16"],"tags":[],"removed":false,"stats":{"gitinfo":{"desc":"Brainlife App (wrapper) for dMRI based fiber tracking using parallel transport tractography https://dmritrekker.github.io","tags":[],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null}]},"success_rate":62.396694214876035,"users":11,"runtime_mean":37618051.82,"runtime_std":23629358.40570497,"requested":341,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3eab62f3d3800f12c286"}],"examples":1,"groups":12},"config":{"lmax2":{"type":"input","file_id":"lmax2","input_id":"csd"},"lmax4":{"type":"input","file_id":"lmax4","input_id":"csd"},"lmax6":{"type":"input","file_id":"lmax6","input_id":"csd"},"lmax8":{"type":"input","file_id":"lmax8","input_id":"csd"},"lmax10":{"type":"input","file_id":"lmax10","input_id":"csd"},"lmax12":{"type":"input","file_id":"lmax12","input_id":"csd"},"lmax14":{"type":"input","file_id":"lmax14","input_id":"csd"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"wm_mask":{"type":"input","file_id":"mask","input_id":"wm_mask"},"odi":{"type":"input","file_id":"odi","input_id":"odi"},"min_length":{"id":"min_length","type":"number","placeholder":"","desc":"min length of streamlines","default":10,"_order":2,"pid":0.1355286170706509},"max_length":{"id":"max_length","type":"number","placeholder":"","desc":"max length of streamlines","default":200,"_order":3,"pid":0.5284392984135142},"lmax":{"id":"lmax","type":"number","placeholder":"","desc":"lmax","default":8,"_order":4,"pid":0.9982611362276315},"count":{"id":"count","type":"number","placeholder":"","desc":"total number of streamlines","default":50000,"_order":5,"pid":0.8479345598530579},"minfodamp":{"id":"minfodamp","type":"string","placeholder":"","advanced":true,"desc":"This is the minimum FOD amplitude. If multiple values are requested, please input as space separated list (example: 0.25 0.5). ","default":"default","_order":6,"pid":0.7764370294038889},"curvatures":{"id":"curvatures","type":"string","placeholder":"","advanced":true,"desc":"Minimum radius of curvature. If multiple values are requested, please input as space separated list (example: 0.25 0.5). ","default":"default","_order":7,"pid":0.8845533121579239},"stepsize":{"id":"stepsize","type":"string","placeholder":"","advanced":true,"desc":"Step size. If multiple values are requested, please input as space separated list (example: 0.25 0.5). ","default":"default","_order":8,"pid":0.6416627769114551},"single_lmax":{"id":"single_lmax","type":"boolean","placeholder":"","advanced":false,"desc":"if only wanting to run on one lmax, set true. else, leave false","default":false,"_order":13,"pid":0.4814017103254975},"probelength":{"id":"probelength","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":14,"pid":0.6979387317939256},"probecount":{"id":"probecount","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":15,"pid":0.28715962174845266},"probequality":{"id":"probequality","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":16,"pid":0.03381490126637998},"proberadius":{"id":"proberadius","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":17,"pid":0.4325833542219766},"maxsampling":{"id":"maxsampling","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":18,"pid":0.3259233485338964},"maxtrials":{"id":"maxtrials","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":19,"pid":0.3090864955195951},"bestAtInit":{"id":"bestAtInit","type":"boolean","placeholder":"","advanced":true,"desc":"","default":false,"_order":20,"pid":0.9867080304958866}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d6231b24cfacf00366c12c5","id":"csd","datatype":"5c536bf0f9109beac46adb45"},{"datatype_tags":["5tt_masks"],"optional":false,"multi":false,"advanced":false,"_id":"5d6251e14cfacf00366c131f","id":"mask","datatype":"5a281aee2c214c9ba83ce620","desc":"5 tissue type mask"},{"datatype_tags":["white_matter"],"optional":true,"multi":false,"advanced":false,"_id":"60073190af402b9dbe4853e8","id":"wm_mask","datatype":"5a281aee2c214c9ba83ce620"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"60073190af402b26114853e9","id":"odi","datatype":"5ed02a620a8ed8e39c482a61"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5d2eada46c03750a8a5252d0","id":"track","datatype":"5907d922436ee50ffde9c549","datatype_tags_pass":null,"files":null}],"github_branch":"v1.4","github":"brainlife/app-trekker","name":"Trekker - scalar testing","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3eac62f3d3800f12c287"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a3eac62f3d3800f12c288"},{"name":"Franco Pestilli","email":null,"_id":"634a3eac62f3d3800f12c289"}],"desc":"Brainlife App (wrapper) for dMRI based fiber tracking using parallel transport tractography https://dmritrekker.github.io","__v":3477,"create_date":"2021-01-19T19:22:56.134Z","doi":"10.25663/brainlife.app.466","_canedit":true},{"_id":"5d2eada46c03750a8a5252cd","stats":{"stars":0,"serviceinfo":{"_id":"5d729e1e78356a109788b1ef","counts":{"_id":"5e5c3e0b87cac74b8dab1423","failed":20,"finished":46,"removed":62,"requested":80,"running":77,"running_sync":0,"stop_requested":11},"success_rate":69.6969696969697,"users":7,"readme_status":"ok","runtime_mean":8788731.347826088,"runtime_std":10752209.709381515,"service":"brainlife/app-trekker","__v":0},"gitinfo":{"desc":"Brainlife App (wrapper) for dMRI based fiber tracking using parallel transport tractography https://dmritrekker.github.io","tags":[],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null}]},"success_rate":62.396694214876035,"users":11,"runtime_mean":37618051.82,"runtime_std":23629358.40570497,"requested":341,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a36bf62f3d3800f11d07c"}],"examples":0,"groups":12},"projects":[],"admins":["1","41","185","19","16"],"tags":[],"removed":false,"config":{"t1":{"type":"input","file_id":"t1","input_id":"anat"},"lmax2":{"type":"input","file_id":"lmax2","input_id":"csd"},"lmax4":{"type":"input","file_id":"lmax4","input_id":"csd"},"lmax6":{"type":"input","file_id":"lmax6","input_id":"csd"},"lmax8":{"type":"input","file_id":"lmax8","input_id":"csd"},"lmax10":{"type":"input","file_id":"lmax10","input_id":"csd"},"lmax12":{"type":"input","file_id":"lmax12","input_id":"csd"},"lmax14":{"type":"input","file_id":"lmax14","input_id":"csd"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"wm_mask":{"type":"input","file_id":"mask","input_id":"wm_mask"},"min_length":{"id":"min_length","type":"number","placeholder":"","desc":"min length of streamlines","default":10,"_order":2,"pid":0.18402784851861642},"max_length":{"id":"max_length","type":"number","placeholder":"","desc":"max length of streamlines","default":200,"_order":3,"pid":0.07483331774969337},"lmax":{"id":"lmax","type":"number","placeholder":"","desc":"lmax","default":8,"_order":4,"pid":0.6172592203085476},"count":{"id":"count","type":"number","placeholder":"","desc":"total number of streamlines","default":50000,"_order":5,"pid":0.6669770663496664},"minfodamp":{"id":"minfodamp","type":"string","placeholder":"","advanced":false,"desc":"This is the minimum FOD amplitude. If multiple values are requested, please input as space separated list (example: 0.25 0.5). ","default":"0.05","_order":6,"pid":0.13565422129175397},"minradius":{"id":"minradius","type":"string","placeholder":"","advanced":false,"desc":"Minimum radius of curvature. If multiple values are requested, please input as space separated list (example: 0.25 0.5). ","default":"0.5","_order":7,"pid":0.45217525761969735},"step_size":{"id":"step_size","type":"string","placeholder":"","advanced":false,"desc":"Step size. If multiple values are requested, please input as space separated list (example: 0.25 0.5). ","default":"0.2","_order":8,"pid":0.7738246430572695},"probelength":{"id":"probelength","type":"number","placeholder":"","advanced":true,"desc":"Trekker: Length of the probe.","default":0.25,"_order":9,"pid":0.2073344591974191,"optional":false},"probequality":{"id":"probequality","type":"number","placeholder":"","advanced":true,"desc":"Trekker: This parameter sets the number of segments to split the cylinder along the length of the probe","default":4,"_order":10,"pid":0.5837895155305219},"proberadius":{"id":"proberadius","type":"number","placeholder":"","advanced":true,"desc":"Trekker: Radius of the probe.","default":0,"_order":11,"pid":0.8583906273702919},"probecount":{"id":"probecount","type":"number","placeholder":"","advanced":true,"desc":"Trekker: determines the number of parallel lines used to model the cylinder.","default":1,"_order":12,"pid":0.3914126357994918},"single_lmax":{"id":"single_lmax","type":"boolean","placeholder":"","advanced":false,"desc":"if only wanting to run on one lmax, set true. else, leave false","default":false,"_order":13,"pid":0.30768822938280915}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d2eada46c03750a8a5252ce","id":"anat","datatype":"58c33bcee13a50849b25879a"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d6231b24cfacf00366c12c5","id":"csd","datatype":"5c536bf0f9109beac46adb45"},{"datatype_tags":["5tt_masks"],"optional":true,"multi":false,"advanced":false,"_id":"5d6251e14cfacf00366c131f","id":"mask","datatype":"5a281aee2c214c9ba83ce620","desc":"5 tissue type mask"},{"datatype_tags":["white_matter"],"optional":true,"multi":false,"advanced":false,"_id":"5ec2ab3941ba1179cef3f84c","id":"wm_mask","datatype":"5a281aee2c214c9ba83ce620"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5d2eada46c03750a8a5252d0","id":"track","datatype":"5907d922436ee50ffde9c549","datatype_tags_pass":null,"files":null},{"datatype_tags":["5tt_masks"],"output_on_root":false,"archive":false,"_id":"5d6244744cfacf00366c130f","id":"mask","datatype":"5a281aee2c214c9ba83ce620","datatype_tags_pass":null,"files":null}],"github_branch":"v1.0","github":"brainlife/app-trekker","name":"Trekker - v1.0","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a36c062f3d3800f11d07d"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a36c062f3d3800f11d07e"},{"name":"Franco Pestilli","email":null,"_id":"634a36c062f3d3800f11d07f"}],"create_date":"2019-07-17T05:09:56.759Z","desc":"Brainlife App (wrapper) for dMRI based fiber tracking using parallel transport tractography https://dmritrekker.github.io","doi":"10.25663/brainlife.app.214","__v":7548,"deprecated_by":"5ecc9bfe1f446412299ed644","_canedit":true},{"_id":"5ecc95311f446482f59ed395","projects":[],"admins":["16","185","41","1"],"tags":["diffusion-mri","mri","tracking","tractography","vision"],"removed":false,"stats":{"gitinfo":{"desc":"Brainlife App (wrapper) for dMRI based fiber tracking between ROIs using parallel transport tractography","tags":["diffusion-mri","mri","tracking","tractography","vision"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"success_rate":44.38652766639935,"users":14,"runtime_mean":9394121.4,"runtime_std":8236894.053758132,"requested":3594,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3b0962f3d3800f124a93"}],"examples":1,"groups":24},"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"lmax2":{"type":"input","file_id":"lmax2","input_id":"csd"},"lmax4":{"type":"input","file_id":"lmax4","input_id":"csd"},"lmax6":{"type":"input","file_id":"lmax6","input_id":"csd"},"lmax8":{"type":"input","file_id":"lmax8","input_id":"csd"},"lmax10":{"type":"input","file_id":"lmax10","input_id":"csd"},"lmax12":{"type":"input","file_id":"lmax12","input_id":"csd"},"lmax14":{"type":"input","file_id":"lmax14","input_id":"csd"},"rois":{"type":"input","file_id":"rois","input_id":"rois"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"brainmask":{"type":"input","file_id":"mask","input_id":"brainmask"},"min_length":{"id":"min_length","type":"number","placeholder":"","advanced":false,"desc":"min length of streamlines","default":10,"_order":2,"pid":0.8492116668292677},"max_length":{"id":"max_length","type":"number","placeholder":"","advanced":false,"desc":"max length of streamlines","default":200,"_order":3,"pid":0.981608464468833},"lmax":{"id":"lmax","type":"number","placeholder":"","advanced":false,"desc":"lmax","default":8,"_order":4,"pid":0.874568580556957},"roiPair":{"id":"roiPair","type":"string","placeholder":"","advanced":false,"desc":"this field is to designate the ROI names to track between. Multiple tracks can be done at the same time but entering the pairs on a new line.\n\nfor example, for a single track with ROI  names of parc-10 and parc-193, this input would be: parc-10 parc-193\n\nif you wanted to do a second track between ROIs with names of parc-25 and parc-250, this input would be:\nparc-10 parc-193\nparc-25 parc-250\n\nPlease see ROI datatype for exact name of each.","default":"","_order":5,"pid":0.6555077449415991,"multiline":true},"exclusion":{"id":"exclusion","type":"string","placeholder":"","advanced":false,"desc":"this field is the exact ROI name or number from the ROI datatype for the exclusion ROIS. Just like in the roiPair field, you can enter a different exclusion ROI for each tract by adding a new line. NOTE: can only do one exclusion ROI per tract.\n\nIf you do not want to use exclusion ROIs, leave blank","default":"","_order":7,"pid":0.11836545466562165,"optional":true,"multiline":true},"count":{"id":"count","type":"number","placeholder":"","advanced":false,"desc":"total number of streamlines","default":500,"_order":9,"pid":0.3355330137552017},"curvatures":{"id":"curvatures","type":"string","placeholder":"","advanced":true,"desc":"minimum radius of curvature. If left as 'default', trekker will automatically determine best curvature. Otherwise, enter value of radius of curvature (i.e 0.5)","default":"default","_order":14,"pid":0.22477083752709026},"stepsize":{"id":"stepsize","type":"string","placeholder":"","advanced":true,"desc":"step size. If left as 'default', trekker will automatically determine best step size. Otherwise, enter value of step size (i.e 0.5)","default":"default","_order":15,"pid":0.44836009976351376},"single_lmax":{"id":"single_lmax","type":"boolean","placeholder":"","advanced":false,"desc":"if want to run on only one lmax, set to true. to ensemble, set to false","default":true,"_order":18,"pid":0.7248039183936363},"minfodamp":{"id":"minfodamp","type":"string","placeholder":"","advanced":true,"desc":"minimum FOD amplitude. If left as 'default', trekker will automatically determine best FOD amplitude. Otherwise, enter value of FOD amplitude (i.e 0.5)","default":"default","_order":19,"pid":0.640593696717719},"maxsampling":{"id":"maxsampling","type":"string","placeholder":"","advanced":true,"desc":"max sampling per seed. If left as 'default', trekker will automatically determine best number of max sampling per seed. Otherwise, enter value here (100000)","default":"default","_order":20,"pid":0.6933070025658128},"maxtrials":{"id":"maxtrials","type":"string","placeholder":"","advanced":true,"desc":"max trials. If left as 'default', trekker will automatically determine best number of max trials. Otherwise, enter value here (100000)","default":"default","_order":21,"pid":0.9759484433282866},"probecount":{"id":"probecount","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":22,"pid":0.408669248321478},"probelength":{"id":"probelength","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":23,"pid":0.02389223469941726},"proberadius":{"id":"proberadius","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":24,"pid":0.13370064493439804},"probequality":{"id":"probequality","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":25,"pid":0.46597746919297145,"optional":false},"bestAtInit":{"id":"bestAtInit","type":"boolean","placeholder":"","advanced":true,"desc":"","default":false,"_order":26,"pid":0.27559805847302754},"reslice":{"id":"reslice","type":"boolean","placeholder":"","advanced":false,"desc":"","default":false,"_order":27,"pid":0.23955238451255245}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d65964c398672b124496250","id":"dwi","datatype":"58c33c5fe13a50849b25879b"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d65964c398672b57f49624e","id":"csd","datatype":"5c536bf0f9109beac46adb45"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d65964c3986725b9b49624d","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9"},{"datatype_tags":["5tt_masks"],"optional":false,"multi":false,"advanced":false,"_id":"5d65964c3986722b1e49624c","id":"mask","datatype":"5a281aee2c214c9ba83ce620","desc":"5-tissue type mask (needed for csd fitting)"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5d65964c398672012849624b","id":"brainmask","datatype":"5a281aee2c214c9ba83ce620","desc":"whole-brain mask"}],"outputs":[{"datatype_tags":["roi_trekker"],"output_on_root":false,"archive":true,"_id":"5d65964c3986726908496255","id":"track","datatype":"5907d922436ee50ffde9c549","datatype_tags_pass":null,"files":null},{"datatype_tags":["brain_mask"],"output_on_root":false,"archive":false,"_id":"5d65964c398672dec1496252","id":"brainmask","datatype":"5a281aee2c214c9ba83ce620","datatype_tags_pass":null,"files":null},{"datatype_tags":["roi_trekker"],"output_on_root":false,"archive":true,"_id":"5d65964c39867210f4496251","id":"wmc","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags_pass":null,"files":null},{"datatype_tags":["roi_tracking_derivatives"],"output_on_root":false,"archive":true,"_id":"5ee1d523c5972bd387b45562","id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null}],"github_branch":"master-app-v1.2","github":"brainlife/app-trekker-roi-tracking","name":"Trekker ROI Tracking (DWI)","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3b0a62f3d3800f124a94"},{"name":"Franco Pestilli","email":null,"_id":"634a3b0a62f3d3800f124a95"}],"desc":"Brainlife App (wrapper) for dMRI based fiber tracking between ROIs using parallel transport tractography","__v":4789,"desc_override":"This app uses [Trekker](https://dmritrekker.github.io) to track between multiple ROIs.","avatar":"","create_date":"2020-05-26T04:04:01.055Z","doi":"10.25663/brainlife.app.355","_canedit":true},{"_id":"5f52e1c542c172f98a6532e4","projects":[],"admins":["16","185","41","1"],"tags":["diffusion-mri","mri","tracking","tractography","vision"],"removed":false,"stats":{"gitinfo":{"desc":"Brainlife App (wrapper) for dMRI based fiber tracking between ROIs using parallel transport tractography","tags":["diffusion-mri","mri","tracking","tractography","vision"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"success_rate":44.38652766639935,"users":14,"runtime_mean":9394121.4,"runtime_std":8236894.053758132,"requested":3594,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3cfa62f3d3800f129e14"}],"examples":0,"groups":24},"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"lmax2":{"type":"input","file_id":"lmax2","input_id":"csd"},"lmax4":{"type":"input","file_id":"lmax4","input_id":"csd"},"lmax6":{"type":"input","file_id":"lmax6","input_id":"csd"},"lmax8":{"type":"input","file_id":"lmax8","input_id":"csd"},"lmax10":{"type":"input","file_id":"lmax10","input_id":"csd"},"lmax12":{"type":"input","file_id":"lmax12","input_id":"csd"},"lmax14":{"type":"input","file_id":"lmax14","input_id":"csd"},"rois":{"type":"input","file_id":"rois","input_id":"rois"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"brainmask":{"type":"input","file_id":"mask","input_id":"brainmask"},"min_length":{"id":"min_length","type":"number","placeholder":"","advanced":false,"desc":"min length of streamlines","default":10,"_order":2,"pid":0.2720642727426814},"max_length":{"id":"max_length","type":"number","placeholder":"","advanced":false,"desc":"max length of streamlines","default":200,"_order":3,"pid":0.9626881521403312},"lmax":{"id":"lmax","type":"number","placeholder":"","advanced":false,"desc":"lmax","default":8,"_order":4,"pid":0.875331917663313},"roiPair":{"id":"roiPair","type":"string","placeholder":"","advanced":false,"desc":"String field to input the names of the ROIs to track between. Enter the exact ROI number or name from the rois datatype for the roi of choice, separated by a space (example: '008109 008209'). Please see ROI datatype for exact name of each.","default":"","_order":5,"pid":0.2729603441108146},"exclusion":{"id":"exclusion","type":"string","placeholder":"","advanced":false,"desc":"this field is the exact ROI names or numbers from the ROI datatype for the exclusion ROIs. Example: 'exclusion_L'.  Please see ROI datatype for exact name of each.\n\nThese exclusion can be any grouping of ROIs that you DO NOT want streamlines to cross. For example, opposite hemisphere white matter, cerebellar white matter, hippocampus are good exclusions for the OR. \n\nIf you do not want to use exclusion ROIs, leave blank","default":"","_order":7,"pid":0.6377055676230503,"optional":true,"multiline":true},"count":{"id":"count","type":"number","placeholder":"","advanced":false,"desc":"total number of streamlines","default":500,"_order":9,"pid":0.8817602429106717},"curvatures":{"id":"curvatures","type":"string","placeholder":"","advanced":true,"desc":"minimum radius of curvature. If left as 'default', trekker will automatically determine best curvature. Otherwise, enter value of radius of curvature (i.e 0.5)","default":"default","_order":14,"pid":0.008474141739240437},"stepsize":{"id":"stepsize","type":"string","placeholder":"","advanced":true,"desc":"step size. If left as 'default', trekker will automatically determine best step size. Otherwise, enter value of step size (i.e 0.5)","default":"default","_order":15,"pid":0.3915773069862658},"single_lmax":{"id":"single_lmax","type":"boolean","placeholder":"","advanced":false,"desc":"if want to run on only one lmax, set to true. to ensemble, set to false","default":true,"_order":18,"pid":0.8199191950029667},"minfodamp":{"id":"minfodamp","type":"string","placeholder":"","advanced":true,"desc":"minimum FOD amplitude. If left as 'default', trekker will automatically determine best FOD amplitude. Otherwise, enter value of FOD amplitude (i.e 0.5)","default":"default","_order":19,"pid":0.7300082516046063},"maxsampling":{"id":"maxsampling","type":"string","placeholder":"","advanced":true,"desc":"max sampling per seed. If left as 'default', trekker will automatically determine best number of max sampling per seed. Otherwise, enter value here (100000)","default":"default","_order":20,"pid":0.08902293341437062},"maxtrials":{"id":"maxtrials","type":"string","placeholder":"","advanced":true,"desc":"max trials. If left as 'default', trekker will automatically determine best number of max trials. Otherwise, enter value here (100000)","default":"default","_order":21,"pid":0.41393241559269334},"probecount":{"id":"probecount","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":22,"pid":0.6781122473288499},"probelength":{"id":"probelength","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":23,"pid":0.7493813613994913},"proberadius":{"id":"proberadius","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":24,"pid":0.9706361192295783},"probequality":{"id":"probequality","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":25,"pid":0.3391115746868032,"optional":false},"bestAtInit":{"id":"bestAtInit","type":"boolean","placeholder":"","advanced":true,"desc":"","default":false,"_order":26,"pid":0.8599362906807095},"reslice":{"id":"reslice","type":"boolean","placeholder":"","advanced":false,"desc":"","default":false,"_order":27,"pid":0.787589700623265},"min_degree":{"id":"min_degree","type":"string","placeholder":"","advanced":false,"desc":"Minimum eccentricity degrees","default":"0 15 30","_order":28,"pid":0.8532871975526111},"max_degree":{"id":"max_degree","type":"string","placeholder":"","advanced":false,"desc":"Minimum eccentricity degrees","default":"3 30 90","_order":29,"pid":0.817297225116902}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d65964c398672b124496250","id":"dwi","datatype":"58c33c5fe13a50849b25879b"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d65964c398672b57f49624e","id":"csd","datatype":"5c536bf0f9109beac46adb45"},{"datatype_tags":["eccentricity"],"optional":false,"multi":false,"advanced":false,"_id":"5d65964c3986725b9b49624d","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9","desc":"Requires eccentricity rois to already have been generated. See https://brainlife.io/app/5f52cc4b42c17250a7651b63"},{"datatype_tags":["5tt_masks"],"optional":false,"multi":false,"advanced":false,"_id":"5d65964c3986722b1e49624c","id":"mask","datatype":"5a281aee2c214c9ba83ce620","desc":"5-tissue type mask (needed for csd fitting)"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5d65964c398672012849624b","id":"brainmask","datatype":"5a281aee2c214c9ba83ce620","desc":"whole-brain mask"}],"outputs":[{"datatype_tags":["roi_trekker","tracking_eccentricity"],"output_on_root":false,"archive":true,"_id":"5d65964c3986726908496255","id":"track","datatype":"5907d922436ee50ffde9c549","datatype_tags_pass":null,"files":null},{"datatype_tags":["dwi"],"output_on_root":false,"archive":false,"_id":"5d65964c398672dec1496252","id":"brainmask","datatype":"5a281aee2c214c9ba83ce620","datatype_tags_pass":null,"files":null},{"datatype_tags":["roi_trekker","tracking_eccentricity"],"output_on_root":false,"archive":true,"_id":"5d65964c39867210f4496251","id":"wmc","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags_pass":null,"files":null},{"datatype_tags":["roi_tracking_derivatives","tracking_eccentricity"],"output_on_root":false,"archive":true,"_id":"5ee1d523c5972bd387b45562","id":"raw","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null}],"github_branch":"master-app-eccentricity-v1.0","github":"brainlife/app-trekker-roi-tracking","name":"Trekker ROI Tracking (DWI) based on Eccentricity","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3cfb62f3d3800f129e15"},{"name":"Franco Pestilli","email":null,"_id":"634a3cfb62f3d3800f129e16"}],"desc":"Brainlife App (wrapper) for dMRI based fiber tracking between ROIs using parallel transport tractography","__v":4155,"desc_override":"This app uses [Trekker](https://dmritrekker.github.io) to track between multiple ROIs.","avatar":"","create_date":"2020-09-05T00:54:30.002Z","doi":"10.25663/brainlife.app.415","_canedit":true},{"_id":"5ecca39d1f4464e2bb9edc0a","projects":[],"admins":["16","185","41","1"],"tags":["diffusion-mri","mri","tracking","tractography","vision"],"removed":false,"stats":{"gitinfo":{"desc":"Brainlife App (wrapper) for dMRI based fiber tracking between ROIs using parallel transport tractography","tags":["diffusion-mri","mri","tracking","tractography","vision"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"success_rate":44.38652766639935,"users":14,"runtime_mean":9394121.4,"runtime_std":8236894.053758132,"requested":3594,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3b2562f3d3800f124b15"}],"examples":0,"groups":24},"config":{"dtiinit":{"type":"input","file_id":"output","input_id":"dtiinit"},"lmax2":{"type":"input","file_id":"lmax2","input_id":"csd"},"lmax4":{"type":"input","file_id":"lmax4","input_id":"csd"},"lmax6":{"type":"input","file_id":"lmax6","input_id":"csd"},"lmax8":{"type":"input","file_id":"lmax8","input_id":"csd"},"lmax10":{"type":"input","file_id":"lmax10","input_id":"csd"},"lmax12":{"type":"input","file_id":"lmax12","input_id":"csd"},"lmax14":{"type":"input","file_id":"lmax14","input_id":"csd"},"rois":{"type":"input","file_id":"rois","input_id":"rois"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"brainmask":{"type":"input","file_id":"mask","input_id":"brainmask"},"min_length":{"id":"min_length","type":"number","placeholder":"","advanced":false,"desc":"min length of streamlines","default":10,"_order":2,"pid":0.7451029288479485},"max_length":{"id":"max_length","type":"number","placeholder":"","advanced":false,"desc":"max length of streamlines","default":200,"_order":3,"pid":0.14212209259687025},"lmax":{"id":"lmax","type":"number","placeholder":"","advanced":false,"desc":"lmax","default":8,"_order":4,"pid":0.3909572357234006},"roiPair":{"id":"roiPair","type":"string","placeholder":"","advanced":false,"desc":"This field is here for whether or not you want to track both hemispheres or one hemisphere at a time. If just one hemisphere is desired, enter the exact ROI number or name from the rois datatype for the roi of choice (example: '008109'). If both are desired, enter both separated by a space (example: '008109 008209'). Please see ROI datatype for exact name of each.","default":"","_order":5,"pid":0.20767205458473526},"exclusion":{"id":"exclusion","type":"string","placeholder":"","advanced":false,"desc":"this field is the exact ROI name or number from the ROI datatype for the V1. Example: 'exclusion_L'. If bother hemispheres are being tracked, enter the name separated by a space for each exclusion 'exclusion_R'. Please see ROI datatype for exact name of each.\n\nThese exclusion can be any grouping of ROIs that you DO NOT want streamlines to cross. For example, opposite hemisphere white matter, cerebellar white matter, hippocampus are good exclusions for the OR. \n\nIf you do not want to use exclusion ROIs, leave blank","default":"","_order":7,"pid":0.2668160299983644,"optional":true,"multiline":true},"count":{"id":"count","type":"number","placeholder":"","advanced":false,"desc":"total number of streamlines","default":500,"_order":9,"pid":0.24655977565500797},"curvatures":{"id":"curvatures","type":"string","placeholder":"","advanced":true,"desc":"minimum radius of curvature. If left as 'default', trekker will automatically determine best curvature. Otherwise, enter value of radius of curvature (i.e 0.5)","default":"default","_order":14,"pid":0.7636749412932486},"stepsize":{"id":"stepsize","type":"string","placeholder":"","advanced":true,"desc":"step size. If left as 'default', trekker will automatically determine best step size. Otherwise, enter value of step size (i.e 0.5)","default":"default","_order":15,"pid":0.09324156271834916},"single_lmax":{"id":"single_lmax","type":"boolean","placeholder":"","advanced":false,"desc":"if want to run on only one lmax, set to true. to ensemble, set to false","default":true,"_order":18,"pid":0.9076444190097201},"minfodamp":{"id":"minfodamp","type":"string","placeholder":"","advanced":true,"desc":"minimum FOD amplitude. If left as 'default', trekker will automatically determine best FOD amplitude. Otherwise, enter value of FOD amplitude (i.e 0.5)","default":"default","_order":19,"pid":0.3886292711695589},"maxsampling":{"id":"maxsampling","type":"string","placeholder":"","advanced":true,"desc":"max sampling per seed. If left as 'default', trekker will automatically determine best number of max sampling per seed. Otherwise, enter value here (100000)","default":"default","_order":20,"pid":0.20763143804157158},"maxtrials":{"id":"maxtrials","type":"string","placeholder":"","advanced":true,"desc":"max trials. If left as 'default', trekker will automatically determine best number of max trials. Otherwise, enter value here (100000)","default":"default","_order":21,"pid":0.4072730678971648},"probecount":{"id":"probecount","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":22,"pid":0.6535347589322826},"probelength":{"id":"probelength","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":23,"pid":0.32166547949200797},"proberadius":{"id":"proberadius","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":24,"pid":0.48127288284456005},"probequality":{"id":"probequality","type":"string","placeholder":"","advanced":true,"desc":"","default":"default","_order":25,"pid":0.5655190617141554,"optional":false},"bestAtInit":{"id":"bestAtInit","type":"boolean","placeholder":"","advanced":true,"desc":"","default":false,"_order":26,"pid":0.7267944002490982},"reslice":{"id":"reslice","type":"boolean","placeholder":"","advanced":false,"desc":"","default":false,"_order":27,"pid":0.31841307659027795}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ecca39d1f4464bde69edc0b","id":"dtiinit","datatype":"58cb234be13a50849b25882f"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d65964c398672b57f49624e","id":"csd","datatype":"5c536bf0f9109beac46adb45"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d65964c3986725b9b49624d","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9"},{"datatype_tags":["5tt_masks"],"optional":false,"multi":false,"advanced":false,"_id":"5d65964c3986722b1e49624c","id":"mask","datatype":"5a281aee2c214c9ba83ce620","desc":"5-tissue type mask (needed for csd fitting)"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5d65964c398672012849624b","id":"brainmask","datatype":"5a281aee2c214c9ba83ce620","desc":"whole-brain mask"}],"outputs":[{"datatype_tags":["roi_trekker"],"output_on_root":false,"archive":true,"_id":"5d65964c3986726908496255","id":"track","datatype":"5907d922436ee50ffde9c549","datatype_tags_pass":null,"files":null},{"datatype_tags":["brain_mask"],"output_on_root":false,"archive":false,"_id":"5d65964c398672dec1496252","id":"brainmask","datatype":"5a281aee2c214c9ba83ce620","datatype_tags_pass":null,"files":null},{"datatype_tags":["roi_trekker"],"output_on_root":false,"archive":true,"_id":"5d65964c39867210f4496251","id":"wmc","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags_pass":null,"files":null}],"github_branch":"master-app-v1.1","github":"brainlife/app-trekker-roi-tracking","name":"Trekker ROI Tracking (dtiinit)","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3b2562f3d3800f124b16"},{"name":"Franco Pestilli","email":null,"_id":"634a3b2562f3d3800f124b17"}],"desc":"Brainlife App (wrapper) for dMRI based fiber tracking between ROIs using parallel transport tractography","__v":4785,"desc_override":"This app uses [Trekker](https://dmritrekker.github.io) to track between multiple ROIs.","avatar":"","create_date":"2020-05-26T05:05:33.306Z","doi":"10.25663/brainlife.app.358","deprecated_by":"5ecc95311f446482f59ed395","_canedit":true},{"_id":"5eb8755ed856c03663270a34","projects":[],"admins":["16"],"tags":["diffusion-mri","mri","tracking","tractography","vision"],"removed":false,"stats":{"success_rate":44.38652766639935,"users":14,"runtime_mean":9394121.4,"runtime_std":8236894.053758132,"requested":3594,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3a6662f3d3800f123dc8"}],"examples":0,"groups":24},"config":{"dtiinit":{"type":"input","file_id":"output","input_id":"dtiinit"},"response":{"type":"input","file_id":"response","input_id":"csd"},"lmax2":{"type":"input","file_id":"lmax2","input_id":"csd"},"lmax4":{"type":"input","file_id":"lmax4","input_id":"csd"},"lmax6":{"type":"input","file_id":"lmax6","input_id":"csd"},"lmax8":{"type":"input","file_id":"lmax8","input_id":"csd"},"lmax10":{"type":"input","file_id":"lmax10","input_id":"csd"},"lmax12":{"type":"input","file_id":"lmax12","input_id":"csd"},"lmax14":{"type":"input","file_id":"lmax14","input_id":"csd"},"rois":{"type":"input","file_id":"rois","input_id":"rois"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"brainmask":{"type":"input","file_id":"mask","input_id":"brainmask"},"anat":{"type":"input","file_id":"t1","input_id":"anat"},"wm_mask":{"type":"input","file_id":"mask","input_id":"wm_mask"},"min_length":{"id":"min_length","type":"number","placeholder":"","advanced":false,"desc":"min length of streamlines","default":10,"_order":2,"pid":0.85928876331793},"max_length":{"id":"max_length","type":"number","placeholder":"","advanced":false,"desc":"max length of streamlines","default":200,"_order":3,"pid":0.7552205087063621},"lmax":{"id":"lmax","type":"number","placeholder":"","advanced":false,"desc":"maximum lmax. if no input, then app will automatically calculate","default":8,"_order":4,"pid":0.5706508796326435,"optional":true},"minfodamp":{"id":"minfodamp","type":"string","placeholder":"","advanced":false,"desc":"Minimum FOD amplitude (default: 0.025)","default":"0.025","_order":9,"pid":0.8436582706523836},"stepsize":{"id":"stepsize","type":"string","placeholder":"","advanced":false,"desc":"","default":"0.25","_order":10,"pid":0.028631331952774453},"roiPair":{"id":"roiPair","type":"string","placeholder":"","advanced":false,"desc":"roiPair for tracking. input seed roi first and termination roi second\nex. \"seed term\"","default":"","_order":10,"pid":0.8344418483066673,"multiline":true},"exclusion":{"id":"exclusion","type":"string","placeholder":"","advanced":false,"desc":"these are the names of the exclusion ROIs you would like to use. Follows the same format as roiPair field. For example, if you want to track in both hemispheres, you could enter \"exclusion_L exclusion_R\". \n\nPlease look at your ROIs datatype for the exact name of your exclusion ROI.\n\nIf you do not want to include exclusion ROIs, leave this empty","default":"","_order":13,"pid":0.31146259487641315,"optional":true,"multiline":true},"count":{"id":"count","type":"number","placeholder":"","advanced":false,"desc":"total number of streamlines","default":500,"_order":14,"pid":0.0658802204812039},"curvatures":{"id":"curvatures","type":"string","placeholder":"","advanced":false,"desc":"minimum radius of curvatures. can be multiple (i.e. ensemble) or one value. default: 1","default":"1","_order":15,"pid":0.16111357126102033},"maxtrials":{"id":"maxtrials","type":"number","placeholder":"","advanced":false,"desc":"Sets the maximum number of attempts to generate streamline from the seed point. Default=1000000.","default":1000000,"_order":15,"pid":0.6802123716403219},"maxsampling":{"id":"maxsampling","type":"number","placeholder":"","advanced":false,"desc":"This option limits the number of samples that can be tested for rejection sampling during propagation. Default=10000.","default":10000,"_order":17,"pid":0.6698465554064446},"single_lmax":{"id":"single_lmax","type":"boolean","placeholder":"","advanced":false,"desc":"Determines whether single lmax (true) or ensemble lmax (false) will be performed","default":true,"_order":18,"pid":0.284150814164547},"probelength":{"id":"probelength","type":"number","placeholder":"","advanced":true,"desc":"Trekker: Length of the probe. Pick 1/4 of the smallest of the FOD(input dwi) voxel dimensions. For whole-brain tractography, use 1.0","default":0.25,"_order":20,"pid":0.5495344919239704},"probecount":{"id":"probecount","type":"number","placeholder":"","advanced":true,"desc":"Trekker: Determines the number of lines outside the cylinder. Default: 1, i.e: by default, the radius of the cylinder (probeRadius) is zero and only a single line is used to model a cylinder.","default":1,"_order":21,"pid":0.3728965052397819},"probequality":{"id":"probequality","type":"number","placeholder":"","advanced":true,"desc":"Trekker: This parameter sets the number of segments to split the cylinder along the length of the probe. The larger the value is, the slower the computation gets. Default=4.","default":4,"_order":22,"pid":0.6684399213534595},"proberadius":{"id":"proberadius","type":"number","placeholder":"","advanced":true,"desc":"Trekker: Probe radius. Default: 0","default":0,"_order":23,"pid":0.4643767487902639},"reslice":{"id":"reslice","type":"boolean","placeholder":"","advanced":false,"desc":"reslice rois into diffusion space if true","default":false,"_order":24,"pid":0.7654417893137773}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5eb8755ed856c0f1cd270a35","id":"dtiinit","datatype":"58cb234be13a50849b25882f"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5db737fe8aeeee0b74f2dc11","id":"csd","datatype":"5c536bf0f9109beac46adb45"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5db737fe8aeeeea727f2dc10","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9"},{"datatype_tags":["5tt_masks"],"optional":true,"multi":false,"advanced":false,"_id":"5db737fe8aeeee4e46f2dc0f","id":"mask","datatype":"5a281aee2c214c9ba83ce620"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5db737fe8aeeeedb0af2dc0e","id":"brainmask","datatype":"5a281aee2c214c9ba83ce620"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e9d31b2f1745d6b8af6830c","id":"anat","datatype":"58c33bcee13a50849b25879a"},{"datatype_tags":["white_matter"],"optional":true,"multi":false,"advanced":false,"_id":"5ec2aa9141ba1194cdf3f5d1","id":"wm_mask","datatype":"5a281aee2c214c9ba83ce620","desc":"This is the path to the white matter mask"}],"outputs":[{"datatype_tags":["roi_trekker"],"output_on_root":false,"archive":true,"_id":"5db737fe8aeeee8147f2dc15","id":"track","datatype":"5907d922436ee50ffde9c549","datatype_tags_pass":null,"files":null},{"datatype_tags":["roi_trekker"],"output_on_root":false,"archive":true,"_id":"5db737fe8aeeee899bf2dc13","id":"wmc","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags_pass":null,"files":null},{"datatype_tags":["brain_mask"],"output_on_root":false,"archive":false,"_id":"5db737fe8aeeeee32ff2dc14","id":"brainmask","datatype":"5a281aee2c214c9ba83ce620","datatype_tags_pass":null,"files":null},{"datatype_tags":[],"output_on_root":false,"archive":false,"_id":"5e5430545b9d90120672cf73","id":"5tt","datatype":"5a281aee2c214c9ba83ce620","datatype_tags_pass":null,"files":null}],"github_branch":"master-app-v1.0","github":"brainlife/app-trekker-roi-tracking","name":"Trekker ROI Tracking (dtiinit) - v1.0","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a3a6762f3d3800f123dc9"},{"name":"Franco Pestilli","email":null,"_id":"634a3a6762f3d3800f123dca"}],"desc":"Brainlife App (wrapper) for dMRI based fiber tracking between ROIs using parallel transport tractography","__v":4913,"create_date":"2020-05-10T21:42:55.002Z","doi":"10.25663/brainlife.app.338","deprecated_by":"5ecca39d1f4464e2bb9edc0a","_canedit":true},{"_id":"5e542e855b9d904b1e72cdc9","projects":[],"admins":["16"],"tags":["diffusion-mri","mri","tracking","tractography","vision"],"removed":false,"stats":{"stars":0,"serviceinfo":{"_id":"5d729e1e78356a109788b1e3","counts":{"_id":"5e5c3e3d87cac7ceb4ab1456","failed":112,"finished":147,"removed":309,"requested":392,"running":302,"running_sync":0,"stop_requested":65},"success_rate":56.75675675675676,"users":7,"readme_status":"ok","runtime_mean":18540062.42,"runtime_std":10967451.73775354,"service":"brainlife/app-trekker-roi-tracking","__v":0},"success_rate":44.38652766639935,"users":14,"runtime_mean":9394121.4,"runtime_std":8236894.053758132,"requested":3594,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a385d62f3d3800f11ef2d"}],"examples":0,"groups":24},"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"response":{"type":"input","file_id":"response","input_id":"csd"},"lmax2":{"type":"input","file_id":"lmax2","input_id":"csd"},"lmax4":{"type":"input","file_id":"lmax4","input_id":"csd"},"lmax6":{"type":"input","file_id":"lmax6","input_id":"csd"},"lmax8":{"type":"input","file_id":"lmax8","input_id":"csd"},"lmax10":{"type":"input","file_id":"lmax10","input_id":"csd"},"lmax12":{"type":"input","file_id":"lmax12","input_id":"csd"},"lmax14":{"type":"input","file_id":"lmax14","input_id":"csd"},"rois":{"type":"input","file_id":"rois","input_id":"rois"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"brainmask":{"type":"input","file_id":"mask","input_id":"brainmask"},"anat":{"type":"input","file_id":"t1","input_id":"anat"},"wm_mask":{"type":"input","file_id":"mask","input_id":"wm_mask"},"min_length":{"id":"min_length","type":"number","placeholder":"","advanced":false,"desc":"min length of streamlines","default":10,"_order":2,"pid":0.8293283492084653},"max_length":{"id":"max_length","type":"number","placeholder":"","advanced":false,"desc":"max length of streamlines","default":200,"_order":3,"pid":0.6692385467504007},"lmax":{"id":"lmax","type":"number","placeholder":"","advanced":false,"desc":"maximum lmax. if no input, then app will automatically calculate","default":8,"_order":4,"pid":0.2639658733070336,"optional":true},"minfodamp":{"id":"minfodamp","type":"string","placeholder":"","advanced":false,"desc":"Minimum FOD amplitude (default: 0.025)","default":"0.025","_order":9,"pid":0.8260710301497018},"roiPair":{"id":"roiPair","type":"string","placeholder":"","advanced":false,"desc":"roiPair for tracking. input seed roi first and termination roi second\nex. \"seed term\"","default":"","_order":10,"pid":0.12579623959667963,"multiline":true},"exclusion":{"id":"exclusion","type":"string","placeholder":"","advanced":false,"desc":"these are the names of the exclusion ROIs you would like to use. Follows the same format as roiPair field. For example, if you want to track in both hemispheres, you could enter \"exclusion_L exclusion_R\". \n\nPlease look at your ROIs datatype for the exact name of your exclusion ROI.\n\nIf you do not want to include exclusion ROIs, leave this empty","default":"","_order":11,"pid":0.6753851620801017,"optional":true,"multiline":true},"stepsize":{"id":"stepsize","type":"string","placeholder":"","advanced":false,"desc":"","default":"0.25","_order":12,"pid":0.46345591287429233},"count":{"id":"count","type":"number","placeholder":"","advanced":false,"desc":"total number of streamlines","default":500,"_order":14,"pid":0.6690826942402492},"maxtrials":{"id":"maxtrials","type":"number","placeholder":"","advanced":false,"desc":"Sets the maximum number of attempts to generate streamline from the seed point. Default=1000000.","default":1000000,"_order":15,"pid":0.75140148728184},"curvatures":{"id":"curvatures","type":"string","placeholder":"","advanced":false,"desc":"minimum radius of curvatures. can be multiple (i.e. ensemble) or one value. default: 1","default":"1","_order":15,"pid":0.9222365850507093},"maxsampling":{"id":"maxsampling","type":"number","placeholder":"","advanced":false,"desc":"This option limits the number of samples that can be tested for rejection sampling during propagation. Default=10000.","default":10000,"_order":17,"pid":0.6359257169542216},"single_lmax":{"id":"single_lmax","type":"boolean","placeholder":"","advanced":false,"desc":"Determines whether single lmax (true) or ensemble lmax (false) will be performed","default":true,"_order":18,"pid":0.6094285243096815},"probelength":{"id":"probelength","type":"number","placeholder":"","advanced":true,"desc":"Trekker: Length of the probe. Pick 1/4 of the smallest of the FOD(input dwi) voxel dimensions. For whole-brain tractography, use 1.0","default":0.25,"_order":20,"pid":0.5945714297600724},"probecount":{"id":"probecount","type":"number","placeholder":"","advanced":true,"desc":"Trekker: Determines the number of lines outside the cylinder. Default: 1, i.e: by default, the radius of the cylinder (probeRadius) is zero and only a single line is used to model a cylinder.","default":1,"_order":21,"pid":0.5991466778068264},"probequality":{"id":"probequality","type":"number","placeholder":"","advanced":true,"desc":"Trekker: This parameter sets the number of segments to split the cylinder along the length of the probe. The larger the value is, the slower the computation gets. Default=4.","default":4,"_order":22,"pid":0.39716367655089035},"proberadius":{"id":"proberadius","type":"number","placeholder":"","advanced":true,"desc":"Trekker: Probe radius. Default: 0","default":0,"_order":23,"pid":0.15255187254106928},"reslice":{"id":"reslice","type":"boolean","placeholder":"","advanced":false,"desc":"reslice rois into diffusion space if true","default":false,"_order":24,"pid":0.533763145106986}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5db737fe8aeeee68c6f2dc12","id":"dwi","datatype":"58c33c5fe13a50849b25879b"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5db737fe8aeeee0b74f2dc11","id":"csd","datatype":"5c536bf0f9109beac46adb45"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5db737fe8aeeeea727f2dc10","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9"},{"datatype_tags":["5tt_masks"],"optional":true,"multi":false,"advanced":false,"_id":"5db737fe8aeeee4e46f2dc0f","id":"mask","datatype":"5a281aee2c214c9ba83ce620"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5db737fe8aeeeedb0af2dc0e","id":"brainmask","datatype":"5a281aee2c214c9ba83ce620"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e9d31b2f1745d6b8af6830c","id":"anat","datatype":"58c33bcee13a50849b25879a"},{"datatype_tags":["white_matter"],"optional":true,"multi":false,"advanced":false,"_id":"5eb99fb0e8e7ac17c98a9f1f","id":"wm_mask","datatype":"5a281aee2c214c9ba83ce620","desc":"This is the path to the precomputed white matter mask. If left empty, a white matter mask will be computed automatically"}],"outputs":[{"datatype_tags":["roi_trekker"],"output_on_root":false,"archive":true,"_id":"5db737fe8aeeee8147f2dc15","id":"track","datatype":"5907d922436ee50ffde9c549","datatype_tags_pass":null,"files":null},{"datatype_tags":["roi_trekker"],"output_on_root":false,"archive":true,"_id":"5db737fe8aeeee899bf2dc13","id":"wmc","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags_pass":null,"files":null},{"datatype_tags":["brain_mask"],"output_on_root":false,"archive":false,"_id":"5db737fe8aeeeee32ff2dc14","id":"brainmask","datatype":"5a281aee2c214c9ba83ce620","datatype_tags_pass":null,"files":null},{"datatype_tags":[],"output_on_root":false,"archive":false,"_id":"5e5430545b9d90120672cf73","id":"5tt","datatype":"5a281aee2c214c9ba83ce620","datatype_tags_pass":null,"files":null}],"github_branch":"master-app-v1.0","github":"brainlife/app-trekker-roi-tracking","name":"Trekker ROI Tracking (dwi) - v1.0","user_id":"16","contributors":[{"name":"Brad Caron","email":null,"_id":"634a385d62f3d3800f11ef2e"},{"name":"Franco Pestilli","email":null,"_id":"634a385d62f3d3800f11ef2f"}],"desc":"Brainlife App (wrapper) for dMRI based fiber tracking between ROIs using parallel transport tractography","__v":5522,"create_date":"2020-02-24T20:13:57.622Z","doi":"10.25663/brainlife.app.280","deprecated_by":"5ecc95311f446482f59ed395","_canedit":true},{"_id":"5b50a45b786e0f002791d301","projects":[],"admins":["16","41","146","1"],"tags":[],"removed":false,"name":"Volume-based Multiple Linear Regression","desc":"SOCR / Volume-based Multiple Linear Regression Analysis","citation":null,"references":[],"github":"brainlife/app-socr-mlra","config":{"t1":{"type":"input","file_id":"t1","input_id":"t1"},"regressors":{"type":"string","placeholder":"","desc":"","default":"age,sex","id":"regressors","pid":0.7419970745951152,"_order":2}},"inputs":[{"datatype_tags":[],"optional":false,"multi":true,"advanced":false,"_id":"5b50a45b786e0f002791d302","id":"t1","datatype":"58c33bcee13a50849b25879a"}],"outputs":[{"datatype_tags":["solr-mlra"],"output_on_root":true,"archive":true,"_id":"5b50a45b786e0f002791d303","id":"output","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null}],"user_id":"1","contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a337562f3d3800f117ecc"}],"create_date":"2018-07-19T14:46:51.757Z","stats":{"stars":0,"requested":347,"users":5,"success_rate":96.72131147540983,"serviceinfo":{"_id":"5d729e1f78356a109788b255","counts":{"_id":"5e5c3db387cac76a3cab13c5","failed":0,"finished":7,"removed":7,"requested":9,"running":7,"running_sync":0,"stop_requested":0},"success_rate":100,"users":3,"readme_status":"too short","runtime_mean":8178746.571428572,"runtime_std":13238948.16180075,"service":"brain-life/app-socr-mlra","__v":0},"gitinfo":{"desc":"SOCR / Volume-based Multiple Linear Regression Analysis","tags":[],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":318400.23,"runtime_std":613013.5496871476,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a337562f3d3800f117ecb"}],"examples":1,"groups":6},"doi":"10.25663/bl.app.84","__v":11939,"_canedit":true},{"_id":"5ec4646f41ba118064f44d41","stats":{"success_rate":91.56626506024097,"users":3,"runtime_mean":72689.71052631579,"runtime_std":43643.373815149025,"requested":87,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3aaf62f3d3800f123e07"}],"examples":1,"groups":3},"projects":[],"admins":["56","41","521"],"tags":["vision"],"removed":false,"config":{"os_raw":{"type":"input","file_id":"os_raw","input_id":"input OCT"},"os_centroid":{"type":"input","file_id":"os_centroid","input_id":"input OCT"},"od_raw":{"type":"input","file_id":"od_raw","input_id":"input OCT"},"od_centroid":{"type":"input","file_id":"od_centroid","input_id":"input OCT"},"layerIndexSequences":{"id":"layerIndexSequences","type":"string","placeholder":"","advanced":false,"desc":"Indicates which layers are to be summed in order to generate the layer amalgams that will be processed later.","default":"1:7,1:4,5,6","_order":2,"pid":0.2405277074205474},"analysesNames":{"id":"analysesNames","type":"string","placeholder":"","advanced":false,"desc":"Indicates the abbreviation for the layer amalgam, will label the output analyses.  Must be of equal length as the layerIndexSequences input.","default":"TT, NL, ONL, PROS","_order":3,"pid":0.5359544882042062},"visFieldDiam":{"id":"visFieldDiam","type":"number","placeholder":"","advanced":false,"desc":"Indicates the total *diameter* of the visual field measured by the experimenter. Assumed to be consistent across subjects. The user/experimenter should know this about their data.  ","default":20,"_order":4,"pid":0.3332941392253643},"theshFloor":{"id":"theshFloor","type":"number","placeholder":"","advanced":false,"desc":"Specifies the desired threshold to be applied. Applied prior to computation of means. Values below this are set to NaN and are not featured in computation of mean. If no threshold is desired, enter a value of 0.","default":0,"_order":5,"pid":0.670013483557321},"gaussKernel":{"id":"gaussKernel","type":"number","placeholder":"","advanced":false,"desc":"Specifies the desired smoothing kernel to be applied. Applied prior to computation of means). Pixel values are thus the result of a gaussian smoothing process. If no threshold is desired, enter a value of 1.  MUST BE AN ODD NUMBER","default":1,"_order":6,"pid":0.6810900348052},"meanShape":{"id":"meanShape","type":"enum","placeholder":"","advanced":false,"desc":"Specifies the desired method for computing the mean. \"rings\" will generate averages for concentric, degree-specific rings (like a bullseye), while \"full\" will compute the mean for the entire visual field (to the specified current, iterated degree).","default":"rings","_order":7,"pid":0.394895360241579,"options":[{"desc":" \"rings\" will generate averages for concentric, degree-specific rings (like a bullseye)","label":"rings","value":"rings"},{"desc":"\"full\" will compute the mean for the entire visual field (for each, iterated degree).","label":"full","value":"full"}]}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ec4646f41ba112340f44d42","id":"input OCT","datatype":"5ebe0bbbb969982124072325"}],"outputs":[{"datatype_tags":["raw"],"output_on_root":false,"archive":true,"_id":"5ec4646f41ba110b5ff44d43","id":"finalOutput","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null,"desc":"Two CSV files showing the mean and standard deviation for each degree of the visual field, across the analyses requested."}],"github_branch":"master","github":"DanNBullock/app-voxeleronOCT","name":"Voxeleron OCT data Processing","user_id":"56","contributors":[{"name":"Daniel Bullock","email":"iisdanbul@gmail.com","_id":"634a3aaf62f3d3800f123e08"},{"name":"Franco Pestilli","email":null,"_id":"634a3aaf62f3d3800f123e09"},{"name":null,"email":null,"_id":"634a3aaf62f3d3800f123e0a"}],"create_date":"2020-05-19T22:57:51.572Z","desc":"This app computes the mean and standard deviation of Voxeleron OTC data for each degree of visual angle.  This can be computed within a single layer, or across layers.  The output of this app is a table for both mean and standard deviation, and the output data (visual angle OCT data) for each combination of eye and layer combination.","doi":"10.25663/brainlife.app.346","__v":4785,"_canedit":true},{"_id":"5cc9ccca4b5e4502275edb56","projects":[],"admins":["41","56"],"tags":["diffusion-mri","segmentation","tractography"],"removed":false,"stats":{"stars":0,"requested":32,"users":5,"success_rate":0,"serviceinfo":{"_id":"5d729e1e78356a109788b1ed","counts":{"_id":"5e5c3df887cac7a065ab140d","failed":14,"finished":0,"removed":15,"requested":21,"running":17,"running_sync":0,"stop_requested":4},"success_rate":0,"users":2,"readme_status":"ok","service":"brainlife/app-segment-tracts-between-multiple-regions","__v":0},"gitinfo":{"desc":"Allows tracking between different regions of the brain.","tags":["diffusion-mri","segmentation","tractography"],"stats":{"stars":0},"contributors":[{"name":"Daniel Bullock","email":null},{"name":"Franco Pestilli","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a360562f3d3800f11bd28"}],"examples":0,"groups":5},"config":{"track":{"type":"input","file_id":"track","input_id":"track"},"atlas":{"type":"input","file_id":"parc","input_id":"atlas"},"key":{"type":"input","file_id":"key","input_id":"atlas"},"roiPairs":{"id":"roiPairs","type":"string","placeholder":"","desc":"Must be in appropriate format, for example:\n 23 95 2 8 ; 1 2 12 34 8 3 5\n 4 5 236 86 ; 72 12 55 \n; indicates separation of ROI pair members (denoted as sets of atlas indices) while line breaks separate ROI pairs.  Thus:\n<ROI1A> ; <ROI1B>\n<ROI2A> ; <ROI2B>\n<ROI3A> ; <ROI3B>\n...","default":"","_order":3,"pid":0.1726763480953012,"multiline":true},"smoothKernel":{"id":"smoothKernel","type":"number","placeholder":"1","desc":"Smoothing Kernel for ROI.  Odd, whole number values only.  Values larger than 1 result in ROI inflation.  0 performs no inflation.\nhttps://www.mathworks.com/help/matlab/ref/smooth3.html","default":1,"_order":4,"pid":0.6139773254474031,"min":1}},"inputs":[{"id":"track","datatype":"5907d922436ee50ffde9c549","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c0865fff9b4a2002efc1584"},{"id":"atlas","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c0865fff9b4a2002efc1583"}],"outputs":[{"id":"classification","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags":[],"datatype_tags_pass":"track","output_on_root":true,"files":null,"archive":true,"_id":"5c094bf8f9b4a2002efc15ca"}],"name":"WMA Tract Segmentation with Atlas","github":"brainlife/app-segment-tracts-between-multiple-regions","user_id":"56","contributors":[{"name":"Daniel Bullock","email":"iisdanbul@gmail.com","_id":"634a360662f3d3800f11bd29"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a360662f3d3800f11bd2a"},{"name":"Franco Pestilli","email":null,"_id":"634a360662f3d3800f11bd2b"},{"name":"David Hunt","email":"davhunt@iu.edu","_id":"634a360662f3d3800f11bd2c"}],"__v":8128,"desc":"Tract Segmentation from input tractography using ROIs","desc_override":"This app segments tracts using pairs of (potentially multiple) specified atlas regions to output a set of tracts. Instead of running this App, we recommend running \"ROI Generation\" App first to convert the Atlas to ROI, then run \"WMA Tract Segmentation with ROIs\" to segment tracts using those ROIs. ","create_date":"2019-05-01T16:43:54.420Z","doi":"10.25663/brainlife.app.190","github_branch":"1.0","_canedit":true},{"_id":"5cc9ce364b5e4502275edb5e","projects":[],"admins":["41","56"],"tags":["diffusion-mri","segmentation","tractography"],"removed":false,"stats":{"stars":0,"requested":32,"users":5,"success_rate":0,"serviceinfo":{"_id":"5d729e1e78356a109788b1ed","counts":{"_id":"5e5c3df987cac74531ab140e","failed":14,"finished":0,"removed":15,"requested":21,"running":17,"running_sync":0,"stop_requested":4},"success_rate":0,"users":2,"readme_status":"ok","service":"brainlife/app-segment-tracts-between-multiple-regions","__v":0},"gitinfo":{"desc":"Allows tracking between different regions of the brain.","tags":["diffusion-mri","segmentation","tractography"],"stats":{"stars":0},"contributors":[{"name":"Daniel Bullock","email":null},{"name":"Franco Pestilli","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a360e62f3d3800f11bd2e"}],"examples":0,"groups":5},"config":{"track":{"type":"input","file_id":"track","input_id":"track"},"ROI":{"type":"input","file_id":"rois","input_id":"ROI"},"roiPairs":{"id":"roiPairs","type":"string","placeholder":"","desc":"Must be in appropriate format, for example:\n 23 95 2 8 ; 1 2 12 34 8 3 5\n 4 5 236 86 ; 72 12 55 \n; indicates separation of ROI pair members (denoted as sets of atlas indices) while line breaks separate ROI pairs.  Thus:\n<ROI1A> ; <ROI1B>\n<ROI2A> ; <ROI2B>\n<ROI3A> ; <ROI3B>\n...","default":"","_order":3,"pid":0.796972071671789,"multiline":true},"smoothKernel":{"id":"smoothKernel","type":"number","placeholder":"1","desc":"Smoothing Kernel for ROI.  Odd, whole number values only.  Values larger than 1 result in ROI inflation.  0 performs no inflation.\nhttps://www.mathworks.com/help/matlab/ref/smooth3.html","default":1,"_order":4,"pid":0.5856480875042628,"min":1}},"inputs":[{"id":"track","datatype":"5907d922436ee50ffde9c549","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c0865fff9b4a2002efc1584"},{"id":"ROI","datatype":"5be9ea0315a8683a39a1ebd9","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c0865fff9b4a2002efc1583"}],"outputs":[{"id":"classification","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags":[],"datatype_tags_pass":"track","output_on_root":false,"files":null,"archive":true,"_id":"5c094bf8f9b4a2002efc15ca"}],"name":"WMA Tract Segmentation with ROIs","github":"brainlife/app-segment-tracts-between-multiple-regions","user_id":"56","contributors":[{"name":"Daniel Bullock","email":"iisdanbul@gmail.com","_id":"634a360f62f3d3800f11bd2f"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a360f62f3d3800f11bd30"},{"name":"Franco Pestilli","email":null,"_id":"634a360f62f3d3800f11bd31"},{"name":"David Hunt","email":"davhunt@iu.edu","_id":"634a360f62f3d3800f11bd32"}],"__v":8131,"desc":"Tract Segmentation from input tractography using ROIs","desc_override":"This app segments tracts using pairs of (potentially multiple) specified rois from an roi directory to output a set of tracts.","create_date":"2019-05-01T16:49:58.345Z","doi":"10.25663/brainlife.app.191","github_branch":"master","_canedit":true},{"_id":"5967b45e81d7ef0021538e89","name":"WMC Figures (AFQ or WMA)","desc":"This service creates 4 figures of each AFQ tract: axial, left sagittal, right sagittal, coronal. Please choose the t1 image slices you would like displayed. The default slices work well for the HCP t1 images if they have not been re-ACPC aligned. If you have ACPC aligned your t1 images using the ACPC alignment app on Brain Life the following values are a good starting point: coronal = 105, sagittal = 89, axial = 65. The img_min and img_max values refer to the value range displayed for the t1 image. The value range is calulated as follow (mean + img_min * std, mean + img_max * std). The default values are a good starting place, adjust them if your t1 is too dark or too light.","github":"kitchell/app-AFQ_figures","github_branch":"v2.1","config":{"AFQ":{"type":"input","file_id":"tracts","input_id":"afq"},"t1":{"type":"input","file_id":"t1","input_id":"t1"},"coronal":{"default":85,"type":"integer","id":"coronal","pid":0.32463928246069806,"_order":2,"optional":false,"desc":""},"sagittal":{"default":74,"type":"integer","id":"sagittal","pid":0.5653938830511431,"_order":3,"optional":false,"desc":""},"axial":{"default":48,"type":"integer","id":"axial","pid":0.12008510395330307,"_order":4,"optional":false,"desc":"48"},"img_max":{"default":2,"desc":"","placeholder":"","type":"integer","id":"img_max","pid":0.9106251481548442,"_order":5},"img_min":{"default":-0.5,"desc":"","placeholder":"","type":"integer","id":"img_min","pid":0.36937375793857385,"_order":6}},"user_id":"43","create_date":"2017-07-13T17:56:46.087Z","removed":false,"_rate":5,"outputs":[{"datatype_tags":["wmc_figures"],"output_on_root":true,"archive":true,"_id":"5967b45e81d7ef0021538e8a","id":"images","datatype":"5967b799b09297d8d831709e","files":null}],"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5967b45e81d7ef0021538e8b","id":"afq","datatype":"58f10a90436ee50ffd9063c5"},{"datatype_tags":["acpc_aligned"],"optional":false,"multi":false,"advanced":false,"_id":"596e25aa62986e00270caca4","id":"t1","datatype":"58c33bcee13a50849b25879a"}],"tags":["quality-check"],"admins":["16","43"],"__v":14301,"projects":[],"contributors":[{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a30e162f3d3800f116526"},{"name":"Brad Caron","email":null,"_id":"634a30e162f3d3800f116527"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a30e162f3d3800f116528"}],"references":[],"stats":{"stars":0,"requested":2027,"users":38,"success_rate":80.15963511972633,"serviceinfo":{"_id":"5d729e1f78356a109788b32b","counts":{"_id":"5e5c687f87cac79ccaab1ba4","failed":201,"finished":949,"removed":1252,"requested":1388,"running":1140,"running_sync":0,"stop_requested":89},"success_rate":82.52173913043478,"users":12,"readme_status":"ok","runtime_mean":1916239.32,"runtime_std":162761.39941693048,"service":"kitchell/app-AFQ_figures","__v":0},"gitinfo":{"desc":"This service creates 4 figures of each AFQ tract: axial, left sagittal, right sagittal, coronal. Please choose the t1 image slices you would like displayed. The default slices work well for the HCP t1 images if they have not been re-ACPC aligned. If you have ACPC aligned your t1 images using the ACPC alignment app on Brain Life the following values are a good starting point: coronal = 105, sagittal = 89, axial = 65. The img_min and img_max values refer to the value range displayed for the t1 image. The value range is calulated as follow (mean + img_min * std, mean + img_max * std). The default values are a good starting place, adjust them if your t1 is too dark or too light.","tags":["quality-check"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":512506.64,"runtime_std":484617.70921336574,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a30e162f3d3800f116525"}],"examples":0,"groups":33},"doi":"10.25663/brainlife.app.145","_canedit":true},{"_id":"5c7319a5badd19003102e8d8","stats":{"stars":0,"requested":8218,"users":1,"success_rate":92.1863260706236,"serviceinfo":{"_id":"5d729e1e78356a109788b21d","counts":{"_id":"5e5c3de887cac73417ab13fb","failed":200,"finished":5941,"removed":5982,"requested":6324,"running":5965,"running_sync":0,"stop_requested":7},"success_rate":96.74320143299137,"users":1,"readme_status":"no README.md","runtime_mean":350899991.56,"runtime_std":1365274067.2197254,"service":"brainlife/app-subj2reference","__v":0},"gitinfo":{"desc":null,"tags":[],"stats":{"stars":0},"contributors":[{"name":"Daniel Bullock","email":null}]},"runtime_mean":11656719.23,"runtime_std":12031083.924789138,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a355862f3d3800f11a19f"}],"examples":2,"groups":4},"projects":[],"admins":["56"],"tags":[],"removed":false,"config":{"t1":{"type":"input","file_id":"t1","input_id":"t1"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"rois":{"type":"input","file_id":"rois","input_id":"rois"}},"inputs":[{"datatype_tags":["!brain_extracted"],"optional":false,"multi":false,"advanced":false,"_id":"5c7319a5badd19003102e8db","id":"t1","datatype":"58c33bcee13a50849b25879a"},{"datatype_tags":["brain"],"optional":false,"multi":false,"advanced":false,"_id":"5c7319a5badd19003102e8da","id":"mask","datatype":"5a281aee2c214c9ba83ce620"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c7319a5badd19003102e8d9","id":"rois","datatype":"5be9ea0315a8683a39a1ebd9"}],"outputs":[{"datatype_tags":["MNI Warp"],"output_on_root":false,"archive":true,"_id":"5c7319a5badd19003102e8dc","id":"output","datatype":"5be9ea0315a8683a39a1ebd9","datatype_tags_pass":"rois","files":null}],"github_branch":"master","github":"brainlife/app-subj2reference","name":"Warp ROIs from subject space to MNI space","user_id":"56","contributors":[{"name":"Daniel Bullock","email":"iisdanbul@gmail.com","_id":"634a355962f3d3800f11a1a0"},{"name":"Franco Pestilli","email":null,"_id":"634a355962f3d3800f11a1a1"}],"create_date":"2019-02-24T22:24:37.125Z","desc":"This app warps your input set of ROIS to a reference space. As it is currently set up, the master branch of this app warps to MNI space.","doi":"10.25663/brainlife.app.169","__v":8176,"_canedit":true},{"_id":"5fa95136afcdcceef4c40294","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3e1662f3d3800f12b9e4"}],"success_rate":60.29411764705882,"users":4,"runtime_mean":133528.46341463414,"runtime_std":94405.20553782459,"requested":73,"examples":1,"groups":5},"projects":[],"admins":["146"],"tags":["alignment"],"removed":false,"config":{"t1":{"type":"input","file_id":"t1","input_id":"0"},"fa":{"type":"input","file_id":"fa","input_id":"1"},"md":{"type":"input","file_id":"md","input_id":"1"},"rd":{"type":"input","file_id":"rd","input_id":"1"},"ad":{"type":"input","file_id":"ad","input_id":"1"},"cl":{"type":"input","file_id":"cl","input_id":"1"},"cp":{"type":"input","file_id":"cp","input_id":"1"},"cs":{"type":"input","file_id":"cs","input_id":"1"},"tensors":{"type":"input","file_id":"tensors","input_id":"1"},"kurtosis":{"type":"input","file_id":"kurtosis","input_id":"1"},"ga":{"type":"input","file_id":"ga","input_id":"1"},"mk":{"type":"input","file_id":"mk","input_id":"1"},"ak":{"type":"input","file_id":"ak","input_id":"1"},"rk":{"type":"input","file_id":"rk","input_id":"1"},"rgb":{"type":"input","file_id":"rgb","input_id":"1"},"warp":{"type":"input","file_id":"warp","input_id":"2"},"affine":{"type":"input","file_id":"affine","input_id":"2"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5fa95136afcdcc4269c40295","id":"0","datatype":"58c33bcee13a50849b25879a","desc":"T1 image to warp"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5fa95136afcdcc5ce6c40296","id":"1","datatype":"5a79df48d071a1753f1d661b","desc":"tensor images to warp"},{"datatype_tags":["!linear"],"optional":false,"multi":false,"advanced":false,"_id":"5fa95324afcdcc5cddc40431","id":"2","datatype":"5bbfb28071454db2a890fbce","desc":"non-linear warp to use for warping"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5fa95136afcdcc3cfdc40297","id":"t1_aligned","datatype":"58c33bcee13a50849b25879a","datatype_tags_pass":"0","files":null,"desc":"warped T1"},{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5fa95136afcdcc9c30c40298","id":"tensor_aligned","datatype":"5a79df48d071a1753f1d661b","datatype_tags_pass":"1","files":null,"desc":"warped tensor"}],"github_branch":"1.0","github":"brainlife/app-warp-t1","name":"Warp T1 and tensor","user_id":"146","contributors":[{"name":"Giulia Bertò","email":null,"_id":"634a3e1762f3d3800f12b9e5"}],"create_date":"2020-11-09T14:24:54.317Z","desc":"Warp T1 and tensor volumes with a given non-linear warp.nii.gz using ANTs.","doi":"10.25663/brainlife.app.448","__v":3937,"_canedit":true},{"_id":"61158b45a5a04c9673f9d510","projects":[],"admins":["56","1"],"tags":[],"removed":false,"stats":{"requested":8218,"users":1,"success_rate":92.1863260706236,"gitinfo":{"desc":null,"tags":[],"stats":{"stars":0},"contributors":[{"name":"Daniel Bullock","email":null}]},"runtime_mean":11656719.23,"runtime_std":12031083.924789138,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a41fd62f3d3800f12f260"}],"examples":0,"groups":4},"config":{"t1":{"type":"input","file_id":"t1","input_id":"t1"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"rois":{"type":"input","file_id":"densitites","input_id":"rois"}},"inputs":[{"datatype_tags":["!brain_extracted"],"optional":false,"multi":false,"advanced":false,"_id":"5c7319a5badd19003102e8db","id":"t1","datatype":"58c33bcee13a50849b25879a"},{"datatype_tags":["brain"],"optional":false,"multi":false,"advanced":false,"_id":"5c7319a5badd19003102e8da","id":"mask","datatype":"5a281aee2c214c9ba83ce620"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c7319a5badd19003102e8d9","id":"rois","datatype":"61151f8ca5a04c1ad3f9a2d1"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5c7319a5badd19003102e8dc","id":"output","datatype":"61151f8ca5a04c1ad3f9a2d1","datatype_tags_pass":"rois","files":null}],"github_branch":"master","github":"brainlife/app-subj2reference","name":"Warp density-probability from subject space to MNI space - copy","user_id":"1","contributors":[{"name":"Daniel Bullock","email":"iisdanbul@gmail.com","_id":"634a41fd62f3d3800f12f261"},{"name":"Franco Pestilli","email":null,"_id":"634a41fd62f3d3800f12f262"}],"desc":"This app warps your input set of ROIS to a reference space. As it is currently set up, the master branch of this app warps to MNI space.","__v":2075,"create_date":"2021-08-12T20:57:41.426Z","doi":"10.25663/brainlife.app.558","_canedit":true},{"_id":"5ac8e11671d0210718658ee2","name":"White Matter Anatomy Segmentation","desc":"Classifies streamlines into known anatomical tracts.","citation":null,"avatar":"https://raw.githubusercontent.com/brain-life/app-wmaSeg/master/wmaSeg.png","github":"brainlife/app-wmaSeg","github_branch":"1.8","config":{"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"track":{"type":"input","file_id":"track","input_id":"tracks"}},"user_id":"43","create_date":"2018-04-07T15:17:42.733Z","removed":false,"_rate":0,"outputs":[{"datatype_tags":["wmaSeg"],"output_on_root":true,"_id":"5ac8e11671d0210718658ee3","id":"output","datatype":"58f10a90436ee50ffd9063c5","files":null,"datatype_tags_pass":"tracks"}],"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ac8e11671d0210718658ee5","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ac8e11671d0210718658ee4","id":"tracks","datatype":"5907d922436ee50ffde9c549"}],"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a327462f3d3800f117501"},{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a327462f3d3800f117502"},{"name":"Daniel Bullock","email":"iisdanbul@gmail.com","_id":"634a327462f3d3800f117503"},{"name":"Franco Pestilli","email":null,"_id":"634a327462f3d3800f117504"},{"name":"Steven O'Riley","email":null,"_id":"634a327462f3d3800f117505"},{"name":"Brad Caron","email":null,"_id":"634a327462f3d3800f117506"}],"tags":["analysis"],"references":[],"admins":["56"],"projects":[],"__v":14251,"stats":{"stars":1,"requested":38346,"users":55,"success_rate":68.61732452463195,"serviceinfo":{"_id":"5d729e1e78356a109788b20d","counts":{"_id":"5e5c68a887cac7b9faab1bd4","failed":3425,"finished":9221,"removed":16901,"requested":18537,"running":12116,"running_sync":0,"stop_requested":445},"success_rate":72.91633718171754,"users":20,"readme_status":"ok","runtime_mean":14985593.77,"runtime_std":3690815.7786162673,"service":"brainlife/app-wmaSeg","__v":0},"gitinfo":{"desc":"Classifies streamlines into known anatomical tracts.","tags":["analysis"],"stats":{"stars":1},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Lindsey Kitchell","email":null},{"name":"Daniel Bullock","email":null},{"name":"Franco Pestilli","email":null},{"name":"Steven O'Riley","email":null}]},"runtime_mean":12269634.63,"runtime_std":6622596.683443095,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a327362f3d3800f1174ff"},{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"634a327362f3d3800f117500"}],"examples":0,"groups":118},"doi":"10.25663/bl.app.41","deprecated_by":"5cc73ef44ed9df00317f6288","_canedit":true},{"_id":"5cc73ef44ed9df00317f6288","projects":[],"admins":["16","56","41","146","1"],"tags":["analysis"],"removed":false,"name":"White Matter Anatomy Segmentation","desc":"Classifies streamlines into known anatomical tracts.","avatar":"https://raw.githubusercontent.com/brain-life/app-wmaSeg/master/wmaSeg.png","github":"brainlife/app-wmaSeg","github_branch":"3.9","config":{"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"track":{"type":"input","file_id":"track","input_id":"tracks"}},"user_id":"1","outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5cc7244b4ed9df00317f6271","id":"classification","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags_pass":null,"files":null}],"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ac8e11671d0210718658ee5","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ac8e11671d0210718658ee4","id":"tracks","datatype":"5907d922436ee50ffde9c549"}],"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a35eb62f3d3800f11b10d"},{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a35eb62f3d3800f11b10e"},{"name":"Daniel Bullock","email":"iisdanbul@gmail.com","_id":"634a35eb62f3d3800f11b10f"},{"name":"Franco Pestilli","email":null,"_id":"634a35eb62f3d3800f11b110"},{"name":"Steven O'Riley","email":null,"_id":"634a35eb62f3d3800f11b111"},{"name":"Brad Caron","email":null,"_id":"634a35eb62f3d3800f11b112"}],"__v":8136,"stats":{"stars":1,"serviceinfo":{"_id":"5d729e1e78356a109788b20d","counts":{"_id":"5e5c3df687cac756adab140b","failed":3425,"finished":9221,"removed":16901,"requested":18537,"running":12116,"running_sync":0,"stop_requested":445},"success_rate":72.91633718171754,"users":20,"readme_status":"ok","runtime_mean":14985593.77,"runtime_std":3690815.7786162673,"service":"brainlife/app-wmaSeg","__v":0},"gitinfo":{"desc":"Classifies streamlines into known anatomical tracts.","tags":["analysis"],"stats":{"stars":1},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Lindsey Kitchell","email":null},{"name":"Daniel Bullock","email":null},{"name":"Franco Pestilli","email":null},{"name":"Steven O'Riley","email":null}]},"success_rate":68.61732452463195,"users":55,"runtime_mean":12269634.63,"runtime_std":6622596.683443095,"requested":38346,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a35ea62f3d3800f11b10b"},{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"634a35ea62f3d3800f11b10c"}],"examples":5,"groups":118},"create_date":"2019-04-29T18:14:12.749Z","doi":"10.25663/brainlife.app.188","desc_override":"An automated segmentation of major white matter tracts from an input whole brain tractography.  Utilizes a WMQL-like approach (https://tract-querier.readthedocs.io/en/latest/) to segment streamlines, as documented in Bullock et al. 2019 (https://doi.org/10.1007/s00429-019-01907-8).  Makes extensive use of the wma tools library (https://github.com/DanNBullock/wma_tools).  ","_canedit":true},{"_id":"59bff3427fb404002d8ce7d4","project":null,"name":"White Matter Anatomy Segmentation with LiFE","desc":"Classifies streamlines into known anatomical tracts.","avatar":"https://raw.githubusercontent.com/brain-life/app-wmaSeg/master/wmaSeg.png","github":"brainlife/app-wmaSeg","github_branch":"1.4","config":{"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"wbfg":{"type":"input","file_id":"fe","input_id":"life"},"tracts":{"type":"string","placeholder":"(all tracts)","desc":"Only output specified set of tracts. List names of tracts that you'd like to output (space delimited). e.g. pArc TPC MdLF-SPL MdLF-Ang VOF","default":"","optional":true,"id":"tracts","pid":0.4965416116563608,"_order":2}},"user_id":"43","create_date":"2017-09-18T16:24:34.704Z","removed":false,"_rate":5,"outputs":[{"datatype_tags":["wmaSeg"],"output_on_root":true,"_id":"59bff3427fb404002d8ce7d5","id":"0","datatype":"58f10a90436ee50ffd9063c5","files":null}],"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"59bff3427fb404002d8ce7d8","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"59bff3427fb404002d8ce7d6","id":"life","datatype":"58d15eaee13a50849b258844"}],"tags":["analysis"],"admins":["43","56"],"__v":14289,"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a312962f3d3800f11666a"},{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a312962f3d3800f11666b"},{"name":"Daniel Bullock","email":"iisdanbul@gmail.com","_id":"634a312962f3d3800f11666c"},{"name":"Franco Pestilli","email":null,"_id":"634a312962f3d3800f11666d"},{"name":"Steven O'Riley","email":null,"_id":"634a312962f3d3800f11666e"},{"name":"Brad Caron","email":null,"_id":"634a312962f3d3800f11666f"}],"projects":[],"references":[],"stats":{"stars":1,"requested":38346,"users":55,"success_rate":68.61732452463195,"serviceinfo":{"_id":"5d729e1e78356a109788b20d","counts":{"_id":"5e5c688587cac71050ab1bac","failed":3425,"finished":9221,"removed":16901,"requested":18537,"running":12116,"running_sync":0,"stop_requested":445},"success_rate":72.91633718171754,"users":20,"readme_status":"ok","runtime_mean":14985593.77,"runtime_std":3690815.7786162673,"service":"brainlife/app-wmaSeg","__v":0},"gitinfo":{"desc":"Classifies streamlines into known anatomical tracts.","tags":["analysis"],"stats":{"stars":1},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Lindsey Kitchell","email":null},{"name":"Daniel Bullock","email":null},{"name":"Franco Pestilli","email":null},{"name":"Steven O'Riley","email":null}]},"runtime_mean":12269634.63,"runtime_std":6622596.683443095,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a312862f3d3800f116668"},{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"634a312862f3d3800f116669"}],"examples":0,"groups":118},"doi":"10.25663/bl.app.40","deprecated_by":"5cc73ef44ed9df00317f6288","_canedit":true},{"_id":"5a28180e67007b77e4d51cce","name":"White Matter Mask","desc":"This application will create a mask nifti file of the white matter of the T1 image using Freesurfer's aparc+aseg.mgz parcellation.","github":"kitchell/app-wmMask","config":{"freesurfer":{"type":"input","file_id":"output","input_id":"0"}},"user_id":"43","create_date":"2017-12-06T16:17:18.331Z","removed":false,"_rate":0,"outputs":[{"datatype_tags":["white_matter","anat"],"output_on_root":true,"archive":true,"_id":"5a28180e67007b77e4d51ccf","id":"mask","datatype":"5a281aee2c214c9ba83ce620","files":null}],"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5a28180e67007b77e4d51cd0","id":"0","datatype":"58cb22c8e13a50849b25882e"}],"contributors":[{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a31a762f3d3800f11685d"}],"tags":["anatomy-preprocessing"],"admins":["16","41","146","43","1"],"projects":[],"__v":14260,"references":[],"stats":{"stars":0,"requested":53,"users":19,"success_rate":50,"serviceinfo":{"_id":"5d729e1f78356a109788b249","counts":{"_id":"5e5c689287cac72a6dab1bbb","failed":5,"finished":22,"removed":27,"requested":34,"running":29,"running_sync":0,"stop_requested":0},"success_rate":81.48148148148148,"users":12,"readme_status":"ok","runtime_mean":14711235.727272727,"runtime_std":41494800.62649944,"service":"kitchell/app-wmMask","__v":0},"gitinfo":{"desc":"This application will create a mask nifti file of the white matter of the T1 image using Freesurfer's aparc+aseg.mgz parcellation.","tags":["anatomy-preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null}]},"runtime_mean":14711235.727272727,"runtime_std":41494800.62649944,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a31a762f3d3800f11685b"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a31a762f3d3800f11685c"}],"examples":0,"groups":11},"doi":"10.25663/bl.app.10","_canedit":true},{"_id":"5e9db4c5f1745d5768f68d19","stats":{"success_rate":48.09201623815967,"users":51,"runtime_mean":23600497.98,"runtime_std":25578287.666498195,"requested":16087,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a39ca62f3d3800f122cca"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a39ca62f3d3800f122ccb"}],"examples":0,"groups":103},"projects":[],"admins":["19","41","1"],"tags":["tracking","tractography"],"removed":false,"config":{"diff":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvec":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bval":{"type":"input","file_id":"bvals","input_id":"dwi"},"anat":{"type":"input","file_id":"t1","input_id":"anat"},"min_length":{"id":"min_length","type":"number","placeholder":"","advanced":false,"desc":"The minimum length a streamline must have","default":25,"_order":2,"pid":0.7817666299872301,"min":25,"max":100},"max_length":{"id":"max_length","type":"number","placeholder":"","advanced":false,"desc":"The maximum length a streamline can have","default":220,"_order":3,"pid":0.1539250262358034,"min":200,"max":275},"imaxs":{"id":"imaxs","type":"number","placeholder":"","advanced":false,"desc":"The lmax that will be fit for modeling the data. If the requested number is not possible with the number of directions present in the data, the highest lmax possible will be used instead.","default":16,"_order":4,"pid":0.20532677873830285,"min":2},"curvs":{"id":"curvs","type":"number","placeholder":"","advanced":false,"desc":"The maximum curvature angle a streamline can take during tracking","default":35,"_order":5,"pid":0.1619429860783963,"min":0,"max":90},"num_fibers":{"id":"num_fibers","type":"number","placeholder":"","advanced":false,"desc":"The number of streamlines to track.","default":1500000,"_order":6,"pid":0.5868042166649741,"min":1,"max":5000000},"do_prb2":{"id":"do_prb2","type":"boolean","placeholder":"","advanced":false,"desc":"Perform MRTrix3 probabilistic tracking.","default":true,"_order":7,"pid":0.5953827086605845,"readonly":true},"tensor_fit":{"id":"tensor_fit","type":"string","placeholder":"","advanced":true,"desc":"","default":"","_order":8,"pid":0.21991019383996746,"optional":true}},"inputs":[{"id":"dwi","desc":"Diffusion-weighted MRI data preprocessed using MRTrix 3.","datatype":"58c33c5fe13a50849b25879b","datatype_tags":["preprocessed"],"optional":false,"multi":false,"advanced":false,"_id":"5e9db4c5f1745d6115f68d1a"},{"id":"anat","desc":"T1w MRI data. Preferably AC-PC aligned. We suggest using the T1w processed with the FreeSurfer App","datatype":"58c33bcee13a50849b25879a","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e9db4c5f1745d5655f68d1b"}],"outputs":[{"id":"track","datatype":"5907d922436ee50ffde9c549","datatype_tags":["sd_prob"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5e9db4c5f1745d0afbf68d1c"},{"id":"tensor","datatype":"5a79df48d071a1753f1d661b","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5e9db4c5f1745d54c9f68d1d"}],"github_branch":"1.4","github":"brainlife/app-mrtrix3-act","name":"Whole Brain Tractography","user_id":"41","contributors":[{"name":"Brent McPherson","email":"bcmcpher@gmail.com","_id":"634a39ca62f3d3800f122ccc"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a39ca62f3d3800f122ccd"},{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a39ca62f3d3800f122cce"},{"name":"Franco Pestilli","email":null,"_id":"634a39ca62f3d3800f122ccf"},{"name":"Brad Caron","email":null,"_id":"634a39ca62f3d3800f122cd0"},{"name":"Anibal Sólon","email":"anibalsolon@gmail.com","_id":"634a39ca62f3d3800f122cd1"}],"create_date":"2020-04-20T14:42:13.592Z","desc":"Runs mrtrix3 ACT (Anatomically Constrained Tractography) using either single- or multi-shell diffusion-weighted MRI data. ","doi":"10.25663/brainlife.app.318","__v":5066,"_canedit":true},{"_id":"60a8274222b42a39e77140e5","stats":{"resources":[],"success_rate":25,"users":1,"runtime_mean":21860,"runtime_std":0,"requested":6,"examples":0,"groups":1},"projects":[],"admins":["1"],"tags":[],"removed":false,"config":{"track":{"type":"input","file_id":"track","input_id":"trk"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"60a8274222b42a567e7140e6","id":"trk","datatype":"5b956f6cd7b3f1e24e9121ce"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"60a8274222b42aaec87140e7","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e"}],"outputs":[{"datatype_tags":["trk2mp4"],"output_on_root":false,"archive":true,"_id":"60a8274222b42a33a67140e8","id":"output","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null}],"github_branch":"master","github":"soichih/app-trk2mp4","name":"[WIP] Create animation from trk","desc_override":"","user_id":"1","contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a40d062f3d3800f12db96"}],"create_date":"2021-05-21T21:33:54.300Z","desc":"Generate animation of trk streamlines","__v":2612,"doi":"10.25663/brainlife.app.526","_canedit":true},{"_id":"632c9b506985655cc5892a9a","user_id":"1994","projects":[],"admins":["1994","2021","146"],"name":"anat-fslswap-app","github":"hanna-willis/app-fslswap","tags":[],"config":{"t1":{"type":"input","file_id":"t1","input_id":"anat"},"swap_dimensions":{"id":"swap_dimensions","type":"string","placeholder":"","advanced":false,"desc":"new x,y,z axes in terms of the  old axes","default":"-x y z","_order":2,"pid":0.6835010981992766}},"inputs":[{"id":"anat","datatype":"58c33bcee13a50849b25879a","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"632c9b506985655cc5892a9b"}],"outputs":[{"id":"out_dir","datatype":"58c33bcee13a50849b25879a","datatype_tags":["flipped"],"datatype_tags_pass":"anat","output_on_root":false,"files":null,"archive":true,"_id":"632c9b506985655cc5892a9c"}],"stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a45d262f3d3800f1311fd"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a45d262f3d3800f1311fe"}],"success_rate":39.02439024390244,"users":2,"groups":2,"runtime_mean":220530.25,"runtime_std":684720.1040068764,"requested":47,"examples":1},"removed":false,"contributors":[{"name":"Franco Pestilli","email":null,"_id":"634a45d362f3d3800f1311ff"},{"name":null,"email":null,"_id":"634a45d362f3d3800f131200"},{"name":"Giulia Bertò","email":null,"_id":"634a45d362f3d3800f131201"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a45d362f3d3800f131202"}],"create_date":"2022-09-22T17:28:48.143Z","desc":"This is a template for a python-based brainlife.io/app","__v":23,"doi":"10.25663/brainlife.app.668","_canedit":true},{"_id":"627a5fc1d0697cf1eacb310b","user_id":"2076","projects":[],"admins":["2076","1"],"name":"app- covariance","github":"zahransa/app-covariance","tags":[],"config":{"fif":{"type":"input","file_id":"fif","input_id":"fif"}},"inputs":[{"id":"fif","datatype":"6000737faacf9ee51fa691cb","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"62860b0dd0697cf1eae1898a"}],"outputs":[{"id":"out_dir","datatype":"5afb21465858d874a4b393a1","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"62860b0dd0697cf1eae1898b"},{"id":"out_dir_report","datatype":"5e56dc330f7fa604cc3cc291","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"628653f8d0697cf1eae27209"}],"stats":{"resources":[],"examples":1,"success_rate":35,"users":1,"groups":1,"runtime_mean":11091.42857142857,"runtime_std":524.8702852386774,"requested":20},"removed":false,"contributors":[{"name":"SaeedZahran","email":"saeedzahran@hotmail.com","_id":"634a445462f3d3800f130df0"}],"create_date":"2022-05-10T12:51:13.197Z","desc":null,"__v":387,"doi":"10.25663/brainlife.app.625","_canedit":true},{"_id":"63344389db978c79919cbb82","user_id":"2076","projects":[],"admins":["2076"],"name":"app-ICA-params","github":"zahransa/app-ICA-params","github_branch":"master","tags":[],"config":{"fif":{"type":"input","file_id":"fif","input_id":"fif"},"n_components":{"id":"n_components","type":"number","placeholder":"","advanced":false,"desc":"","default":null,"_order":2,"pid":0.5805461333014532},"method":{"id":"method","type":"string","placeholder":"","advanced":false,"desc":"","default":"","_order":3,"pid":0.004413202998313048},"max_iter":{"id":"max_iter","type":"string","placeholder":"","advanced":false,"desc":"","default":"","_order":4,"pid":0.04370088808379968},"allow_ref_meg":{"id":"allow_ref_meg","type":"boolean","placeholder":"","advanced":false,"desc":"","default":false,"_order":5,"pid":0.5152886556010288}},"inputs":[{"id":"fif","datatype":"6000737faacf9ee51fa691cb","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"63344389db978c79919cbb83"}],"outputs":[{"id":"out_dir","datatype":"6283e821d0697cf1eade9d5c","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"63344389db978c79919cbb84"},{"id":"out_figs","datatype":"59666a40b09297d8d8271dfc","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"633a80d16c7d095e9d7269a9"}],"stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a460862f3d3800f1312af"},{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a460862f3d3800f1312b0"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a460862f3d3800f1312b1"}],"success_rate":43.75,"users":1,"groups":1,"runtime_mean":36939.142857142855,"runtime_std":7505.990187435469,"requested":17,"examples":1},"removed":false,"contributors":[{"name":"SaeedZahran","email":"saeedzahran@hotmail.com","_id":"634a460962f3d3800f1312b2"}],"create_date":"2022-09-28T12:52:25.283Z","desc":null,"__v":19,"doi":"10.25663/brainlife.app.675","_canedit":true},{"_id":"633449badb978c79919ced98","user_id":"2076","projects":[],"admins":["2076"],"name":"app-ICA-plot ","github":"zahransa/app-ICA-plot","github_branch":"master","tags":[],"config":{"ica":{"type":"input","file_id":"ica","input_id":"ica"}},"inputs":[{"id":"ica","datatype":"6283e821d0697cf1eade9d5c","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"633449badb978c79919ced99"}],"outputs":[{"id":"out_figs","datatype":"59666a40b09297d8d8271dfc","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"633449badb978c79919ced9a"}],"stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a461162f3d3800f1312bd"},{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a461162f3d3800f1312be"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a461162f3d3800f1312bf"}],"success_rate":54.54545454545454,"users":1,"groups":1,"requested":16,"examples":1,"runtime_mean":34377.833333333336,"runtime_std":17780.59653495599},"removed":false,"contributors":[{"name":"SaeedZahran","email":"saeedzahran@hotmail.com","_id":"634a461262f3d3800f1312c0"}],"create_date":"2022-09-28T13:18:50.563Z","desc":null,"__v":20,"doi":"10.25663/brainlife.app.676","_canedit":true},{"_id":"62b9578ff3194eded6f713f2","user_id":"2076","projects":[],"admins":["2076","1348","670"],"name":"app-SSP","github":"zahransa/app-SSP","github_branch":"main","tags":[],"config":{"fif":{"type":"input","file_id":"fif","input_id":"fif"}},"inputs":[{"id":"fif","datatype":"6000737faacf9ee51fa691cb","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"62b9578ff3194eded6f713f3"}],"outputs":[{"id":"out-dir","datatype":"6000737faacf9ee51fa691cb","datatype_tags":[],"datatype_tags_pass":"fif","output_on_root":false,"files":null,"archive":true,"_id":"62b9578ff3194eded6f713f4"}],"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a455262f3d3800f131013"}],"examples":1,"success_rate":100,"users":1,"groups":1,"runtime_mean":43876,"runtime_std":0,"requested":1},"removed":false,"contributors":[{"name":"SaeedZahran","email":"saeedzahran@hotmail.com","_id":"634a455262f3d3800f131014"}],"create_date":"2022-06-27T07:09:03.501Z","desc":null,"__v":195,"doi":"10.25663/brainlife.app.654","_canedit":true},{"_id":"63340c27db978c79919b9684","user_id":"2076","projects":[],"admins":["2076"],"name":"app-SSP-projectors-EOG ","github":"zahransa/app-SSP-projectors-EOG","github_branch":"main","tags":[],"config":{"fif":{"type":"input","file_id":"fif","input_id":"fif"},"n_grad":{"id":"n_grad","type":"number","placeholder":"","advanced":false,"desc":"","default":null,"_order":4,"pid":0.00865476884960481},"n_mag":{"id":"n_mag","type":"number","placeholder":"","advanced":false,"desc":"","default":null,"_order":5,"pid":0.9294983022623915},"n_eeg":{"id":"n_eeg","type":"number","placeholder":"","advanced":false,"desc":"","default":null,"_order":6,"pid":0.13396427666821875},"average":{"id":"average","type":"boolean","placeholder":"","advanced":false,"desc":"","default":true,"_order":7,"pid":0.9876772404548992}},"inputs":[{"id":"fif","datatype":"6000737faacf9ee51fa691cb","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"63340c27db978c79919b9685"}],"outputs":[{"id":"out_dir","datatype":"6283e7e9d0697cf1eade9bda","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"63340c27db978c79919b9686"},{"id":"out_figs","datatype":"59666a40b09297d8d8271dfc","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"633a72dc6c7d095e9d724bbc"}],"stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a45f662f3d3800f131294"},{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a45f662f3d3800f131295"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a45f662f3d3800f131296"}],"success_rate":66.66666666666666,"users":1,"groups":1,"runtime_mean":24937.25,"runtime_std":8790.771706027861,"requested":9,"examples":1},"removed":false,"contributors":[{"name":"SaeedZahran","email":"saeedzahran@hotmail.com","_id":"634a45f762f3d3800f131297"}],"create_date":"2022-09-28T08:56:07.487Z","desc":null,"__v":18,"doi":"10.25663/brainlife.app.673","_canedit":true},{"_id":"62c7f9e5f3194eded6ff05ab","user_id":"2076","projects":[],"admins":["2076"],"name":"app-anatomy","github":"zahransa/app-anatomy","github_branch":"main","tags":[],"config":{},"inputs":[],"outputs":[],"stats":{"resources":[],"examples":0},"removed":false,"contributors":[{"name":"SaeedZahran","email":"saeedzahran@hotmail.com","_id":"634a457762f3d3800f131104"}],"create_date":"2022-07-08T09:33:25.065Z","desc":null,"__v":134,"doi":"10.25663/brainlife.app.658","_canedit":true},{"_id":"63358285db978c7991a30e5b","user_id":"2076","projects":[],"admins":["2076"],"name":"app-apply-ICA","github":"zahransa/app-apply-ICA","github_branch":"master","tags":[],"config":{"fif":{"type":"input","file_id":"fif","input_id":"fif"},"ica":{"type":"input","file_id":"ica","input_id":"ica"}},"inputs":[{"id":"fif","datatype":"6000737faacf9ee51fa691cb","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"63358285db978c7991a30e5c"},{"id":"ica","datatype":"6283e821d0697cf1eade9d5c","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"63358285db978c7991a30e5d"}],"outputs":[],"stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a462d62f3d3800f1312db"},{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a462d62f3d3800f1312dc"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a462d62f3d3800f1312dd"}],"examples":0},"removed":false,"contributors":[{"name":"SaeedZahran","email":"saeedzahran@hotmail.com","_id":"634a462d62f3d3800f1312de"}],"create_date":"2022-09-29T11:33:25.131Z","desc":null,"__v":16,"doi":"10.25663/brainlife.app.679","_canedit":true},{"_id":"62b1c272ab3e66978065736f","user_id":"2076","projects":[],"admins":["2076"],"name":"app-artifact-amplitude","github":"zahransa/app-artifact-amplitude","github_branch":"main","tags":[],"config":{"epo":{"type":"input","file_id":"epo","input_id":"epo"},"reject_mag":{"id":"reject_mag","type":"number","placeholder":"","advanced":false,"desc":"","default":null,"_order":2,"pid":0.29491788960090615}},"inputs":[{"id":"epo","datatype":"61797fc39538685e5db952b0","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"62b1c272ab3e669780657370"}],"outputs":[{"id":"out_dir","datatype":"61797fc39538685e5db952b0","datatype_tags":[],"datatype_tags_pass":"epo","output_on_root":false,"files":null,"archive":true,"_id":"62b1c3e8ab3e669780657517"},{"id":"out_figs","datatype":"59666a40b09297d8d8271dfc","datatype_tags":[],"datatype_tags_pass":"epo","output_on_root":false,"files":null,"archive":true,"_id":"62b1c3e8ab3e669780657518"}],"stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a454962f3d3800f131009"}],"examples":0},"removed":false,"contributors":[{"name":"SaeedZahran","email":"saeedzahran@hotmail.com","_id":"634a454962f3d3800f13100a"}],"create_date":"2022-06-21T13:06:58.962Z","desc":null,"__v":225,"doi":"10.25663/brainlife.app.653","_canedit":true},{"_id":"60107014c0810378a8b98e1b","stats":{"resources":[],"success_rate":97.72727272727273,"users":1,"runtime_mean":33776.93023255814,"runtime_std":51774.353508544074,"requested":45,"examples":1,"groups":3},"projects":["5d64733db29ac960ca2e797f","6046775eebfe453e373a6b1a","5ff7630241130d34f7185ceb"],"admins":["1348"],"tags":[],"removed":false,"config":{"output":{"type":"input","file_id":"output","input_id":"freesurfer"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"60107014c0810377eab98e1c","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e"}],"outputs":[{"datatype_tags":["bst_anat"],"output_on_root":false,"archive":true,"_id":"6026f0bfdea2e2690e795fe6","id":"out_data","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null},{"datatype_tags":["bst_html"],"output_on_root":false,"archive":true,"_id":"60274b02dea2e20ccd796990","id":"out_dir","datatype":"5e56dc330f7fa604cc3cc291","datatype_tags_pass":null,"files":null}],"github_branch":"master","github":"guiomar/app-brainstorm-1_import_anatomy","name":"app-brainstorm_1_import_anatomy","desc_override":"prueba","user_id":"1348","contributors":[{"name":"Julia Guiomar Niso Galán","email":null,"_id":"634a3eb462f3d3800f12c2a4"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a3eb462f3d3800f12c2a5"}],"create_date":"2021-01-26T19:40:04.893Z","desc":null,"__v":3432,"doi":"10.25663/brainlife.app.467","_canedit":true},{"_id":"625d3130cc8ab2b339ea2692","user_id":"2076","projects":[],"admins":["2076","1348","670","1"],"name":"app-epoch","github":"zahransa/app-epoch","github_branch":"master","tags":[],"config":{"fif":{"type":"input","file_id":"fif","input_id":"fif"},"events":{"type":"input","file_id":"events","input_id":"fif"},"t_min":{"id":"t_min","type":"number","placeholder":"","advanced":true,"desc":" The time relative to each event at which to start epoch (in seconds).","default":-0.3,"_order":2,"pid":0.7881777440820064,"min":-1,"max":1},"t_max":{"id":"t_max","type":"number","placeholder":"","advanced":true,"desc":"The time relative to each event at which to end each epoch (in seconds).","default":0.7,"_order":3,"pid":0.9549568805708695,"min":-1,"max":3},"param_eeg":{"id":"param_eeg","type":"boolean","placeholder":"","advanced":false,"desc":"Include EEG channels in the generated report.","default":false,"_order":4,"pid":0.7150622060003571},"param_meg":{"id":"param_meg","type":"boolean","placeholder":"","advanced":false,"desc":"Include MEG channels in the generated report.","default":false,"_order":5,"pid":0.3280148583266216},"param_eog":{"id":"param_eog","type":"boolean","placeholder":"","advanced":false,"desc":"If True include EOG channels.","default":false,"_order":6,"pid":0.24236820404846715},"param_ecg":{"id":"param_ecg","type":"boolean","placeholder":"","advanced":false,"desc":"If True include ECG channels.","default":false,"_order":7,"pid":0.19596116237820982},"param_emg":{"id":"param_emg","type":"boolean","placeholder":"","advanced":false,"desc":"If True include EMG channels.","default":false,"_order":8,"pid":0.9688845817754765},"param_stim":{"id":"param_stim","type":"boolean","placeholder":"","advanced":false,"desc":"If True include stimulus channels.","default":false,"_order":9,"pid":0.3996178714722669},"event_id_condition":{"id":"event_id_condition","type":"string","placeholder":"auditory/left- 1,  auditory/right- 2,  visual/left- 3","advanced":false,"desc":"Mapping the integer Event ID to experiment descriptions. The description will be used to label each event with more descriptive text rather than the original event ID which might not be intuitive to all users as it might contains numbers of such as \"1\", \"2\", \"3\". For example. Here you can map those event IDs to more human understandable text such as \"auditroy/left\", \"auditory/right\", rather than displaying \"1\", \"2\", \"3\".","default":"","_order":10,"pid":0.494886622278772},"stim_channel":{"id":"stim_channel","type":"string","placeholder":"","advanced":false,"desc":"","default":"","_order":11,"pid":0.896497606062276}},"inputs":[{"id":"fif","datatype":"6000737faacf9ee51fa691cb","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"625d3130cc8ab2b339ea2693"}],"outputs":[{"id":"out_dir","datatype":"61797fc39538685e5db952b0","datatype_tags":[],"datatype_tags_pass":"fif","output_on_root":false,"files":null,"archive":true,"_id":"625d3130cc8ab2b339ea2694"},{"id":"out_dir_report","desc":"HTML report from MNE epoch","datatype":"5e56dc330f7fa604cc3cc291","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"6274d1efcbc76827b7230f72"}],"stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a43eb62f3d3800f13083f"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a43eb62f3d3800f130840"}],"examples":1,"success_rate":58.119658119658126,"users":2,"groups":3,"runtime_mean":250306.89705882352,"runtime_std":956504.5110910065,"requested":122},"removed":false,"contributors":[{"name":"SaeedZahran","email":"saeedzahran@hotmail.com","_id":"634a43eb62f3d3800f130841"},{"name":"Brad Caron","email":null,"_id":"634a43eb62f3d3800f130842"}],"create_date":"2022-04-18T09:36:48.282Z","desc":null,"__v":532,"doi":"10.25663/brainlife.app.613","_canedit":true},{"_id":"632993fd71291bb27f9ab7c9","user_id":"2076","projects":[],"admins":["2076"],"name":"app-events","github":"zahransa/app-events","github_branch":"master","tags":[],"config":{"fif":{"type":"input","file_id":"fif","input_id":"fif"},"stim_channel":{"id":"stim_channel","type":"string","placeholder":"","advanced":false,"desc":"","default":"","_order":2,"pid":0.3667491009633652},"consecutive":{"id":"consecutive","type":"string","placeholder":"","advanced":false,"desc":"","default":"","_order":3,"pid":0.5857416321569131},"mask":{"id":"mask","type":"number","placeholder":"","advanced":false,"desc":"","default":null,"_order":4,"pid":0.00001785534757003937},"mask_type":{"id":"mask_type","type":"string","placeholder":"","advanced":false,"desc":"","default":"","_order":5,"pid":0.3959188389865702},"min_duration":{"id":"min_duration","type":"number","placeholder":"","advanced":false,"desc":"","default":null,"_order":6,"pid":0.6631107090987125}},"inputs":[{"id":"fif","datatype":"6000737faacf9ee51fa691cb","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"6331785d6985655cc5905350"}],"outputs":[{"id":"out_dir_report","datatype":"5e56dc330f7fa604cc3cc291","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"6331785d6985655cc5905351"},{"id":"out_figs","datatype":"59666a40b09297d8d8271dfc","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"633d268e6c7d095e9d76a674"}],"stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a45c062f3d3800f1311c2"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a45c062f3d3800f1311c3"}],"success_rate":30.76923076923077,"users":1,"groups":1,"requested":14,"examples":1,"runtime_mean":29702.75,"runtime_std":13150.477070718765},"removed":false,"contributors":[{"name":"SaeedZahran","email":"saeedzahran@hotmail.com","_id":"634a45c062f3d3800f1311c4"}],"create_date":"2022-09-20T10:20:45.348Z","desc":null,"__v":22,"doi":"10.25663/brainlife.app.666","_canedit":true},{"_id":"62697515f3858674a2a22372","user_id":"2076","projects":[],"admins":["2076","670","1348"],"name":"app-evoked-averaged ","github":"zahransa/app-evoked-averaged","github_branch":"main","tags":[],"config":{"fif":{"type":"input","file_id":"epo","input_id":"fif"}},"inputs":[{"id":"fif","datatype":"61797fc39538685e5db952b0","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"62697515f3858674a2a22373"}],"outputs":[{"id":"out_dir","datatype":"5978fd38b09297d8d8aa8746","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"62697515f3858674a2a22374"},{"id":"out_dir_report","datatype":"5e56dc330f7fa604cc3cc291","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"62816a8bd0697cf1eadb817c"}],"stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a441262f3d3800f130b5f"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a441262f3d3800f130b60"}],"examples":1,"success_rate":95.23809523809523,"users":1,"groups":1,"runtime_mean":23543.9,"runtime_std":30922.21993470068,"requested":21},"removed":false,"contributors":[{"name":"SaeedZahran","email":"saeedzahran@hotmail.com","_id":"634a441262f3d3800f130b61"}],"create_date":"2022-04-27T16:53:41.518Z","desc":null,"__v":455,"doi":"10.25663/brainlife.app.618","_canedit":true},{"_id":"62c7fc68f3194eded6ff06aa","user_id":"2076","projects":[],"admins":["2076"],"name":"app-filter","github":"zahransa/app-filter","github_branch":"main","tags":[],"config":{},"inputs":[],"outputs":[],"stats":{"resources":[],"examples":0},"removed":false,"contributors":[{"name":"SaeedZahran","email":"saeedzahran@hotmail.com","_id":"634a459262f3d3800f13110a"}],"create_date":"2022-07-08T09:44:08.870Z","desc":null,"__v":134,"doi":"10.25663/brainlife.app.661","_canedit":true},{"_id":"627a60e9d0697cf1eacb34d7","user_id":"2076","projects":[],"admins":["2076"],"name":"app-forward","github":"zahransa/app-forward","tags":[],"config":{"transform":{"type":"input","file_id":"transform","input_id":"transform"},"forward":{"type":"input","file_id":"forward","input_id":"forward"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"}},"inputs":[{"id":"transform","datatype":"6283e821d0697cf1eade9d5c","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"628b6ff9d0697cf1eaeb89c6"},{"id":"forward","datatype":"6283e916d0697cf1eadea5a3","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"628b6ff9d0697cf1eaeb89c7"},{"id":"freesurfer","datatype":"58cb22c8e13a50849b25882e","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"628b6ff9d0697cf1eaeb89c8"}],"outputs":[{"id":"out_dir_report","datatype":"5e56dc330f7fa604cc3cc291","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"628b6ff9d0697cf1eaeb89c9"}],"stats":{"resources":[],"examples":1,"success_rate":18.181818181818183,"users":1,"groups":2,"requested":11,"runtime_mean":11789,"runtime_std":326},"removed":false,"contributors":[{"name":"SaeedZahran","email":"saeedzahran@hotmail.com","_id":"634a445d62f3d3800f130dfa"}],"create_date":"2022-05-10T12:56:09.347Z","desc":null,"__v":386,"doi":"10.25663/brainlife.app.627","_canedit":true},{"_id":"60c086470ad40db0cdcc2798","stats":{"resources":[],"success_rate":null,"users":1,"runtime_mean":null,"runtime_std":null,"requested":3},"projects":["60a14ca503bcad0ad27cada9"],"admins":["1574"],"tags":[],"removed":false,"config":{"t1":{"type":"input","file_id":"t1","input_id":"t1"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"60c086470ad40d58d2cc2799","id":"t1","datatype":"58c33bcee13a50849b25879a"}],"outputs":[{"datatype_tags":["visualization"],"output_on_root":false,"archive":true,"_id":"60c086470ad40d22bccc279a","id":"output.txt","datatype":"5ed53b69da664506f88e6df9","datatype_tags_pass":null,"files":null}],"github_branch":"1.0","github":"M-ballabio1/app-helloworld1","name":"app-helloworld1","desc_override":"This is a trial app for print metadata of t1-w","user_id":"1574","contributors":[{"_id":"6155d7b68ce8606e63c8f88e","name":"Matteo","email":null}],"create_date":"2021-06-09T09:13:43.396Z","desc":"prova","__v":806,"doi":"10.25663/brainlife.app.533","_canedit":true},{"_id":"627a6508d0697cf1eacb410f","user_id":"2076","projects":[],"admins":["2076"],"name":"app-inverse","github":"zahransa/app-inverse","github_branch":null,"tags":[],"config":{},"inputs":[],"outputs":[],"stats":{"resources":[],"examples":0},"removed":false,"contributors":[{"name":"SaeedZahran","email":"saeedzahran@hotmail.com","_id":"634a446662f3d3800f130dfc"}],"create_date":"2022-05-10T13:13:44.971Z","desc":null,"__v":383,"doi":"10.25663/brainlife.app.628","_canedit":true},{"_id":"62c7fbf5f3194eded6ff0675","user_id":"2076","projects":[],"admins":["2076"],"name":"app-maxwell-filtering","github":"zahransa/app-maxwell-filtering","github_branch":"main","tags":[],"config":{},"inputs":[],"outputs":[],"stats":{"resources":[],"examples":0},"removed":false,"contributors":[{"name":"SaeedZahran","email":"saeedzahran@hotmail.com","_id":"634a458962f3d3800f131108"}],"create_date":"2022-07-08T09:42:13.451Z","desc":null,"__v":134,"doi":"10.25663/brainlife.app.660","_canedit":true},{"_id":"5cbe38a66ff3840034f7f19e","projects":["5c50b6f12daf2e0032f880eb","5c702228dac33f00310c13d1","5c702244dac33f00310c13d2","5cab973c1d8cbc029e50e217","5ca77206666d760036a7b97f"],"admins":["19"],"tags":[],"removed":false,"stats":{"stars":0,"requested":6155,"users":2,"success_rate":58.98962408572886,"serviceinfo":{"_id":"5d729e1e78356a109788b22b","counts":{"_id":"5e5c3df187cac73d17ab1406","failed":2405,"finished":3464,"removed":4214,"requested":6145,"running":5357,"running_sync":0,"stop_requested":359},"success_rate":59.0219798943602,"users":2,"readme_status":"no README.md","runtime_mean":37910281.14,"runtime_std":19848677.144017108,"service":"bcmcpher/app-repeat-tracking","__v":0},"gitinfo":{"desc":"repeat of fixed parameters for OHBM 2019 submission","tags":[],"stats":{"stars":0},"contributors":[{"name":"Brent McPherson","email":null}]},"runtime_mean":38107838.32,"runtime_std":20075808.416652452,"resources":[{"resource_id":"5931bee335530000253833d2","name":"osgconnect","_id":"634a35b362f3d3800f11a22f"}],"examples":1,"groups":3},"config":{"anat":{"type":"input","file_id":"t1","input_id":"anat"},"lmax2":{"type":"input","file_id":"lmax2","input_id":"lmax"},"lmax4":{"type":"input","file_id":"lmax4","input_id":"lmax"},"lmax6":{"type":"input","file_id":"lmax6","input_id":"lmax"},"lmax8":{"type":"input","file_id":"lmax8","input_id":"lmax"},"lmax10":{"type":"input","file_id":"lmax10","input_id":"lmax"},"lmax12":{"type":"input","file_id":"lmax12","input_id":"lmax"},"lmax14":{"type":"input","file_id":"lmax14","input_id":"lmax"},"parc":{"type":"input","file_id":"parc","input_id":"parc"},"key":{"type":"input","file_id":"key","input_id":"parc"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"fa":{"type":"input","file_id":"fa","input_id":"tensor"},"md":{"type":"input","file_id":"md","input_id":"tensor"},"rd":{"type":"input","file_id":"rd","input_id":"tensor"},"ad":{"type":"input","file_id":"ad","input_id":"tensor"},"num_fibers":{"id":"num_fibers","type":"number","placeholder":"","desc":"total number of streamlines to track per lmax found","default":null,"_order":2,"pid":0.8098208177814177}},"inputs":[{"datatype_tags":["acpc_aligned"],"optional":false,"multi":false,"_id":"5ca2625965ade200e89d649f","id":"anat","datatype":"58c33bcee13a50849b25879a"},{"datatype_tags":[],"optional":false,"multi":false,"_id":"5ca2625965ade200e89d649e","id":"lmax","datatype":"5c536bf0f9109beac46adb45"},{"datatype_tags":[],"optional":false,"multi":false,"_id":"5cbe38a66ff3840034f7f1a1","id":"parc","datatype":"5c1a7489f9109beac4a88a1f"},{"datatype_tags":[],"optional":false,"multi":false,"_id":"5cbe38a66ff3840034f7f1a0","id":"mask","datatype":"5a281aee2c214c9ba83ce620"},{"datatype_tags":[],"optional":false,"multi":false,"_id":"5cbe38a66ff3840034f7f19f","id":"tensor","datatype":"5a79df48d071a1753f1d661b"}],"outputs":[{"datatype_tags":["networkmatrices"],"output_on_root":false,"_id":"5ca262ba65ade200e89d64a6","id":"net02","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null,"archive":true},{"datatype_tags":["networkmatrices"],"output_on_root":false,"_id":"5cacc27576cdaa0030b92180","id":"net03","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null,"archive":true},{"datatype_tags":["networkmatrices"],"output_on_root":false,"_id":"5cacc27576cdaa0030b9217f","id":"net04","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null,"archive":true},{"datatype_tags":["networkmatrices"],"output_on_root":false,"_id":"5cacc27576cdaa0030b9217e","id":"net05","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null,"archive":true},{"datatype_tags":["networkmatrices"],"output_on_root":false,"_id":"5cacc27576cdaa0030b9217d","id":"net06","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null,"archive":true},{"datatype_tags":["networkmatrices"],"output_on_root":false,"_id":"5cacc27576cdaa0030b9217c","id":"net07","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null,"archive":true},{"datatype_tags":["networkmatrices"],"output_on_root":false,"_id":"5cacc27576cdaa0030b9217b","id":"net08","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null,"archive":true},{"datatype_tags":["networkmatrices"],"output_on_root":false,"_id":"5cacc27576cdaa0030b9217a","id":"net09","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null,"archive":true},{"datatype_tags":["networkmatrices"],"output_on_root":false,"_id":"5cacc27576cdaa0030b92179","id":"net10","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null,"archive":true}],"github_branch":"osg-dag-net","github":"bcmcpher/app-repeat-tracking","name":"app-repeat-network-osg","user_id":"19","contributors":[{"name":"Brent McPherson","email":"bcmcpher@gmail.com","_id":"634a35b362f3d3800f11a230"}],"desc":"repeat of fixed parameters for OHBM 2019 submission","__v":8194,"create_date":"2019-04-22T21:56:54.119Z","doi":"10.25663/brainlife.app.183","_canedit":true},{"_id":"5ca2625965ade200e89d649d","stats":{"stars":0,"requested":6155,"users":2,"success_rate":58.98962408572886,"serviceinfo":{"_id":"5d729e1e78356a109788b22b","counts":{"_id":"5e5c3ded87cac7c3a4ab1400","failed":2405,"finished":3464,"removed":4214,"requested":6145,"running":5357,"running_sync":0,"stop_requested":359},"success_rate":59.0219798943602,"users":2,"readme_status":"no README.md","runtime_mean":37910281.14,"runtime_std":19848677.144017108,"service":"bcmcpher/app-repeat-tracking","__v":0},"gitinfo":{"desc":"repeat of fixed parameters for OHBM 2019 submission","tags":[],"stats":{"stars":0},"contributors":[{"name":"Brent McPherson","email":null}]},"runtime_mean":38107838.32,"runtime_std":20075808.416652452,"resources":[{"resource_id":"5931bee335530000253833d2","name":"osgconnect","_id":"634a357d62f3d3800f11a202"}],"examples":0,"groups":3},"projects":["5c50b6f12daf2e0032f880eb","5c702228dac33f00310c13d1","5c702244dac33f00310c13d2"],"admins":["19"],"tags":[],"removed":false,"config":{"anat":{"type":"input","file_id":"t1","input_id":"1"},"lmax2":{"type":"input","file_id":"lmax2","input_id":"2"},"lmax4":{"type":"input","file_id":"lmax4","input_id":"2"},"lmax6":{"type":"input","file_id":"lmax6","input_id":"2"},"lmax8":{"type":"input","file_id":"lmax8","input_id":"2"},"lmax10":{"type":"input","file_id":"lmax10","input_id":"2"},"lmax12":{"type":"input","file_id":"lmax12","input_id":"2"},"lmax14":{"type":"input","file_id":"lmax14","input_id":"2"},"num_fibers":{"id":"num_fibers","type":"number","placeholder":"","desc":"total number of streamlines to track","default":null,"_order":2,"pid":0.3007683852954509}},"inputs":[{"datatype_tags":["acpc_aligned"],"optional":false,"multi":false,"_id":"5ca2625965ade200e89d649f","id":"1","datatype":"58c33bcee13a50849b25879a"},{"datatype_tags":[],"optional":false,"multi":false,"_id":"5ca2625965ade200e89d649e","id":"2","datatype":"5c536bf0f9109beac46adb45"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"_id":"5ca262ba65ade200e89d64a6","id":"rep02","datatype":"5907d922436ee50ffde9c549","datatype_tags_pass":null,"files":null,"archive":true},{"datatype_tags":[],"output_on_root":false,"_id":"5caf762b454d3c00353fa0b7","id":"rep03","datatype":"5907d922436ee50ffde9c549","datatype_tags_pass":null,"files":null,"archive":true},{"datatype_tags":[],"output_on_root":false,"_id":"5caf762b454d3c00353fa0b6","id":"rep04","datatype":"5907d922436ee50ffde9c549","datatype_tags_pass":null,"files":null,"archive":true},{"datatype_tags":[],"output_on_root":false,"_id":"5caf762b454d3c00353fa0b5","id":"rep05","datatype":"5907d922436ee50ffde9c549","datatype_tags_pass":null,"files":null,"archive":true},{"datatype_tags":[],"output_on_root":false,"_id":"5caf762b454d3c00353fa0b4","id":"rep06","datatype":"5907d922436ee50ffde9c549","datatype_tags_pass":null,"files":null,"archive":true},{"datatype_tags":[],"output_on_root":false,"_id":"5caf762b454d3c00353fa0b3","id":"rep07","datatype":"5907d922436ee50ffde9c549","datatype_tags_pass":null,"files":null,"archive":true},{"datatype_tags":[],"output_on_root":false,"_id":"5caf762b454d3c00353fa0b2","id":"rep08","datatype":"5907d922436ee50ffde9c549","datatype_tags_pass":null,"files":null,"archive":true},{"datatype_tags":[],"output_on_root":false,"_id":"5caf762b454d3c00353fa0b1","id":"rep09","datatype":"5907d922436ee50ffde9c549","datatype_tags_pass":null,"files":null,"archive":true},{"datatype_tags":[],"output_on_root":false,"_id":"5caf762b454d3c00353fa0b0","id":"rep10","datatype":"5907d922436ee50ffde9c549","datatype_tags_pass":null,"files":null,"archive":true}],"github_branch":"master","github":"bcmcpher/app-repeat-tracking","name":"app-repeat-tracking","user_id":"19","contributors":[{"name":"Brent McPherson","email":"bcmcpher@gmail.com","_id":"634a357e62f3d3800f11a203"}],"create_date":"2019-04-01T19:11:21.215Z","desc":"repeat of fixed parameters for OHBM 2019 submission","doi":"10.25663/brainlife.app.175","__v":8368,"_canedit":true},{"_id":"5ca664f2666d760036a7b94b","projects":["5c50b6f12daf2e0032f880eb","5c702228dac33f00310c13d1","5c702244dac33f00310c13d2","5cab973c1d8cbc029e50e217","5cd04c87c6afad032c30b697","5ca77206666d760036a7b97f"],"admins":["19"],"tags":[],"removed":false,"stats":{"stars":0,"requested":6155,"users":2,"success_rate":58.98962408572886,"serviceinfo":{"_id":"5d729e1e78356a109788b22b","counts":{"_id":"5e5c3dee87cac7a751ab1401","failed":2405,"finished":3464,"removed":4214,"requested":6145,"running":5357,"running_sync":0,"stop_requested":359},"success_rate":59.0219798943602,"users":2,"readme_status":"no README.md","runtime_mean":37910281.14,"runtime_std":19848677.144017108,"service":"bcmcpher/app-repeat-tracking","__v":0},"gitinfo":{"desc":"repeat of fixed parameters for OHBM 2019 submission","tags":[],"stats":{"stars":0},"contributors":[{"name":"Brent McPherson","email":null}]},"runtime_mean":38107838.32,"runtime_std":20075808.416652452,"resources":[{"resource_id":"5931bee335530000253833d2","name":"osgconnect","_id":"634a358662f3d3800f11a205"}],"examples":0,"groups":3},"config":{"anat":{"type":"input","file_id":"t1","input_id":"1"},"lmax2":{"type":"input","file_id":"lmax2","input_id":"2"},"lmax4":{"type":"input","file_id":"lmax4","input_id":"2"},"lmax6":{"type":"input","file_id":"lmax6","input_id":"2"},"lmax8":{"type":"input","file_id":"lmax8","input_id":"2"},"lmax10":{"type":"input","file_id":"lmax10","input_id":"2"},"lmax12":{"type":"input","file_id":"lmax12","input_id":"2"},"lmax14":{"type":"input","file_id":"lmax14","input_id":"2"},"num_fibers":{"id":"num_fibers","type":"number","placeholder":"","desc":"total number of streamlines to track per lmax found","default":null,"_order":2,"pid":0.5257705437669957}},"inputs":[{"datatype_tags":["acpc_aligned"],"optional":false,"multi":false,"_id":"5ca2625965ade200e89d649f","id":"1","datatype":"58c33bcee13a50849b25879a"},{"datatype_tags":[],"optional":false,"multi":false,"_id":"5ca2625965ade200e89d649e","id":"2","datatype":"5c536bf0f9109beac46adb45"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"_id":"5ca262ba65ade200e89d64a6","id":"rep02","datatype":"5907d922436ee50ffde9c549","datatype_tags_pass":null,"files":null,"archive":true},{"datatype_tags":[],"output_on_root":false,"_id":"5cacc27576cdaa0030b92180","id":"rep03","datatype":"5907d922436ee50ffde9c549","datatype_tags_pass":null,"files":null,"archive":true},{"datatype_tags":[],"output_on_root":false,"_id":"5cacc27576cdaa0030b9217f","id":"rep04","datatype":"5907d922436ee50ffde9c549","datatype_tags_pass":null,"files":null,"archive":true},{"datatype_tags":[],"output_on_root":false,"_id":"5cacc27576cdaa0030b9217e","id":"rep05","datatype":"5907d922436ee50ffde9c549","datatype_tags_pass":null,"files":null,"archive":true},{"datatype_tags":[],"output_on_root":false,"_id":"5cacc27576cdaa0030b9217d","id":"rep06","datatype":"5907d922436ee50ffde9c549","datatype_tags_pass":null,"files":null,"archive":true},{"datatype_tags":[],"output_on_root":false,"_id":"5cacc27576cdaa0030b9217c","id":"rep07","datatype":"5907d922436ee50ffde9c549","datatype_tags_pass":null,"files":null,"archive":true},{"datatype_tags":[],"output_on_root":false,"_id":"5cacc27576cdaa0030b9217b","id":"rep08","datatype":"5907d922436ee50ffde9c549","datatype_tags_pass":null,"files":null,"archive":true},{"datatype_tags":[],"output_on_root":false,"_id":"5cacc27576cdaa0030b9217a","id":"rep09","datatype":"5907d922436ee50ffde9c549","datatype_tags_pass":null,"files":null,"archive":true},{"datatype_tags":[],"output_on_root":false,"_id":"5cacc27576cdaa0030b92179","id":"rep10","datatype":"5907d922436ee50ffde9c549","datatype_tags_pass":null,"files":null,"archive":true}],"github_branch":"osg-dag","github":"bcmcpher/app-repeat-tracking","name":"app-repeat-tracking-osg","user_id":"19","contributors":[{"name":"Brent McPherson","email":"bcmcpher@gmail.com","_id":"634a358762f3d3800f11a206"}],"desc":"repeat of fixed parameters for OHBM 2019 submission","__v":8341,"create_date":"2019-04-04T20:11:30.433Z","doi":"10.25663/brainlife.app.176","_canedit":true},{"_id":"63358117db978c7991a302cb","user_id":"2076","projects":[],"admins":["2076"],"name":"app-selecting-ICA-components-manually","github":"zahransa/app-selecting-ICA-components-manually","github_branch":"master","tags":[],"config":{"ica":{"type":"input","file_id":"ica","input_id":"ica"},"exclude":{"id":"exclude","type":"number","placeholder":"","advanced":false,"desc":"","default":null,"_order":2,"pid":0.45156824388250305}},"inputs":[{"id":"ica","datatype":"6283e821d0697cf1eade9d5c","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"63358117db978c7991a302cc"}],"outputs":[{"id":"out_dir","datatype":"6283e821d0697cf1eade9d5c","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"63358117db978c7991a302cd"},{"id":"out_figs","datatype":"59666a40b09297d8d8271dfc","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"633a8bba6c7d095e9d7275b2"}],"stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a462462f3d3800f1312d6"},{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a462462f3d3800f1312d7"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a462462f3d3800f1312d8"}],"success_rate":100,"users":1,"groups":1,"runtime_mean":16816.5,"runtime_std":5300.5,"requested":2,"examples":1},"removed":false,"contributors":[{"name":"SaeedZahran","email":"saeedzahran@hotmail.com","_id":"634a462462f3d3800f1312d9"}],"create_date":"2022-09-29T11:27:19.516Z","desc":null,"__v":17,"doi":"10.25663/brainlife.app.678","_canedit":true},{"_id":"6123dbd52301762133d575a5","stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a423e62f3d3800f12f44e"}],"success_rate":84.29944436101516,"users":9,"runtime_mean":289186.47,"runtime_std":418896.15332488925,"requested":14258,"examples":1,"groups":24},"projects":[],"admins":["1619"],"tags":["brainlife","brainlifeio","neuroimaging"],"removed":false,"config":{"t1":{"type":"input","file_id":"t1","input_id":"nifti_input"},"optional_params":{"id":"optional_params","type":"string","placeholder":"","advanced":false,"desc":"add all optional parameters here, in the format below:\n\n-parameter option -parameter2 \n\nif no optional parameters needed, leave empty. for a full list of optional parameters and what they do, see AFNI's documentation: https://afni.nimh.nih.gov/pub/dist/doc/program_help/3dSkullStrip.html\n\nexamples:\n\n-ld 30 -no_spatnorm\n\n-niter 750 -ld 50\n\n-monkey -spatnorm_dxyz","default":"null","_order":2,"pid":0.641300544898537,"optional":false}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"6123dbd52301763d80d575a6","id":"nifti_input","datatype":"58c33bcee13a50849b25879a","desc":"T1W in NIfTI format"}],"outputs":[{"datatype_tags":["brain_extracted","3dSkullStrip"],"output_on_root":false,"archive":true,"_id":"6123dbd5230176b0ded575a7","id":"output","datatype":"58c33bcee13a50849b25879a","datatype_tags_pass":null,"files":null,"desc":"skull-stripped t1w"}],"github_branch":"1.0","github":"vnbcs/app-skullStrip","name":"app-skullStrip ","avatar":"https://afni.nimh.nih.gov/sites/default/files/default_images/afnilogo.png","desc_override":"","user_id":"1619","contributors":[{"name":"eva bacas","email":"enbacas@gmail.com","_id":"634a423f62f3d3800f12f44f"}],"create_date":"2021-08-23T17:33:09.726Z","desc":"brainlife app - runs AFNI's skullstrip function on NIfTI files","__v":1992,"doi":"10.25663/brainlife.app.565","_canedit":true},{"_id":"60210bc3ab40ca86284bf784","stats":{"resources":[],"success_rate":57.714285714285715,"users":2,"runtime_mean":61031.74,"runtime_std":168248.07326864815,"requested":194,"examples":1,"groups":2},"projects":["5d64733db29ac960ca2e797f","5ff32b04116c5cbba4d1929b"],"admins":["1342"],"tags":[],"removed":false,"config":{"fif":{"type":"input","file_id":"fif","input_id":"test1"},"channels":{"type":"input","file_id":"channels","input_id":"test1"},"headshape":{"type":"input","file_id":"headshape","input_id":"test1"},"coordsystem":{"type":"input","file_id":"coordsystem","input_id":"test1"},"calibration":{"type":"input","file_id":"calibration","input_id":"test1"},"crosstalk":{"type":"input","file_id":"crosstalk","input_id":"test1"},"destination":{"type":"input","file_id":"destination","input_id":"test1"},"events":{"type":"input","file_id":"events","input_id":"test1"},"events_json":{"type":"input","file_id":"events_json","input_id":"test1"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"60648ffad04008ce80b0796b","id":"test1","datatype":"6000737faacf9ee51fa691cb"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"602ba7ce3a001162d54c351d","id":"out_dir","datatype":"6000737faacf9ee51fa691cb","datatype_tags_pass":null,"files":null}],"github_branch":"master","github":"AuroreBussalb/app-test","name":"app-test","user_id":"1342","contributors":[{"name":null,"email":null,"_id":"634a3eea62f3d3800f12c57d"}],"create_date":"2021-02-08T10:00:35.027Z","desc":"This a little App to test registration steps on Brainlife and to test how to run it.","__v":3395,"doi":"10.25663/brainlife.app.473","desc_override":"","_canedit":true},{"_id":"62c7fa47f3194eded6ff05cb","user_id":"2076","projects":[],"admins":["2076"],"name":"app-time-frequency","github":"zahransa/app-time-frequency","github_branch":"main","tags":[],"config":{},"inputs":[],"outputs":[],"stats":{"resources":[],"examples":0},"removed":false,"contributors":[{"name":"SaeedZahran","email":"saeedzahran@hotmail.com","_id":"634a458062f3d3800f131106"}],"create_date":"2022-07-08T09:35:03.377Z","desc":null,"__v":134,"doi":"10.25663/brainlife.app.659","_canedit":true},{"_id":"615b769ffc8eb96633f613aa","stats":{"resources":[],"success_rate":52.63157894736842,"users":1,"runtime_mean":4500600.975,"runtime_std":3447888.05459122,"requested":109,"examples":1,"groups":2},"projects":[],"admins":["146","123","41"],"tags":[],"removed":false,"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"sbref":{"type":"input","file_id":"sbref","input_id":"dwi"},"sbref_json":{"type":"input","file_id":"sbref_json","input_id":"dwi"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"nf":{"id":"nf","type":"number","placeholder":"","advanced":false,"desc":"Maximum number of fibres to fit in each voxel.","default":3,"_order":2,"pid":0.12302831146353976},"bi":{"id":"bi","type":"number","placeholder":"","advanced":false,"desc":"burnin period, default 1000","default":1000,"_order":3,"pid":0.05584364317025914},"fudge":{"id":"fudge","type":"number","placeholder":"","advanced":false,"desc":"fudge (an integer) – ARD fudge factor","default":1,"_order":4,"pid":0.03167916515875624}},"inputs":[{"id":"dwi","desc":"A 4D series of data volumes. This will include diffusion-weighted volumes and volume(s) with no diffusion weighting.","datatype":"58c33c5fe13a50849b25879b","datatype_tags":["preprocessed"],"optional":false,"multi":false,"advanced":false,"_id":"615b769ffc8eb918e5f613ab"},{"id":"mask","desc":" 3D binary brain mask volume derived from running bet on nodif (i.e. on a volume with no diffusion weighting). Created using FSL Brain Extraction (BET) on DWI brainlife/app-FSLBET","datatype":"5a281aee2c214c9ba83ce620","datatype_tags":["dwi","brain","preprocessed"],"optional":false,"multi":false,"advanced":false,"_id":"615b769ffc8eb97c4ef613ac"}],"outputs":[{"id":"output","desc":"This folder contains the entire set of folders and files outputted by the FSL BedpostX  process","datatype":"622138875d8ab5d5f0212b05","datatype_tags":["bedpostx","preprocessed","dwi"],"datatype_tags_pass":"dwi","output_on_root":false,"files":null,"archive":true,"_id":"615b769ffc8eb999e4f613ad"}],"github":"sandrahanekamp/app-bedpostx","name":"bedpostx","user_id":"123","contributors":[{"name":"Sandra Hanekamp","email":"sandrahanekamp@gmail.com","_id":"634a42ac62f3d3800f12f745"}],"create_date":"2021-10-04T21:48:15.707Z","desc":"FSL's bedpostx app for brainlife","__v":1674,"github_branch":"main","doi":"10.25663/brainlife.app.578","_canedit":true},{"_id":"5b2975d616fe38002748e79a","projects":[],"admins":["316","256","1","49"],"tags":[],"removed":false,"name":"clever","desc":"Clever","citation":null,"references":[],"github":"mandymejia/app-clever","config":{"bold":{"type":"input","file_id":"bold","input_id":"bold"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"projection":{"id":"projection","type":"enum","placeholder":"","advanced":false,"desc":"`clever` works by first choosing PCs of the data which are likely to contain information about outliers. \n\n`kurtosis` selects PCs of high kurtosis among the PCs which explain the top 90% of variance. It is based on the observation that the presence of outliers often induces high kurtosis. \n\n`variance` selects PCs of greater-than-average variance, and is based on the observation that the larger PCs often contain outlier information, whereas smaller PCs often represent typical variation in the data. We recommend the `kurtosis` method over the `variance` method.\n\n`PCATF` (PCA Trend Filtering) works differently from the other two projection methods: it computes a variation of PCA which minimizes the zero norm of first-differences in each PC score. This has the effect of making PC scores constant within neighborhoods of little change, thus highlighting regions of artifact presence. It is based on the observation that timepoints with artifacts tend to be adjacent (due to an artifact source persisting or otherwise affecting the fMRI across multiple scans).\n\nIf multiple projections are chosen, each projection will be used with each compatible measure of outlyingness.","default":"variance","_order":6,"pid":0.9213113894816912,"options":[{"desc":"","label":"kurtosis","value":"kurtosis"},{"desc":"","label":"variance","value":"variance"},{"desc":"","label":"PCATF","value":"PCATF"},{"desc":"","label":"kurtosis and variance","value":"kurtosis, variance"},{"desc":"","label":"kurtosis and PCATF","value":"kurtosis, PCATF"},{"desc":"","label":"variance and PCATF","value":"variance, PCATF"},{"desc":"","label":"kurtosis, variance, and PCATF","value":"kurtosis, variance, PCATF"}]},"out_meas":{"id":"out_meas","type":"enum","placeholder":"","advanced":false,"desc":"After projecting the data, `clever` computes an outlyingness score for each observation.\n\n`leverage` is based on a regression model using the PC scores as a design matrix. \n\n`robdist` is a robust measure of the minimum covariance determinant (MCD) distance. It is currently being revamped; for now, we recommend the `leverage` option.","default":"leverage","_order":7,"pid":0.2596861685279038,"options":[{"desc":"","label":"leverage","value":"leverage"},{"desc":"","label":"robust distance","value":"robdist"},{"desc":"","label":"leverage and robust distance","value":"leverage, robdist"}]},"DVARS":{"id":"DVARS","type":"enum","placeholder":"","advanced":false,"desc":"DVARS is another common measure of outlyingness for fMRI data based on the standard deviation of the voxels' change from the previous timepoint. Unlike the other methods, it is not based on first projecting the data. ","default":"TRUE","_order":11,"pid":0.2472621633277171,"options":[{"desc":"","label":"do not also compute DVARS","value":"FALSE"},{"desc":"","label":"also compute DVARS","value":"TRUE"}]},"detrend":{"id":"detrend","type":"enum","placeholder":"","advanced":false,"desc":"Should the PCs be detrended before measuring the outlyingness of each observation? Detrending is highly recommended for fMRI data for two reasons. First, temporal trends induce positive or negative kurtosis, contaminating the connection between high kurtosis and outlier presence. Second, trends tend to reduce the size of the in-MCD subset for the robust distance method causing many false positives.\n\nIn addition to `TRUE` and `FALSE`, a third option `kurtosis` can be used to only detrend the PCs for the purpose of measuring kurtosis, and not for the actual outlyingness measurement.\n\nThis option will not affect the PCATF projection, which is never detrended.","default":"TRUE","_order":12,"pid":0.5224921202971754,"options":[{"desc":"","label":"detrend","value":"TRUE"},{"desc":"","label":"do not detrend","value":"FALSE"},{"desc":"","label":"detrend only for kurtosis","value":"kurtosis"}]},"kurt_quantile":{"id":"kurt_quantile","type":"string","placeholder":"","advanced":false,"desc":"A number between 0 and 1. Only applicable for the `kurtosis` projection method. PCs of kurtosis greater than this quantile will be retained. The quantile will be based on the sampling distribution of kurtosis for Normal, independent data (estimated by simulation or with the theoretical asymptotic distribution). The default value of 0.95 was chosen because the kurtosis of PCs with outliers should easily surpass this quantile, and 0.05 is a reasonable rate for false positives (retaining PCs without outlier information) under the null hypothesis of no outliers.\n\nNote that at least one PC will be retained in each projection, regardless of the value of `kurt_quantile`.","default":"0.95","_order":14,"pid":0.8838183507015275},"id_outliers":{"id":"id_outliers","type":"enum","placeholder":"","advanced":false,"desc":"Should outliers be identified?","default":"TRUE","_order":16,"pid":0.03109892160282035,"options":[{"desc":"","label":"Identify outliers","value":"TRUE"},{"desc":"","label":"Do not identify outliers","value":"FALSE"}]},"lev_cutoff":{"id":"lev_cutoff","type":"string","placeholder":"","advanced":true,"desc":"The outlier cutoff value for leverage, as a multiple of the median leverage.","default":"4","_order":18,"pid":0.460427802499467},"rbd_cutoff":{"id":"rbd_cutoff","type":"string","placeholder":"","advanced":true,"desc":"The outlier cutoff quantile for MCD distance. ","default":"0.9999","_order":19,"pid":0.09901543372671617},"lev_images":{"id":"lev_images","type":"string","placeholder":"","advanced":true,"desc":"Leverage images are currently not supported by the `clever` BrainLife app. ","default":"FALSE","_order":21,"pid":0.4742189824426093,"readonly":true},"verbose":{"id":"verbose","type":"enum","placeholder":"","advanced":false,"desc":"Should occasional updates be printed? Default is `FALSE`.","default":"FALSE","_order":22,"pid":0.022687498628009894,"options":[{"desc":"","label":"verbose","value":"TRUE"},{"desc":"","label":"silent","value":"FALSE"}]},"main":{"id":"main","type":"string","placeholder":"","desc":"Override title for output plot(s).","default":"","_order":23,"pid":0.4130754234211812,"optional":true},"sub":{"id":"sub","type":"string","placeholder":"","desc":"Override subtitle for output plot(s).","default":"","_order":24,"pid":0.9759430439873599,"optional":true},"xlab":{"id":"xlab","type":"string","placeholder":"","desc":"Override x-axis label for output plot(s).","default":"","_order":25,"pid":0.735338919121606,"optional":true},"ylab":{"id":"ylab","type":"string","placeholder":"","desc":"Override y-axis label for output plot(s).","default":"","_order":26,"pid":0.640027170479074,"optional":true},"png":{"id":"png","type":"string","placeholder":"cleverPlot.png","desc":"Name of file to save plot to.","default":"cleverPlot.png","_order":27,"pid":0.9473262999371327,"optional":true},"csv":{"id":"csv","type":"string","placeholder":"cleverTable.csv","desc":"Name of file to save table to.","default":"cleverTable.csv","_order":28,"pid":0.26331854812287736,"optional":true}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5b2975d616fe38002748e79c","id":"bold","datatype":"59b685a08e5d38b0b331ddc5","desc":"The brain volume time-course to look for outlying timepoints in."},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5b2975d616fe38002748e79b","id":"mask","datatype":"5a281aee2c214c9ba83ce620","desc":"The whole brain mask. Voxels to be retained for analysis should be 1; voxels to be discarded should be 0."}],"outputs":[{"datatype_tags":["clever"],"output_on_root":false,"archive":true,"_id":"5b2975d616fe38002748e79d","id":"clever","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null,"desc":"Outlier detection for high-dimensional data."}],"desc_override":"`clever` computes principal Components LEVERage (“CLEVER”) and other measures of outlyingness for fMRI data. It can be used for flagging timepoints which are likely to contain artifacts (\"scrubbing\") as well as general quality-control of fMRI data.","user_id":"1","contributors":[{"name":"Damon Pham","email":"damondpham@gmail.com","_id":"634a336362f3d3800f117ebc"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a336362f3d3800f117ebd"}],"create_date":"2018-06-19T21:29:58.865Z","stats":{"stars":0,"requested":201,"users":3,"success_rate":22.950819672131146,"serviceinfo":{"_id":"5d729e1f78356a109788b26b","counts":{"_id":"5e5c3db287cac75142ab13c3","failed":74,"finished":7,"removed":8,"requested":95,"running":93,"running_sync":0,"stop_requested":12},"success_rate":8.641975308641975,"users":3,"readme_status":"too short","service":"mandymejia/app-clever","__v":0,"runtime_mean":629681.75,"runtime_std":437885.69517533627},"gitinfo":{"desc":"Clever","tags":[],"stats":{"stars":0},"contributors":[{"name":"Damon Pham","email":"damondpham@gmail.com"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":3756366.6666666665,"runtime_std":5414504.945903389,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a336362f3d3800f117ebb"}],"examples":0,"groups":4},"doi":"10.25663/bl.app.71","__v":12651,"github_branch":"2.0","_canedit":true},{"_id":"6340875ffa262bbde2a153f7","user_id":"1994","projects":[],"admins":["1994","16"],"name":"combine-scans-rois","github":"hanna-willis/app-combine-roi-scans","github_branch":"master","desc_override":"This app will combine multiple ROI datatypes, diffusion scans and t1 scans into one ROI file. This app is adapted from svincibo/app-combineROI.","tags":[],"config":{"rois":{"type":"input","file_id":"rois","input_id":"rois"},"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"sbref":{"type":"input","file_id":"sbref","input_id":"dwi"},"sbref_json":{"type":"input","file_id":"sbref_json","input_id":"dwi"},"t1":{"type":"input","file_id":"t1","input_id":"anat"}},"inputs":[{"id":"rois","datatype":"5be9ea0315a8683a39a1ebd9","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"6340875ffa262bbde2a153f8"},{"id":"dwi","datatype":"58c33c5fe13a50849b25879b","datatype_tags":["preprocessed"],"optional":false,"multi":false,"advanced":false,"_id":"6340875ffa262bbde2a153f9"},{"id":"anat","datatype":"58c33bcee13a50849b25879a","datatype_tags":["preprocessed"],"optional":false,"multi":false,"advanced":false,"_id":"6340875ffa262bbde2a153fa"}],"outputs":[{"id":"output","datatype":"59c3eae633fc1cf9ead71679","datatype_tags":["visual_check"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"6340875ffa262bbde2a153fb"}],"stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a463f62f3d3800f1313b6"},{"resource_id":"5e309300e017b06c99948e0a","name":"stampede2(knl) @ TACC/UT","_id":"634a463f62f3d3800f1313b7"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a463f62f3d3800f1313b8"}],"success_rate":69.56521739130434,"users":1,"groups":1,"runtime_mean":26002.875,"runtime_std":11297.077514090757,"requested":38,"examples":0},"removed":false,"contributors":[{"name":null,"email":null,"_id":"634a464062f3d3800f1313b9"}],"create_date":"2022-10-07T20:09:03.322Z","desc":"An app that combines ROIs, diffusion image and t1 image into same location for easier viewing. ","__v":11,"doi":"10.25663/brainlife.app.681","_canedit":true},{"_id":"5e94e5ec5092192299f0dde6","stats":{"success_rate":97.03196347031964,"users":4,"runtime_mean":294305.11,"runtime_std":2029802.003662638,"requested":450,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a399b62f3d3800f122b3e"}],"examples":2,"groups":6},"projects":[],"admins":["126"],"tags":[],"removed":false,"config":{"rois1":{"type":"input","file_id":"rois","input_id":"roi1"},"rois2":{"type":"input","file_id":"rois","input_id":"roi2"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e94e5ec5092190fddf0dde7","id":"roi1","datatype":"5be9ea0315a8683a39a1ebd9"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e94e919509219152ff0de6e","id":"roi2","datatype":"5be9ea0315a8683a39a1ebd9"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5e94e5ec509219bfdaf0dde8","id":"output","datatype":"5be9ea0315a8683a39a1ebd9","datatype_tags_pass":null,"files":null}],"github":"svincibo/app-combineROI","name":"combineROI","avatar":"https://upload.wikimedia.org/wikipedia/commons/c/c5/Voronoi_Diagram.png","user_id":"126","contributors":[{"name":"Sophia Vinci-Booher","email":null,"_id":"634a399c62f3d3800f122b3f"},{"name":"Brad Caron","email":null,"_id":"634a399c62f3d3800f122b40"}],"create_date":"2020-04-13T22:21:32.418Z","desc":"This app will merge two ROI datatype sets into one ROI datatype dataset.","doi":"10.25663/brainlife.app.313","__v":5074,"desc_override":"This app will combine two ROI datatype datasets into one ROI datatype dataset. If, for example, there are 3 rois in the first ROI dataset and 2 rois in the second ROI dataset, the output ROI data set will contain 5 rois.\n\nNOTE: This app can be used to extract one roi from an ROI dataset. If you enter the same roi in the roi1 and roi2 fields, the resulting ROI will simply be that roi.","_canedit":true},{"_id":"5f6a01dfcfa365587cc9995f","stats":{"resources":[],"success_rate":44.129649976455816,"users":11,"runtime_mean":23610057.12,"runtime_std":10514580.892609518,"requested":20342,"examples":4,"groups":31},"projects":[],"admins":["1179"],"tags":[],"removed":false,"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"target":{"id":"target","type":"string","placeholder":"","advanced":false,"desc":"Specify which pathways to map.  You may assign partial names to select all matching bundles. Multiple names separated by comma can be included. If not specified, the default text is \n\nFasciculus,Cingulum,Aslant,Cortico,Optic,Fornix,Corpus\n\nThe following is the list of available bundle for selection.\n\nArcuate_Fasciculus_L Arcuate_Fasciculus_R Cingulum_Frontal_Parahippocampal_L Cingulum_Frontal_Parahippocampal_R Cingulum_Frontal_Parietal_L Cingulum_Frontal_Parietal_R Cingulum_Parahippocampal_Parietal_L Cingulum_Parahippocampal_Parietal_R Cingulum_Parahippocampal_L Cingulum_Parahippocampal_R Cingulum_Rarolfactory_Parietal_L Cingulum_Rarolfactory_Parietal_R Extreme_Capsule_L Extreme_Capsule_R Frontal_Aslant_Tract_L Frontal_Aslant_Tract_R Inferior_Fronto_Occipital_Fasciculus_L Inferior_Fronto_Occipital_Fasciculus_R Inferior_Longitudinal_Fasciculus_L Inferior_Longitudinal_Fasciculus_R Middle_Longitudinal_Fasciculus_L Middle_Longitudinal_Fasciculus_R Parietal_Aslant_Tract_L Parietal_Aslant_Tract_R Superior_Longitudinal_Fasciculus1_L Superior_Longitudinal_Fasciculus1_R Superior_Longitudinal_Fasciculus2_L Superior_Longitudinal_Fasciculus2_R Superior_Longitudinal_Fasciculus3_L Superior_Longitudinal_Fasciculus3_R Uncinate_Fasciculus_L Uncinate_Fasciculus_R Vertical_Occipital_Fasciculus_L Vertical_Occipital_Fasciculus_R Acoustic_Radiation_L Acoustic_Radiation_R Corticobulbar_Tract_L Corticobulbar_Tract_R Corticopontine_Tract_L Corticopontine_Tract_R Corticostriatal_Pathway_L Corticostriatal_Pathway_R Corticospinal_Tract_L Corticospinal_Tract_R Corticothalamic_Pathway_L Corticothalamic_Pathway_R Dentatorubrothalamic_Tract_L Dentatorubrothalamic_Tract_R Fornix_L Fornix_R Optic_Radiation_L Optic_Radiation_R Reticulospinal_Tract_L Reticulospinal_Tract_R Anterior_Commissure Corpus_Callosum_Forceps_Minor Corpus_Callosum_Body Corpus_Callosum_Tapetum Corpus_Callosum_Forceps_Major Cerebellum_L Cerebellum_R Inferior_Cerebellar_Peduncle_L Inferior_Cerebellar_Peduncle_R Middle_Cerebellar_Peduncle Superior_Cerebellar_Peduncle Vermis CNII_L CNII_R CNIII_L CNIII_R CNV_L CNV_R CNVII_L CNVII_R CNVIII_L CNVIII_R ","default":"","_order":2,"pid":0.7079091136446807,"optional":true},"other":{"id":"other","type":"string","placeholder":"","advanced":false,"desc":"Other parameters (e.g., --overwrite=1 --export_trk=0 ). For complete list, see http://dsi-studio.labsolver.org/Manual/command-line-for-dsi-studio#TOC-Automatic-tracking-of-bundles","default":"","_order":6,"pid":0.6259029092905437,"optional":true}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5f6a01dfcfa36571bfc99960","id":"dwi","datatype":"58c33c5fe13a50849b25879b"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5f6a01dfcfa365054bc99961","id":"fib","datatype":"5f6957e2cfa3659a64c96606","datatype_tags_pass":null,"files":null},{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5f6a01dfcfa3657863c99962","id":"tts","datatype":"5f6a9c7ecfa365847cc9dc75","datatype_tags_pass":null,"files":null},{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5f6a33d7cfa3658e1fc9b751","id":"stat","datatype":"5f6aa135cfa3656ab4c9e245","datatype_tags_pass":null,"files":null}],"github":"frankyeh/dsi-studio-atk","name":"dsi-studio-atk","avatar":"https://github.com/frankyeh/DSI-Studio/blob/master/icons/dsi_studio.png?raw=true","user_id":"1179","contributors":[{"name":"Fang-Cheng (Frank) Yeh","email":"frank.yeh@gmail.com","_id":"634a3d3262f3d3800f12a235"}],"create_date":"2020-09-22T13:53:35.428Z","desc":"DSI Studio augmented fiber tracking and automatic segmentation for mapping major white matter pathways (Yeh, Neuroimage, 2020). The pathway includes projection, association, and commissural pathways.","doi":"10.25663/brainlife.app.423","__v":4186,"desc_override":"","_canedit":true},{"_id":"5f6960bacfa3657551c967e1","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3d2962f3d3800f12a10e"}],"success_rate":77.52375296912113,"users":10,"runtime_mean":1838643.86,"runtime_std":5245766.754112764,"requested":17817,"examples":3,"groups":33},"projects":[],"admins":["1179"],"tags":[],"removed":false,"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5f6960bacfa365cfd0c967e2","id":"dwi","datatype":"58c33c5fe13a50849b25879b"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5f6960bacfa365b0eec967e3","id":"src","datatype":"5f6956d9cfa365c3dcc965ec","datatype_tags_pass":null,"files":null}],"github":"frankyeh/dsi-studio-dwi2src","name":"dsi-studio-dwi2src","user_id":"1179","contributors":[{"name":"Fang-Cheng (Frank) Yeh","email":"frank.yeh@gmail.com","_id":"634a3d2962f3d3800f12a10f"}],"create_date":"2020-09-22T02:26:02.929Z","desc":"DSI Studio scripts converting DWI file to SRC format.","doi":"10.25663/brainlife.app.422","__v":4160,"avatar":"https://github.com/frankyeh/DSI-Studio/blob/master/icons/dsi_studio.png?raw=true","desc_override":"","_canedit":true},{"_id":"5f6b8de3cfa3655f0bca477d","stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3d5662f3d3800f12a357"},{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"634a3d5662f3d3800f12a358"}],"success_rate":69.54054054054055,"users":7,"runtime_mean":438821.88,"runtime_std":1142589.3757124147,"requested":7890,"examples":2,"groups":17},"projects":[],"admins":["1179"],"tags":[],"removed":false,"config":{"src":{"type":"input","file_id":"src","input_id":"src"},"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5f6b920acfa36579adca4fb2","id":"dwi","datatype":"58c33c5fe13a50849b25879b"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5f6b8de3cfa3657abbca477e","id":"src","datatype":"5f6956d9cfa365c3dcc965ec","desc":"If an SRC file is assigned, DSI Studio will ignore \"dwi\""}],"outputs":[{"datatype_tags":["qc"],"output_on_root":false,"archive":true,"_id":"5f6b8de3cfa365ed65ca477f","id":"stat","datatype":"5f6bf981cfa36596f6ca7dd4","datatype_tags_pass":null,"files":null}],"github":"frankyeh/dsi-studio-qc","name":"dsi-studio-qc","avatar":"https://github.com/frankyeh/DSI-Studio/blob/master/icons/dsi_studio.png?raw=true","user_id":"1179","contributors":[{"name":"Fang-Cheng (Frank) Yeh","email":"frank.yeh@gmail.com","_id":"634a3d5762f3d3800f12a359"}],"create_date":"2020-09-23T18:03:15.551Z","desc":"Quality control for DWI data","doi":"10.25663/brainlife.app.428","__v":4160,"_canedit":true},{"_id":"5f6b88d3cfa36516c9ca3dda","stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3d4d62f3d3800f12a2f8"}],"success_rate":80.78616352201257,"users":8,"runtime_mean":1461809.77,"runtime_std":4574037.165527036,"requested":6845,"examples":3,"groups":21},"projects":[],"admins":["1179"],"tags":[],"removed":false,"config":{"src":{"type":"input","file_id":"src","input_id":"src"},"length_ratio":{"id":"length_ratio","type":"number","placeholder":"","advanced":false,"desc":"The length ratio used in GQI and QSDR reconstruction. Larger value leads to sharper resolution but more sensitive to noise.\n*For animal or ex-vivo studies, please use a low value (e.g. 0.6)","default":1.25,"_order":2,"pid":0.7766234640020688,"min":0.1,"max":2},"qsdr":{"id":"qsdr","type":"boolean","placeholder":"","advanced":false,"desc":"Reconstruct data into MNI space using QSDR (for correlational tractography and group analysis)","default":false,"_order":3,"pid":0.36735032462186523}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5f6b88d3cfa3655e55ca3ddb","id":"src","datatype":"5f6956d9cfa365c3dcc965ec"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5f6b88d3cfa3652a22ca3ddc","id":"fib","datatype":"5f6957e2cfa3659a64c96606","datatype_tags_pass":null,"files":null}],"github":"frankyeh/dsi-studio-src2fib","name":"dsi-studio-src2fib","avatar":"https://github.com/frankyeh/DSI-Studio/blob/master/icons/dsi_studio.png?raw=true","user_id":"1179","contributors":[{"name":"Fang-Cheng (Frank) Yeh","email":"frank.yeh@gmail.com","_id":"634a3d4d62f3d3800f12a2f9"}],"create_date":"2020-09-23T17:41:39.926Z","desc":"Reconstruction of DWI signals to extract fiber orientations.","doi":"10.25663/brainlife.app.427","__v":4152,"_canedit":true},{"_id":"5f6c0db66bbee327dd99efa4","stats":{"resources":[],"success_rate":100,"users":5,"runtime_mean":54260.28,"runtime_std":36992.79131860152,"requested":650,"examples":1,"groups":9},"projects":[],"admins":["1179"],"tags":[],"removed":false,"config":{"fib":{"type":"input","file_id":"fib","input_id":"fib"},"mapping":{"type":"input","file_id":"mapping","input_id":"fib"},"fiber_count":{"id":"fiber_count","type":"number","placeholder":"","advanced":false,"desc":"Total number of track generated","default":10000000,"_order":2,"pid":0.890562935915669,"min":1},"cmd":{"id":"cmd","type":"string","placeholder":"","advanced":false,"desc":"Other command line options, see http://dsi-studio.labsolver.org/Manual/command-line-for-dsi-studio#TOC-Fiber-tracking","default":"","_order":3,"pid":0.6627175176486757,"optional":true}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5f6c0db66bbee3ca5899efa5","id":"fib","datatype":"5f6957e2cfa3659a64c96606"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5f6c0db66bbee3863f99efa6","id":"tt","datatype":"5f6954c7cfa36577f4c96595","datatype_tags_pass":null,"files":null}],"github":"frankyeh/dsi-studio-trk","name":"dsi-studio-trk","avatar":"https://github.com/frankyeh/DSI-Studio/blob/master/icons/dsi_studio.png?raw=true","user_id":"1179","contributors":[{"name":"Fang-Cheng (Frank) Yeh","email":"frank.yeh@gmail.com","_id":"634a3d6062f3d3800f12a39d"}],"create_date":"2020-09-24T03:08:38.842Z","desc":"DSI Studio fiber tracking","doi":"10.25663/brainlife.app.429","__v":4150,"_canedit":true},{"_id":"5f6a7c2bcfa3656568c9d1b4","stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3d4462f3d3800f12a26b"}],"success_rate":37.5,"users":2,"runtime_mean":46696,"runtime_std":17389.256855886626,"requested":8,"examples":1,"groups":2},"projects":[],"admins":["1179"],"tags":[],"removed":false,"config":{"track":{"type":"input","file_id":"track","input_id":"trk"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5f6a7c2bcfa365f0d8c9d1b5","id":"trk","datatype":"5b956f6cd7b3f1e24e9121ce"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5f6a7c2bcfa365af76c9d1b6","id":"tt","datatype":"5f6954c7cfa36577f4c96595","datatype_tags_pass":null,"files":null}],"github_branch":"master","github":"frankyeh/dsi-studio-trk2tt","name":"dsi-studio-trk2tt","avatar":"https://github.com/frankyeh/DSI-Studio/blob/master/icons/dsi_studio.png?raw=true","user_id":"1179","contributors":[{"name":"Fang-Cheng (Frank) Yeh","email":"frank.yeh@gmail.com","_id":"634a3d4462f3d3800f12a26c"}],"create_date":"2020-09-22T22:35:23.024Z","desc":"Convert TinyTrack format to TRK format","doi":"10.25663/brainlife.app.426","__v":4150,"_canedit":true},{"_id":"5f6a7bd0cfa3655296c9d143","stats":{"resources":[],"success_rate":0,"users":4,"requested":135,"examples":0,"groups":7},"projects":[],"admins":["1179"],"tags":[],"removed":false,"config":{"tt":{"type":"input","file_id":"tt","input_id":"tt"},"tts":{"type":"input","file_id":"tts","input_id":"tts"}},"inputs":[{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5f6a7bd0cfa3655c83c9d144","id":"tt","datatype":"5f6954c7cfa36577f4c96595"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5f6b830bcfa3654540ca3519","id":"tts","datatype":"5f6a9c7ecfa365847cc9dc75"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5f6a7bd0cfa365716cc9d145","id":"trk","datatype":"5b956f6cd7b3f1e24e9121ce","datatype_tags_pass":null,"files":null}],"github":"frankyeh/dsi-studio-tt2trk","name":"dsi-studio-tt2trk","avatar":"https://github.com/frankyeh/DSI-Studio/blob/master/icons/dsi_studio.png?raw=true","user_id":"1179","contributors":[{"name":"Fang-Cheng (Frank) Yeh","email":"frank.yeh@gmail.com","_id":"634a3d3b62f3d3800f12a237"}],"create_date":"2020-09-22T22:33:52.656Z","desc":"Convert TRK format to TinyTrack format","doi":"10.25663/brainlife.app.425","__v":4155,"_canedit":true},{"_id":"5a77640c5bf7fb0039f2f809","name":"dt6 To Nifti Converter","desc":"Will take a dt6 and create tensor (FA,MD,AD,RD) and Westin Shape Indices (cl, cp, cs) nifti images from a dt6.mat structure.","citation":null,"github":"brainlife/app-dt6tonifti","github_branch":"1.0","config":{"dt6":{"type":"input","file_id":"output","input_id":"0"}},"user_id":"16","create_date":"2018-02-04T19:50:36.637Z","removed":false,"_rate":0,"outputs":[{"datatype_tags":[],"output_on_root":true,"archive":true,"_id":"5a77640c5bf7fb0039f2f80a","id":"0","datatype":"5a79df48d071a1753f1d661b","files":null},{"datatype_tags":["tensor"],"output_on_root":true,"archive":true,"_id":"5a79df8e5bf7fb0039f2f81d","id":"1","datatype":"59c3eae633fc1cf9ead71679","files":null}],"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5a77640c5bf7fb0039f2f80b","id":"0","datatype":"58cb234be13a50849b25882f"}],"contributors":[{"name":"Brad Caron","email":null,"_id":"634a321562f3d3800f116b0f"},{"name":"Franco Pestilli","email":null,"_id":"634a321562f3d3800f116b10"}],"tags":["convert"],"references":[],"admins":["1","16"],"projects":[],"__v":14245,"stats":{"stars":0,"requested":239,"users":4,"success_rate":96.20253164556962,"serviceinfo":{"_id":"5d729e1f78356a109788b323","counts":{"_id":"5e5c689d87cac7836eab1bc8","failed":108,"finished":4527,"removed":4571,"requested":4905,"running":4635,"running_sync":0,"stop_requested":16},"success_rate":97.66990291262137,"users":18,"readme_status":"ok","runtime_mean":1152835.42,"runtime_std":4937531.064418811,"service":"brain-life/app-dt6tonifti","__v":0},"gitinfo":{"desc":"Will take a dt6 and create tensor (FA,MD,AD,RD) and Westin Shape Indices (cl, cp, cs) nifti images from a dt6.mat structure.","tags":["convert"],"stats":{"stars":0},"contributors":[{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"runtime_mean":35569.06,"runtime_std":11117.940301890454,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a321462f3d3800f116b0e"}],"examples":2,"groups":8},"doi":"10.25663/bl.app.48","_canedit":true},{"_id":"58c56cf7e13a50849b258800","user_id":"1","create_date":"2017-02-18T01:05:51.509Z","name":"dtiInit","desc":"Runs vistasoft/dtiInit to preprocess and register dwi to anat/t1","github":"brainlife/app-dtiinit","admins":["16","41","146","43","45","1"],"inputs":[{"datatype_tags":["single_shell"],"optional":false,"multi":false,"advanced":false,"_id":"58f2c40caf44920021b9e0a2","id":"dwi","datatype":"58c33c5fe13a50849b25879b"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"58f2c40caf44920021b9e0a3","id":"t1","datatype":"58c33bcee13a50849b25879a","desc":"T1 image to align the output dwi data to."}],"outputs":[{"datatype_tags":[],"output_on_root":true,"archive":true,"_id":"58f2c40caf44920021b9e0a4","id":"output","datatype":"58cb234be13a50849b25882f","files":null},{"datatype_tags":["dtiinit"],"output_on_root":true,"archive":true,"_id":"5ba1736601381a00289088a5","id":"dwi","datatype":"58c33c5fe13a50849b25879b","datatype_tags_pass":"dwi","files":null}],"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"t1":{"type":"input","file_id":"t1","input_id":"t1"},"phaseEncodeDir":{"type":"enum","placeholder":"","desc":"Taken from the rawDti nifti field, you can specify it here if it does not exist. If you collected your DTI data using GE's ASSET, you may be prompted to provide phase-encode direction (1= L/R 'row', 2 = A/P 'col'). Information about this, as well as the b-value and gradient code, can befound in the dicom file header.","default":"2","options":[{"desc":"use the y dimension","label":"y dimension","value":"2"},{"desc":"use the x dimension","label":"x dimension","value":"1"},{"desc":"use the z dimension","label":"z dimension","value":"3"}],"id":"phaseEncodeDir","pid":0.8523940876881033,"_order":2},"resolution":{"type":"string","placeholder":"use default resolution","desc":"enter the three values of the desired resolution separated by spaces","default":"default","id":"resolution","pid":0.1001809309488364,"_order":3},"rotateBvecsWithCanXform":{"type":"boolean","placeholder":"","desc":"Rotate the bvectors according to the canonical xForm. You need to set this to true for Siemens data (such as HCP) and Philips (see mrDiffusion/dtiInit/dtiInit.m section VII)","default":true,"id":"rotateBvecsWithCanXform","pid":0.718689019063131,"_order":4},"rotateBvecsWithRx":{"type":"boolean","placeholder":"","desc":"Rotate the bvectors according to the prescription (see mrDiffusion/dtiInit/dtiInit.m section VII)","default":true,"id":"rotateBvecsWithRx","pid":0.046197968321420424,"_order":5},"eddyCorrect":{"type":"enum","placeholder":"","desc":"do eddy current and motion correction","default":"1","options":[{"desc":"no eddy current or motion correction","label":"(-1) no eddy current or motion correction","value":"-1"},{"desc":"do eddy current and motion correction","label":"(1) do eddy current and motion correction","value":"1"},{"desc":"only do motion correction","label":"(0) only do motion correction","value":"0"}],"id":"eddyCorrect","pid":0.7100685881031383,"_order":6},"noDwiAlignment":{"id":"noDwiAlignment","type":"boolean","placeholder":"","desc":"Do not align the DWI data to T1. When True, the DWI data are considered already acpc aligned to T1 and have neurological orientation. The configuration of eddy correction is forced to -1 and Bvecs rotations to False.","default":false,"_order":7,"pid":0.5848996842670158}},"__v":14345,"_rate":5,"tags":["diffusion-preprocessing"],"removed":false,"projects":[],"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a304c62f3d3800f115c97"},{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a304c62f3d3800f115c98"},{"name":"Paolo Avesani","email":null,"_id":"634a304c62f3d3800f115c99"},{"name":"Franco Pestilli","email":null,"_id":"634a304c62f3d3800f115c9a"}],"github_branch":"1.6","references":[],"stats":{"stars":1,"requested":14368,"users":39,"success_rate":54.958155692404866,"serviceinfo":{"_id":"5d729e1e78356a109788b233","counts":{"_id":"5e5c686f87cac7de3eab1b92","failed":30,"finished":1044,"removed":1558,"requested":1609,"running":1089,"running_sync":0,"stop_requested":29},"success_rate":97.20670391061452,"users":19,"readme_status":"ok","runtime_mean":2202728,"runtime_std":3686661.6435123985,"service":"brainlife/app-dtiinit","__v":0},"gitinfo":{"desc":"Runs vistasoft/dtiInit to preprocess and register dwi to anat/t1","tags":["diffusion-preprocessing"],"stats":{"stars":1},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Lindsey Kitchell","email":null},{"name":"Paolo Avesani","email":null},{"name":"Franco Pestilli","email":null}]},"runtime_mean":1524106.2,"runtime_std":1697659.2785998548,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a304b62f3d3800f115c95"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a304b62f3d3800f115c96"}],"examples":5,"groups":63},"avatar":"https://avatars0.githubusercontent.com/u/3299217?s=200&v=4","doi":"10.25663/bl.app.3","_canedit":true},{"_id":"62ac6847ab3e66978063e37c","user_id":"1994","projects":["624c4cd65d8ab5d5f06d99be"],"admins":["1994","2021","146"],"name":"dwi-fslswap-app","github":"hanna-willis/app-fslswap","github_branch":"master","tags":[],"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"sbref":{"type":"input","file_id":"sbref","input_id":"dwi"},"sbref_json":{"type":"input","file_id":"sbref_json","input_id":"dwi"},"swap_dimensions":{"id":"swap_dimensions","type":"string","placeholder":"","advanced":false,"desc":"new x,y,z axes in terms of the  old axes","default":"-x y z","_order":2,"pid":0.16532718912168698}},"inputs":[{"id":"dwi","datatype":"58c33c5fe13a50849b25879b","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"62ac68caab3e66978063e3ef"}],"outputs":[{"id":"out_dir","datatype":"58c33c5fe13a50849b25879b","datatype_tags":["flipped"],"datatype_tags_pass":"dwi","output_on_root":false,"files":null,"archive":true,"_id":"62ac68caab3e66978063e3f0"}],"stats":{"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a453f62f3d3800f131002"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a453f62f3d3800f131003"}],"examples":1,"success_rate":39.02439024390244,"users":2,"groups":2,"runtime_mean":220530.25,"runtime_std":684720.1040068764,"requested":47},"removed":false,"contributors":[{"name":"Franco Pestilli","email":null,"_id":"634a454062f3d3800f131004"},{"name":null,"email":null,"_id":"634a454062f3d3800f131005"},{"name":"Giulia Bertò","email":null,"_id":"634a454062f3d3800f131006"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a454062f3d3800f131007"}],"create_date":"2022-06-17T11:40:55.283Z","desc":"This is a template for a python-based brainlife.io/app","__v":256,"doi":"10.25663/brainlife.app.652","_canedit":true},{"_id":"5fd7a1ee57aacd10b72ebecf","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3e6862f3d3800f12baf2"}],"success_rate":0,"users":2,"requested":3,"examples":0,"groups":2},"projects":[],"admins":["1310"],"tags":[],"removed":false,"config":{"fa":{"type":"input","file_id":"fa","input_id":"adnideepdti"},"md":{"type":"input","file_id":"md","input_id":"adnideepdti"},"ad":{"type":"input","file_id":"ad","input_id":"adnideepdti"}},"inputs":[{"datatype_tags":["dti"],"optional":true,"multi":true,"advanced":false,"_id":"5fd7bc2457aacd3c3f2ec961","id":"adnideepdti","datatype":"5a79df48d071a1753f1d661b","desc":"FA maps classified by a CNN"}],"outputs":[{"datatype_tags":["dti","dipy_reconst_dti"],"output_on_root":false,"archive":true,"_id":"5fd7bc2457aacd67802ec962","id":"dwi","datatype":"5a79df48d071a1753f1d661b","datatype_tags_pass":null,"files":null,"desc":"Model of CNN for a 3D"}],"github_branch":"v0.6.0","github":"roijo/NiftyNet","name":"earlyCNN","user_id":"1310","contributors":[{"name":"Wenqi Li","email":null,"_id":"634a3e6c62f3d3800f12baf3"},{"name":null,"email":null,"_id":"634a3e6c62f3d3800f12baf4"},{"name":null,"email":null,"_id":"634a3e6c62f3d3800f12baf5"},{"name":"Zach","email":null,"_id":"634a3e6c62f3d3800f12baf6"},{"name":"Dzhoshkun Ismail Shakir","email":"dzhoshkun.shakir@gmail.com","_id":"634a3e6c62f3d3800f12baf7"},{"name":null,"email":null,"_id":"634a3e6c62f3d3800f12baf8"},{"name":"Tom Doel","email":null,"_id":"634a3e6c62f3d3800f12baf9"},{"name":null,"email":null,"_id":"634a3e6c62f3d3800f12bafa"},{"name":"Fernando Pérez-García","email":null,"_id":"634a3e6c62f3d3800f12bafb"},{"name":"Pritesh Mehta","email":"pritesh.mehta@kcl.ac.uk","_id":"634a3e6c62f3d3800f12bafc"},{"name":"Eric Kerfoot","email":null,"_id":"634a3e6c62f3d3800f12bafd"},{"name":null,"email":null,"_id":"634a3e6c62f3d3800f12bafe"},{"name":"Irme","email":null,"_id":"634a3e6c62f3d3800f12baff"},{"name":null,"email":null,"_id":"634a3e6c62f3d3800f12bb00"},{"name":"Patrick Liu","email":null,"_id":"634a3e6c62f3d3800f12bb01"},{"name":"Petru-Daniel Tudosiu","email":null,"_id":"634a3e6c62f3d3800f12bb02"},{"name":"Bryce Besler","email":null,"_id":"634a3e6c62f3d3800f12bb03"},{"name":null,"email":null,"_id":"634a3e6c62f3d3800f12bb04"},{"name":"Joeri Nicolaes","email":null,"_id":"634a3e6c62f3d3800f12bb05"},{"name":"Yipeng Hu","email":"yipeng.hu@ucl.ac.uk","_id":"634a3e6c62f3d3800f12bb06"},{"name":"Tom Vercauteren","email":null,"_id":"634a3e6c62f3d3800f12bb07"},{"name":"Lucas Fidon","email":"lucas.fidon@owkin.com","_id":"634a3e6c62f3d3800f12bb08"},{"name":"Thomas Varsavsky","email":null,"_id":"634a3e6c62f3d3800f12bb09"},{"name":"Oeslle Lucena","email":null,"_id":"634a3e6c62f3d3800f12bb0a"},{"name":"Rafael Palomar","email":null,"_id":"634a3e6c62f3d3800f12bb0b"},{"name":null,"email":null,"_id":"634a3e6c62f3d3800f12bb0c"},{"name":"Amit Kumar","email":null,"_id":"634a3e6c62f3d3800f12bb0d"},{"name":"Imanol Luengo","email":null,"_id":"634a3e6c62f3d3800f12bb0e"},{"name":null,"email":null,"_id":"634a3e6c62f3d3800f12bb0f"},{"name":null,"email":null,"_id":"634a3e6c62f3d3800f12bb10"}],"create_date":"2020-12-14T17:33:34.867Z","desc":"[unmaintained] An open-source convolutional neural networks platform for research in medical image analysis and image-guided therapy","__v":3755,"doi":"10.25663/brainlife.app.459","_canedit":true},{"_id":"61d5e77d33cb3deb49834d4a","user_id":"822","projects":[],"admins":["822","1"],"name":"extract_b0_masks","github":"dPys/app-extract_b0_masks","github_branch":"main","tags":[],"config":{"dwi":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"},"sbref":{"type":"input","file_id":"sbref","input_id":"dwi"},"sbref_json":{"type":"input","file_id":"sbref_json","input_id":"dwi"}},"inputs":[{"id":"dwi","datatype":"58c33c5fe13a50849b25879b","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"61d5e81633cb3deb49835217"}],"outputs":[{"id":"b0_extractions","datatype":"5ddf1381936ca39318c5f045","datatype_tags":[],"datatype_tags_pass":"dwi","output_on_root":false,"files":null,"archive":true,"_id":"61d5e89433cb3deb498356de"}],"stats":{"resources":[{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"634a436d62f3d3800f13002b"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a436d62f3d3800f13002c"}],"examples":0,"success_rate":0,"users":1,"requested":21,"groups":1},"removed":false,"contributors":[{"name":"Derek Pisner","email":null,"_id":"634a436d62f3d3800f13002d"}],"create_date":"2022-01-05T18:46:21.317Z","desc":null,"__v":1065,"doi":"10.25663/brainlife.app.600","_canedit":true},{"_id":"5ed05fe8e3f4538080268585","stats":{"success_rate":54.5607499098666,"users":63,"runtime_mean":311155.48,"runtime_std":1266478.8829840035,"requested":9413,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a3b9362f3d3800f12671b"}],"examples":5,"groups":87},"projects":[],"admins":["239"],"tags":[],"removed":false,"config":{"fmri":{"type":"input","file_id":"bold","input_id":"fmri"},"parc":{"type":"input","file_id":"parc","input_id":"parc"},"key":{"type":"input","file_id":"key","input_id":"parc"},"label":{"type":"input","file_id":"label","input_id":"parc"},"confounds":{"type":"input","file_id":"regressors","input_id":"confounds"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"strategy":{"id":"strategy","type":"enum","placeholder":"","advanced":false,"desc":"Strategy of nuisance regression, all strategies include linear de-trending","default":"36P","_order":2,"pid":0.30453316785669493,"options":[{"desc":"Satterthwaite 36 parameter strategy","label":"36P","value":"36P"},{"desc":"Anatomical CompCor strategy","label":"24aCompCor","value":"24aCompCor"},{"desc":"Just global signal regression, nothing else","label":"globalsig","value":"globalsig"},{"desc":"Just linear de-trending","label":"linear","value":"linear"},{"desc":"Anatomical CompCor strategy with global signal ","label":"24aCompCorGsr","value":"24aCompCorGsr"}],"optional":false},"tr":{"id":"tr","type":"number","placeholder":"","advanced":false,"desc":"If you know the TR, you can set it here.  Script will also try to automatically read it from BL info (try this first). ","default":"","_order":4,"pid":0.1624004857670176,"optional":true,"min":0,"max":5},"smoothfwhm":{"id":"smoothfwhm","type":"number","placeholder":"","advanced":false,"desc":"FWHM of spatial smoothing kernel applied to bold.nii.gz (put 0 for no smoothing)","default":0,"_order":4,"pid":0.40616255388668043,"min":0,"max":6,"optional":true},"lowpass":{"id":"lowpass","type":"number","placeholder":"","advanced":false,"desc":"Low-pass temporal filter","default":0.08,"_order":5,"pid":0.7201505853786201,"optional":true},"highpass":{"id":"highpass","type":"number","placeholder":"","advanced":false,"desc":"High-pass temporal filter","default":0.008,"_order":6,"pid":0.031078170163084673,"optional":true},"addlinear":{"id":"addlinear","type":"boolean","placeholder":"","advanced":false,"desc":"Add linear regressor to nuisance regression. This makes your time series generally centered around 0. ","default":true,"_order":9,"pid":0.21277136068786717},"spikethresh":{"id":"spikethresh","type":"number","placeholder":"","advanced":true,"desc":"If you want a spike regressor for frames that exceed a certain FD threshold, set that threshold here. Threshold is typically in the 0.5 to 1 range; else, \"9999\" means no spike regressor. ","default":9999,"_order":11,"pid":0.2471331426797072,"min":0.2},"inspace":{"id":"inspace","type":"enum","placeholder":"","advanced":true,"desc":"In almost ALL cases, this should be set to 'data'. It will take a super long time to run the app if you set it to 'label' and you might run out of memory. ","default":"data","_order":12,"pid":0.6860581220202335,"options":[{"desc":"compute time series from data grid, resample labels","label":"data","value":"data"},{"desc":"computer time series from label grid, resample data","label":"label","value":"label"}]},"savets":{"id":"savets","type":"boolean","placeholder":"","advanced":false,"desc":"","default":true,"_order":13,"pid":0.15819963468324594,"readonly":true},"nomatrix":{"id":"nomatrix","type":"boolean","placeholder":"","advanced":false,"desc":"","default":true,"_order":14,"pid":0.2930898428201676,"readonly":true}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ed05fe8e3f4537991268586","id":"fmri","datatype":"59b685a08e5d38b0b331ddc5","desc":"from fMRIPrep"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ed05fe8e3f4535a42268587","id":"parc","datatype":"5c1a7489f9109beac4a88a1f","desc":"From multi-atlas transfer app; should be aligned to preprocessed bold.nii.gz (i.e. same space).  The internal functions of this app will re-slice the func and the parc to be on the same voxel grid. "},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5ed05fe8e3f4532a07268588","id":"confounds","datatype":"5c4f6a8af9109beac4b3dae0","desc":"from fMRIPrep"},{"datatype_tags":["func"],"optional":false,"multi":false,"advanced":false,"_id":"5ed05fe8e3f453391d268589","id":"mask","datatype":"5a281aee2c214c9ba83ce620","desc":"from fMRIPrep"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":false,"_id":"5ed05fe8e3f453ad7626858a","id":"output_regress","datatype":"59b685a08e5d38b0b331ddc5","datatype_tags_pass":"fmri","files":null,"desc":"regressed output bold"},{"datatype_tags":["time series"],"output_on_root":false,"archive":true,"_id":"60a6ba3222b42a5bcf700b3c","id":"out_ts","datatype":"604a4553ebfe4559de3af944","datatype_tags_pass":null,"files":null,"desc":"new timeseries datatype"}],"github_branch":"0.1.6","github":"faskowit/app-fmri-2-mat","name":"fMRI Timeseries Extraction","user_id":"239","contributors":[{"name":"Josh Faskowitz","email":null,"_id":"634a3b9462f3d3800f12671c"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a3b9462f3d3800f12671d"}],"create_date":"2020-05-29T01:05:44.133Z","desc":"fmriprep outputs to connectivity matrices ","doi":"10.25663/brainlife.app.369","__v":4711,"avatar":"https://upload.wikimedia.org/wikipedia/commons/9/9b/T1map_brain_3.png","_canedit":true},{"_id":"5c720cf63e2f2c0030a23486","stats":{"stars":0,"serviceinfo":{"_id":"5d729e1e78356a109788b1d1","counts":{"_id":"5e5c3de687cac70678ab13f9","failed":65,"finished":409,"removed":327,"requested":541,"running":494,"running_sync":0,"stop_requested":28},"success_rate":86.28691983122363,"users":8,"readme_status":"ok","runtime_mean":814507.84,"runtime_std":1581039.47136238,"service":"faskowit/app-fmri-2-mat","__v":0},"gitinfo":{"desc":"fmriprep outputs to connectivity matrices ","tags":[],"stats":{"stars":0},"contributors":[{"name":"Josh Faskowitz","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"success_rate":54.5607499098666,"users":63,"runtime_mean":311155.48,"runtime_std":1266478.8829840035,"requested":9413,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a354562f3d3800f119f12"}],"examples":5,"groups":87},"projects":[],"admins":["1","239"],"tags":[],"removed":false,"config":{"fmri":{"type":"input","file_id":"bold","input_id":"fmri"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"parc":{"type":"input","file_id":"parc","input_id":"parc"},"key":{"type":"input","file_id":"key","input_id":"parc"},"confounds":{"type":"input","file_id":"regressors","input_id":"confounds"}},"inputs":[{"datatype_tags":["func"],"optional":false,"multi":false,"advanced":false,"_id":"5c720cf63e2f2c0030a23489","id":"mask","datatype":"5a281aee2c214c9ba83ce620","desc":"Please select fmriprep bold mask"},{"datatype_tags":["preprocessed"],"optional":false,"multi":false,"advanced":false,"_id":"5c720cf63e2f2c0030a2348a","id":"fmri","datatype":"59b685a08e5d38b0b331ddc5","desc":"Please use the bold output in subject (T1w) space."},{"datatype_tags":["SupraTentorial"],"optional":false,"multi":false,"advanced":false,"_id":"5c720cf63e2f2c0030a23488","id":"parc","datatype":"5c1a7489f9109beac4a88a1f","desc":"From multi-atlas transfer app"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c720cf63e2f2c0030a23487","id":"confounds","datatype":"5c4f6a8af9109beac4b3dae0"}],"outputs":[{"datatype_tags":["regress"],"output_on_root":false,"archive":true,"_id":"5c720cf63e2f2c0030a2348c","id":"output_regress","datatype":"59b685a08e5d38b0b331ddc5","datatype_tags_pass":"fmri","files":null},{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5c720cf63e2f2c0030a2348b","id":"cm","datatype":"5d34d9f744947d8aea0e0d2f","datatype_tags_pass":"fmri","files":null}],"github_branch":"0.1.5","github":"faskowit/app-fmri-2-mat","name":"fMRI to Connectivity Matrices","user_id":"239","contributors":[{"name":"Josh Faskowitz","email":null,"_id":"634a354562f3d3800f119f13"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a354562f3d3800f119f14"}],"create_date":"2019-02-24T03:18:14.498Z","desc":"fmriprep outputs to connectivity matrices ","doi":"10.25663/brainlife.app.167","__v":8669,"avatar":"https://cdn61.picsart.com/197163332004202.jpg?c480x480","_canedit":true},{"_id":"5dfceebd32bff0640ce27bbd","projects":[],"admins":["16","156","283","146","239","1","1619"],"tags":["fmri","preprocessing"],"removed":false,"stats":{"stars":1,"requested":74317,"users":171,"success_rate":42.9802159436219,"serviceinfo":{"_id":"5d729e1e78356a109788b1d7","counts":{"_id":"5e5c3e3387cac72eb6ab144a","failed":345,"finished":893,"removed":868,"requested":1485,"running":1265,"running_sync":0,"stop_requested":90},"success_rate":72.13247172859451,"users":26,"readme_status":"ok","runtime_mean":8657706.8,"runtime_std":2072534.0096058971,"service":"brainlife/app-fmriprep","__v":0},"gitinfo":{"desc":"runs fmriprep for brainlife","tags":["brain","fmri","mri","preprocessing"],"stats":{"stars":1},"contributors":[{"name":"Josh Faskowitz","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":5253069.78,"runtime_std":2950132.944432693,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a381662f3d3800f11e854"},{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a381662f3d3800f11e855"},{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"634a381662f3d3800f11e856"},{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"634a381662f3d3800f11e857"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a381662f3d3800f11e858"}],"examples":5,"groups":328},"config":{"t1":{"type":"input","file_id":"t1","input_id":"t1w"},"fmri":{"type":"input","file_id":"bold","input_id":"fmri"},"sbref":{"type":"input","file_id":"sbref","input_id":"fmri"},"sbref_json":{"type":"input","file_id":"sbref_json","input_id":"fmri"},"events":{"type":"input","file_id":"events","input_id":"fmri"},"events_json":{"type":"input","file_id":"events_json","input_id":"fmri"},"physio":{"type":"input","file_id":"physio","input_id":"fmri"},"physio_json":{"type":"input","file_id":"physio_json","input_id":"fmri"},"fsin":{"type":"input","file_id":"output","input_id":"freesurfer"},"t2":{"type":"input","file_id":"t2","input_id":"t2w"},"phasediff":{"type":"input","file_id":"phasediff","input_id":"fmap"},"phasediff_json":{"type":"input","file_id":"phasediff_json","input_id":"fmap"},"magnitude":{"type":"input","file_id":"magnitude","input_id":"fmap"},"magnitude1":{"type":"input","file_id":"magnitude1","input_id":"fmap"},"magnitude2":{"type":"input","file_id":"magnitude2","input_id":"fmap"},"fieldmap":{"type":"input","file_id":"fieldmap","input_id":"fmap"},"fieldmap_json":{"type":"input","file_id":"fieldmap_json","input_id":"fmap"},"phase1":{"type":"input","file_id":"phase1","input_id":"fmap"},"phase1_json":{"type":"input","file_id":"phase1_json","input_id":"fmap"},"phase2":{"type":"input","file_id":"phase2","input_id":"fmap"},"phase2_json":{"type":"input","file_id":"phase2_json","input_id":"fmap"},"epi1":{"type":"input","file_id":"epi1","input_id":"fmap"},"epi1_json":{"type":"input","file_id":"epi1_json","input_id":"fmap"},"epi2":{"type":"input","file_id":"epi2","input_id":"fmap"},"epi2_json":{"type":"input","file_id":"epi2_json","input_id":"fmap"},"space":{"id":"space","type":"enum","placeholder":"","advanced":false,"desc":"","default":"fsaverage5","_order":9,"pid":0.5870351694388216,"options":[{"desc":"FreeSurfer average meshes (density)","label":"fsaverage5","value":"fsaverage5"},{"desc":"FreeSurfer average meshes (density)","label":"fsaverage6","value":"fsaverage6"},{"desc":"individual subject surface","label":"fsnative","value":"fsnative"}]},"skipbidsvalidation":{"id":"skipbidsvalidation","type":"boolean","placeholder":"","advanced":false,"desc":"Skip the BIDS validation of input data. Try this option if your data is not BIDS compatible but you'd like to go ahead and process it through fmriprep anyway.","default":false,"_order":10,"pid":0.6972715335872175}},"inputs":[{"id":"t1w","desc":"t1 anatomy to register the input fmri data. Please be sure to use the same t1 used to generate the freesurfer input.","datatype":"58c33bcee13a50849b25879a","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c61c84f14027a01b14adcba"},{"id":"fmri","desc":"fmri data to preprocess","datatype":"59b685a08e5d38b0b331ddc5","datatype_tags":["!preprocessed"],"optional":false,"multi":false,"advanced":false,"_id":"5c61c84f14027a01b14adcb8"},{"id":"freesurfer","desc":"freesurfer output used to aid preprocessing","datatype":"58cb22c8e13a50849b25882e","datatype_tags":["!v5"],"optional":false,"multi":false,"advanced":false,"_id":"5c61c84f14027a01b14adcb5"},{"id":"t2w","datatype":"594c0325fa1d2e5a1f0beda5","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5c61c84f14027a01b14adcb9"},{"id":"fmap","desc":"2phasemag fieldmap is not yet supported by fmriprep (https://github.com/poldracklab/sdcflows/issues/15) - testing 1.5.2 should should suppor it.","datatype":"5c390505f9109beac42b00df","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5c61c84f14027a01b14adcb6"}],"outputs":[{"id":"regress","datatype":"5c4f6a8af9109beac4b3dae0","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5c719f4b3e2f2c0030a23478"},{"id":"anat","desc":"preprocessed t1 (same alignment as the original t1, but level adjusted - editme)","datatype":"58c33bcee13a50849b25879a","datatype_tags":["preprocessed"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5c7378b7badd19003102e900"},{"id":"anat_mask","datatype":"5a281aee2c214c9ba83ce620","datatype_tags":["anat","brain"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5c7378b7badd19003102e8ff"},{"id":"output_report","desc":"fmriprep HTML report and figures","datatype":"5e56dc330f7fa604cc3cc291","datatype_tags":["fmriprep"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5dfa753032bff09a13e2548c"},{"id":"cifti","desc":"surface timeseries data in cifti","datatype":"5fa9a60cafcdcc57e2c444ad","datatype_tags":["dtseries"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5fa9a6c7afcdcc6b1dc445ce"},{"id":"surface-data","desc":"","datatype":"5f78b377268f76598c29b27a","datatype_tags":["func"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5fad8c927e8ecb7207aa204e"},{"id":"surface-vertices","desc":"surface vertices. only meaningful for fsnative.","datatype":"5f78b255268f764bdd29b254","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5fad8c927e8ecb1d40aa204f"}],"github_branch":"20.2.1","github":"brainlife/app-fmriprep","name":"fMRIPrep - Surface Output","avatar":"https://media.springernature.com/m312/springer-static/image/art%3A10.1038%2Fs41592-018-0235-4/MediaObjects/41592_2018_235_Fig1_HTML.png?as=webp","user_id":"1","contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a381762f3d3800f11e859"},{"name":"David Hunt","email":"davhunt@iu.edu","_id":"634a381762f3d3800f11e85a"},{"name":"Josh Faskowitz","email":null,"_id":"634a381762f3d3800f11e85b"},{"name":"Brad Caron","email":null,"_id":"634a381762f3d3800f11e85c"},{"name":"Franco Pestilli","email":null,"_id":"634a381762f3d3800f11e85d"},{"name":"Giulia Bertò","email":null,"_id":"634a381762f3d3800f11e85e"}],"desc":"fMRIPrep is a functional magnetic resonance imaging (fMRI) data preprocessing pipeline that is designed to provide an easily accessible, state-of-the-art interface that is robust to variations in scan acquisition protocols and that requires minimal user input, while providing easily interpretable and comprehensive error and output reporting.","__v":6501,"create_date":"2019-12-20T15:54:37.416Z","doi":"10.25663/brainlife.app.267","_canedit":true},{"_id":"5c61c69f14027a01b14adcb3","stats":{"stars":1,"requested":74317,"users":171,"success_rate":42.9802159436219,"serviceinfo":{"_id":"5d729e1e78356a109788b1d7","counts":{"_id":"5e5c3de287cac79fd6ab13f4","failed":345,"finished":893,"removed":868,"requested":1485,"running":1265,"running_sync":0,"stop_requested":90},"success_rate":72.13247172859451,"users":26,"readme_status":"ok","runtime_mean":8657706.8,"runtime_std":2072534.0096058971,"service":"brainlife/app-fmriprep","__v":0},"gitinfo":{"desc":"runs fmriprep for brainlife","tags":["brain","fmri","mri","preprocessing"],"stats":{"stars":1},"contributors":[{"name":"Josh Faskowitz","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":5253069.78,"runtime_std":2950132.944432693,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a351b62f3d3800f119582"},{"resource_id":"5df95630cc67237c37bce485","name":"Stampede2(skx) @ TACC/UT","_id":"634a351b62f3d3800f119583"},{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"634a351b62f3d3800f119584"},{"resource_id":"60366f1e8b397487b52d34f2","name":"Expanse@SDSC (shared)","_id":"634a351b62f3d3800f119585"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a351b62f3d3800f119586"}],"examples":5,"groups":328},"projects":[],"admins":["16","156","283","146","239","1","1619"],"tags":["fmri","preprocessing"],"removed":false,"config":{"t1":{"type":"input","file_id":"t1","input_id":"t1w"},"fmri":{"type":"input","file_id":"bold","input_id":"fmri"},"sbref":{"type":"input","file_id":"sbref","input_id":"fmri"},"sbref_json":{"type":"input","file_id":"sbref_json","input_id":"fmri"},"events":{"type":"input","file_id":"events","input_id":"fmri"},"events_json":{"type":"input","file_id":"events_json","input_id":"fmri"},"physio":{"type":"input","file_id":"physio","input_id":"fmri"},"physio_json":{"type":"input","file_id":"physio_json","input_id":"fmri"},"fsin":{"type":"input","file_id":"output","input_id":"freesurfer"},"t2":{"type":"input","file_id":"t2","input_id":"t2w"},"phasediff":{"type":"input","file_id":"phasediff","input_id":"fmap"},"phasediff_json":{"type":"input","file_id":"phasediff_json","input_id":"fmap"},"magnitude":{"type":"input","file_id":"magnitude","input_id":"fmap"},"magnitude1":{"type":"input","file_id":"magnitude1","input_id":"fmap"},"magnitude2":{"type":"input","file_id":"magnitude2","input_id":"fmap"},"fieldmap":{"type":"input","file_id":"fieldmap","input_id":"fmap"},"fieldmap_json":{"type":"input","file_id":"fieldmap_json","input_id":"fmap"},"phase1":{"type":"input","file_id":"phase1","input_id":"fmap"},"phase1_json":{"type":"input","file_id":"phase1_json","input_id":"fmap"},"phase2":{"type":"input","file_id":"phase2","input_id":"fmap"},"phase2_json":{"type":"input","file_id":"phase2_json","input_id":"fmap"},"epi1":{"type":"input","file_id":"epi1","input_id":"fmap"},"epi1_json":{"type":"input","file_id":"epi1_json","input_id":"fmap"},"epi2":{"type":"input","file_id":"epi2","input_id":"fmap"},"epi2_json":{"type":"input","file_id":"epi2_json","input_id":"fmap"},"space":{"id":"space","type":"enum","placeholder":"","advanced":false,"desc":"output space of the preprocessed func/task output (bold). ","default":"T1w","_order":9,"pid":0.2898571335772977,"options":[{"desc":"Input t1w space","label":"T1w","value":"T1w"},{"desc":"","label":"MNI152NLin2009cAsym","value":"MNI152NLin2009cAsym"},{"desc":"","label":"MNI152NLin6Asym","value":"MNI152NLin6Asym"}]},"resolution":{"id":"resolution","type":"enum","placeholder":"","advanced":false,"desc":"","default":"original","_order":10,"pid":0.961838921032721,"options":[{"desc":"Output in original bold resolution","label":"original","value":"original"},{"desc":"","label":"2mm isotropic","value":"res-2"}]},"skipbidsvalidation":{"id":"skipbidsvalidation","type":"boolean","placeholder":"","advanced":false,"desc":"Skip the BIDS validation of input data. Try this option if your data is not BIDS compatible but you'd like to go ahead and process it through fmriprep anyway.","default":false,"_order":11,"pid":0.5431432980188811},"aroma":{"id":"aroma","type":"boolean","placeholder":"","advanced":false,"desc":"Use ICA based procedure to identify confounding time series related to head-motion [Prium2015].","default":false,"_order":12,"pid":0.15712372448091938}},"inputs":[{"id":"t1w","desc":"t1 anatomy to register the input fmri data. Please be sure to use the same t1 used to generate the freesurfer input.","datatype":"58c33bcee13a50849b25879a","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c61c84f14027a01b14adcba"},{"id":"fmri","desc":"fmri data to preprocess","datatype":"59b685a08e5d38b0b331ddc5","datatype_tags":["!preprocessed"],"optional":false,"multi":false,"advanced":false,"_id":"5c61c84f14027a01b14adcb8"},{"id":"freesurfer","desc":"freesurfer output used to aid preprocessing","datatype":"58cb22c8e13a50849b25882e","datatype_tags":["!v5"],"optional":false,"multi":false,"advanced":false,"_id":"5c61c84f14027a01b14adcb5"},{"id":"t2w","datatype":"594c0325fa1d2e5a1f0beda5","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5c61c84f14027a01b14adcb9"},{"id":"fmap","desc":"2phasemag fieldmap is not yet supported by fmriprep (https://github.com/poldracklab/sdcflows/issues/15) - should be supported by now","datatype":"5c390505f9109beac42b00df","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5c61c84f14027a01b14adcb6"}],"outputs":[{"id":"bold_img","datatype":"59b685a08e5d38b0b331ddc5","datatype_tags":["preprocessed"],"datatype_tags_pass":"fmri","output_on_root":false,"files":null,"archive":true,"_id":"5c719f4b3e2f2c0030a2347a"},{"id":"bold_mask","desc":"There is no such datatype tag for mask as \"bold\". It will be removed in favor of \"func\"","datatype":"5a281aee2c214c9ba83ce620","datatype_tags":["brain","bold","func"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5c719f4b3e2f2c0030a23479"},{"id":"regress","datatype":"5c4f6a8af9109beac4b3dae0","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5c719f4b3e2f2c0030a23478"},{"id":"anat","desc":"preprocessed t1 (same alignment as the original t1, but level adjusted - editme)","datatype":"58c33bcee13a50849b25879a","datatype_tags":["preprocessed"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5c7378b7badd19003102e900"},{"id":"anat_mask","datatype":"5a281aee2c214c9ba83ce620","datatype_tags":["anat","brain"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5c7378b7badd19003102e8ff"},{"id":"output_report","desc":"fmriprep HTML report and figures","datatype":"5e56dc330f7fa604cc3cc291","datatype_tags":["fmriprep"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5dfa753032bff09a13e2548c"},{"id":"transform","datatype":"62618e2afdf0b815e4ba5372","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"626b0b0df3858674a2a58433"},{"id":"parcellation","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags":["freesurfer"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"626b0b0df3858674a2a58434"}],"github_branch":"20.2.3-2","github":"brainlife/app-fmriprep","name":"fMRIPrep - Volume Output","avatar":"https://media.springernature.com/m312/springer-static/image/art%3A10.1038%2Fs41592-018-0235-4/MediaObjects/41592_2018_235_Fig1_HTML.png?as=webp","user_id":"239","contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a351c62f3d3800f119587"},{"name":"David Hunt","email":"davhunt@iu.edu","_id":"634a351c62f3d3800f119588"},{"name":"Josh Faskowitz","email":null,"_id":"634a351c62f3d3800f119589"},{"name":"Brad Caron","email":null,"_id":"634a351c62f3d3800f11958a"},{"name":"Franco Pestilli","email":null,"_id":"634a351c62f3d3800f11958b"},{"name":"Giulia Bertò","email":null,"_id":"634a351c62f3d3800f11958c"}],"create_date":"2019-02-11T19:01:51.983Z","desc":"fMRIPrep is a functional magnetic resonance imaging (fMRI) data preprocessing pipeline that is designed to provide an easily accessible, state-of-the-art interface that is robust to variations in scan acquisition protocols and that requires minimal user input, while providing easily interpretable and comprehensive error and output reporting.","doi":"10.25663/brainlife.app.160","__v":8850,"_canedit":true},{"_id":"63458604fa262bbde2a93af2","user_id":"1619","projects":[],"admins":["16","156","283","146","239","1","1619"],"avatar":"https://media.springernature.com/m312/springer-static/image/art%3A10.1038%2Fs41592-018-0235-4/MediaObjects/41592_2018_235_Fig1_HTML.png?as=webp","name":"fMRIPrep - Volume Output - ICA-AROMA","github":"vnbcs/app-fmriprep","github_branch":"ic-aroma","desc":"fMRIPrep is a functional magnetic resonance imaging (fMRI) data preprocessing pipeline that is designed to provide an easily accessible, state-of-the-art interface that is robust to variations in scan acquisition protocols and that requires minimal user input, while providing easily interpretable and comprehensive error and output reporting.","desc_override":"fMRIPrep modified to save ICA-AROMA output, as well as csv recording ICA-AROMA components removed. See \"fMRIPrep - Volume Output\" for more details on fMRIPrep. ","tags":[],"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a464a62f3d3800f1313bb"},{"name":"David Hunt","email":"davhunt@iu.edu","_id":"634a464a62f3d3800f1313bc"},{"name":"Josh Faskowitz","email":null,"_id":"634a464a62f3d3800f1313bd"},{"name":"Brad Caron","email":null,"_id":"634a464a62f3d3800f1313be"},{"name":"Franco Pestilli","email":null,"_id":"634a464a62f3d3800f1313bf"},{"name":"Giulia Bertò","email":null,"_id":"634a464a62f3d3800f1313c0"}],"config":{"t1":{"type":"input","file_id":"t1","input_id":"t1w"},"fmri":{"type":"input","file_id":"bold","input_id":"fmri"},"sbref":{"type":"input","file_id":"sbref","input_id":"fmri"},"sbref_json":{"type":"input","file_id":"sbref_json","input_id":"fmri"},"events":{"type":"input","file_id":"events","input_id":"fmri"},"events_json":{"type":"input","file_id":"events_json","input_id":"fmri"},"physio":{"type":"input","file_id":"physio","input_id":"fmri"},"physio_json":{"type":"input","file_id":"physio_json","input_id":"fmri"},"fsin":{"type":"input","file_id":"output","input_id":"freesurfer"},"t2":{"type":"input","file_id":"t2","input_id":"t2w"},"phasediff":{"type":"input","file_id":"phasediff","input_id":"fmap"},"phasediff_json":{"type":"input","file_id":"phasediff_json","input_id":"fmap"},"magnitude":{"type":"input","file_id":"magnitude","input_id":"fmap"},"magnitude1":{"type":"input","file_id":"magnitude1","input_id":"fmap"},"magnitude2":{"type":"input","file_id":"magnitude2","input_id":"fmap"},"fieldmap":{"type":"input","file_id":"fieldmap","input_id":"fmap"},"fieldmap_json":{"type":"input","file_id":"fieldmap_json","input_id":"fmap"},"phase1":{"type":"input","file_id":"phase1","input_id":"fmap"},"phase1_json":{"type":"input","file_id":"phase1_json","input_id":"fmap"},"phase2":{"type":"input","file_id":"phase2","input_id":"fmap"},"phase2_json":{"type":"input","file_id":"phase2_json","input_id":"fmap"},"epi1":{"type":"input","file_id":"epi1","input_id":"fmap"},"epi1_json":{"type":"input","file_id":"epi1_json","input_id":"fmap"},"epi2":{"type":"input","file_id":"epi2","input_id":"fmap"},"epi2_json":{"type":"input","file_id":"epi2_json","input_id":"fmap"},"space":{"id":"space","type":"enum","placeholder":"","advanced":false,"desc":"output space of the preprocessed func/task output (bold). ","default":"T1w","_order":9,"pid":0.7859189114686465,"options":[{"desc":"Input t1w space","label":"T1w","value":"T1w"},{"desc":"","label":"MNI152NLin2009cAsym","value":"MNI152NLin2009cAsym"},{"desc":"","label":"MNI152NLin6Asym","value":"MNI152NLin6Asym"}]},"resolution":{"id":"resolution","type":"enum","placeholder":"","advanced":false,"desc":"","default":"original","_order":10,"pid":0.5528961310157153,"options":[{"desc":"Output in original bold resolution","label":"original","value":"original"},{"desc":"","label":"2mm isotropic","value":"res-2"}]},"skipbidsvalidation":{"id":"skipbidsvalidation","type":"boolean","placeholder":"","advanced":false,"desc":"Skip the BIDS validation of input data. Try this option if your data is not BIDS compatible but you'd like to go ahead and process it through fmriprep anyway.","default":false,"_order":11,"pid":0.9467750099463021},"aroma":{"id":"aroma","type":"boolean","placeholder":"","advanced":false,"desc":"Use ICA based procedure to identify confounding time series related to head-motion [Prium2015].","default":false,"_order":12,"pid":0.488842058849962}},"inputs":[{"id":"t1w","desc":"t1 anatomy to register the input fmri data. Please be sure to use the same t1 used to generate the freesurfer input.","datatype":"58c33bcee13a50849b25879a","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c61c84f14027a01b14adcba"},{"id":"fmri","desc":"fmri data to preprocess","datatype":"59b685a08e5d38b0b331ddc5","datatype_tags":["!preprocessed"],"optional":false,"multi":false,"advanced":false,"_id":"5c61c84f14027a01b14adcb8"},{"id":"freesurfer","desc":"freesurfer output used to aid preprocessing","datatype":"58cb22c8e13a50849b25882e","datatype_tags":["!v5"],"optional":false,"multi":false,"advanced":false,"_id":"5c61c84f14027a01b14adcb5"},{"id":"t2w","datatype":"594c0325fa1d2e5a1f0beda5","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5c61c84f14027a01b14adcb9"},{"id":"fmap","desc":"2phasemag fieldmap is not yet supported by fmriprep (https://github.com/poldracklab/sdcflows/issues/15) - should be supported by now","datatype":"5c390505f9109beac42b00df","datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5c61c84f14027a01b14adcb6"}],"outputs":[{"id":"bold_img","datatype":"59b685a08e5d38b0b331ddc5","datatype_tags":["preprocessed"],"datatype_tags_pass":"fmri","output_on_root":false,"files":null,"archive":true,"_id":"5c719f4b3e2f2c0030a2347a"},{"id":"bold_mask","desc":"There is no such datatype tag for mask as \"bold\". It will be removed in favor of \"func\"","datatype":"5a281aee2c214c9ba83ce620","datatype_tags":["brain","bold","func"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5c719f4b3e2f2c0030a23479"},{"id":"regress","datatype":"5c4f6a8af9109beac4b3dae0","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5c719f4b3e2f2c0030a23478"},{"id":"anat","desc":"preprocessed t1 (same alignment as the original t1, but level adjusted - editme)","datatype":"58c33bcee13a50849b25879a","datatype_tags":["preprocessed"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5c7378b7badd19003102e900"},{"id":"anat_mask","datatype":"5a281aee2c214c9ba83ce620","datatype_tags":["anat","brain"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5c7378b7badd19003102e8ff"},{"id":"output_report","desc":"fmriprep HTML report and figures","datatype":"5e56dc330f7fa604cc3cc291","datatype_tags":["fmriprep"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5dfa753032bff09a13e2548c"},{"id":"transform","datatype":"62618e2afdf0b815e4ba5372","datatype_tags":[],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"626b0b0df3858674a2a58433"},{"id":"parcellation","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags":["freesurfer"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"626b0b0df3858674a2a58434"}],"stats":{"success_rate":42.98855406104501,"groups":328,"users":171,"runtime_mean":5253069.78,"runtime_std":2950132.944432693,"requested":74305,"gitinfo":{"desc":"runs fmriprep for brainlife","tags":["brain","fmri","mri","preprocessing"],"stats":{"stars":1},"contributors":[{"name":"Josh Faskowitz","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null}]},"resources":[],"examples":0},"removed":false,"__v":4,"create_date":"2022-10-11T15:04:36.508Z","doi":"10.25663/brainlife.app.682","_canedit":true},{"_id":"5e8b5ae6952fefe5407b097e","stats":{"success_rate":78.48101265822784,"users":4,"runtime_mean":783905.6935483871,"runtime_std":2803960.445063879,"requested":86,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a393362f3d3800f120f01"}],"examples":1,"groups":11},"projects":[],"admins":["126"],"tags":[],"removed":false,"config":{"track1":{"type":"input","file_id":"track","input_id":"track1"},"track2":{"type":"input","file_id":"track","input_id":"track2"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e8b5ae6952fef95327b097f","id":"track1","datatype":"5907d922436ee50ffde9c549"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e8b5ae6952fef1f647b0980","id":"track2","datatype":"5907d922436ee50ffde9c549"}],"outputs":[{"datatype_tags":["merged"],"output_on_root":false,"archive":true,"_id":"5e8b5ae6952fefa7857b0981","id":"track","datatype":"5907d922436ee50ffde9c549","datatype_tags_pass":null,"files":null}],"github_branch":"master","github":"svincibo/app-mergeTCK","name":"merge2TCKs","desc_override":"This is copy of the mergeTCK BL app (https://doi.org/10.25663/brainlife.app.219) modified to take two tractograms as input. This is a temporary workaround for the lack of functionality for multi-input datatypes in brainlife Pipelines.","user_id":"16","contributors":[{"name":"Sophia Vinci-Booher","email":null,"_id":"634a393462f3d3800f120f02"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a393462f3d3800f120f03"},{"name":"Brad Caron","email":null,"_id":"634a393462f3d3800f120f04"},{"name":"Franco Pestilli","email":null,"_id":"634a393462f3d3800f120f05"}],"create_date":"2020-04-06T16:37:58.862Z","desc":"Merge multiple TCK files into one TCK file.","doi":"10.25663/brainlife.app.304","__v":5189,"avatar":"https://upload.wikimedia.org/wikipedia/en/0/08/DTI_Brain_Tractogram_lateral_view.jpg","_canedit":true},{"_id":"5e419e50301ffc2c9833fe09","stats":{"stars":0,"serviceinfo":{"_id":"5e41f34b1a2e69792a64a0b2","counts":{"_id":"5e5c3e3987cac76deeab1452","failed":5,"finished":2,"removed":0,"requested":7,"running":7,"running_sync":0,"stop_requested":0},"success_rate":28.57142857142857,"users":2,"readme_status":"ok","runtime_mean":22220,"runtime_std":301,"service":"svincibo/app-mergeDWI","__v":0},"success_rate":68.75,"users":6,"runtime_mean":568107,"runtime_std":739341.6342294615,"requested":22,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a383862f3d3800f11ee2c"}],"examples":0,"groups":5},"projects":[],"admins":["126"],"tags":[],"removed":false,"config":{"dwis":{"type":"input","file_id":"dwi","input_id":"dwi"},"bvecs":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bvals":{"type":"input","file_id":"bvals","input_id":"dwi"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":true,"advanced":false,"_id":"5e419e50301ffc10e133fe0a","id":"dwi","datatype":"58c33c5fe13a50849b25879b"}],"outputs":[{"datatype_tags":["merged"],"output_on_root":false,"archive":true,"_id":"5e419e50301ffc187a33fe0b","id":"output","datatype":"58c33c5fe13a50849b25879b","datatype_tags_pass":null,"files":null}],"github":"svincibo/app-mergeDWI","name":"mergeDWI","avatar":"https://prod-images-static.radiopaedia.org/images/19321622/9c1bc243387781a19966723f185e1b.png","user_id":"126","contributors":[{"name":"Sophia Vinci-Booher","email":null,"_id":"634a383862f3d3800f11ee2d"}],"create_date":"2020-02-10T18:17:52.275Z","desc":"Concatenates one or more diffusion images.","doi":"10.25663/brainlife.app.275","__v":4001,"_canedit":true},{"_id":"5e94f84e509219bc56f0e1ea","stats":{"success_rate":97.32620320855615,"users":3,"runtime_mean":1369309.26,"runtime_std":4204635.105033748,"requested":881,"resources":[],"examples":1,"groups":4},"projects":[],"admins":["126"],"tags":[],"removed":false,"config":{"rois":{"type":"input","file_id":"rois","input_id":"roi"},"roi1_name":{"id":"roi1_name","type":"string","placeholder":"Enter the name of the .nii.gz file (e.g., ROI0012, ca23) contained in the ROI.","advanced":false,"desc":"If this field is left empty, the all rois within the ROI dataset will be merged.","default":"","_order":2,"pid":0.35275245475296413,"optional":true},"roi2_name":{"id":"roi2_name","type":"string","placeholder":"Enter the name of the .nii.gz file (e.g., ROI0012, ca23) contained in the ROI.","advanced":false,"desc":"If this field is left empty, the all rois within the ROI dataset will be merged.","default":"","_order":3,"pid":0.18870244694253002,"optional":true},"roiout_name":{"id":"roiout_name","type":"string","placeholder":"Enter the name desired for the merged ROI.","advanced":false,"desc":"","default":"","_order":4,"pid":0.8521005735388483}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e94f84e50921947c5f0e1eb","id":"roi","datatype":"5be9ea0315a8683a39a1ebd9"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5e94f84e5092195dbaf0e1ec","id":"output","datatype":"5be9ea0315a8683a39a1ebd9","datatype_tags_pass":null,"files":null}],"github":"svincibo/app-mergeROI","name":"mergeROI","avatar":"https://upload.wikimedia.org/wikipedia/commons/7/7a/Diamond-crystal-structure.jpg","user_id":"126","contributors":[{"name":"Sophia Vinci-Booher","email":null,"_id":"634a39a562f3d3800f122b69"}],"create_date":"2020-04-13T23:39:58.835Z","desc":null,"doi":"10.25663/brainlife.app.314","__v":4054,"desc_override":"This app will merge two rois within an ROI datatype dataset into one ROI. The user must specify which two rois should be merged. The app will output one roi that contains all of the voxels that were in the two original rois.","_canedit":true},{"_id":"5d5c2a214cfacf00366c0fd0","stats":{"stars":0,"serviceinfo":{"_id":"5d729e1e78356a109788b1d5","counts":{"_id":"5e5c3e0e87cac716c2ab1425","failed":7,"finished":21,"removed":18,"requested":31,"running":31,"running_sync":0,"stop_requested":3},"success_rate":75,"users":3,"readme_status":"ok","runtime_mean":204854.38095238095,"runtime_std":76518.54276577497,"service":"svincibo/app-mergeTCK","__v":0},"gitinfo":{"desc":"Merge multiple TCK files into one TCK file.","tags":[],"stats":{"stars":0},"contributors":[{"name":"Sophia Vinci-Booher","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Brad Caron","email":null},{"name":"Franco Pestilli","email":null}]},"success_rate":78.48101265822784,"users":4,"runtime_mean":783905.6935483871,"runtime_std":2803960.445063879,"requested":86,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a36d162f3d3800f11d0bc"}],"examples":0,"groups":11},"projects":[],"admins":["126"],"tags":[],"removed":false,"config":{"tcks":{"type":"input","file_id":"track","input_id":"track"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":true,"advanced":false,"_id":"5d5c2a214cfacf00366c0fd1","id":"track","datatype":"5907d922436ee50ffde9c549","desc":"TCK files to merge."}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5d5c2a214cfacf00366c0fd2","id":"output","datatype":"5907d922436ee50ffde9c549","datatype_tags_pass":"track","files":null,"desc":"Merged TCK."}],"github_branch":"master","github":"svincibo/app-mergeTCK","name":"mergeTCK","avatar":"https://upload.wikimedia.org/wikipedia/commons/c/cd/The_Human_Connectome.png","user_id":"126","contributors":[{"name":"Sophia Vinci-Booher","email":null,"_id":"634a36d262f3d3800f11d0bd"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a36d262f3d3800f11d0be"},{"name":"Brad Caron","email":null,"_id":"634a36d262f3d3800f11d0bf"},{"name":"Franco Pestilli","email":null,"_id":"634a36d262f3d3800f11d0c0"}],"create_date":"2019-08-20T17:13:05.780Z","desc":"Merge multiple TCK files into one TCK file.","doi":"10.25663/brainlife.app.219","__v":7278,"_canedit":true},{"_id":"5eee4834d39ceb0c28a114a0","stats":{"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a3c2162f3d3800f127c48"}],"success_rate":92.85714285714286,"users":8,"runtime_mean":2291220.4725274723,"runtime_std":2904397.8716536458,"requested":122,"examples":1,"groups":13},"projects":[],"admins":["239"],"tags":["alignment"],"removed":false,"config":{"image1":{"type":"input","file_id":"t1","input_id":"image1"},"image2":{"type":"input","file_id":"t1","input_id":"image2"},"skulls":{"id":"skulls","type":"boolean","placeholder":"","advanced":false,"desc":"do skull struc","default":true,"_order":2,"pid":0.9757728658959102}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5eee4834d39ceb9613a114a1","id":"image1","datatype":"58c33bcee13a50849b25879a"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5eee4834d39ceb8fc5a114a2","id":"image2","datatype":"58c33bcee13a50849b25879a"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5eee4834d39ceb04c4a114a3","id":"output_avg","datatype":"58c33bcee13a50849b25879a","datatype_tags_pass":null,"files":null,"desc":"average of inputs, reslices to resolution of image1"}],"github_branch":"master","github":"brainlife/app-align-n-average-images","name":"midway align and average T1w","user_id":"239","contributors":[{"name":"Josh Faskowitz","email":null,"_id":"634a3c2262f3d3800f127c49"},{"name":"Franco Pestilli","email":null,"_id":"634a3c2262f3d3800f127c4a"}],"create_date":"2020-06-20T17:32:36.870Z","desc":"align one image to another, and then average","doi":"10.25663/brainlife.app.385","__v":4582,"avatar":"https://upload.wikimedia.org/wikipedia/commons/thumb/e/ee/Yin_Yang_rotated.svg/240px-Yin_Yang_rotated.svg.png","_canedit":true},{"_id":"5e9dced9f1745d6994f692c0","projects":[],"admins":["19","41"],"tags":["tracking","tractography"],"removed":false,"name":"mrtrix3 - WMC Anatomically Constrained Tractography (ACT)","desc":"Runs mrtrix3 ACT (Anatomically Constrained Tractography) using either single- or multi-shell diffusion-weighted MRI data. ","github":"brainlife/app-mrtrix3-act","github_branch":"1.4","config":{"bvec":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bval":{"type":"input","file_id":"bvals","input_id":"dwi"},"diff":{"type":"input","file_id":"dwi","input_id":"dwi"},"anat":{"type":"input","file_id":"t1","input_id":"anat"},"min_length":{"default":"25","desc":"the minimum length a streamline may be","placeholder":"","type":"string","id":"min_length","pid":0.021047599732092026,"_order":4},"max_length":{"default":"220","desc":"the maximum length a streamline may be","placeholder":"","type":"string","id":"max_length","pid":0.12079515576295141,"_order":5},"imaxs":{"default":" ","desc":"This will find the maximum possible lmax within the data and use that.","placeholder":"","type":"string","id":"imaxs","pid":0.11100042234015106,"_order":6,"readonly":true,"advanced":true},"ens_lmax":{"default":false,"desc":"perform ensemble tracking on every lmax up to the maximum value passed","placeholder":"","type":"boolean","id":"ens_lmax","pid":0.008545160626320047,"_order":7,"readonly":true,"advanced":true},"curvs":{"default":"35","desc":"the maximum curvature angle streamline can take during tracking","placeholder":"","type":"string","id":"curvs","pid":0.9401844660558323,"_order":8},"num_fibers":{"default":"1500000","desc":"the number of streamlines to produce","placeholder":"","type":"string","id":"num_fibers","pid":0.482430164293161,"_order":9},"do_prb2":{"default":true,"desc":"perform mrtrix3 probabilistic tractography","placeholder":"","type":"boolean","id":"do_prb2","pid":0.9223418716314564,"_order":15,"readonly":true},"premask":{"id":"premask","type":"boolean","placeholder":"","advanced":true,"desc":"If the input anatomical T1s have already been skull stripped, check this to prevent 5ttgen from cutting off a portion of the brain.  (This sets -premasked option for 5ttgens)","default":false,"_order":17,"pid":0.10673720240715445},"norm":{"id":"norm","type":"boolean","placeholder":"","advanced":true,"desc":"unused and unmodified intensity normalization","default":false,"_order":20,"pid":0.46938664437854105,"readonly":true},"tensor_fit":{"id":"tensor_fit","type":"string","placeholder":"","advanced":true,"desc":"","default":"","_order":21,"pid":0.5525392210285849,"optional":true}},"user_id":"19","outputs":[{"datatype_tags":[],"output_on_root":true,"archive":true,"_id":"5aac2437f0b5260027e24ae3","id":"tracking","datatype":"5907d922436ee50ffde9c549","files":null},{"datatype_tags":[],"output_on_root":true,"archive":true,"_id":"5aac2437f0b5260027e24ae2","id":"tensor","datatype":"5a79df48d071a1753f1d661b","files":{"tensors":"tensor.nii.gz"}},{"datatype_tags":[],"output_on_root":true,"archive":true,"_id":"5c536e10405b850032979e46","id":"csd","datatype":"5c536bf0f9109beac46adb45","datatype_tags_pass":null,"files":null}],"inputs":[{"datatype_tags":["preprocessed"],"optional":false,"multi":false,"advanced":false,"_id":"5aac2437f0b5260027e24ae5","id":"dwi","datatype":"58c33c5fe13a50849b25879b"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5aac2437f0b5260027e24ae4","id":"anat","datatype":"58c33bcee13a50849b25879a"}],"contributors":[{"name":"Brent McPherson","email":"bcmcpher@gmail.com","_id":"634a39d662f3d3800f12313c"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a39d662f3d3800f12313d"},{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a39d662f3d3800f12313e"},{"name":"Franco Pestilli","email":null,"_id":"634a39d662f3d3800f12313f"},{"name":"Brad Caron","email":null,"_id":"634a39d662f3d3800f123140"},{"name":"Anibal Sólon","email":"anibalsolon@gmail.com","_id":"634a39d662f3d3800f123141"}],"__v":5074,"stats":{"requested":16087,"users":51,"success_rate":48.09201623815967,"gitinfo":{"desc":"Runs mrtrix3 ACT (Anatomically Constrained Tractography) using either single- or multi-shell diffusion-weighted MRI data. ","tags":["tracking","tractography"],"stats":{"stars":0},"contributors":[{"name":"Brent McPherson","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":23600497.98,"runtime_std":25578287.666498195,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a39d562f3d3800f12313a"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a39d562f3d3800f12313b"}],"examples":4,"groups":103},"create_date":"2020-04-20T16:33:29.381Z","doi":"10.25663/brainlife.app.319","desc_override":"This is a clone of \"mrtrix3 - Anatomically Constrained Tractography (ACT)\" App (https://brainlife.io/app/5aac2437f0b5260027e24ae1) but with optimal configuration set to run ACT on white-matter tracts.  ","_canedit":true},{"_id":"5a813e52dc4031003b8b36f9","name":"mrtrix3 preprocess","desc":"Run the recommended preprocessing procedure provided by mrtrix3. The options available mostly reflect the optimal DESIGNER pipeline that was recently proposed. This App runs for >15 on topup if both PA and AP dwi files are provided. It detects bvecs flipping (dwigradcheck) and update the gradient table accordingly.","citation":null,"github":"brainlife/app-mrtrix3-preproc","github_branch":"1.7","config":{"anat":{"type":"input","file_id":"t1","input_id":"anat"},"bvec":{"type":"input","file_id":"bvecs","input_id":"dwi"},"bval":{"type":"input","file_id":"bvals","input_id":"dwi"},"diff":{"type":"input","file_id":"dwi","input_id":"dwi"},"rbvc":{"type":"input","file_id":"bvecs","input_id":"reverse"},"rbvl":{"type":"input","file_id":"bvals","input_id":"reverse"},"rdif":{"type":"input","file_id":"dwi","input_id":"reverse"},"acqd":{"type":"enum","placeholder":"","desc":"provide the encoding direction used for the dwi data for the preprocessing steps below","default":"AP","options":[{"desc":"","label":"Posterior -> Anterior (+y)","value":"PA"},{"desc":"","label":"Right -> Left (+x)","value":"RL"},{"desc":"","label":"Inferior -> Superior (+z)","value":"IS"},{"desc":"","label":" anterior -> posterior (-y)","value":"AP"},{"desc":"","label":"Left > Right (-x)","value":"LR"},{"desc":"","label":"Inferior -> Superior (-z)","value":"SI"}],"id":"acqd","pid":0.9694794588492783,"_order":3},"dwigradcheck":{"id":"dwigradcheck","type":"boolean","placeholder":"","advanced":true,"desc":"Check dwi gradient orientation. The default value is 'true', but sometimes with low data quality or low voxel resolution, this process may fail. If that's the case, you may want to set this value as 'false'.","default":true,"_order":4,"pid":0.07855266601736344},"denoise":{"type":"boolean","placeholder":"","desc":"Perform PCA denoising on the input data","default":true,"id":"denoise","pid":0.6893191767240401,"_order":5},"degibbs":{"type":"boolean","placeholder":"","desc":"Perform correction on Gibbs ringing artifact","default":true,"id":"degibbs","pid":0.034230551057084835,"_order":6},"eddy":{"type":"boolean","placeholder":"","desc":"Perform motion and eddy current correction with FSL","default":true,"id":"eddy","pid":0.5198637534085417,"_order":7},"bias":{"type":"boolean","placeholder":"","desc":"Perform bias correction with ANTs N4","default":true,"id":"bias","pid":0.2562385556775584,"_order":8},"ricn":{"id":"ricn","type":"boolean","placeholder":"","desc":"Remove Rician background noise","default":true,"_order":9,"pid":0.9948308738536138},"norm":{"type":"boolean","placeholder":"","desc":"Perform mode value intensity normalization in white matter","default":false,"id":"norm","pid":0.6915437049405591,"_order":10},"nval":{"type":"number","placeholder":"","desc":"The value to which the mode value intensity normalization will normalize the white matter intensity.\n","default":1000,"min":100,"max":50000,"id":"nval","pid":0.632769218808223,"_order":11},"acpc":{"type":"boolean","placeholder":"","desc":"Align dwi data and gradients to anatomical (t1w) input using BBR in FSL","default":true,"id":"acpc","pid":0.12238944304551702,"_order":12},"reslice":{"type":"string","placeholder":"leave empty to use the native diffusion resolution","desc":"The final isotropic voxel dimension in mm of the processed dwi data","default":"","optional":true,"id":"reslice","pid":0.6627404796904608,"_order":13},"eddy_data_is_shelled":{"id":"eddy_data_is_shelled","type":"boolean","placeholder":"","advanced":true,"desc":"Do not check that data is shelled","default":true,"_order":14,"pid":0.8942236090483373},"eddy_slm":{"id":"eddy_slm","type":"enum","placeholder":"","advanced":true,"desc":"\"Second level model\" that specifies the mathematical form for how the diffusion gradients cause eddy currents. For high quality data with 60 directions, or more, sampled on the whole sphere we have not found any advantage of performing second level modelling. Hence our recommendation for such data is to use none, and that is also the default.\n\nIf the data has quite few directions and/or is has not been sampled on the whole sphere it can be advantageous to specify --slm=linear.","default":"linear","_order":15,"pid":0.8498140074366718,"options":[{"desc":"default for eddy","label":"none","value":"none"},{"desc":"default for BL","label":"linear","value":"linear"},{"desc":"","label":"quadratic","value":"quadratic"}]},"eddy_niter":{"id":"eddy_niter","type":"number","placeholder":"","advanced":true,"desc":"eddy does not check for convergence. Instead it runs a fixed number of iterations given by --niter. This is not unusual for registration algorithms where each iteration is expensive (i.e. takes long time). Instead we run it for a fixed number of iterations, 5 as default.\n\nIf, on visual inspection, one finds residual movement or EC-induced distortions it is possible that eddy has not fully converged. In that case we primarily recommend that one uses --fwhm=10,0,0,0,0, as described above, to speed up convergence. Only if that fails do we recommend increasing the number of iterations.","default":5,"_order":16,"pid":0.2760649303865106,"min":0,"max":10},"eddy_repol":{"id":"eddy_repol","type":"boolean","placeholder":"","advanced":true,"desc":"Remove any slices deemed as outliers and replace them with predictions made by the Gaussian Process. Exactly what constitutes an outlier is affected by the parameters --ol_nstd, --ol_nvox, --ol_type, --ol_pos and --ol_sqr. If the defaults are used for all those parameters an outlier is defined as a slice whose average intensity is at least four standard deviations lower than the expected intensity, where the expectation is given by the Gaussian Process prediction.  The default is to not do outlier replacement since we don't want to risk people using it \"unawares\". However, our experience and tests indicate that it is always a good idea to use --repol.","default":true,"_order":17,"pid":0.00937643754469586,"readonly":false},"eddy_mporder":{"id":"eddy_mporder","type":"number","placeholder":"","advanced":true,"desc":"If one wants to do slice-to-vol motion correction --mporder should be set to an integer value greater than 0 and less than the number of excitations in a volume. (The timing of acquisition of each slice must be known in order to perform slice-to-volume correction. This is provided to eddy via eddy_slspec option). Only when --mporder > 0 will any of the parameters prefixed by --s2v_ be considered. The larger the value of --mporder, the more degrees of freedom for modelling movement. If --mporder is set to N-1, where N is the number of excitations in a volume, the location of each slice/MB-group is individually estimated. We don't recommend going that high and in our tests we have used values of N/4 -- N/2. The underlying temporal model of movement is a DCT basis-set of order N.\n\nSlice-to-vol motion correction is computationally very expensive so it is only implemented for the CUDA version.","default":0,"_order":18,"pid":0.4801766611456848,"min":0,"max":10,"optional":false},"eddy_slspec":{"id":"eddy_slspec","type":"string","placeholder":"(leave it empty to not set)","advanced":true,"desc":"Specifies a text-file that describes how the slices/MB-groups were acquired. This information is necessary for eddy to know how a temporally continuous movement translates into location of individual slices/MB-groups. Let us say a given acquisition has N slices and that m is the MB-factor (also known as Simultaneous Multi-Slice (SMS)). Then the file pointed to be --slspec will have N/m rows and m columns. Let us for example assume that we have a data-set which has been acquired with an MB-factor of 3, 15 slices and interleaved slice order. The file would then be\n\n0 5 10\n2 7 12\n4 9 14\n1 6 11\n3 8 13\nwhere the first row \"0 5 10\" specifies that the first, sixth and 11th slice are acquired first and together, followed by the third, eighth and 13th slice etc. For single-band data and for multi-band data with an odd number of excitations/MB-groups it is trivial to work out the --slspec file using the logic of the example. For an even number of excitations/MB-groups it is considerably more difficult and we recommend using a DICOM->niftii converter that writes the exact slice timings into a .JSON file. This can then be used to create the --slspec file.","default":"","_order":19,"pid":0.4799573432335742,"multiline":true,"optional":true},"dilate_mask":{"id":"dilate_mask","type":"boolean","placeholder":"","advanced":true,"desc":"Apply dilate maskfilter on b0 whole brain mask","default":false,"_order":20,"pid":0.7077067741754695},"round_bvals":{"id":"round_bvals","type":"boolean","placeholder":"","advanced":false,"desc":"If you are seeing this error message \"dwipreproc: [ERROR] Unable to determine matching reversed phase-encode direction volume for DWI volume 1\". You might be able to work around it by rounding your bvals to the nearest 50s. ","default":false,"_order":21,"pid":0.263599341985139},"topup_lambda":{"id":"topup_lambda","type":"string","placeholder":"","advanced":true,"desc":"Replace lambda value in topup","default":"0.005,0.001,0.0001,0.000015,0.000005,0.0000005,0.00000005,0.0000000005,0.00000000001","_order":22,"pid":0.06024884862465796},"bias_method":{"id":"bias_method","type":"enum","placeholder":"","advanced":false,"desc":"Select bias correction algorithm.","default":"ants","_order":23,"pid":0.6847963199718459,"options":[{"desc":"use ANTs N4 algorithm","label":"ANTs","value":"ants"},{"desc":"use FSL FAST algorithm","label":"FSL","value":"fsl"}]},"antsb":{"id":"antsb","type":"string","placeholder":"","advanced":true,"desc":"Advanced option for ANTs N4 bias field removal.","default":"[150,3]","_order":24,"pid":0.3472579684003987},"antsc":{"id":"antsc","type":"string","placeholder":"","advanced":true,"desc":"Advanced option for ANTs N4 bias field removal.","default":"[200x200,1e-6]","_order":25,"pid":0.6653631171182985},"antss":{"id":"antss","type":"string","placeholder":"","advanced":true,"desc":"Advanced option for ANTs N4 bias field removal.","default":"2","_order":26,"pid":0.421766829342751}},"desc_override":"","user_id":"19","create_date":"2018-02-12T07:12:18.285Z","removed":false,"_rate":0,"outputs":[{"id":"output","datatype":"58c33c5fe13a50849b25879b","datatype_tags":["preprocessed"],"datatype_tags_pass":"dwi","output_on_root":false,"files":null,"archive":true,"_id":"5b9fee5001381a0028908855"},{"id":"eddyqc","desc":"QC output from eddy. Please see quad/qc.pdf file for summary","datatype":"59c3eae633fc1cf9ead71679","datatype_tags":["eddyqc"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"609315aa8fe49f1cf51d6171"}],"inputs":[{"id":"anat","desc":"the t1w image to align the input dwi image","datatype":"58c33bcee13a50849b25879a","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5a813e52dc4031003b8b36fb"},{"id":"dwi","desc":"The dwi image to preprocess","datatype":"58c33c5fe13a50849b25879b","datatype_tags":["!preprocessed"],"optional":false,"multi":false,"advanced":false,"_id":"5a813e52dc4031003b8b36fa"},{"id":"reverse","desc":"optional reverse encoding data set","datatype":"58c33c5fe13a50849b25879b","datatype_tags":["!preprocessed"],"optional":true,"multi":false,"advanced":false,"_id":"5b24253416fe38002748e6bf"}],"contributors":[{"name":"Brent McPherson","email":"bcmcpher@gmail.com","_id":"634a322062f3d3800f116fd8"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a322062f3d3800f116fd9"},{"name":"Franco Pestilli","email":null,"_id":"634a322062f3d3800f116fda"},{"name":"Giulia Bertò","email":null,"_id":"634a322062f3d3800f116fdb"},{"name":null,"email":null,"_id":"634a322062f3d3800f116fdc"}],"tags":["diffusion-mri","mri","tractography"],"references":[],"admins":["19","146","16"],"projects":[],"__v":14280,"stats":{"stars":0,"requested":51525,"users":71,"success_rate":68.01558276355541,"serviceinfo":{"_id":"5d729e1f78356a109788b367","counts":{"_id":"5e5c689e87cac7908eab1bc9","failed":2233,"finished":8226,"removed":10647,"requested":11756,"running":10569,"running_sync":0,"stop_requested":289},"success_rate":78.6499665359977,"users":24,"readme_status":"too short","runtime_mean":4331679.21,"runtime_std":7086272.954949098,"service":"brain-life/app-mrtrix3-preproc","__v":0},"gitinfo":{"desc":"Run the recommended preprocessing procedure provided by mrtrix3. The options available mostly reflect the optimal DESIGNER pipeline that was recently proposed. This App runs for >15 on topup if both PA and AP dwi files are provided.","tags":["diffusion-mri","mri","tractography"],"stats":{"stars":0},"contributors":[{"name":"Brent McPherson","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":4501773.96,"runtime_std":9974788.645408604,"resources":[{"resource_id":"5e309300e017b06c99948e0a","name":"stampede2(knl) @ TACC/UT","_id":"634a321f62f3d3800f116fd5"},{"resource_id":"5ffc99da0df8ff7fc740c95a","name":"Bridges2 @ PSC (GPU-Shared)","_id":"634a321f62f3d3800f116fd6"},{"resource_id":"6022ea9f8b3974517723692e","name":"Bridges2 @ PSC (RM-Shared)","_id":"634a321f62f3d3800f116fd7"}],"examples":5,"groups":190},"doi":"10.25663/bl.app.68","_canedit":true},{"_id":"5d14bc062daec10035f3f86e","stats":{"stars":0,"requested":609,"users":1,"success_rate":79.14110429447852,"serviceinfo":{"_id":"5d729e1e78356a109788b22f","counts":{"_id":"5e5c3e0787cac79650ab141e","failed":99,"finished":384,"removed":462,"requested":594,"running":499,"running_sync":0,"stop_requested":55},"success_rate":79.5031055900621,"users":1,"readme_status":"too short","runtime_mean":11729742.59,"runtime_std":6514231.5668496685,"service":"giulia-berto/app-multi-lap","__v":0},"gitinfo":{"desc":"White matter bundle segmentation as multiple Linear Assignment Problems (multi-LAP).","tags":[],"stats":{"stars":0},"contributors":[{"name":"Giulia Bertò","email":null}]},"runtime_mean":12036686.96,"runtime_std":8066802.534735993,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a369b62f3d3800f11cfa7"}],"examples":1,"groups":3},"projects":[],"admins":["146"],"tags":["segmentation","white-matter-segmentation"],"removed":false,"config":{"tractogram_static":{"type":"input","file_id":"track","input_id":"0"},"t1_static":{"type":"input","file_id":"t1","input_id":"1"},"segmentations":{"type":"input","file_id":"classification","input_id":"2"},"tracts":{"type":"input","file_id":"tracts","input_id":"2"},"tractograms_moving":{"type":"input","file_id":"track","input_id":"3"},"t1s_moving":{"type":"input","file_id":"t1","input_id":"4"},"k":{"id":"k","type":"number","placeholder":"","desc":"value for k-NN to compute the superset","default":2000,"_order":3,"pid":0.6782222787710248},"step_size":{"id":"step_size","type":"number","placeholder":"","desc":"step size for resampling","default":0.625,"_order":4,"pid":0.36304839909980124},"slr":{"id":"slr","type":"boolean","placeholder":"","desc":"If false, assuming subjects already co-registered in the same space","default":true,"_order":6,"pid":0.7270101660149844},"tractID_list":{"id":"tractID_list","type":"string","placeholder":"allowed values: 1-20 (if AFQ examples provided), 1-78 (if WMA examples provided)","desc":"ID list of the bundles of interest, separated by commas","default":"","_order":7,"pid":0.06139623064190003}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5d14bc062daec10035f3f873","id":"0","datatype":"5907d922436ee50ffde9c549","desc":"Tractogram of static (target) subject"},{"datatype_tags":["acpc_aligned"],"optional":false,"multi":false,"advanced":false,"_id":"5d14bc062daec10035f3f872","id":"1","datatype":"58c33bcee13a50849b25879a","desc":"T1 of static (target) subject"},{"datatype_tags":[],"optional":false,"multi":true,"advanced":false,"_id":"5d14bc062daec10035f3f871","id":"2","datatype":"5cc1d64c44947d8aea6b2d8b","desc":"Segmentations of moving (examples) subjects (they should be extracted from the tractogram provided)"},{"datatype_tags":[],"optional":false,"multi":true,"advanced":false,"_id":"5d14bc062daec10035f3f870","id":"3","datatype":"5907d922436ee50ffde9c549","desc":"Tractograms of moving (example) subjects"},{"datatype_tags":["acpc_aligned"],"optional":false,"multi":true,"advanced":false,"_id":"5d14bc062daec10035f3f86f","id":"4","datatype":"58c33bcee13a50849b25879a","desc":"Ts1 of moving (example) subjects"}],"outputs":[{"datatype_tags":["multi-LAP"],"output_on_root":false,"archive":true,"_id":"5d14bc062daec10035f3f874","id":"output_wmc","datatype":"5cc1d64c44947d8aea6b2d8b","datatype_tags_pass":"2","files":null}],"github_branch":"3.1","github":"giulia-berto/app-multi-lap","name":"multi-LAP","user_id":"146","contributors":[{"name":"Giulia Bertò","email":null,"_id":"634a369b62f3d3800f11cfa8"}],"create_date":"2019-06-27T12:52:22.265Z","desc":"White matter bundle segmentation as multiple Linear Assignment Problems (multi-LAP).","doi":"10.25663/brainlife.app.209","__v":7688,"avatar":"https://github.com/giulia-berto/app-multi-lap/blob/master/lap-avatar.png?raw=true","_canedit":true},{"_id":"5c9619c665ade200e89d60c5","stats":{"stars":0,"requested":609,"users":1,"success_rate":79.14110429447852,"serviceinfo":{"_id":"5d729e1e78356a109788b22f","counts":{"_id":"5e5c3ded87cac790ddab13ff","failed":99,"finished":384,"removed":462,"requested":594,"running":499,"running_sync":0,"stop_requested":55},"success_rate":79.5031055900621,"users":1,"readme_status":"too short","runtime_mean":11729742.59,"runtime_std":6514231.5668496685,"service":"giulia-berto/app-multi-lap","__v":0},"gitinfo":{"desc":"White matter bundle segmentation as multiple Linear Assignment Problems (multi-LAP).","tags":[],"stats":{"stars":0},"contributors":[{"name":"Giulia Bertò","email":null}]},"runtime_mean":12036686.96,"runtime_std":8066802.534735993,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a357462f3d3800f11a1ff"}],"examples":0,"groups":3},"projects":[],"admins":["146"],"tags":["segmentation","white-matter-segmentation"],"removed":false,"config":{"tractogram_static":{"type":"input","file_id":"track","input_id":"0"},"t1_static":{"type":"input","file_id":"t1","input_id":"1"},"segmentations":{"type":"input","file_id":"output","input_id":"2"},"tractograms_moving":{"type":"input","file_id":"track","input_id":"3"},"t1s_moving":{"type":"input","file_id":"t1","input_id":"4"},"true_segmentation":{"type":"input","file_id":"output","input_id":"5"},"k":{"id":"k","type":"number","placeholder":"","desc":"value for k-NN to compute the superset","default":2000,"_order":2,"pid":0.07410887799414279},"step_size":{"id":"step_size","type":"number","placeholder":"","desc":"step size for resampling","default":0.625,"_order":3,"pid":0.17603759960216103},"tract1":{"id":"tract1","type":"number","placeholder":"","desc":"ID of the bundle of interest","default":null,"_order":4,"pid":0.6004442751266819,"optional":true}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c9619c665ade200e89d60ca","id":"0","datatype":"5907d922436ee50ffde9c549","desc":"Tractogram of static (target) subject"},{"datatype_tags":["acpc_aligned"],"optional":false,"multi":false,"advanced":false,"_id":"5c9619c665ade200e89d60c9","id":"1","datatype":"58c33bcee13a50849b25879a","desc":"T1 of static (target) subject"},{"datatype_tags":[],"optional":false,"multi":true,"advanced":false,"_id":"5c9619c665ade200e89d60c8","id":"2","datatype":"58f10a90436ee50ffd9063c5","desc":"Segmentations of moving (examples) subjects (they should be extracted from the tractogram provided)"},{"datatype_tags":[],"optional":false,"multi":true,"advanced":false,"_id":"5c9619c665ade200e89d60c7","id":"3","datatype":"5907d922436ee50ffde9c549","desc":"Tractograms of moving (example) subjects"},{"datatype_tags":["acpc_aligned"],"optional":false,"multi":true,"advanced":false,"_id":"5c9619c665ade200e89d60c6","id":"4","datatype":"58c33bcee13a50849b25879a","desc":"Ts1 of moving (example) subjects"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5c9658e865ade200e89d60db","id":"5","datatype":"58f10a90436ee50ffd9063c5","desc":"The ground truth (target) segmentation (used to compute the ROC curve)"}],"outputs":[{"datatype_tags":["multi-LAP"],"output_on_root":true,"archive":true,"_id":"5c963c0465ade200e89d60da","id":"6","datatype":"58f10a90436ee50ffd9063c5","datatype_tags_pass":null,"files":null,"desc":"segmented bundles with multi-LAP in wmc format"},{"datatype_tags":["ROC"],"output_on_root":false,"archive":true,"_id":"5c9a571065ade200e89d610e","id":"csv","datatype":"599f305ad1f46fec1759f363","datatype_tags_pass":null,"files":null,"desc":"ROC and AUC values for both multi-NN and multi-LAP"}],"github_branch":"1.0","github":"giulia-berto/app-multi-lap","name":"multi-LAP and multi-NN (deprecated)","user_id":"146","contributors":[{"name":"Giulia Bertò","email":null,"_id":"634a357562f3d3800f11a200"}],"create_date":"2019-03-23T11:34:30.387Z","desc":"White matter bundle segmentation as multiple Linear Assignment Problems (multi-LAP).","doi":"10.25663/brainlife.app.174","__v":8437,"deprecated_by":"5d14bc062daec10035f3f86e","desc_override":"White matter bundle segmentation as multiple Linear Assignment Problems (multi-LAP). It also performs Nearest Neighbor (NN, or multi-NN) segmentation for comparison. WARNING: This App was used specifically for a Replicability Study and has been deprecated.","_canedit":true},{"_id":"5bbd0649fcb14c00272a3876","projects":["5a74ccd66ed91402ce400cc6"],"admins":["1"],"tags":[],"removed":false,"config":{},"inputs":[],"outputs":[],"name":"noop","github":"brainlife/app-noop","user_id":"1","references":[],"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a33f362f3d3800f118470"}],"create_date":"2018-10-09T19:49:29.436Z","desc":"Service that does nothing (exist to do inter-resource transfer)","stats":{"stars":0,"requested":254505,"users":470,"success_rate":99.83808060512942,"serviceinfo":{"_id":"5d729e1e78356a109788b227","counts":{"_id":"5e5c3dbf87cac75d2bab13d3","failed":8,"finished":25399,"removed":19922,"requested":25456,"running":0,"running_sync":25375,"stop_requested":0},"success_rate":99.96851261463377,"users":124,"readme_status":"no README.md","runtime_mean":180.57,"runtime_std":63.274205644954556,"service":"brainlife/app-noop","__v":0},"gitinfo":{"desc":"Service that does nothing (exist to do inter-resource transfer)","tags":[],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":112.35,"runtime_std":6.960423837669669,"resources":[{"resource_id":"5979f579abf0be0023d11be4","name":"brainlife upload / validator","_id":"634a33f362f3d3800f11846f"}],"examples":0,"groups":860},"doi":"10.25663/brainlife.app.110","__v":10078,"_canedit":true},{"_id":"5a70cc8142d17b00459e80dc","name":"old ensemble tracking","desc":"This App creates a large set of candidate streamlines using an ensemble of algorithms and parameter values. All outputs will be then combined into a single track.tck output.","citation":null,"github":"brainlife/app-ensembletracking","github_branch":"singularity","config":{"freesurfer":{"type":"input","file_id":"output","input_id":"0"},"dtiinit":{"type":"input","file_id":"output","input_id":"1"},"do_probabilistic":{"type":"boolean","placeholder":"","desc":"","default":true,"id":"do_probabilistic","pid":0.7445776692352206,"_order":2},"do_deterministic":{"type":"boolean","placeholder":"","desc":"","default":true,"id":"do_deterministic","pid":0.3999143234626439,"_order":3},"do_tensor":{"type":"boolean","placeholder":"","desc":"","default":true,"id":"do_tensor","pid":0.7975381709829237,"_order":4},"fibers":{"default":660000,"desc":"","placeholder":"","type":"number","readonly":false,"id":"fibers","pid":0.47218225275540515,"_order":5}},"user_id":"43","create_date":"2018-01-30T19:50:25.981Z","removed":false,"_rate":0,"outputs":[{"datatype_tags":[],"output_on_root":true,"archive":true,"_id":"5a70cc8142d17b00459e80dd","id":"0","datatype":"5907d922436ee50ffde9c549","files":null}],"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5a70cc8142d17b00459e80df","id":"0","datatype":"58cb22c8e13a50849b25882e"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5a70cc8142d17b00459e80de","id":"1","datatype":"58cb234be13a50849b25882f"}],"contributors":[{"name":"Lindsey Kitchell","email":"lindsey.kitchell@jhuapl.edu","_id":"634a320c62f3d3800f116aac"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a320c62f3d3800f116aad"},{"name":"Brent McPherson","email":"bcmcpher@gmail.com","_id":"634a320c62f3d3800f116aae"},{"name":"Franco Pestilli","email":null,"_id":"634a320c62f3d3800f116aaf"}],"tags":["tracking"],"references":[],"admins":["43","16"],"projects":[],"__v":14248,"stats":{"stars":0,"serviceinfo":{"_id":"5d729e1f78356a109788b2cf","counts":{"_id":"5e5c689c87cac74df3ab1bc7","failed":3487,"finished":8002,"removed":13974,"requested":22463,"running":16311,"running_sync":0,"stop_requested":341},"success_rate":69.64922969797198,"users":61,"readme_status":"ok","runtime_mean":6502764.34,"runtime_std":3757949.399415393,"service":"brain-life/app-ensembletracking","__v":0},"gitinfo":{"desc":"This service uses MRtrix 0.2.12 to do ensemble tracking using tensor and constrained spherical deconvolution (csd) algorithms. It generates a large set of candidate streamlines using a tensor-based deterministic model, csd-based deterministic model, and csd-based probabilistic model. The csd-based models can be computed at lmax values of 2, 4, 6, 8, 10, and 12. All candidate streamlines are combined into a single track.mat file. If you know the max lmax value for your data input the value for max_lmax, otherwise leave it blank and it will be calculated for you. If you wish to use just deterministic tracking (MRtrix streamtrack parameter SD_STREAM) check do_deterministic. If you wish to use just probabilistic tracking (MRtrix streamtrack parameter SD_PROB) check do_probabilistic If you wish to use the tensor tracking (MRtrix streamtrack parameter DT_STREAM) check do_tensor. By default it will use all three tracking methods. For more information about Ensemble Tractography see Takemura, H., Caiafa, C. F., Wandell, B. A., & Pestilli, F. (2016). Ensemble tractography. PLoS computational biology, 12(2), e1004692.","tags":["brain-connectome","diffusion-mri","mri","tracking","tractography","white-matter"],"stats":{"stars":0},"contributors":[{"name":"Lindsey Kitchell","email":null},{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Brent McPherson","email":null},{"name":"Franco Pestilli","email":null}]},"success_rate":34.61945031712473,"users":13,"runtime_mean":1206734.29,"runtime_std":2026412.4706887305,"requested":2011,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a320b62f3d3800f116aaa"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a320b62f3d3800f116aab"}],"examples":0,"groups":12},"doi":"10.25663/brainlife.app.149","deprecated_by":"592dbbccb3cd7c00211dc235","_canedit":true},{"_id":"5afc9831322997002773ed1c","doi":"10.25663/bl.app.31","stats":{"stars":0,"requested":35,"users":3,"success_rate":24.137931034482758,"serviceinfo":{"_id":"5d729e1e78356a109788b215","counts":{"_id":"5e5c3da087cac762a7ab13b1","failed":13,"finished":6,"removed":12,"requested":23,"running":19,"running_sync":0,"stop_requested":0},"success_rate":31.57894736842105,"users":2,"readme_status":"too short","service":"brainlife/app-prf","__v":0,"runtime_mean":28643087.666666668,"runtime_std":26318452.17967312},"gitinfo":{"desc":"pRF for BrainLife","tags":[],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Justin Gardner","email":null},{"name":"Steven O'Riley","email":null}]},"runtime_mean":27934812.14285714,"runtime_std":24427838.41657127,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a32cf62f3d3800f117a87"}],"examples":0,"groups":4},"name":"pRFLife mrTools","desc":"This app will compute a population receptive field (i.e. pRF) analysis on a given time series. Inputs needed include: a time series nifti, a stimulus nifti, the measurements of the visual stimulus in space (stimimageunits), and dimensions of a mask (mask; optional). Outputs include: x.nii, y.nii, rfWidth.nii and r2.nii. Please see http://gru.stanford.edu/doku.php/mrTools/tutorialsprf for more detail.","citation":null,"github":"brainlife/app-prf","github_branch":"master","config":{"bold":{"type":"input","file_id":"bold","input_id":"bold"},"stimimage":{"type":"input","file_id":"stim","input_id":"stimimage"},"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"visual_angle_width":{"id":"visual_angle_width","type":"number","placeholder":"","desc":"(in degree) full visual angle of the stimulation image. assumes central fixation. It should be 16 for HCP Retinotopy datasets.","default":16,"_order":5,"pid":0.054315584342028655},"visual_angle_height":{"id":"visual_angle_height","type":"number","placeholder":"","desc":"(in degree) full visual angle of the stimulation image. assumes central fixation. It should be 16 for HCP Retinotopy datasets.","default":16,"_order":6,"pid":0.07884692310522512},"frameperiod":{"id":"frameperiod","type":"number","placeholder":"","desc":"(in seconds) the time for each volume of the BOLD time series (typically the TR)","default":1,"_order":7,"pid":0.741860466140581},"prefitOnly":{"id":"prefitOnly","type":"boolean","placeholder":"","desc":"Only do the grid search that finds approximately good parameters for the model and will not optimize with the nonlinear search. This will speed up the program but will not produce optimized fits. Nonetheless it should be good enough for debugging.","default":false,"_order":8,"pid":0.24098558186359353}},"user_id":"16","create_date":"2018-05-16T20:44:33.056Z","removed":false,"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5afc9831322997002773ed1d","id":"prf","datatype":"5d9d18d8e30ae43bb0612715","datatype_tags_pass":null,"files":null}],"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5afc9831322997002773ed1f","id":"bold","datatype":"59b685a08e5d38b0b331ddc5"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5afc9831322997002773ed1e","id":"stimimage","datatype":"5afc7c555858d874a40c6dda"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5cc504374ed9df00317f6226","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e","desc":"Freesurfer output used to create mask for visual cortex"}],"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a32d062f3d3800f117a88"},{"name":"Justin Gardner","email":null,"_id":"634a32d062f3d3800f117a89"},{"name":"David Hunt","email":"davhunt@iu.edu","_id":"634a32d062f3d3800f117a8a"},{"name":"Steven O'Riley","email":null,"_id":"634a32d062f3d3800f117a8b"}],"tags":["vision"],"references":[],"admins":["201","1","41","16"],"projects":[],"__v":13443,"desc_override":"","avatar":"https://raw.githubusercontent.com/brainlife/app-prf/master/screen.png","_canedit":true},{"_id":"5e9613ce6365e976b7471d50","stats":{"success_rate":32.432432432432435,"users":1,"runtime_mean":85804083.08333333,"runtime_std":112690653.6729291,"requested":46,"resources":[{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a39ad62f3d3800f122b7b"}],"examples":1,"groups":1},"projects":[],"admins":["283"],"tags":[],"removed":false,"config":{"fmri":{"type":"input","file_id":"bold","input_id":"fMRI"},"events":{"type":"input","file_id":"events","input_id":"fMRI"},"events_json":{"type":"input","file_id":"events_json","input_id":"fMRI"},"sbref":{"type":"input","file_id":"sbref","input_id":"fMRI"},"sbref_json":{"type":"input","file_id":"sbref_json","input_id":"fMRI"},"physio":{"type":"input","file_id":"physio","input_id":"fMRI"},"physio_json":{"type":"input","file_id":"physio_json","input_id":"fMRI"},"stim":{"type":"input","file_id":"stim","input_id":"stim"},"output":{"type":"input","file_id":"output","input_id":"freesurfer"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"frontal":{"id":"frontal","type":"boolean","placeholder":"","advanced":false,"desc":"Include frontal cortex in mask","default":false,"_order":2,"pid":0.12218671481976551},"temporal":{"id":"temporal","type":"boolean","placeholder":"","advanced":false,"desc":"Include temporal cortex in mask","default":false,"_order":3,"pid":0.8446518016362956},"parietal":{"id":"parietal","type":"boolean","placeholder":"","advanced":false,"desc":"Include parietal cortex in mask","default":false,"_order":4,"pid":0.06423972130660216},"occipital":{"id":"occipital","type":"boolean","placeholder":"","advanced":false,"desc":"Include occipital cortex in mask","default":true,"_order":5,"pid":0.9207866359244181},"preprocess":{"id":"preprocess","type":"boolean","placeholder":"","advanced":false,"desc":"Perform slice timing and head motion correction on fMRI before running prf","default":true,"_order":6,"pid":0.2800691385244891},"TR":{"id":"TR","type":"number","placeholder":"","advanced":true,"desc":"Repetition time of fMRI (read from the nii header if unspecified)","default":"","_order":7,"pid":0.03574228275346658,"optional":true},"stimsizeX":{"id":"stimsizeX","type":"number","placeholder":"","advanced":false,"desc":"Width in degrees subtended of visual stimulus (16° for HCP)","default":16,"_order":8,"pid":0.5725488495196727},"stimsizeY":{"id":"stimsizeY","type":"number","placeholder":"","advanced":false,"desc":"Height in degrees subtended of visual stimulus (16° for HCP)","default":16,"_order":9,"pid":0.30135069348389765},"gsr":{"id":"gsr","type":"enum","placeholder":"","advanced":true,"desc":"Specifies whether global signal regression (GSR) on input fMRI should be done, conversion to % change from baseline","default":"none","_order":10,"pid":0.1517188518204915,"options":[{"desc":"no GSR","label":"none","value":"none"},{"desc":"regresses out mean signal per voxel","label":"per-voxel normalization","value":"pvn"},{"desc":"regresses out global mean","label":"grand-mean scaling","value":"gms"}]},"quickFit":{"id":"quickFit","type":"boolean","placeholder":"","advanced":false,"desc":"Only do the grid search that finds approximately good parameters for the model and will not optimize with the nonlinear search. This will speed up the program but will not produce optimized fits.","default":false,"_order":11,"pid":0.9489314077059461}},"inputs":[{"datatype_tags":[],"optional":false,"multi":true,"advanced":false,"_id":"5e9613ce6365e975c1471d51","id":"fMRI","datatype":"59b685a08e5d38b0b331ddc5"},{"datatype_tags":[],"optional":false,"multi":true,"advanced":false,"_id":"5e9613ce6365e9ab1e471d52","id":"stim","datatype":"5afc7c555858d874a40c6dda"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5e9613ce6365e94029471d53","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e"},{"datatype_tags":[],"optional":true,"multi":false,"advanced":false,"_id":"5e9613ce6365e91276471d54","id":"mask","datatype":"5a281aee2c214c9ba83ce620"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5e9613ce6365e912c3471d55","id":"prf","datatype":"5d9d18d8e30ae43bb0612715","datatype_tags_pass":null,"files":null}],"github_branch":"master","github":"davhunt/app-prfv2","name":"pRFLife with mrTools","user_id":"283","contributors":[{"name":"David Hunt","email":"davhunt@iu.edu","_id":"634a39ae62f3d3800f122b7c"}],"create_date":"2020-04-14T19:49:34.816Z","desc":null,"doi":"10.25663/brainlife.app.315","__v":5122,"_canedit":true},{"_id":"6115c829a5a04c2a80f9e7f7","projects":[],"admins":["16","283"],"tags":[],"removed":false,"stats":{"requested":420,"users":8,"success_rate":62.825278810408925,"gitinfo":{"desc":"Brainlife.io app for Noah Benson's neuropythy library, retinotopy from T1 anatomy","tags":[],"stats":{"stars":1},"contributors":[{"name":"Noah C. Benson","email":"nben@nyu.edu"},{"name":"David Hunt","email":"davhunt@indiana.edu"},{"name":"Ariel Rokem","email":"arokem@gmail.com"},{"name":"Gio Piantoni","email":"github@gpiantoni.com"},{"name":"Michael Waskom","email":null}]},"runtime_mean":889562.69,"runtime_std":691196.8751185539,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a420662f3d3800f12f2ec"},{"resource_id":"61005350b5554234facf0cec","name":"quartz @ IU","_id":"634a420662f3d3800f12f2ed"}],"examples":4,"groups":8},"config":{"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"},"template":{"id":"template","type":"enum","placeholder":"","advanced":true,"desc":"the template to use","default":"Benson14","_order":2,"pid":0.9264660542562742,"options":[{"desc":"Benson14","label":"Benson14","value":"Benson14"}]}},"inputs":[{"id":"freesurfer","datatype":"58cb22c8e13a50849b25882e","datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5cc4cd3f4ed9df00317f621e"}],"outputs":[{"id":"prf","datatype":"5d9d18d8e30ae43bb0612715","datatype_tags":["benson14_retinotopy"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5cc4cd3f4ed9df00317f621f"},{"id":"varea","desc":"Parcellation of visually-responsive cortex into 12 regions12 regions (V1, V2, V3, hV4, VO1, VO2, LO1, LO2, TO1, TO2, V3b, V3a)","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags":["benson14_retinotopy","varea"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5dae319c5d19160b532059e8"},{"id":"varea_surface","desc":"Parcellation of visually-responsive cortex into 12 regions12 regions (V1, V2, V3, hV4, VO1, VO2, LO1, LO2, TO1, TO2, V3b, V3a)","datatype":"5f78b377268f76598c29b27a","datatype_tags":["parcellation","varea","benson14_retinotopy"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"6115c829a5a04c8517f9e7fd"},{"id":"surfaces","datatype":"5f78b255268f764bdd29b254","datatype_tags":["parcellation","varea","benson14_retinotopy"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"6115c829a5a04c6710f9e7fe"},{"id":"parc_deprecated","desc":"Parcellation of visually-responsive cortex into 12 regions12 regions (V1, V2, V3, hV4, VO1, VO2, LO1, LO2, TO1, TO2, V3b, V3a)","datatype":"5c478b7bf9109beac4520be6","datatype_tags":["parcellation","varea","benson14_retinotopy"],"datatype_tags_pass":null,"output_on_root":false,"files":null,"archive":true,"_id":"5df128c52d1c25d48d92b5bc"}],"github_branch":"v1.1","github":"brainlife/app-benson14-retinotopy","name":"pRFs / Benson14-Retinotopy","user_id":"16","contributors":[{"name":"Noah C. Benson","email":"n@nben.net","_id":"634a420762f3d3800f12f2ee"},{"name":"David Hunt","email":"davhunt@iu.edu","_id":"634a420762f3d3800f12f2ef"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a420762f3d3800f12f2f0"},{"name":"Brad Caron","email":null,"_id":"634a420762f3d3800f12f2f1"},{"name":"Ariel Rokem","email":"arokem@gmail.com","_id":"634a420762f3d3800f12f2f2"},{"name":"Gio Piantoni","email":"github@gpiantoni.com","_id":"634a420762f3d3800f12f2f3"},{"name":"Michael Waskom","email":null,"_id":"634a420762f3d3800f12f2f4"}],"desc":"Brainlife.io app for Noah Benson's neuropythy library, retinotopy from T1 anatomy","__v":2076,"avatar":"https://raw.githubusercontent.com/davhunt/app-benson14-retinotopy/master/screen.png","create_date":"2021-08-13T01:17:29.539Z","doi":"10.25663/brainlife.app.559","_canedit":true},{"_id":"5cc4cd3f4ed9df00317f621d","stats":{"stars":1,"requested":4282,"users":37,"success_rate":89.39354838709677,"serviceinfo":{"_id":"5d729e1e78356a109788b217","counts":{"_id":"5e5c3df487cac70c8eab140a","failed":236,"finished":1075,"removed":1358,"requested":1514,"running":1340,"running_sync":0,"stop_requested":85},"success_rate":81.99847444698703,"users":7,"readme_status":"ok","runtime_mean":6119739.02,"runtime_std":32301530.45499196,"service":"davhunt/app-benson14-retinotopy","__v":0},"gitinfo":{"desc":"Brainlife.io app for Noah Benson's neuropythy library, retinotopy from T1 anatomy","tags":[],"stats":{"stars":1},"contributors":[{"name":"Noah C. Benson","email":"nben@nyu.edu"},{"name":"David Hunt","email":"davhunt@indiana.edu"},{"name":"Ariel Rokem","email":"arokem@gmail.com"},{"name":"Gio Piantoni","email":"github@gpiantoni.com"},{"name":"Michael Waskom","email":null}]},"runtime_mean":244857.85,"runtime_std":143995.18671687436,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a35da62f3d3800f11a71b"}],"examples":5,"groups":54},"projects":[],"admins":["16","283"],"tags":[],"removed":false,"config":{"freesurfer":{"type":"input","file_id":"output","input_id":"freesurfer"}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5cc4cd3f4ed9df00317f621e","id":"freesurfer","datatype":"58cb22c8e13a50849b25882e"}],"outputs":[{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5cc4cd3f4ed9df00317f621f","id":"prf","datatype":"5d9d18d8e30ae43bb0612715","datatype_tags_pass":null,"files":null},{"datatype_tags":["benson14_retinotopy"],"output_on_root":false,"archive":true,"_id":"5dae319c5d19160b532059e8","id":"varea","datatype":"5c1a7489f9109beac4a88a1f","datatype_tags_pass":null,"files":null,"desc":"Parcellation of visually-responsive cortex into 12 regions12 regions (V1, V2, V3, hV4, VO1, VO2, LO1, LO2, TO1, TO2, V3b, V3a)"},{"datatype_tags":[],"output_on_root":false,"archive":true,"_id":"5df128c52d1c25d48d92b5bc","id":"varea_surf","datatype":"5c478b7bf9109beac4520be6","datatype_tags_pass":null,"files":null}],"github_branch":"master","github":"davhunt/app-benson14-retinotopy","name":"pRFs / Benson14-Retinotopy - Deprecated","user_id":"283","contributors":[{"name":"Noah C. Benson","email":"n@nben.net","_id":"634a35db62f3d3800f11a71c"},{"name":"David Hunt","email":"davhunt@iu.edu","_id":"634a35db62f3d3800f11a71d"},{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a35db62f3d3800f11a71e"},{"name":"Brad Caron","email":null,"_id":"634a35db62f3d3800f11a71f"},{"name":"Ariel Rokem","email":"arokem@gmail.com","_id":"634a35db62f3d3800f11a720"},{"name":"Gio Piantoni","email":"github@gpiantoni.com","_id":"634a35db62f3d3800f11a721"},{"name":"Michael Waskom","email":null,"_id":"634a35db62f3d3800f11a722"}],"create_date":"2019-04-27T21:44:31.326Z","desc":"Brainlife.io app for Noah Benson's neuropythy library, retinotopy from T1 anatomy","doi":"10.25663/brainlife.app.187","__v":8153,"avatar":"https://raw.githubusercontent.com/davhunt/app-benson14-retinotopy/master/screen.png","deprecated_by":"6115c829a5a04c2a80f9e7f7","_canedit":true},{"_id":"5ef2c397c67a0d84a529667a","projects":[],"admins":["16","41","146","1"],"tags":[],"removed":false,"name":"pydeface","desc":"Brainlife wrapper for poldracklab/pydeface - MRI defacing App based on flirt and face template mask. https://github.com/poldracklab/pydeface ","github":"brainlife/app-pydeface","github_branch":"2.0-1","config":{"t1":{"type":"input","file_id":"t1","input_id":"t1"},"cost":{"id":"cost","type":"enum","placeholder":"","advanced":false,"desc":"flirt cost function to use","default":"mutualinfo","_order":2,"pid":0.8779285383330921,"options":[{"desc":"","label":"mutualinfo","value":"mutualinfo"},{"desc":"","label":"corratio","value":"corratio"},{"desc":"","label":"normcorr","value":"normcorr"},{"desc":"","label":"normmi","value":"normmi"},{"desc":"","label":"leastsq","value":"leastsq"},{"desc":"","label":"labeldiff","value":"labeldiff"},{"desc":"","label":"bbr","value":"bbr"}]}},"user_id":"1","outputs":[{"datatype_tags":["defaced"],"output_on_root":false,"archive":true,"_id":"59714d376c3b7e0029153f54","id":"output","datatype":"58c33bcee13a50849b25879a","files":null,"datatype_tags_pass":"t1","desc":"T1 anatomical image defaced"}],"inputs":[{"datatype_tags":["!defaced"],"optional":false,"multi":false,"advanced":false,"_id":"59714d376c3b7e0029153f55","id":"t1","datatype":"58c33bcee13a50849b25879a","desc":"T1 anatomical image to deface"}],"__v":4559,"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a3c3c62f3d3800f127cf1"}],"stats":{"requested":594,"users":12,"success_rate":66.84210526315789,"gitinfo":{"desc":"Runs freesurfer/mri_deface with talairach_mixed_with_skull.gca and face.gca","tags":["anatomy-preprocessing"],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"}]},"runtime_mean":611262.42,"runtime_std":228571.277946385,"resources":[],"examples":2,"groups":12},"create_date":"2020-06-24T03:08:07.337Z","doi":"10.25663/brainlife.app.388","_canedit":true},{"_id":"5cf9582f94cb4c02b711c797","stats":{"stars":0,"requested":95,"users":9,"success_rate":64.28571428571429,"serviceinfo":{"_id":"5d729e1e78356a109788b1e5","counts":{"_id":"5e5c3e0687cac72726ab141d","failed":22,"finished":49,"removed":50,"requested":74,"running":73,"running_sync":0,"stop_requested":2},"success_rate":69.01408450704226,"users":6,"readme_status":"ok","runtime_mean":3654761.5714285714,"runtime_std":4487192.076110282,"service":"brainlife/app-rsHRF","__v":0},"gitinfo":{"desc":"Hemodynamic Response Function Retrieval and Deconvolution (RS-HRF)","tags":[],"stats":{"stars":0},"contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu"},{"name":"Franco Pestilli","email":null}]},"runtime_mean":6322722.12962963,"runtime_std":12536752.285248613,"resources":[{"resource_id":"5943cd40055b490021abb7b6","name":"Carbonate @ IU","_id":"634a369262f3d3800f11cf56"}],"examples":0,"groups":10},"projects":[],"admins":["463","41","474","473","469","1","1781"],"tags":[],"removed":false,"config":{"bold":{"type":"input","file_id":"bold","input_id":"bold"},"mask":{"type":"input","file_id":"mask","input_id":"mask"},"estimation":{"id":"estimation","type":"enum","placeholder":"","desc":"estimation procedure ","default":"canon2dd","_order":2,"pid":0.8742933812026517,"options":[{"desc":"canonical shape with 2 derivatives","label":"canon2dd","value":"canon2dd"},{"desc":"smoothed Finite Impulse Response","label":"sFIR","value":"sFIR"},{"desc":"Finite Impulse Response","label":"FIR","value":"FIR"},{"desc":"Gamma Basis Set","label":"Gamma","value":"Gamma"},{"desc":"Fourier Basis set","label":"Fourier","value":"Fourier"},{"desc":"Fourier Basis with Hanning","label":"Hanning","value":"Hanning"}]},"tempmask":{"id":"tempmask","type":"string","placeholder":"","desc":"Enter the slice number that you like to scrub (skip). Enter string like \"1,2,4,56,555\"","default":"","_order":3,"pid":0.6395988625838631,"optional":true}},"inputs":[{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5cf9582f94cb4c02b711c799","id":"bold","datatype":"59b685a08e5d38b0b331ddc5"},{"datatype_tags":[],"optional":false,"multi":false,"advanced":false,"_id":"5cf9582f94cb4c02b711c798","id":"mask","datatype":"5a281aee2c214c9ba83ce620","desc":"brain mask (passes as --atlas)"}],"outputs":[{"datatype_tags":["rsHRF"],"output_on_root":false,"archive":true,"_id":"5cf9582f94cb4c02b711c79a","id":"results","datatype":"59c3eae633fc1cf9ead71679","datatype_tags_pass":null,"files":null}],"github_branch":"1.0.8","github":"brainlife/app-rsHRF","name":"rsHRF","user_id":"1","contributors":[{"name":"Soichi Hayashi","email":"hayashis@iu.edu","_id":"634a369262f3d3800f11cf57"},{"name":"Franco Pestilli","email":null,"_id":"634a369262f3d3800f11cf58"}],"create_date":"2019-06-06T18:15:11.483Z","desc":"Hemodynamic Response Function Retrieval and Deconvolution (RS-HRF)","doi":"10.25663/brainlife.app.208","__v":7849,"avatar":"https://www.nitrc.org/project/screenshot.php?thumbnail=true&group_id=1304&screenshot_id=1220","_canedit":true}]
